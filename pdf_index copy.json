[
  {
    "filename": "Papers/03_cells-and-links.pdf",
    "content": "1\nCells and Links\nCELLs and LINKs are fundamental elements. LINKs are bipartite causal\nrelationships connected over physical cables (backplanes, coax, fiber).\n1.1\nCells\nA CELL is not merely a general-purpose computer. It is a reactive, self-\ncontained participant in a global program. Each CELL holds local state,\nexecutes transactions, and engages in atomic communication with its\nneighbors. It participates in reversible protocols, encodes causal histo-\nries in state transitions, and makes decisions based on local informa-\ntion while remaining consistent with a global ordering.\nCELLs maintain a timebase, manage a local execution queue, and\nprocess both incoming transactions and local tasks. Their execution\nmodel is event-driven and transactional, but grounded in physical\nlinks—each CELL ’s “world” is bounded by the links it can reach.\nCrucially, CELLs are interchangeable.\nThere is no distinction be-\ntween a compute node, a storage node, or a network switch. Each\nCELL contains a portion of all three. The specialization comes from\nprogrammatic configuration and emergent behavior, not fixed hard-\nware roles.\n1.1.1\nFailure Modes\nCELLs fail in bounded ways. The execution environment guarantees\nthat failure is:\n• Local: A failing CELL does not compromise its neighbors.\n• Detectable: Liveness and responsiveness can be externally verified\nthrough link activity and expected transactions.\n• Reversible: As much as possible, computation and state changes\nat a CELL can be rolled back or isolated through transaction lineage\nand local journaling.\nopen atomic ethernet\n2\nFailures may be:\n• Crash-fail: power loss, watchdog-triggered resets, or thermal shut-\ndowns.\n• Byzantine: misbehavior due to bitflips, radiation events, or mali-\ncious actors.\nThese are constrained by cryptographic and causal\ntransaction tracking.\n• Soft: overloaded slots, or clock skew outside tolerances.\nThe system design assumes failure. What matters is how neighbor-\ning CELLs detect, isolate, and route around the failure using only local\nknowledge.\n1.2\nLinks\nA LINK is a bidirectional tunnel-element; an autonomous communica-\ntion entity between two CELLs. Think of LINKs as compute elements\nwith their own autonomous and independent failure domain. Physi-\ncally, the LINK comprises the cable and SerDes’ on both ends to form a\nself contained execution environment.\nLINKs are autonomous in that they maintain state: pending trans-\nactions, reversibility buffers, sequence tracking, and retry logic. They\nmediate causality between two CELLs and enforce atomic delivery guar-\nantees over physical media that may be noisy, lossy, or delayed.\nA healthy LINK behaves like a lock-free memory bus: it transmits\nevents, ensures ordering, and preserves invertibility for transactional\nsafety. But unlike a memory bus, it must contend with delay, noise,\nand the limits of the speed of light. Its job is to conceal those imper-\nfections behind a deterministic, reversible interface.\nLINKs are not passive – they can be reset, throttled, or even repro-\ngrammed in the field. They may expose telemetry, accept diagnostic\npings, or reconfigure modulation in response to environmental condi-\ntions.\n1.2.1\nLink Utilities\nPhysical LINKs Implement utilities that used to be in logical link do-\nmains above L2: in L3, L4, or L7; composed into an abstraction of\nlogical links. This is an illusion. If the pairing of Shannon information\nis thrown away at layer 2, it cannot be recovered in higher layers. This\nis addressed in more detail in the Key Issue section below.\nAn example1 LINK utility is The I Know That You Know That I Know\n1 Synchronization of timing domains in\ncomputers generally start from the pro-\ncessor clock on the motherboard, and\nfan out through the logic into the I/O\nsubsystems.\nIUI lives in the LINK be-\ntween two independent computers, and\nalthough it receives information from ei-\nther side, it is not synchronized with\neither side.\nThis independent asyn-\nchronous domain (already exploited in\nthe HFT Industry) – enables failure in-\ndependence and atomicity.\n(TIKTYKTIK) property; which enables us to address some of the most\ndifficult and pernicious problems in distributed systems today.\nopen atomic ethernet\n3\nAnother example LINK utility is Indivisible Unit of Information (IUI).\nUnlike replicated state machines (RSM’s) used throughout distributed\napplications today, LINKs are state machines: the two halves of which\nmaintain shared state through hidden packet exchanges. When a lo-\ncal agent or actor is ready, theIUI protocol transfers indivisible tokens\nacross the LINK to the other agent, atomically (all or nothing) 2.\n2 LINKs are exquisitely sensitive to packet\nloss.\nThis is intentional: we turn the\nFLP result upside down, and use “a single\nunannounced process death” to guaran-\ntee the atomic property forIUI.\nTIKTYKTIK and IUI properties are mathematically compositional.\nWhat’s necessary is an entanglement between state machines – lock-\ning them together silently in normal operation, and failing locally at\nthe first failure. The entanglement cannot be recovered if information\nfrom events can disappear. This is the only solution to the problem in\nthe latency–disconnection ambiguity [Ref: CAP Theorem Tradeoffs].\nTo put it in terms an engineer can internalize, a system that fails in-\nstantly, can heal immediately.\n1.2.2\nFailure Modes\nThe shared state property is strengthened by mechanisms to recover\nfrom each type of failure. The more types of failures, the more com-\nplex and intractable this becomes. LINKs are independent failure do-\nmains, with (effectively) one failure hazard: disconnection 3; which is\n3 In any physical system it is possible\nto drop packets, it will be much rarer\nbut it is still possible. LINKs can recover\nfrom individually dropped or corrupted\npackets, and shared state integrity can be\nmaintained through out the successive\nreversibility recovery – back to the equi-\nlibrium state.\nstraightforward to recover from.\n1.3\nInitial Discovery\nFigure 1.1: A Link yet to be discovered,\nor a flakey link that need to be repaired\nCELLs discover connections ∃xist on each of their ports. For connections\nthat once existed (which may have been remembered from previously\nbeing powered up), we will find it impossible to tell whether we are\nbeing woken up for the 1st time, or the Nth time*.\n*Sleeping Beauty paradox: Veritasium:\nThe Most Controversial Problem in Phi-\nlosophy\nAlice and Bob have no knowledge of each other prior to being pow-\nered up for the first time. They discover each other by sending and re-\nsponding to BEACONs on each of their 8 ports {n, ne, de, se, ds, sw, dw, nw}.\nBEACONs are questions: “is anyone there?” They assume neighbor CELLs\nhave SerDes’ that can send & receive @ 25Gb/s (defined by local clocks,\nin their frame of reference). Photon cavities (copper and fiber) are ex-\npected to be in a fixed frame of reference relative to the SELF CELL.\nMobile entities may need to adjust this expectation based on the range\nof doppler shifts expected by CELLs in motion, for example, in moving\nvehicles, cars, planes, and spacecraft.\nAlice sends BEACONs with an exponential backoff: every 1µs, 2µs,\n4µs, 8 µs, etc. The policy for a maximum interval is determined by the\nenvironment, e.g. within a datacenter, one might wish to send BEACONs\nopen atomic ethernet\n4\nevery second, whether you need to or not. This represents a balance\nbetween infrastructure liveness and needless energy dissipation.\nSingle Links are subject to partial or total failure.\nAlthough net-\nworks use the word ‘partition’, for example in the CAP Theorem?, this\nconcept is inappropriate except in the single LINK case, when there’s\nno communication with the other side; the causal universes** are now\n**Quantum Compatible Interpretation\nisolated from each other.\n1.4\nIt takes Two to Tango, and Three to Party\nBecause a single link between Alice and Bob can be causally dis-\nconnected by real-world, permanent or intermittent failures, an alter-\nnative: statistically–independent–failure–path is necessary, to recover\nfrom LINK Failures. This is the heart of the Æ ATOMICITY claim: A local\n(one hop LINK) TRIANGLE is the minimum necessary. See TRIANGLE\nClocks later in this specification.\nFigure 1.2: It takes three to party. Links\nneed an alternate path. This won’t work\nover a Switched (Clos) Network.\nFigure 1.3:\n2 x 2 =4 connected nodes\nwith 6 flakey LINKs. Any one of which\nmay be working in both directions: {11},\nonly one direction: {01} or {10}, or not-\nworking in both directions: {11}.\nFor\n4 nodes, there are\n(n(n−1)\n2\n= 6.\nWith\n4 reliability configurations on each LINK\n{00, 01, 10, 11} This gives us ONE correct\n(all links working correctly) and 46 −1 =\n4095 possible failure modes.\n1.5\nFault Detection Model\nBenefits include (i) Shorter packets and\nmore effective use of bandwidth, (ii)\nmore complete coverage of possible fail-\nure modes. (iii) Guarantees at least the\nfirst slice is perfect (matches what the\ntransmitter knows they sent).\nAE-Links present two major differences to the conventional FEC think-\ning in today’s Ethernet, which exploits the physics from 25Gb/s to\n1.6Tb and beyond:\nPerfect Information Transfer (PIF) Æ-Links use Back-to-Back (B2B) Shan-\nnon Links, where the receiver returns the first 8-byte slice of each\n64-Byte packet to the transmitter. This “here is what I heard you\nsay\" ( Perfect Information Transfer (PIF)?\nEpistricted Registers (EPI) Borrowing from the Spekkens’ toy model for\nquantum entanglement, we narrow down the possible entangled\nstates to a vastly smaller set of possibilities, using the model de-\nscribed in Quantum Ethernet?.\n1.6\nFailure Model\nConsider a network of n nodes connected by undirected Ethernet links.\nEach link can be in one of four independent reliability states, where\nΣ = {00, 01, 10, 11},\n11 means the link works in both directions, 10 or 01 means it works in\nonly one direction, and 00 means it is broken in both directions.\n1.7\nLink count\nBecause every node may attach to at most eight neighbours (an octava-\nlent mesh), the number of physical links is\nL(n) = min\n\b(n\n2), 4n\n\t =\n\n\n\n(n\n2),\nn ≤9,\n4n,\nn ≥9.\nopen atomic ethernet\n5\n1.8\nReliability configurations\nEach link chooses a state from Σ independently, so the total number of\nconfigurations is 4 L(n). Exactly one of these is fully healthy (all links\nin state 11), hence\nFailureModes(n) = 4 L(n) −1.\n1.8.1\nEnumerated results for 2 ≤n ≤20\nn\nL(n)\nFailure modes 4 L −1\n2\n1\n3\n3\n3\n63\n4\n6\n4 095\n5\n10\n1 048 575\n6\n15\n1.074 × 109\n7\n21\n4.398 × 1012\n8\n28\n7.206 × 1016\nTable 1.1: Failure-mode counts for an oc-\ntavalent mesh with n nodes.\n1.9\nSet Reconciliation of Shannon Slots\nThe first claim is that a finite and enumerable number of ‘slots’ exist\non both sides of the LINK. In conventional Ethernet, once these slots\nare exhausted (with for example, a timeout and retry, the XPU CELLS\n(SmartNICs) on both sides of the LINK must evict (erase) the infor-\nmation on one side and then the other. This ‘loss of Koherence’ is the\ncentral problem of Distributed Systems. From an information theoretic\n(Back to Back Shannon channel) perspective, this precipitates a ‘smash\nand restart (SAR) of the Shannon Information – the loss of ‘pairing’\nof information. This is described in more detail in the specification of\nback-to-back Shannon Pairs.\nTimeouts and Retries are the root of all evil. Once a Timeout Storm\noccurs, in a switched network, the distributed systems in the Host pro-\ncessor are all broken. Unless RELIABILITY (maintenance of Shannon\nLink Pairing), the ‘global’ illusion of event ordering in distributed sys-\ntems will be lost, and corruption will occur. This is why queue-pairs\nwork in Infiniband/RDMA. This is why information pairing is essen-\ntial, in Tandem’s Process Pairs, and RDMA’s Queue pairs.\nThe whole point of this specification is to engineer a solution, where\nShannon-pairing is never lost, but if it is, a TRIANGLE healing occurs\nlocally, without the need to depend on a switched or router to discover\nand ‘reconverge’ their routing tables, to re-establish the point to point\nconnections over a different paths in the network.\nThe main mechanism to do this is to make the Æthernet Link main-\ntain Koherence, and when loss occurs, a 3rd party (The Triangle rela-\ntionship) can recover with local information only. This makes XPU/S-\nmartNICs, where the recovery algorithms (healing the tree) occur lo-\ncally, instead of waiting for the switched or routed packets (in a sepa-\nrate switched network.\nThe original Ethernet was unreliable. This was a mistake. Infini-\nband already proved this, and succeeded both in the trust system\narchicitcts have in the far greater. The unique contributions of this\nopen atomic ethernet\n6\nspecification is to go (far) beyond Infiniband’s discovery, and recog-\nnize the fundamental simplifications and benefits that Infiniband (and\nToken Ring, Fibrechannel, and Sonet), in creating ‘Race-Free’ proto-\ncols, where distributed systems can guarantee, not just the ‘ordering\nof events’, but the guarantee of recovery of transactional loss in when\nfailures occur in the middle of, say, a 2 Phase Commit.\nÆthernet (Atomic Ethernet) guarantees that Shannon Pairing is never\nlost, and if a link breaks, that the Coordinator (Charlie, Carol, Chief)\ncan recover with TRIANGLE Relationships, far faster than any proto-\ncol stack in the host processor, or in the RMDA message relationships,\nbut then add, on top of this a true ‘atomic’ relationship between CELLS\n(nodes) in a distributed system.\nThe original Ethernet [ref] was designed around a notion of slots.\nThese were ‘time slots’ on an imaginary timeline that each node on\nthe Ethernet Cable, could manage in a half-Duplex way.\nThe new\nnotion is to replace this with circulating tokens, where each slice is\nindependently acknowledged, providing a guarantee of delivery to\nthe NEXT hop in the network.\nThis is achieved with 1PC (one phase commit), where each Ethernet\nPacket (eight slices) are fully acknowledged in each link. The general-\nization of this is to explicitly manage Shannon slots (data structures on\neach side of the link) to maintain Koherence, even when the link fails\n(in one direction, the other direction, or in both directions at once).\nThis can be done (as in Fibrechannel) by arranging the ‘interaction\nprotocol’ to guarantee the pairing of events, and not resort to Timeout\nand Retry (TAR), which causes cascade failures in networks, both large\nand small.\nThis is achieved with the Link Protocol employing the Alternating\nBit protocol, and adding the Bill Lynch ABP reconciliation, with two or\nmore bits instead of the individual 1 bit of alternation, which required\na round trip to guarantee Shannon Slot Pairing.\n1.10\nFAQ\nQ1 (Alan) What problem are you addressing in the scouting writeup?\nIf it’s discovering routes, it’s not clear to me that ant or bees or even\nboth together do full discovery of the network. In what way are they\nbetter than the flooding algorithm I used?\nA1 This is how to achieve ‘Scale-Independence’ We eliminate the\nneed for every node to do a ‘full discovery’ of the network, which is\nwhat a flooding algorithm would do. ANTs and BEEs explicitly do not\nopen atomic ethernet\n7\ndo “Global\" routing. This is an extra way to limit the size of the secure\nenclave, and not have it able to connect to the outside world.\n"
  },
  {
    "filename": "Papers/01_principles-of-operation.pdf",
    "content": "1\nPrinciples of Operation\nRcv\nSnd\nSnd\nRcv\nBob\nAlice\nGreen: Forward Evolution\nBlue: Reverse Evolution\nForward Progress (+1)\nReverse Progress (-1)\nTernary Logic Link\nEquilibrium = 0\nFigure 1.1: Two CELLs and a LINK with\nConserved Quantities (CQ) in dynamic\nequilibrium (Alternating Bit Protocol),\nepistricted with Ternary Logic\nThis chapter defines the foundational principles that govern op-\neration over LINKs in Atomic Ethernet (Æthernet). While traditional\nprotocols prioritize throughput by maximizing raw bit rates, Æth-\nernet focuses on reversible, causally deterministic, and information-\nconserving communication. Rather than treating bandwidth as a fun-\ngible resource, Æthernet embraces a model rooted in equilibrium, to-\nken transfer, and fixed-sized transactional units.\nThis framing en-\nables high reliability and high throughput data movement even in\nfailure-prone environments, where every deviation from equilibrium\nis accounted for and correctable. We describe the architectural conse-\nquences of these choices, highlighting symmetry, liveness, and feedback-\ninformed interaction.\n1.1\nSymmetric Reversibility\nAt the heart of Atomic Ethernet lies a symmetric, reversible link proto-\ncol, governed by deterministic state machines operating on both ends\nof a point-to-point connection. Together, these machines co-create a\nunified, bidirectional construct called a LINK. LINKs are not merely a\npassive channel, but an active agent with its own failure domain, causal\nboundaries, and defined error recovery semantics.\nA LINK is thus a joint stateful system. Both peers (e.g., Alice and\nBob) implement identical state machines that evolve synchronously\nvia the exchange of fixed-size, causally significant tokens. These to-\nkens encode both data and flow-control intent, and their transitions\nare mirrored on each end. There is no concept of master/slave — ei-\nther side may assume the role of INITIATOR or RESPONDER, depending\non who possesses the token.\nopen atomic ethernet\n2\nDefinitions\nsymmetric: each side executes the same logic, defined by the same tran-\nsition rules, enabling fully mirrored behavior.\nNo global sequencing is\nrequired beyond token ownership.\nreversible: for every operation on the link, there exists a logically defined\ninverse that restores the prior state.\nTogether, a symmetric, reversible protocol enables new guarantees\non the network:\n• Partial transactions can be aborted cleanly, returning to an equilib-\nrium where no partial, unconfirmed state is leaked on either side.\n• Errors (e.g., bit flips, packet loss) can be rolled back without cor-\nrupting state.\n• All token transfers are atomic: they either complete fully or leave\nthe system unchanged.\nThese properties allow LINKs to resume normal operation even in\nthe presence of transient failures. No global reset is needed; instead,\nlocal error recovery and rebalancing maintain the equilibrium between\npeers.\nThis symmetry and reversibility simplify correctness proofs, enable\nformal verification of protocol behavior, and provide a foundation for\nconstructing reliable distributed systems from fundamentally unreli-\nable components.\n1.2\nInteractions, not Bandwidth\nTraditional networks treat bandwidth as a fungible resource; Like a\npipe to be filled as much and as fast as possible. Success is measured in\nutilization, and failure in dropped packets. In contrast, Æthernet rede-\nfines communication as a series of causal interactions between peers,\nwhere each exchange has semantic weight and is governed by LINK\nstate machines.\nIn this model, throughput is an emergent property of sustained,\nreversible token exchanges — not burst transmission. Initiators flow\nframes toward responders without waiting, and responders flow re-\nsponses back in kind. The rate of progress is governed not by the raw\nlink speed, but by the rate of acknowledged interaction. This change\nin framing brings several practical consequences:\n• Stable Congestion Behavior: Systems built on causal flow control\nnaturally avoid head-of-line blocking and buffer overflows, espe-\ncially under sustained high load.\n• Implicit Clock Recovery: Each interaction provides timing and syn-\nchronization cues, enabling robust clock alignment without separate\ntiming channels.\nopen atomic ethernet\n3\n• Minimized Latency Variance:\nBecause there are no speculative\ntransmissions, queuing and jitter are dramatically reduced, even\nunder full load.\n• Atomic Forward Progress: A transfer either completes causally or\nis fully rolled back, preserving global consistency without the need\nfor speculative multi-path packet spraying.\nWire Length and Occupation Time:\nBecause each transmission occupies\nthe physical wire for longer than it takes for a signal to traverse it, ac-\nknowledgments from the receiver can begin arriving before the sender\ncompletes transmission of the next wire slot.\n1.3\nFixed size Slots, Perfect Information Feedback\nÆthernet operates exclusively on fixed-size records, or slots, ensuring\nevery transaction carries a known, bounded amount of entropy. This\nconstraint, far from limiting expressiveness, unlocks a powerful class\nof deterministic behaviors aligned with the structure of digital hard-\nware and the limits of information theory. Each transaction transfers\nexactly one slot: a fixed-length, self-contained unit of data and control.\nBecause slots are of known and equal size, flow control is dramat-\nically simplified.\nThis ensures that the sender knows exactly how\nmuch information is in flight, and the receiver can verify complete-\nness without ambiguity. There is no need to infer transfer boundaries,\nnegotiate variable lengths, or guess at incomplete frames. Every in-\nteraction is atomic and unambiguous. The result is a link state that\nevolves in predictable, stepwise increments.\nDefinitions\n• Shannon Slots, the logical atomic units of information maintained in\nthe protocol state machine (typically within FPGA registers).\n• Wire Slots, the physical representation of a slot as it is serialized across\nthe wire.\nThe transition from Shannon Slot to Wire Slot is a fixed-length en-\ncoding operation — deterministic, invertible, and clock-aligned. Tim-\ning closure in the FPGA limits the frequency at which these slots can\nbe emitted or consumed. However, because the slot size is constant\nand interaction is feedback-governed, the system avoids speculative\noverrun and maintains perfect pacing even at high utilization.\n1.4\nRace Conditions and Conserved Quantities\nFor short-range ≤1m links, intrinsic\n(internal ASIC or FPGA) rates of the\nSerDes dominate, making cable propa-\ngation ‘time’ and RTT irrelevant because\nthe occupation length of the packet\nexceeds the length of the wire.\nWith appropriate buffering and pipeline\nmanagement,\nmaximum\nEthernet\nthroughput\nbecomes\nachievable,\nstrongly favoring short-range intercon-\nnects for high-performance and ultra-\nlow-latency Ethernet.\nwhile providing\nreliable (ACK/NAK) transfers ?\nAtomic Ethernet treats Shannon slots as conserved quantities. Each\nslot represents an indivisible unit of knowledge. Slots are never silently\nopen atomic ethernet\n4\ndropped, corrupted, or left in undefined states.\nThis conservation\nprinciple draws a key distinction from best-effort packet-switched net-\nworks, where data loss is expected and recovery is probabilistic. In\nÆthernet, every Shannon slot is not merely a container of bits, but a\nsemantic object with causal responsibility.\nAtomic Ethernet is fully reversible; on any error the receiver can\nreverse the transfer of a token returning ownership, and return re-\nsponsibility for correct operation to the initiator (e.g. Hardware Error,\nProtocol violation, Software Error or resource exhaustion error).\n1.5\nFrom API to Bits-on-the-wire\nÆthernet introduces a fundamentally new substrate for reliable com-\nmunication.\nEvery transmission is atomic, reversible, and causally\nconsistent. To application developers, this creates the illusion of an\nunbreakable network, where transactions either succeed completely or\nfail without side effects.\nYet to enable adoption, Æthernet must integrate seamlessly with\nexisting infrastructure.\nThe compatibility boundary is the IP layer.\nAbove this layer, applications continue to operate as before. Below\nit, Æthernet provides a drop-in replacement for traditional Ethernet,\nunobservable by legacy systems, but dramatically more reliable in be-\nhavior.\nHowever, the true potential of Æthernet lies beyond emulation. Its\natomic transaction model enables a new class of guarantees – deter-\nministic delivery, fault-local reversibility, and programmable transport\nsemantics – that cannot be expressed in the traditional IP or TCP ab-\nstractions. To expose these capabilities to applications, a new vertically\nintegrated stack is needed.\nThis stack must:\n• Extend from the API boundary (e.g., sockets, RPC, shared memory\ntransport) down to the bits on the wire.\n• Preserve atomicity and reversibility guarantees across all abstrac-\ntion layers.\n• Offer language-level semantics (e.g., async/await, futures, or trans-\nactions) that map directly to causal protocol operations.\nIn essence, Æthernet is not just a new physical protocol. It is a new\nfoundation for building distributed systems, one in which software\nand hardware speak the same language of atomic, bidirectional flow.\nNew transaction guarantees can be offered to applications, but re-\nquires a entirely new networking stack from API to bits on the wire\nopen atomic ethernet\n5\nthat propagates the same guarantees of atomicity and reversibility into\nthe languages that application developers write code with.\n"
  },
  {
    "filename": "STANDALONE/Transactions-A-B-C.pdf",
    "content": "Rethinking Atomicity: Toward Reversible Transac-\ntions\nSahas Munamala, Paul Borrill, et.al.\nThis document challenges the Forward-In-Time-Only (FITO) assump-\ntions behind conventional transactions in distributed systems. It argues\nthat atomicity, as currently conceived, is a flawed abstraction and\nproposes a framework for reversible subtransactions as a more robust\nalternative.\nTransactions and the Illusion of Atomicity\n“Transactions begin and they end.”\n—Charlie Johnson, TMF Product News\nThis simple phrase conceals deep design hazards. Transactions\nappear to begin with a trigger and end with a commit, but in dis-\ntributed systems, these bookends obscure severe internal inconsisten-\ncies.\nAt issue are the mechanisms we use to track and guarantee these\ntransactional intervals: timestamps, logs, filesystems, and even\nour concepts of causality. Each introduces cracks in the facade of\natomicity.\nThe Forward-In-Time-Only Fallacy\nFITO: Forward-In-Time-Only thinking\nassumes linear causality.\nMost distributed systems today adopt what we call Forward-In-Time-\nOnly (FITO) thinking. That is:\n1. Open a transaction with a timestamp.\n2. Apply a sequence of operations.\n3. Close the transaction with a commit or rollback.\nBut this approach breaks down under scrutiny.\nThree FITO Hazards\n1. Timestamps are not unique. Even on a single machine with GHz\nprocessors and nanosecond clocks, timestamp collisions occur.\nOS-level clock management does not guarantee uniqueness.\n2. Timestamps are single points of failure. Any drift, packet loss, or\nsync error in NTP/PTP introduces false ordering assumptions.\n3. Simultaneity is an illusion. Relativity tells us simultaneity is\nobserver-dependent. Building global event orderings on times-\ntamps is unsafe.\nrethinking atomicity: toward reversible transactions\n2\nThe False Comfort of Atomicity\nWe often say: \"all or nothing.\" But our stack is built on sand:\n• The database relies on the log.\n• The log relies on the filesystem.\n• The filesystem relies on fsync.\n• fsync relies on storage hardware.\nEach of these layers fails to guarantee true atomicity. When one fails,\nthe recovery model becomes: Smash and Restart.\nThe Myth of Reliable Commit\nProtocols like Two-Phase Commit (2PC) attempt to enforce dis-\ntributed agreement. But they depend on:\n• Log synchronization across nodes\n• Network reliability\n• Time-based coordination\nWhen any assumption breaks, so does safety. Eventually, we re-\nplace consistency with survivability—and correctness with heuristics.\nToward Reversible Thinking\nSuppose we reject FITO. Suppose we view the transaction as re-\nversible.\nIf the forward protocol is correct, we can construct a reverse protocol.\nThis leads to reversible subtransactions: bounded operations that\ncan be undone without global rollback.\nCounterfactual Transactions\n• A transaction can end, then begin again.\n• Logs become braids, not linear sequences.\n• Atomicity becomes a constraint, not an assumption.\nInspired by Marletto’s counterfactual physics, this model embraces\npartial reversibility as an engineering practice.\nrethinking atomicity: toward reversible transactions\n3\nClosing the Interval—Reopened\nSimultaneity is not fundamental.\nCausality is.\n\"Closing the interval\" with a commit only makes sense if we know\nthe state is stable. In reality, it’s a guess based on layers of non-\natomic operations.\nBy rethinking transactions through reversible logic, we can:\n• Define precise causal dependencies\n• Undo partial effects\n• Recover without restart\nReversibility isn’t science fiction. It is what rollback always wanted\nto be.\nConclusion\nThe abstraction of atomicity has outlived its usefulness as a guaran-\ntee. In modern distributed systems, FITO thinking and timestamp\ndependency introduce hazards we can no longer ignore.\nIt is time to engineer reversible protocols, built on causal seman-\ntics—not illusions of simultaneity. Let us design transactions that\ndon’t just commit or roll back, but that can unwind.\nrethinking atomicity: toward reversible transactions\n4\nGoing deeper\nTransactions and Atomicity\nAccording to Charlie Johnson*, “transactions begin and they end”.\n[*TMF Product News]\nThey begin when one computer receives a trigger to start a new\ntransaction (the internal interval is opened). It’s easy to label the\nopening of this interval, with a bunch of bits provided by a times-\ntamp service, such as TSC, or as a leaf at the end of a branch on a\ntree synchronized by NTP or PTP.\nThere are three things wrong with this picture, if the developer is\noblivious to the hazards:\n1. Timestamps cannot be used alone as a unique identifier. Even on\na single computer. Multiple cores running on a 3-5 GHz processor\nwill find the timestamps colliding some fraction of the time, even\nif their operating system manages the clock to a nanosecond,\ninternal accuracy. It will be much worse if the operating system\nmanages only a microsecond internal accuracy.\n2. Timestamps represent a single point failure in any process. If\nthe clock synchronization has failed, even for a moment, it will\ngive false readings. Such failures occur every time and network\npetitions. For example, every time a switch, router on NIC drops\na packet. Because NTP and PTP, broadcast the tree, there is no\ninherent relationship to the notions of causality needed by an\napplication to ensure the events are applied in the order necessary\nto satisfy constraints needed by the distributed algorithm.\n3. Timestamps propagate the false illusion that we can create a\nsimultaneity plane against which we can order events. We learned\nover 100 years ago that physical simultaneity cannot exist, even\nin principle. Depending on this illusion for the safety of our\ndistributed algorithms will therefore be problematic in practice.\nOpening this “interval” and labelling it with a timestamp is only\nthe beginning of the trouble we will experience as we try to make\ntransactions reliable.\n“When we begin a transaction, update the database, and then\nend that transaction, we have to make sure it sticks, even if there is a\nsystem failure”.\nThis ceremonial event is “complete” only when all copies of the\nlog are (a) internally consistent, (b) flushed to disk atomically (c)\nwritten redundantly to other systems, both local and remote. An\nexample of the kinds of hazards involved are described in [Protocol\nAware Recovery]. This is Forward-In-Time-Only (FITO) thinking.\nrethinking atomicity: toward reversible transactions\n5\nThe problem comes when we try to “close the interval”. We put\nthe transaction commit at the end when we have cleaned up the mess\nof all the things that could go wrong.\nEvery system and even different sub-processes running on the\nsame computer will timestamps all over the place. Timestamps are an\nunreliable ordering construct.\n“A Database can have a nearly infinite number of states”. There\nis no such thing as Atomicity, when we think only in a forward\ndirection of time. There is no such thing as Reliabilty when our\nonly method of recovery is “smash and restart”. As it is for many\ndistributed systems, such as containers supervised by Kubernetes.\nConsistency can be loosely defined as “Log Serialization”, because\nthe real database is in the log. If there are multiple nodes, those logs\nhave to “interlock” with multi-phase interaction protocols, such as\ntwo phase commit.\nHere is where the fun begins: Storage systems are not “stable” be-\ncause they are not atomic. File systems (on which databases depend)\nare not atomic. fsync, on which file systems depend, is not atomic.\nThis (both mechanical and solid state) on which fsync depends is not\natomic. We discover a whole world of hurt when we make believe we\ncan make anything atomic.\nReliance on a “all-or-nothing” atomicity property is fraught with\npain and anguish. I started the SNIA in 1997 to address problems\nlike this, but the incumbents hijacked the SNIA for their marketing\ncampaigns to carry on selling what they already had, instead of\nsolving these fundamental issues that persist today, in even greater\nvarieties and at all scales.\nBut even if we solve the atomic storage problem, say on each\nlocal machine so it doesn’t have to go over the network) we would\nstill end up deeper in hell when we try to achieve atomicity over the\nnetwork.\nTransactions don’t just “begin and end”. Once we allow the Coun-\nterfactual [Chiara Marletto], transactions will “end and then begin”:\nby eliminating the FITO thinking in our notions of transactions over\nthe network, we can expose the cracks in our thinking about reliabil-\nity and let the sunlight in. 1\nBy putting our notions of “all-or-nothing-atomicity” under the\nmicroscope, we will find a whole universe of things crawling around\ndown there, that require ever more fine- grain notions of subtrans-\nactions. And as we apply our ingenuity as engineers, we will find\nthe closer we look, the more we will see sequences of things we wish\nwere atomic.\nBut atomicity by itself is a flawed concept. It forces us into a box\nrethinking atomicity: toward reversible transactions\n6\nof thinking where the only solution is to throw our hands up in the\nair and declaring atomicity to be “good enough”, and then fatefully\nsuffering the consequences of “smash and restart” when atomicity\nhas failed us.\nThere is an alternative. If our distributed algorithms can be spec-\nified with a correct “order” to safely modify the distributed data\nstructures in the ‘forward’ direction then we can also specify the\nprotocol in reverse to “undo” an operation where atomicity has\nfailed.\nThen, instead of “Smash and Restart” (SAR) when we run into an\nirreconcilable hazard deep in a subtransactions we can “successively\nreverse” the subtransactions to return the distributed data structure\nto a safe “quiescent” state. After all Jim Gray’s “transaction rollback”\nis already a crude form of reversibility.\nAssuming that we can sharpen the Guillotine on our timestamped\nbased notions of atomicity, is a fools errand. Much like the notions\nof metastability in our semiconductor circuits where the uncertainty\nwindow goes to infinity. This kind of thinking is purely classical\n(pre-quantum) and no longer serves us in our design of electronics or\nsoftware.\nReversible Subtransactions are far easier than we might think.\nOnce we have the algorithm working in the (forward) direction,\nwe simply apply the logic and mathematical formalisms to do the\nreverse for us on our data structures.\nIt’s common among architects to believe that PTP overcomes\nnetwork weather and system load issues with hardware support\nin the NIC’s; but PTP is just as susceptible to link/node failures,\nmisconfiguration, and unexplained configuration drift.\nClosing the Interval. When we talk about causality, we can knock\nthe dominos down from one end of the set or the other. Reversibility\nis a way of thinking.\n"
  },
  {
    "filename": "STANDALONE/Graph-Algorithms.pdf",
    "content": "Scouting at Layer 2\nPaul Borrill\nMay 19, 2025\nThis document proposes a Layer 2 Ethernet routing protocol called\nScouting at Layer 2, inspired by recent advances in edge coloring algo-\nrithms from graph theory. It aims to enable deterministic, loop-free\npath discovery and forwarding solely at the MAC layer, bypassing the\nneed for Layer 3 mechanisms such as IP routing.\nIntroduction\nEthernet is traditionally a broadcast-based Layer 2 protocol, relying\non IP-based Layer 3 protocols for routing. However, modern data\ncenters and specialized networks demand low-latency, deterministic,\nand topology-aware communication mechanisms without the full\noverhead of the IP stack. To this end, we introduce Scouting at Layer 2,\na distributed routing protocol that operates entirely within the Data\nLink Layer.\nThe design is motivated by recent work on edge coloring of graphs\nin near-linear time li2024vizing, which provides a scalable and\ncollision-free scheme for link differentiation.\nDesign Goals\nlabel=– Layer 2 Only: Operates exclusively using MAC addresses.\nlabel=– No Broadcast Storms: Avoids STP/RSTP flooding and en-\nables deterministic paths.\nlabel=– Loop-Free Forwarding: Guarantees no cycles using path\nidentifiers.\nlabel=– Dynamic Topology Support: Accommodates changes in\nnetwork structure.\nlabel=– Low Computational Overhead: Efficient enough to run in\nSmartNICs or ASICs.\nGraph-Theoretic Inspiration\nIn the protocol, each Ethernet node and its direct connections are\nmodeled as a graph G = (V, E), where:\n• Vertices V are MAC-layer devices (bridges, switches, NICs).\nscouting at layer 2\n2\n• Edges E represent Ethernet links.\n• Each edge is assigned a color, i.e., a unique local forwarding tag,\nsuch that no two edges incident to the same vertex share the same\ncolor.\nUsing the result of Li et al. li2024vizing, we can perform this\ncoloring with at most ∆+ 1 colors in O(m log ∆) time, where m = |E|\nand ∆is the maximum degree.\nProtocol Description\nInitialization Phase\nEach node performs neighbor discovery and assigns temporary col-\nors (tags) to its outgoing links, ensuring local uniqueness. Nodes\nthen gossip their tag assignments to neighbors until a global stable\ncoloring is reached.\nPath Discovery Phase\nTo reach a given MAC address, a node constructs a sequence of tags\n(path identifiers) describing a color-consistent path through the net-\nwork. These path sequences are constructed in a Dijkstra-like traver-\nsal with color-awareness to avoid collisions.\nFrame Forwarding\nFrames are modified to include a Path Identifier Sequence (PIS) field,\nwhich encodes the list of edge colors (tags) to follow. As the frame\ntraverses the network:\n1. The switch reads the next tag in the PIS.\n2. It matches this tag to an outbound port.\n3. It decrements the PIS and forwards the frame.\nThis process continues until the PIS is empty, and the destination\nMAC is reached.\nscouting at layer 2\n3\nFrame Format\nField\nLength (Bytes)\nNotes\nDestination MAC\n6\nStandard MAC\nSource MAC\n6\nStandard MAC\nType/PIS Identifier\n2\nEthertype or custom\nPath Identifier Sequence\nVariable\nEncoded tag list\nPayload\nVariable\nAs usual\nFCS\n4\nStandard CRC\nAdvantages\n• No need for Layer 3 routing tables.\n• Supports programmable switching (e.g., in SmartNICs or eBPF).\n• Scales to large networks with sparse connectivity.\n• Deterministic pathing avoids congestion and loops.\nChallenges\n• Path sequence length is limited by MTU.\n• Requires coordination to avoid inconsistent tag assignment.\n• Topology changes require propagation of new path info.\nApplications\n• HPC clusters with low-latency mesh topologies.\n• Edge compute zones with fixed link-layer infrastructure.\n• Datacenter overlays where IP is inefficient or unavailable.\nConclusion\nBy leveraging edge-coloring strategies for deterministic path discov-\nery and forwarding, Scouting at Layer 2 offers a novel approach to\nMAC-layer routing. Its foundation in recent algorithmic advances\nsuch as those by Li et al. li2024vizing provides a robust and efficient\nscheme, particularly suited to programmable and high-performance\nenvironments.\n"
  },
  {
    "filename": "STANDALONE/HFT-main.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\nÆthernet: Ultra Low Latency (ULL)\nSahasMunamala, JohnLockwood, AlanKarp, PaulBorrill, et.al.\nJune 7, 2025\nIntroduction: Ultra-Low Latency Protocols\nREQUIREMENTS PROPOSAL\nTHIS IS NOT A SPECIFICATION\nDRAFT 0.5 FOR REVIEW\nModern applications such as AI/ML Training and Inference, High-\nFrequency Trading (HFT) and Distributed Systems Foundations, all\ndemand Ultra-Low Latency (ULL), deterministic behavior, and extreme\nefficiency. Traditional Ethernet framing introduces overheads ill-suited\nfor point-to-point deterministic environments. This proposal examines\nthe feasibility of a radically minimalist Ethernet-like protocol tailored\nfor applications that need ultra-low latency, such as HFT and AI/ML\nInference: devoid of headers, preambles, gaps, or MAC source/desti-\nnation addresses—because both ends already know everything necessary\nto communicate.\nParsimony in Protocol Design\nPerfection is Achieved Not When\nThere Is Nothing More to Add,\nBut When There Is Nothing Left to\nTake Away\nAntoine de Saint-Exupéry\nNOTE TO READER\nTHIS FORMAT IS DESIGNED\nFOR YOU TO ADD COMMENTS\nAND QUESTIONS IN THE\nRIGHT MARGIN, ETHER IN\nYOUR FAVORITE PDF VIEWER,\nOR IN THE LATEX DOCUMENT.\nPerfect for iPad + Pencil\nA primary goal of Æthernet is to re-examine the original design\nchoices made by Ethernet five decades ago, and ask if these choices\nremain valid today within racks and chiplet modules. While RISC\nprocessors revolutionized computing, the same reduced complexity\nmind-set has not before been applied to make networking fundamen-\ntally simpler, formally verifiable, and suitable for transactions.\nWe adopt the same design philosophy and principles of the origi-\nnal Ethernet. Only after we have completed a first-principles analysis\n(the charter of the Open Atomic Ethernet OAE Project), only then\ndo we ask what is the best way to make it compatible with existing\nhardware and systems.\nFixed (preemptable) 64-byte Frame\nReconciling information slots on both sides of a Back to Back (B2B)\nShannon channel requires making them fixed size. We eliminate all\nvariable length streams, and their expensive conversion across Links,\nand the PCIe (or other) buses connecting IPUs to host processors.\nIn deterministic topologies, every wire is a\ncontract—and every slot is a commitment.\nReliability becomes a property of structure,\nnot exception handling.\næthernet: ultra low latency (ull)\n2\nFixed - 64B Pre-emptible Frame\nExtensions to 256B, 1024B and 4096B (Cache Lines and Pages)\nRcv\nSnd\nSnd\nRcv\nBob\nAlice\nGreen: Forward Evolution\nBlue: Reverse Evolution\nForward Progress (+1)\nReverse Progress (-1)\nTernary Logic Link\nEquilibrium = 0\nFigure 1: Two CELLs and a LINK with\nConserved Quantities (CQ) in dynamic\nequilibrium (Alternating Bit Protocol),\nepistricted with Ternary Logic\nPrinciples of Operation\nSymmetric Reversibility\nThis protocol is symmetric and reversible. Asymmetry occurs when\none party becomes the INITIATOR, and the other party becomes the\nRESPONDER. When the responder is complete and closes the transac-\ntion with the sender, the LINK returns to the equilibrium state. There\nis no need for counting protocols. Accounting of Shannon infor-\nmation is how far we deviate from equilibrium, and what precisely is\nneeded to bring it back.\nAtomicity and Causal Determinism\nTo begin and remain open, this protocol\nis based on the earliest known prior art\n[Bartlett, Lynch & Metcalfe]\nCausal operators follow a mathematical framework of invertibility\nand an equilibrium state (§). Equilibrium is maintained in the LINK\nthrough continually circulating tokens in the PHI layer, to maintain\nliveness, keeping LINKs in a state of preparedness for transactions.\nThis mathematical symmetry is re-\nflected throughout the architecture\nRISC-like radical minimalist design.\nShift from promiscuous Bandwidth \"rate\" to causal Interaction \"rate\"\nInitiators Flow Frames (without stopping), to responders. Responders\nflow responses (without stopping) back to initiators.\nRace Conditions and Conserved Quantities\nFor short-range ≤1m links, intrin-\nsic (internal ASIC or FPGA) rates of\nthe SerDes dominate, making cable\npropagation ‘time’ and RTT irrelevant\nbecause the occupation length of the\npacket exceeds the length of the wire.\nWith appropriate buffering and pipeline\nmanagement, maximum Ethernet\nthroughput becomes achievable,\nstrongly favoring short-range intercon-\nnects for high-performance and ultra-\nlow-latency Ethernet. while providing\nreliable (ACK/NAK) transfers\nAlice may initiate new transactions when she (a) owns the token,\nand (b) has that token in her possession in the alternating message\nprotocol. The other party (Bob) becomes the responder, as if the\ntoken were borrowed. All protocol interactions must be paired (c.f.\nqueue pairs, process pairs, or rpc pairs in other protocols).\nAtomic Ethernet is fully reversible; on any error the receiver can\nreverse the transfer of a token returning ownership, and return re-\nsponsibility for correct operation to the initiator (e.g. Hardware Error,\nProtocol violation, Software Error or resource exhaustion error).\nFixed size Slots, Perfect Information Feedback\nBy returning the first (context) slice (with minor rewriting rules), we\ncan Achieve Perfect Information Transfer\n“In Information Theory Terms, those\nchannels are modeled as channels\nwith perfect information feedback”.\n[Abramson, 1973]\nWe distinguish between Shannon Slots (in the FPGA registers),\nand bits on the wire slots. The rate (FPGA clock) is limited by the\nability to \"close timing\" within the chosen FPGA Clock.\næthernet: ultra low latency (ull)\n3\n64-Byte Record (Frame) Format\nSlice 1 (8 Bytes)\nSlice 2 (16 Bytes)\nSlice 3 (24 Bytes)\nSlice 4 (32 Bytes)\nSlice 5 (40 Bytes)\nSlice 6 (48 Bytes)\nSlice 7 (56 Bytes)\nSlice 8 (64 Bytes)\nFigure 2: 64-Byte Record. 8 × 8 byte\nslices, pre-emptible by responders\nFrame size of 64 Bytes. Follows a log2 increase in slot size. The first\nslot (Context) corresponds to the arrival of the first slice off the bits\non the wire. Remaining slots follows a Hadamard multiple (1, 2, 4, or\nany multiple of 4 slices).\nCONTEXT Processing : From the Inside Out\nSlice 1 [8 Bytes LINK Context] Protocol <RTL>\nSlice 2 [8 Bytes CELL Context] Context] <FSA> <Linear Algebra>\nSlices 3-4 [16 Bytes TILE Context] <State Machines><Petri-Nets>\nSlices 5-8 [32-Bytes ] ULL App PAYLOAD> <Address Bridging>\nProtocol hierarchy: Four levels of Reversibility:\n• Context Slice Reversibility\n• Shannon Information (Operand Zone A in Serdes)\n• Spekkens Knowledge (Operand Zone B FPGAs, 2-3 clock cycles in)\n• Metcalfe Semantics (Operand Zone C in FPGA, 5-8 clock cycles in)\nExtended Addressing Modes for Legacy Compatibility\nTo guarantee that no information is lost1 the slots must be fixed size.\n1 All distributed systems need trans-\nactions. Even applications that run\non a single (multicore) machine need\nthem. If it runs in the cloud, it needs a\ntransactional infrastructure underneath.\nPCIe and CXL attempt to transfer 64 bytes minimum. This makes the\nlatency (occupation time on the wire) too long for ULL applications.\nInstead, we propose a minimum of the first slice (Protocol – Context).\nOptional second slice (Reliability/Recoverability). The rest is payload\nfor local Ultra-Low-Latency (ULL) Transactions.\nContext (Slice 1 [0..7] 8 Octets)\nOperand Zone A  (Slice 2 [8..15] Octets)\n Operand Zone B (Slices 3-4 [16..31 Octets)\nOperand Zone C (Slices 5-8 [32-64 Octets])\n64 Bits\nArrival order of slices in SerDes\nFigure 3: Slice Arrival order (Temporal\nIntimacy Depth)\nMode 1 - N2N Neighbor Self-Addressing\nMode 2 - Ethernet MAC Addressing\nMode 3 - 32-Bit IP Addressing\nMode 4 - 128-Bit IP Addressing (Container virtual addresses?)\nMode 5 - 10-Bit Cluster Addressing 12-bit VLAN Addressing.\nModes 6..8 - Reserved\nMode 7 - Reserved\nMode 8 - Reserved\næthernet: ultra low latency (ull)\n4\nFLOW TRANSACTIONS (Systolic Heartbeats)\nOperator (4B)\nPayload  (4B)\n64-bits (8B)\n1 Slice\nFigure 4: 1 Slice Flow Subtransaction\nULL protocol designers play around with 32 bits as the minimum\nunit of transactional transfer, but experiments demonstrate the dif-\nficulty of making this consistently reliable; the general consensus is\nthat modern SerDes’ work best with ≥64 bit (8 Byte) slices/flits, and\nwith 66/64 bit encoding. Ethernet has a minimum frame size of 64\nbytes (although only 42 bytes were available for the payload).\n2 Slices\nPayload  (12B)\nOperator (4B)\nOperand\nFigure 5: 2 slice Flow SubTransaction\nWe therefore choose a fixed 64 Byte frame for the Shannon Slots,\nbut make them pre-emptable so that even the minimum size frame\ndoes not need to occupy space on the wire, increase latency, or FPGA\nprocessing steps, when the receiver has something more important it\nwishes to send (e.g. local status messages sent in the background can\nbe pre-empted, giving way to a two phase commit (2PC) transaction).\n4 Slices\nPayload  (28B)\nOperator (4B)\nOperand\nFigure 6: 4 4 slice Flow SubTransaction\nwith 28B payload (operand)\nSome transactional systems are sensitive to making transactions\nreliable, but don’t mind missing events, such as highly perishable\nmarket data. We might call these one-phase commit (1PC) transac-\ntions. These can be made to flow at maximum line rate, even though\neach individual slice is being acknowledged. This is particularly\nimportant in HFT for example.\nWe therefore provide the following “flow\" transactions in the\nencoding scheme:\nPayload  (60B)\nOperator (4B)\n8 Slices\nOperand\nFigure 7: 1 × 8 slice Flow Transaction\nwith 60B payload\nBack Propagation Encodings\nThis encoding scheme (with slice acknowledgements), guarantees\ncommon knowledge in a flow of transactions, and their backpropaga-\ntion packed into a single frame. Examples shown here include:\n1. One Flow Transaction with 4B payload in a single slice (additional\nencoding in TX beats:\n01 I intend to send only one slice.\n10 I intend to send 2 slices, count down from there in replies\n11 I intend to send 4 slices, count down from there in replies\nOperator (4B)\nPayload  (4B)\nOperator (4B)\nPayload  (4B)\nOperator (4B)\nPayload  (4B)\nOperator (4B)\nPayload  (4B)\nOperator (4B)\nPayload  (4B)\nOperator (4B)\nPayload  (4B)\nOperator (4B)\nPayload  (4B)\nOperator (4B)\nPayload  (4B)\n8 Slices\n64-bits (8B)\nFigure 8: 8 independent Flow Transac-\ntions in a one frame\n2. One Two Slice Flow Transaction context with 12B of Payload\n3. One Four Slice Flow Transaction context with 28B of Payload\n4. Eight one-slice Flow Transactions context with 60B of Payload\næthernet: ultra low latency (ull)\n5\nMixing and Matching Flow Transactions\nOperator (4B)\nPayload \nPayload  (28B)\nOperator (4B)\nPayload  (28B)\nOperator (4B)\nOperand\nOperand\n8 Slices\n64-bits (8 Octets)\nFigure 9: 2 × 4 slice Flow Transactions\nFlow Transactions provide four micro operand sizes: 4, 12, 28 or 60\nBytes. Use-cases include:\n1. Transaction guarantees through invertible linear algebra.\n2. High Frequency Trading, where < 3ns response times are neces-\nsary with minimum payloads [Cite Lockwood]\n3. AI/ML Data Structures: encode linear algebra functions into the\nAtomic Ethernet Slice/frame protocol, such as the dat structures\ndescribed in the DeepSeek papers, e.g. log(sign, exponent, mantissa)\n[cite Deepseek]\nPayload  (12B)\nOperator (4B)\nOperand\nPayload  (12B)\nOperator (4B)\nPayload  (12B)\nOperator (4B)\nPayload  (12B)\nOperator (4B)\nOperand\nOperand\nOperand\n8 Slices\n64-bits (8 Octets)\nFigure 10: 4 × 2 slice Flow Transactions\nTwo 4 slice Flow Transactions\nYou can also mix them in the same frame, but remember, they can\nonly be used for One-Phase-Commit (1PC) in a single stream of\ntransactions. This is because 1PC requires only one \"round trip\",\nwhereas 2PC requires two round trips (although this scheme can be\nmade to work for 2PC, and perhaps 4PC, but they have not yet been\ntested).\nFour 2 slice Flow Transactions\nEight one-slice Flow Transactions\nMixture of different Flow Transactions\nPayload  (28B)\nOperator (4B)\nOperand\nPayload  (12B)\nOperator (4B)\nOperator (4B)\nPayload  (4B)\nOperator (4B)\nPayload  (4B)\nOperand\n8 Slices\n64-bits (8 Octets)\nFigure 11: One 8 slice Flow Sub Trans-\naction with 60B payload\nLink Efficiency\nTable 1: Transaction efficiency by\noperator and operand size.\nFlows Operator Operand Efficiency\n1\n4\n4\n50%\n1\n4\n12\n75%\n1\n4\n28\n87.5%\n1\n4\n60\n93.75%\n2\n4\n4\n100%\n2\n4\n12\n150%\n2\n4\n28\n175%\n2\n4\n60\n187.5%\n4\n4\n4\n200%\n4\n4\n12\n300%\n4\n4\n28\n350%\n4\n4\n60\n375%\n8\n4\n4\n400%\n8\n4\n12\n600%\n8\n4\n28\n700%\n8\n4\n60\n750%\nCPU Fast Path\nThe industry has already moved to kernel bypass, using the Linux\nkernel to set up authentication.\nThe next step is to bypass the PCIe/UCIe Bus entirelyand connect\ninto the CPU Registers2. [Ibanez et. al., “The Case for a Network Fast\n2\nPath to the CPU].\næthernet: ultra low latency (ull)\n6\nVirtual Channels\nThe protocol provides Endpoints for Virtual Channels. The IPV6 For-\nmat has been proposed, but this would give the false impression that\nthe outside world (Internet) and inside world (Transaction Fabrix™).\nThe LINK, not the CELLs (Node) are the transaction resource.\næthernet: ultra low latency (ull)\n7\nRISC Protocol Design: OPCODE (Information)\nOPCODE\nJAM\nPROTOCOL\nBEATS\nSLICE\nFigure 12: One Byte Provides the entry\npoint for an Entire family of Protocols\nCONTEXT Frame format: First Slice, First Byte: OPCODE\n8SLICE\n11 -- TX Sender Init\n11 -- RX SACK 1 (8B)\n10 -- RX SACK 2 (16B)\n01 -- RX SACK 3 (32B)\n00 -- RX SACK 4 (64B)\n(SLICE, BEATS, PROTOCOL, JAM) provides state encodings for an\nultra-low-latency, hardware-friendly, and atomic transaction-friendly\nÆthernet protocol.\nSupports transactional operations, structured acknowledgments,\nand reversible flow control (causal backpropagation). Instead of\npositive-only credits, the first hop receiver provides the equivalent of\nnegative credits, to indicate it is returning previously sent frames.\n4SLICE\n10 -- TX Sender Init\n10 -- RX SACK 3 (32B)\n01 -- RX SACK 1 (8B)\n00 -- RX SACK 2 (16B)\n2SLICE\n01 -- TX Sender Init\n01 -- RX SACK 1 (8B)\n00 -- RX SACK 2 (16B)\n1SLICE\n00 -- TX Sender Init\n00 -- RX SACK 1 (8B)\nnSLICE\nOn cables shorter than the occupation\ntime on the wire, slice acknowledges\nare sent before the receiver sees the\nwhole frame – exploiting full concur-\nrency on the transmit/receive channels.\nSet by the Sender to[00] – indicating a new context.\nModified by the receiver Closing the loop: [11]→[10]→[01]→[00]\nEncodes how many slices of the sender’s 64-byte Frame has been\nreceived so far. A 2-bit field with reversed temporal direction to\nencode the acknowledgment depth in a power of 2 number of slices.\nThis might represent the trailing edge of a window in a reversible or\npartially committed state machine. The naming “SACK” suggests slot\nor slice acknowledgments, as fine-grained positions in the interaction.\nBEATS\nBEATS\n00 -- TX 1 FRAME (64B)\n01 -- TX 4 FRAMES (256B)\n10 -- TX 16 FRAMES (1024B)\n11 -- TX 64 FRAMES (4096B)\n00 -- RACK 1 FRAME (64B)\n01 -- RACK 4 FRAMES (256B)\n10 -- RACK 16 FRAMES (1024B)\n11 -- RACK 64 FRAMES (4096B)\nEncodes burst sizes TX (forwardproaga-\ntion) and RX (backpropagation) code to\nframe groupings, enabling optimization\nof bandwidth and latency trade-offs.\nDefines a beat-structured flow control mechanism. Sender declares\nthe number of frames it plans to send advance. The receiver responds\nwith a corresponding \"slot acknowledgment\". Aimed at reliable,\nordered delivery without the need for heavyweight TCP.\nPROTOCOL\nPROTOCOL\n000 -- Initialization\n001 -- Liveness\n010 -- State Machines\n011 -- RESERVED\n100 -- RESERVED\n101 -- RESERVED\n110 -- RESERVED\n111 -- ESCAPE\nThis field defines the high-level intent of the frame or transaction,\nby the sender (causal initiator). The 3-bit code is always in the first\n(context) slice of the Frame. Three of the eight possibilities are de-\nfined in this specification. The remaining ones are reserved for higher\nlevel protocols in this standard. Escape will always be available to\nescape to legacy protocols. This compact opcode space (3 bits) is sim-\nilar to what RISC architectures do. This simplifies logic at the NIC or\nSmartNIC level and allows for deterministic dispatch.\nJAM\nABORT/CANCEL\nPRE-EMPT/JAM\nThe use of “JAM” evokes classic Eth-\nernet collision handling, but here it’s\nmodernized for transactional cancella-\ntion or rollback.\nSet by TX to [0]. Set by RX to [0] to accept, and [1] to pre-empt, for\nerror, or to (cancel/rollback the transaction).\næthernet: ultra low latency (ull)\n8\nRISC Protocol Design: LIVENESS (Knowledge)\nProtocol\nLiveness\nState Machine\nTransition\nFirst Slice: CONTEXT (Packet Mission). All\nbits are green (owned and written by Alice)\nBipartite Link\nThere are exactly two parties on the ÆLINK. We could call them alice\nand bob. We prefer to call them self and not self to preserve symme-\ntry. From Alice’s perspective, she knows her own identify, but she\ndoes not know the identity of the party she is communicating with\n(yet). We aim to achieve mathematical precision in our specifications.\nThis will be important when we wish to formally verify the scouting,\nrouting, and cluster membership protocols. It will be critical also in\nformally verifying confinement properties of the trees above.\nThe encoding supports Intanglement (hidden circulating events in-\nternal to the link) and Extanglement (Atomic Token Passing through\nthe link (Newtons cradle). These protocols obey the mathematics of\nmutual information, and provides some of the properties of quantum\nentanglement, such as superposition, conservation of information,\nand no-cloning. We use these properties to provide our protocols\nwith a clear notion of simultaneity (through the synchronization of\nmutual information), and guarantee atomicity for transaction proto-\ncols through conserved quantities which in-turn guarantees exactly\nonce semantics (EOS).\nConventional L2 & L3 networks rely on redundancy, repetition\nand rerouting, in multipartite (1:N) relationships. Which was neces-\nsary when information is disseminated (transmitted blindly hoping\nthe receiver catches it). When information can also be synchronized,\nby a Tx/Rx—T/Rx loop on a bipartite Ethernet link, we can em-\nploy Pseudo Entanglement: A form of temporal intimacy, where\nbits shared in a circulating frame can exploit the same mathematics,\n(but not the full quantum properties) of Entanglement. This insight\nallows us to engineer a clear notion of simultaneity, and exploit a\nclassical version of the no-cloning theorem to achieve the holy grail in\ndistributed systems and database isolation: exactly once semantics.\nLink Engine\nAlternating Causality (AC) is the name we give to the initialization,\nmaintenance and tear down of Common Knowledge (CK) in the\nLink. Experience with modern SerDes designs leads us to an 8 byte\næthernet: ultra low latency (ull)\n9\nslice architecture for a “minimum irreducible” CK protocol. Symme-\ntry demands that we use half (4-bytes) for alice (what I know about\nme) and the other 4-bytes for bob (what I know about you). Three\npacket exchanges get us from initialization (both sides know nothing\nabout each other) to the “I know that you know that I know” (IKT\nYKT IKT) equilibrium state for basic liveness.\nIt takes a while to gain an intuition\nfor this issue of causality, based on the\nphysics. For now, please accept that this\nis way of doing things is essential and\nenables a rich set of transaction types\nto be built on top, all with immunity to\nlink hazards.\nWe don’t use classical (increment only) clocks, counters, or timers\nin the link. Instead, we use balanced ternary arithmetic [1] The digits\nof a balanced ternary numeral are coefficients of powers of 3, but\ninstead of coming from the set 0, 1, 2, the digits are -1, 0 and +1.\nThey are balanced because they are arranged symmetrically about\nzero. We use this symmetry to manage the direction of causality\n(is alice the initiator of causal flow sending tokens to bob, or the\nreceiver in causal flow receiving tokens from bob?). This becomes\nimportant as we go up the protocol stack and construct reversible\nsubtransactions.\nWe extend the simple ternary arithmetic with plus and minus\nzero. {-1,-0,+0,+1} to define equilibrium. This enables the protocol to\ndifferentiate between the posibits and negabits [2], with an ancilla\ncontrol over the intended direction of the next operation (positive or\nnegative causality). This is used to control the direction of the state\nmachine when recovering from errors.\nIntanglement is enabled by reserving 4 bits in the frame for CK (2\nbits for Alice, 2 Bits for Bob). One message will let Bob know about\nAlice. A second message lets Alice know that Bob knows, the third\nmessage lets Bob know that Alice knows that Bob Knows, consis-\ntent with both Moses and Halpern version of CK, and the Spekkens\nKnowledge Balance Principle (KBP). Time, inside the link moves for-\nward when packets arrive. Time moves backwards when packets\ndepart. It doesn’t matter how many times a packet bounces around,\ntime goes forward only when it is received by one end of the link and\nit stays (is absorbed). Information is then turned into Knowledge.\nIn a similar way to two phase locking, Link CK can be extended\nfrom 2 Ternary bits (Trits) to any number. Since we are using 2 binary\nbits to encode one Trit, we posit that the set of 2-message exchanges\nto synchronize them is 1, 2, 4 and any multiple of 4. This observation\ndrives the encoding for the State Machine Engine, Described below.\nOur Protocol is based on Reversible Computing.\næthernet: ultra low latency (ull)\n10\nProtocol\nLiveness\nState Machine\nTransition\nFigure 13: First Slice: CONTEXT. Least\nsignificant 32 bits of transmitted packet.\nSlice Engine\nThe core of the Æ protocol is the Slice Engine. The first slice (or pre-\nframe slice) determines the packet mission, and carries the alternat-\ning causality for the Link State Machine (LSM).\nEach 64-bit slice represents an atomic delivery of bits on the wire\nfrom the SerDes. Typically 2 slices will be sent back to back and the\nSlice Engine must be prepared to receive both, although the receiver\nmay decide to pre-empt the frame in its immediate response to the\nfirst slice if it wishes to immediately begin a real data or transaction\noperation. The second slice will be on its way, and its Error Detection\nByte must be evaluated before forwarding on other ports (with the\nexception of the port it was received on, which is the entanglement\nmechanism).\nLIVENESS (Knowledge)\nALICE\nBOB\nFigure 14: One Byte Provides\nKnowledge\nAlice Token\n8-bits\nBob Token\n4-bits\n4-bits\nAlice \nToken\nBob \nToken\n2-bits\n2-bits\nFigure 15: First Rewriting Rule. Alice\nOwns and possesses Context Slice\nThe first slice completely defines the rest of the frame. There are\n4 fields: PROTOCOL, LIVENESS, STATE, and TRANSITION. This is\n“reflected” from the upper half to the lower half by the receiver, so\nthat only the lower 32 bits are modified, and the upper 32 bits remain\nunmodified.\nThe PROTOCOL Byte defines the “mission” of the packet. What each\nside of the link needs the other side to know about the current frame.\nLIVENESS defines the Temporal Intimacy of the link — whether events\non both sides of the link are directly connected or not.\nSTATE Defines which state machine is currently in use. Can be\nused as a sanity check in conjunction with Protocol. Transition De-\nfines which state in the state machine we are in, and which direction\nwe are going (forward or reverse).\nGeneral Principles\nLinks are constantly interacting, at the slice level, instead broad-\ncasting entire frames (or sets of frames) imposing on the other side\nand hoping they catch the bits. This provides opportunities for er-\nror detection and correction that would otherwise require ECC and\nFEC. The theory behind this is described in detail in the document\n“Shannon-Interaction-Machine”.\nThe first 4 slices are dedicated to Theseus (scouting protocols).\nThe payload (slices 4-7) contain the Theseus Opcode and parameters\n— instructions to the scout, including what to do if it encounters an\nexception (a software or hardware hazard).\nWhen the protocol type is Ariadne (groundplane/trees) the last 4\nslices (payload) contains tree-building instructions, such as the CellID\næthernet: ultra low latency (ull)\n11\nof the originator, and the CellID of the Deputy (one hop away from\nroot). This becomes a complete specification for dissemination of the\ntree without unnecessarily revealing secrets which need to be kept\nlocal (confined).\nAnother protocol type is Icarus (legacy connections to the outside\nworld). This represents a more heavyweight protocol which provides\na formally verified TPI (Transaction Processing Interface), which\nprovides significant guarantees, but with costs.\nerror detection/correction philosophy\n12\nGeneral Frame Format\nB1\nB2\nB3\nB4\nB5\nB6\nB7\nB8\nS1\nProtocol\nLiveness\nState Machine\nTransition\nProtocol\nLiveness\nState Machine\nTransition\nS2\nOperand 1 (2nd Slice)\nS3\nOperand 2 (3rd/4th Slice)\nS4\nS5\nOperand 3  (5th through 8th Slice)\nS6\nS7\nS8\nThis protocol is symmetric. We describe all operations from the\nperspective of ALICE, with responses from BOB.\nError Detection and Correction\nError Detection/Correction philosophy\nNo EDC or FEC Needed\nEach side of the link maintains two EPI (epistricted) registers : the\nSee Quantum Ethernet\nlast slice sent out, and the last slice received. The sender “owns” the\nlower 32 bits, and preserves the upper 32 bits. When slice 1 is re-\nceived, the upper 32 bits are swapped with the lower 32 bits. This\npreserves the symmetry of the protocol, and clearly delineates the\ncausal initiator register field ownership in addition to causal owner-\nship.\nThis provides the first level of error detection: the Initiator has Per-\nfect Information Feedback (PIF) and sees. exactly what the receiver\nsees, and compare it to what was sent, And if they don’t agree, de-\nclare an error and proceed with mitigations to get the link back in\nsync again.\nEpistricted registers\nImagine two vectors [abcd] one for Alice and one for Bob. A 4 x 4\nmatrix has 16 slots, which has 216 = 65, 535 possible states. However,\nerror detection/correction philosophy\n13\naccording t o the Spekkens Toy model applied to FPGA Registers,\nthere are only 12 ’disjoint’ (6 for Alice and a complimentary 6 for\nBob). Instead of trying to build a EDD/EDC code, we check only the\ndisjoint states by combining them into one register and sending them\nback and forth in the context frame.\ntopology\nA Section\nA Subsection\nAnother Section\nThe transmitted first (context) slice is reflected by the receiver back\nto the transmitter – this Perfect Information Feedback [Ref] means\nthat the context byte does not need additional error detection codes\nsuch as Checksums, CRC or FEC. This is especially true with flow\ntransactions.\nHowever, the rest of the payload is under the complete control of\nthe application, and the Application can append (within the available\nblocks) any coding scheme it wishes to ensure that the data arrives\nintact and untampered with. This will often mean that the senders\nand receivers will have pre-arranged cryptographic keys which al-\nlow them to manage the entropy and cryptographic strength of the\nauthentication.\nOVERVIEW\nProtocol Overview\nTRANSACTION FABRIC: A separate compute realm, sandwiched\nbetween the CXL bus and Ethernet, to support database semantics.\nWe eliminate CAP Theorem tradeoffs, by providing the illusion of\nan unbreakable network: detecting, isolating and healing failures\nfar faster than protocol or application stacks using traditional\ntimeouts and retries.\nTHESEUS: Ethernet-based scouting protocols explore local envi-\nronments to discover and bring back knowledge of resources,\nconstraints, and topologies in local (Chiplet) environments. THE-\nSEUS silently monitors local connectivity, raising alerts when links\nbecome flakey or server software hiccups.\nARIADNE: Ethernet based routing protocols dynamically construct\nerror detection/correction philosophy\n14\nand tear down communication graphs for consensus, load bal-\nancing and failover in global (rack-scale) environments. Enables:\nobservability on demand, fault isolation and distributed debug-\nging.\nICARUS: Connects the secure internal world of the Transaction\nFabrix with the hostile external world of legacy systems and net-\nworks; using compositional (zero knowledge) techniques: formally\nverified APIs, comprehensively tested implementations.\nLABYRINTH: A simulator driven toolset for Chiplet based micro-\ndatadatacenters. Based on algorithms whose assumptions about\ncausality go beyond simplistic notions of time. We empower\ndistributed system developers with formally verified rules and\nFPGAs to execute Reversible Subtransactions ‘invisibly’ and ‘indi-\nvisibly’ in the Transaction Fabrix.\nThe specifications for each of these components are described\nbelow.\nTIKTYKTIK Description from Alan\nerror detection/correction philosophy\n15\nTIKTYKTIK Details\nNOTE TO READER: FORMAT\nDESIGNED FOR COMMENTS &\nQUESTIONS IN RIGHT MARGIN,\nWITH AN iPAD/PENCIL, IN\nYOUR FAVORITE PDF VIEWER,\nOR IN THE LATEX DOCUMENT\nTIKTYKTIK is like the alternating-bit and stop-and-wait protocols\nin that receipt of a packet over a link is acknowledged over that link\nwith a “signal” packet. In that sense, these three protocols implement\ncredit based flow control, which simplifies buffer management and\nmakes it possible to not have to drop packets when there is a lot of\ntraffic.\nTIKTYKTIK adds a second round trip, which provides partial\ncommon knowledge helpful for recovery from link failures. This doc-\nument walks through TIKTYKTIK showing how that common knowl-\nedge is used. First look at the various stages of common knowledge\nas the protocol runs without failure when Alice sends a packet to\nBob.\n1. Alice sends the packet to Bob\n• Alice doesn’t know if Bob received the packet\n• Bob does not know the packet exists\n2. Bob receives the packet\n• Bob knows that Alice doesn’t know that Bob received the packet\n3. Bob sends a signal to Alice\n• Bob doesn’t know if Alice knows that Bob received the packet\n4. Alice receives the signal\n• Alice knows that Bob received the packet\n• Alice knows that Bob doesn’t know that Alice knows that Bob\nreceived the packet\n5. Alice sends the signal\n• Alice doesn’t know if Bob knows that Alice knows that Bob\nreceived the packet.\n6. Bob receives the signal\n• Bob knows that Alice knows that Bob received the packet.\n• Bob doesn’t know if Alice knows that Bob knows that Alice\nknows that Bob received the packet.\n• Bob can forward the packet\n7. Alice receives the signal\n• Alice knows that Bob knows that Alice knows that Bob received\nthe packet.\nerror detection/correction philosophy\n16\n• Alice can delete her copy of the packet.\nThis common knowledge is not needed if links never fail. Alice\ncould delete the packet as soon as she sent it, and Bob could forward\nit as soon as he received it. That’s what current systems do and why\nit’s so hard to recover from a link failure.\nA data packet can serve as a signal.3 Links can fail in a number\n3 A data packet can serve as a signal.\nof ways. If they physically break or are unplugged, the PHY detects\nthe lost of electrical signal and informs the higher layers. Links can\nalso fail silently, such as when the NIC misbehaves. They can also fail\nin one direction but not the other. Silent failures can be detected in\nthese protocols because a signal will never be received in either di-\nrection. In that sense, there is a level of common knowledge on a link\nfailure. In what follows, I’ll describe what happens when Alice wants\nto send a packet to Bob, but the link fails at various steps of the pro-\ntocol. The link is no longer used once one of these failures occurs.\n(The link can be used later after re-initializing the connection.)\n• 1 Alice has a packet to send when link fails\n– Alice\n* Knows Bob doesn’t have the packet\n* Knows Alice is responsible for it\n– Bob\n* Doesn’t know the packet exists\n• 2 Alice sends the packet to Bob then link fails\n– Alice\n* Doesn’t know if Bob got the packet\n* Knows that Bob knows Alice is responsible\n– Bob\n* Doesn’t know that the packet exists\n• 3 Bob receives the packet then link fails\n– Bob\n* Knows that Alice knows that Alice is responsible\n– Alice\n* Alice doesn’t know if Alice or Bob is responsible\n• 4 Bob sends signal then link fails\n– Bob\n* Doesn’t know if Alice got the signal\nerror detection/correction philosophy\n17\n* Doesn’t know if Bob or Alice is responsible\n– Alice\n* Alice doesn’t know if Alice or Bob is responsible\n• 5 Alice receives the signal then link fails\n– Alice\n* Knows that Bob is responsible\n* Knows that Bob doesn’t know he is responsible\n– Bob\n* Doesn’t know if Alice got the signal\n* Doesn’t know if Alice knows that Bob is responsible\n• 6 Alice sends signal then link fails\n– Alice\n* Knows that Bob is responsible\n* Doesn’t know if Bob knows he is responsible\n– Bob\n* Doesn’t know if he’s responsible for the packet\n• 7 Bob receives the signal then link fails\n– Bob\n* Knows that Alice knows that Bob is responsible\n– Alice\n* Doesn’t know if Bob knows that Bob is responsible\n• 8 Bob sends signal then link fails\n– Bob\n* Knows that he is responsible\n* Doesn’t know if Alice knows he is responsible\n– Alice\n* Knows that Bob is responsible\n* Doesn’t know if Bob knows that Bob is responsible\n• 9 Alice receives signal\n– Alice\n* Knows that Bob knows that he is responsible\nAt this point, Alice knows that Bob knows that Bob is responsible,\nand Bob knows that Alice knows that Bob is responsible.\nThe items in red indicate where incomplete common knowledge\nneeds to be resolved over the new path between Alice and Bob.\nerror detection/correction philosophy\n18\nFeedback from ChatGPT\nThe analysis you provided explores how \"common knowledge\" oper-\nates within the TIKTYKTIK protocol, especially in the context of link\nfailure recovery. The progression of common knowledge is explained\nthrough several stages, starting with Alice sending a packet to Bob\nand progressing through various acknowledgment signals and link\nfailures.\nKey observations:\n1. Common Knowledge Phases: The stages you outlined show how\nknowledge evolves between Alice and Bob as they interact, es-\npecially when there’s uncertainty about packet receipt and ac-\nknowledgment. These stages are useful for understanding how\ncommunication protocols can handle and resolve ambiguities.\n2. Link Failures: You go into detail about different link failure sce-\nnarios, from Alice sending the packet before failure to Bob ac-\nknowledging receipt of the packet after a failure. Each failure step\nindicates the differing levels of knowledge held by Alice and Bob.\nThese steps, especially when the link fails, highlight the challenges\nof network fault tolerance, and the importance of \"common knowl-\nedge\" for recovering from these failures.\n3. Protocol Behavior with Failure: The distinction between knowl-\nedge of responsibility and knowledge of receipt is well captured.\nThe incomplete common knowledge as the link fails suggests that\nTIKTYKTIK, by adding a second round-trip acknowledgment,\nresolves uncertainties that could otherwise hinder recovery.\nSuggested Refinements:\nClarity: Consider rephrasing the stages of knowledge with more\nemphasis on the protocol mechanics and timing of messages. It\ncould be helpful to lay out the flow of the protocol in a diagram or\na clearer timeline to illustrate the evolution of knowledge.\nLink Failures and Recovery: While the failure scenarios are well out-\nlined, you could further enhance the analysis by providing exam-\nples of real-world failure cases and how TIKTYKTIK compares to\nother protocols in handling these failures. For example, you could\ncontrast how TCP handles packet loss versus how TIKTYKTIK’s\nmulti-step acknowledgment approach helps resolve knowledge\ngaps.\nerror detection/correction philosophy\n19\nMathematical Notation: If possible, you could introduce formal mathe-\nmatical notations to express the knowledge states. This would help\nreaders better grasp the protocol’s behavior in a more structured\nform.\n"
  },
  {
    "filename": "STANDALONE/heritage.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\næthernet: ultra low latency (ull)\n1\nLegacy Compatibility(Heritage)\nFigure 1: Herritage Compatibility at the\nIP Layer. Give all applications at least\nanother 10 years of life\nCompatibility with conventional Ethernet takes place at layer 3. Ev-\nerything above is 100% compatible with innovations at layer 1 and\n2.\nSecure Enclave\nFigure 2: Vertical Mesh\n"
  },
  {
    "filename": "STANDALONE/LLC.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) -- All Rights Reserved\nLLC and How It Differs from Other Ethernet Proto-\ncols\nPaul Borrill\nApril 28, 2025\nQuestion\nTell me about LLC, and how it might differ from other Ethernet\nProtocols.\nWhere LLC Sits in the Stack\n+-----------------------------+\n<- Network layer (IP, CLNP, ...)\n|\nNetwork Layer\n|\n+-------------+---------------+\n|\nLLC\n|\nMAC\n|\n<- IEEE 802 data-link (L2)\n|\n(802.2)\n|\n(802.3)\n|\n+-------------+---------------+\n|\nPhysical Layer (L1)\nThe IEEE 802 data-link layer is divided into\n• MAC (Medium-Access Control, 802.3), which is medium specific\nand defines framing, addressing, and access rules, and\n• LLC (Logical Link Control, 802.2), a medium independent sub-\nlayer that offers a uniform service interface to the network layer\nand, when desired, adds sequencing and acknowledgments.\nCore Functions of LLC\nFrame-Format Comparison\nEthernet II\n802.3 + LLC\n802.3 + LLC + SNAP\n---------------\n---------------\n---------------------\nDest MAC\nDest MAC\nDest MAC\nSrc MAC\nSrc MAC\nSrc MAC\nEtherType\nLength\nLength\nDSAP\nDSAP = 0xAA\nSSAP\nSSAP = 0xAA\nControl\nControl = 0x03\nOUI (3 B) = 0x000000\nEtherType\nllc and how it differs from other ethernet protocols\n2\nFunction\nHow LLC Provides It\nComparable Mechanism Outside LLC\nService multiplexing\nDSAP / SSAP (8 bit each) identify the upper\nlayer protocol.\nEtherType field in Ethernet II.\nThree service types\nType 1: connectionless, unacknowledged\n(mandatory). Type 3: connectionless, acknowl-\nedged. Type 2: connection oriented with se-\nquencing and flow control.\nIP is always connectionless; TCP gives\nconnection oriented reliability above\nL2.\nMedia independence\nSame LLC PDU rides over 802.3, 802.11, 802.5,\nFDDI, etc.\nEthernet II framing is Ethernet only.\nOptional reliability\nHDLC style control field allows SABME,\nRR/REJ, etc.\nModern networks push reliability to\nTCP or lossless fabrics such as RoCE\nPFC.\nSNAP extension\nAdds 5 bytes (OUI + EtherType) so Ether-\nType based protocols still work over any 802\nmedium.\nNative EtherType in Ethernet II.\nTable 1: Key LLC features and where\nsimilar facilities reside when LLC is not\nused.\nPayload ...\nPayload ...\nPayload ...\nFCS\nFCS\nFCS\nEthernet II places the EtherType immediately after the source\nMAC and is the framing used by practically all modern IP traffic.1\n1 See IEEE Std 802.3-2022, Section 3.1.\nWith 802.3 + LLC, the receiver must parse the LLC header (DSAP /\nSSAP) to learn which upper layer service is carried. SNAP keeps the\n802 structure while still transporting traditional EtherType values.\nWhy LLC Faded on Ethernet\n1. Simplicity and cost. Early NICs already spoke Ethernet II, so\nadding LLC parsing logic gave little benefit.\n2. IP dominance. Most traffic needed only EtherType 0x0800 (IPv4)\nor 0x86DD (IPv6), so DSAP / SSAP were redundant.\n3. Redundant reliability. LLC Type 2 and 3 capabilities overlapped\nwith TCP end to end guarantees.\n4. VLAN tagging. 802.1Q inserts its own 4 byte shim but preserves\nEtherType demultiplexing.\nAs a result, modern NICs understand LLC/SNAP for legacy\nframes (for example STP, LLDP), yet more than 99 percent of ev-\neryday traffic uses Ethernet II framing.\nLLC Versus Other Ethernet Related Layers\nTake Aways for New Protocol Design\n• If you need to multiplex a new L3 protocol, registering an Ether-\nType or using OUI + SNAP is simpler than reviving DSAP / SSAP\nllc and how it differs from other ethernet protocols\n3\nAspect\nLLC (802.2)\nEthernet II\nMAC Control / PFC\nPurpose\nUniform service, op-\ntional reliability\nMinimal frame wrap-\nper\nFlow control, security\nMedia scope\nAny IEEE 802 medium\nEthernet only\nEthernet only\nHeader size\n3 B (8 B with SNAP)\nnone beyond MAC +\nEtherType\nControl frames are sep-\narate 64 B PDUs\nError handling\nOptional ACK / REJ at\nL2\nNone\nPause frames stop the\ntransmitter; no ARQ\nTypical use today\nSTP, LLDP, some indus-\ntrial stacks\nIP, ARP, VLANs, nearly\nall data traffic\nDatacenter congestion\ncontrol, MACsec\nTable 2: Comparative position of LLC\nand other Ethernet related layers.\nvalues.\n• Link layer reliability costs latency. Modern reversible or causal\nordering schemes are better placed above the MAC, much as Ro-\nCEv2 rides over UDP/IP.\n• For designs that must traverse Wi Fi or other IEEE 802 media,\nSNAP framing keeps you inside the standard while preserving\nfamiliar EtherType semantics.\n"
  },
  {
    "filename": "STANDALONE/Topology.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\næthernet: ultra low latency (ull)\n1\nRethinking Datacenter Management\nOwners and operators of the network determine the relation-\nships among distributed applications today. Minimum spanning\ntrees, on which all routing is done, are built, and torn down, by\nswitches; based on protocols standardized long ago when we first\nlearned how our computers could communicate.\nFigure 1: CENTRALIZED\nFigure 2: DECENTRALIZED\nFigure 3: DISTRIBUTED\nToday’s datacenter architects build their infrastructures using two\nkinds of boxes: switches and servers.\nWe refer to all network devices as switches. Those that route at\nlayer 3 are simply layer 3 switches. They connect them using individ-\nual cables, which they bundle together to make them convenient to\nroute within and around physical structures. This forms a centralized\nor decentralizedtopology, where the switches become hubs and servers\nbecome leaves.\nPaul Baran’s classification provides insight:\nCENTRALIZED (A) shows 46 univalent nodes connected to a special\nhigh radix or valency\nWe use valency to denote the number of physical ports on a hy-\nperconverged cell. A cell is a single type of node element (au-\ntonomous unit of compute, storage and packet processing).\nA link is an individual, bidirectional, computation object (an\nautonomous communication entity between two cells) This is to dis-\ntinguish us from radix, used in switches, but is equivalent to degree\n(δ), in graph theory.\nIf the central hub dies, all nodes are cut off. DECENTRALIZED (B)\nshows 47 nodes and links, 7 nodes with a valency of 5-7 serve as\nswitches, and 40 as univalent (leaf) nodes. If one of the switches fails,\nthe network fractures into isolated partitions; and only nodes within\nthe partitions can continue to communicate locally. DISTRIBUTED (C)\nshows 47 identical, multivalent (valency ∼5) nodes, and 98 links.\nThe network has better resilience: failed nodes are routed around,\nand many links must fail before any node is finally isolated.\nDatacenter Topologies\nCENTRALIZED topologies are avoided because they represent bottle-\nnecks and have a single point of failure. DECENTRALIZED topologies\nare (hub & spoke) topologies may be economically necessary for\nlarge-scale geographically disparate systems like the interstate road-\nways and airline networks. are most prevalent, which is surprising\ngiven how non-optimal they are when looked at from a perspective of\ndistributed microservices container life-cycles\næthernet: ultra low latency (ull)\n2\nDistributed microservices have an overwhelming predominance of\nEast-West Traffic. Containers can be created in microseconds and last\nonly seconds or milliseconds.,\nToday’s datacenter networks evolved from their roots in the ad-hoc\nconnection of Ethernet broadcast domains with switches housed in\nwiring closets and managed by individuals with specialized expertise\nin routing and proprietary management interfaces.\nThe SPoF’s in decentralized topologies are mitigated by redun-\ndancy in modern multi-slice Clos Networks. Modern Clos networks\ntypically have two, three or four slices of spline and leaf switches,\nalong with multiple sets of cables.. Switches networks that perpetu-\nate this model, are embarrassingly complex, unreliable, arcane, and\nparochial. This results in very high operational costs, poor securi-\nty/high vulnerability, and nothing close to five nines reliability [From\nJoe Howard, The perpetuation of complexity:\n“Ethernet and IP networking is embarrassingly complex, unreliable,\narcane, and parochial. That results in very high operational costs, poor\nsecurity/high vulnerability, and nothing close to five nines reliability.\nIn almost any other product category this would be considered un-\nacceptable. Network technology has changed very little since the late\n1980s, with the exception of faster speeds/feeds and some additional\nprotocols and features.”\nDISTRIBUTED topologies are rarely used (so far) in datacenters,\nexcept for a few HPC applications. Except for HPC applications,\nwhich have used various forms of hypercube routing, based on a\ncartesian coordinate system of destination addresses (a God’s-Eye-\nView), which assumes that failures are rare, and uses complex band-\naids to route around failed nodes.\nWhen we use a relative addressing scheme instead, routing around\nfailed nodes becomes far simpler, and we can build entirely new\nkinds of stacked graph covers to provide functionality not previously\nneeded (or envisaged) on hypercube interconnects..\nHowever, within the same or lower capital cost, DISTRIBUTED\ntopologies provide: greater resilience, lower latencies, higher avail-\nable bandwidth and far more flexibility; by connecting cells\nWe combine switches and servers, into a single concept: cells,\nand make them substitutable (i.e. although they may not be identical in\nall aspects of their capabilities, they can at least be managed as one ‘type’.),\nwhich, in turn, makes them fungible, and easier to manage. The additional\ndensity of the physical topology, afforded by the cell’s ‘middle’ range va-\nlency (5 to 9), enables far richer virtual topologies to be built. directly\nwith neighbor to neighbor (N2N) connections rather than through\na switched or aggregated network. By not perpetuating the man-\nagement complexity of switched networks, and introducing new,\næthernet: ultra low latency (ull)\n3\nsimpler, control/forwarding planes through cells, we can also dra-\nmatically lower operational costs.\nPerhaps the time has come to recognize the genius of Paul\nBaran’s insights, and ask why DISTRIBUTED topologies are not\ndeployed in datacenters, where their resilience and security can\nbe readily exploited?\nDatacenter Programmability\nTwo types of teams co-evolved to manage modern datacenters: one to\ndesign and manage the networks, and one to program and manage\nthe servers. This worked when datacenters had a single owner or\ntenant, their applications and physical infrastructure evolved slowly,\nand different business units could work within their own silo’s. This\nis no longer a viable architecture in today’s highly dynamic multi-\ntenant datacenters.\nDistributed applications can no longer afford to be held back by\nthe slow pace of networking innovation.\nWhile programmable switches may be a promising approach to\nimprove the performance and manageability of datacenters, they are\nstill (a) under the control of the network owners and operators, and\n(b) limited by the low-level endpoint routing and packet forward-\ning paradigm of today’s network engineering. What is needed to\ncomplete this revolution is to include the cells (agents on servers) as\nfirst class members of this set of devices which are allowed to route\npackets as well as process them.\nTRAPHs: Programmable Application Topologies\nCritical layers are missing between applications and infrastructure:\na layer which contains the evolving graph relationships of modern\nmicroservices. A substrate that programmers can own and man-\nage themselves1. This provides the missing abstraction for a pro-\n1 A substrate that can work in con-\njunction with the simpler forwarding\nfunctions within NICs and switches\ngrammable, and deterministic-when-needed, topologies as tools\nand resources to the application architect. For example, application\nprogrammers can program these TRAPHs (Tree gRAPHs) using a\nGraph Virtual Machine (GVM) to provide services such as distributed\nconsensus, atomic broadcast, and presence management among\nmembers of a cluster or microservice set.\nTRAPHs enable datacenter operators to organize graphs of re-\nsources, managing them on trees, enabling computing on graphs.\næthernet: ultra low latency (ull)\n4\nFrom the perspective of different vantage points, each with least-\nprivilage2. They also provide developers of microservices complete\n2 E.g. Managing realms, jurisdictions,\ntenants and sub-tenants as graphs\ninstead of lists.\nfreedom (within the nodes assigned to them), to programmatically\ndetermine their sub-relationships, and the protocol characteristics\nmost needed for their applications.\nExamples\nThe advantage or using TRAPHS over a distributed network is that\napplication developers can program their behavior instead of hav-\ning to wait for permission, or suffer the externalities of the network\noptimizing itself without regard to the application’s health. This\nsimplifies some important use cases such as:\nLogical & Virtual Segregation Planes Enable capability-based secu-\nrity graphs, to provide secure containment of communication\nenvironments for multi-tenant infrastructures. E.g., exchange the\nmanagement of lists (ACL’s and iptables) by replacing them with\nricher and more manageable graph equations. Virtual Segregation\nPlanes: graph applications: erasure coding, machine learning, etc.\nCoherent graph overlays where cache heterarchies co-exist to auto-\nmatically manage the placement and eviction of caches based on\nrequest patterns. One use case would be a coherent configuration\nfile system, which provide a unified mechanism to keep config-\nuration files synchronized, for Docker, etc. Another would be a\ncoherent memcached. Eliminating cascade failure incidents, like\nGoogle saw recently spread to all regions of their Cloud Platform\ndue race conditions to update configuration files.\nManaging Infrastructure as Sets, Graphs & Tensors, instead of Boxes, Files & Lists.\nAll routing is predicated on building shortest path trees, e.g.\nBellman-Ford for L2, or Dijkstra at L3. The roots for these trees\nare in the switches, and thus under the administrative control of\nnetwork owners and operators. With TRAPHs, large subgraphs, or\ngraph-covers comprising cells and links allocated to a particular\ntenant, may be used by that tenant for any topology whatsoever,\nincluding allocation to sub-tenants. Graph computing on TRAPHs\n(Tree-gRAPHs) enable automatic mapping of the natural DAG\nrelationships of distributed applications on nested datacenter in-\nfrastructure resources.\nConclusion: Allowing application developers to build and man-\nage their own routing substrate under API control would dra-\nmatically improve the performance, efficiency and flexibility of\nmodern infrastructures, reducing inter-tenant interference, en-\nabling privacy, and improving manageability.\næthernet: ultra low latency (ull)\n5\nThe Evolution of Baran to Chiplets\nFigure 4: Partial Network Partitioning\nFigure 5: Distributed (valency 8)\nBaran Distributed\nBaran Chiplet\nFigure 6: Baran Chiplet\n"
  },
  {
    "filename": "STANDALONE/Metcalfe.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\næthernet: ultra low latency (ull)\n1\nShannon + Metcalfe\nOriginal Half-Duplex\nFigure 1: Half-Duplex Metcalfe\nModern Full-Duplex\nFigure 2: Full Duplex Metcalfe.\n"
  },
  {
    "filename": "STANDALONE/Best-Effort-Test.pdf",
    "content": "Why Best-Effort is Not Good Enough:\nThe Case Against Ethernet’s Legacy Assumptions\nPaul Borrill\nIntroduction\nEthernet has achieved unprecedented global dominance across all\nlayers of modern networking—from local area networks (LANs) to\ndatacenter fabrics and high-frequency trading interconnects. De-\nsigned in the 1970s by Metcalfe and Boggs, Ethernet’s simplicity,\nscalability, and cost-effectiveness stemmed from its foundational\ndesign principle: best-effort delivery. But today, in an era defined by\nprecision timing, distributed consensus, transactional integrity, and\nreversible computation, this principle has become a liability rather\nthan a virtue.\nThis essay argues that best-effort delivery is no longer sufficient.\nInstead, a reliable, acknowledged, semantically enriched, and tempo-\nrally disciplined Ethernet fabric is now necessary to meet the grow-\ning demands of critical infrastructure, high-performance distributed\ncomputing, and secure information flow.\nThe Myth of “Good Enough”\nBest-effort delivery means packets may be lost, reordered, duplicated,\nor delayed arbitrarily, and the network makes no guarantees beyond\nbasic frame integrity. This was tolerable when applications lived\non the same machine or within a few hops of each other and could\ntolerate latency spikes or re-transmissions.\nToday, however, large-scale systems depend on deterministic\nbehavior:\n– Distributed databases depend on atomic commit, snapshot isola-\ntion, and causal ordering.\n– Control loops in robotics and finance demand low-jitter, bounded-\nlatency paths.\n– AI accelerators and smartNICs coordinate at sub-microsecond\ntime scales.\nBest-effort delivery now injects unpredictability at precisely the layers\nthat require guarantees.\nwhy best-effort is not good enough: the case against ethernet’s legacy assumptions\n2\nHidden Complexity: What Best-Effort Pushes Upstairs\nTo compensate for its unreliability, Ethernet offloads responsibility\nonto higher layers:\n1. TCP/IP must implement complex state machines for reliability,\nordering, congestion avoidance.\n2. Distributed applications implement timeout/retry logic, risking\nretry storms and tail latency spikes.\n3. System designers must implement chaos testing and compensat-\ning transactions to mitigate partial failure.\nThis bloated layering violates the end-to-end argument: reliability\nthat could be implemented in the NIC is instead delegated upward,\ncausing inefficiency and software complexity.\nFailure Modes and Their Costs\nBest-effort networks exhibit the following problematic failure modes:\nSilent packet drops: undetected by hardware; retries hide faults until\nbuffers overflow.\nOut-of-order delivery: breaks RPC frameworks that assume FIFO\nchannels.\nCongestion collapse: caused by self-inflicted retransmission storms.\nHead-of-line blocking: exacerbated by a lack of per-flow scheduling\nor credit-based flow control.\nThe economic cost of these failures is non-trivial. In high-frequency\ntrading, nanoseconds matter; in autonomous systems, a missed\npacket may become a catastrophic error.\nThe Path Forward: Beyond Best-Effort\nWe propose an evolution of Ethernet in which the Layer 2 transport\nmodel includes:\n– Reliable Delivery: acknowledgment (ACK/NACK) mechanisms\nat the NIC level.\n– Congestion Notification: credit-based or rate-based flow control\ninstead of reactive retransmission.\n– Semantic Channels: protocol-aware framing to support logical\ntransactions, not just bits.\nwhy best-effort is not good enough: the case against ethernet’s legacy assumptions\n3\n– Temporal Semantics: packet time tagging, expiration windows,\nand causal ordering support.\nSeveral technologies point in this direction: InfiniBand, Homa,\nScale-Out Ethernet, and the emerging Open Atomic Ethernet pro-\nposal. Each reveals how a reliable, low-latency data plane can be both\nefficient and correct.\nConclusion\nBest-effort delivery was a brilliant compromise for the world of\n10Mbps coaxial networks. But in 2025, it is no longer good enough. If\nwe are to build systems that are resilient, reversible, and auditable—if\nwe are to eliminate retry storms, tail-latency disasters, and trans-\naction ambiguity—we must evolve Ethernet beyond its legacy of\nhopeful transmission.\nA future of reliable, accountable, and semantically structured\ncommunication awaits.\n"
  },
  {
    "filename": "STANDALONE/Andromeda.pdf",
    "content": "The Illusion of Simultaneity with Perfect Atomic\nClocks\nMay 24, 2025\nIntroduction\nThe relativity of simultaneity implies that two observers moving rela-\ntive to one another can disagree on what events are happening “right\nnow” at distant locations. Even if both observers carry perfectly syn-\nchronized atomic clocks, their determinations of simultaneous events\nat remote locations (e.g., the Andromeda Galaxy) can differ dramati-\ncally.\nTime Shift Due to Relative Motion\nLet v be the relative velocity between two observers, and D the dis-\ntance to a distant object (e.g., a galaxy). The relativity of simultaneity\npredicts a difference in the perceived “now” at the remote location:\n∆t ≈vD\nc2 ,\n(1)\nwhere c is the speed of light.\nExamples\n• For walking speed (v = 1.39 m/s) and D = 2.5 million light-years\n(Andromeda):\n∆t ≈1.39 × 2.365 × 1022\n(3 × 108)2\n≈4.2 days\n• For hypersonic ﬂight (v = 1700 m/s):\n∆t ≈1700 × 2.365 × 1022\n(3 × 108)2\n≈5170 days ≈14 years\nAtomic Clock Precision\nModern optical lattice clocks can achieve stability better than 10−18,\ncorresponding to an error of less than 1 second over 30 billion years.\nOver a day (86400 s):\nδtclock = 10−18 × 86400 ≈8.64 × 10−14 seconds\n(2)\nThis is less than a femtosecond, utterly negligible compared to the\nrelativity-induced differences in simultaneity.\nthe illusion of simultaneity with perfect atomic clocks\n2\nDiagram: Disagreement Despite Synchronized Clocks\nTime (t)\nSpace (x\nObserver A\nObserver B\nEvent in And\nA’s simultane\nB’s simu\nFigure 1: Two observers, A and B, with\nsynchronized clocks, disagree on what\nevent in Andromeda is simultaneous\nwith their current time.\nADDED BY PAUL\nNo degree of ‘precision’ or ‘disciplining’ of clocks will enable us to\n‘synchronize time\".\nSimultaneity is impossible in theory. It will therefore be problem-\natic in practice. Physicists know this. Computer scientists have yet to\ndiscover relativity and quantum mechanics.\nConclusion\nPerfectly synchronized atomic clocks do not resolve disagreements\nabout simultaneity at distant locations. Such disagreements are a\nfeature of spacetime itself in special relativity — not of timekeeping\nimprecision.\n"
  },
  {
    "filename": "STANDALONE/Case-for-Reliable-Atomic-Links-old-02025-APR-25.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\næthernet: ultra low latency (ull)\n1\nThe Case for Reliable Atomic Links\nRcv\nSnd\nSnd\nRcv\nBob\nAlice\nGreen: Forward Evolution\nBlue: Reverse Evolution\nForward Progress (+1)\nReverse Progress (-1)\nTernary Logic Link\nEquilibrium = 0\nFigure 1: Two cells and a link with\nconserved quantities\nMany problems encountered in datacenters today arise from our\ninability to distinguish between a node that is merely slow from\none that has failed or become unreachable due to network failure\nWe take the two most recognizable elements in datacenters today:\nservers and switches, and refactor them into simpler, more founda-\ntional elements (fully independent failure domains): cells and links.\nA cell is a single type of node (autonomous unit of compute, storage\n& packet processing). A link is a bidirectional computation object\n(an autonomous communication entity between two cells)1.\n1 Think of \"cells\" in cellular automata.\nThink of a link as a compute element\nwith its own autonomous and inde-\npendent failure domain; comprising\nthe cable and NICs on both ends which\nform their own self contained execution\nenvironment. In the same way devices\nwithin a single execution environment\nare considered a single failure domain;\nthe link can detect device and cable\nerrors and stop the machine.\nA consequence of the former is that unifying node elements makes\nthings simpler because we have only one type of node to manage\ninstead of two. The consequence of the latter is profoundly more\ninteresting: we raise the notion of a link to first order – a first-class\ncitizen in the infrastructure – a bipartite)2 element of conserved in-\n2 Not related to biparitie graphs. Here,\nwe mean the more classical definition\nof bipartite as “having two parts, or an\nagreement between two parties.”\nformation with two complementary halves – persistable through failure\nand recovery events. i.e., a communication object that doesn’t rule\nout that some fault-detection and computation is involved.\nAn example3 link utility is The I Know That You Know That I Know\n3 Synchronization of timing domains\nin computers generally start from the\nprocessor clock on the motherboard,\nand fan out through the logic into the\nI/O subsystems. IUI is the link between\ntwo computers, and although it receives\ninformation from either side, it is not\nsynchronized to either side. This “deep\nasynchronous domain\" enables failure\nindependence and atomicity.\n(TIKTYKTIK) property; which enables us to address some of the most\ndifficult and pernicious problems in distributed systems today.\nAnother example link utility is Indivisible Unit of Information (IUI).\nUnlike replicated state machines used throughout distributed applica-\ntions today, links are single state machines: the two halves of which\nmaintain temporal intimacy through hidden packet exchanges. When\na local agent or actor is ready, the IUI protocol transfers indivisible\ntokens across the link to the other agent, atomically (all or nothing)4.\n4 links are exquisitely sensitive to packet\nloss. This is intentional: we turn the\nFLP result upside down, and use a single\nfailed process to guarantee the atomic\nproperty for IUI.\nTIKTYKTIK and IUI properties are compositional. Trees of links pro-\nvide a deterministic conserved quantities mechanism to reliably dis-\ntribute tokens among agents on an application graph. Intermediate\ncells promise5 to never lose IUI tokens. This defends against lost to-\n5 The alternative definition of Fu-\ntures/Promises also applies: execution\nis primed to create future liveness events.\nkens because if any part of the chain (or tree) breaks, alternate paths\nare available to seamlessly recover the conserved quantity and con-\ntinue operation6.\n6 links also provide a more reliable\nfoundation for distributed system\nservices for applications: consensus,\natomic broadcast, leader election,\ncluster membership and distributed\narithmetic, Which, in-turn, enable\nhigher level functions such as network-\nassisted-transactions which serve, for\nexample, distributable (scale-out),\npersistable (durable), and lightweight\n(but-accurate) accounting of conserved\nquantities associated with application\nstate or resource usage.\nBy strengthening the system model, links & IUI tokens provide\na general foundation to solve many distributed systems problems\nsuch as failure-detection, consensus and distributed transactions.\nFailure Modes\nOne might imagine7 if each host (or its SmartNIC) maintains its half\n7 Such a recovery mechanism is not\navailable through conventional\nswitched networks; because of the\nuncertainty of how many packets\nwere lost, exactly where along the\npath through the switched network\nthey were lost, how many were dupli-\ncated, and how they might have been\nre-ordered in the switched network.\nof the shared state, then shouldn’t the switched network be able to\nact as a proxy for a single logical link? When a switched network\næthernet: ultra low latency (ull)\n2\nfails, and reroutes, can’t the two sides (SmartNICs) just stitch the two\nhalves of the shared state back together again? we could achieve the\nproperties of links over existing switched networks.\nThis simple hazard analysis8 misses a fundamental issue: networks\n8 Typical hazards: (1) Servers with a link\nto a single Top of Rack Switch (ToR)\nare unable to heal at all; there is only\none path from the server to anyone.\n(2) ToRs represent SPoFs; when they\nfail, many servers (in that rack) also\nbecome unavailable. Worse still: the\nservers don’t go down, they keep on\ncomputing but don’t know they are\nisolated. ToRs have also been known to\nexhibit complex cascade failures where\na firmware failure triggered in one will\ntake down many neighbor TORs.\ndon’t maintain state on behalf of applications. Switches drop packets (and\nstate) whenever they feel like it, so there are many more ways for\nlogical links to get confused over switched networks and compromise\nthe integrity of the shared state.\nKey issue: Switched networks drop packets anywhere along the\npath; eradicating state and events needed to maintain promises\nand liveness respectively. When a link fails, both sides are pre-\nserved. If there is a failure in the token transfer it can always be\ndetected, and retransmissions occur only on a real failure (such as\ndisconnection–where alternative routes are explicitly coordinated\nwith applications), thus enforcing that tokens have no duplicate\nor out of order deliveries on the link 9,10.\nWhen packets are dropped in a switched network, more than infor-\nmation is lost, events are lost, and it becomes extraordinarily diffi-\ncult to recover both sides of a shared state that stretches across even\na single switch. A directly connected link can promise three things\na switched network cannot11: (a) maintain an ordering of events\n9 Even without failures, the behavior\nof switched networks forces us into a\nhigh overhead approach. If packets can\nbe indiscriminately dropped, delayed,\nduplicated and reordered, we have no\nchoice but to implement TCP/IP, or\nsomething very much like it (which\nis unlikely to have the maturity and\nrobustness of the existing tried and\ntested implementations). However, even\nin optimal situations, TCP introduces\nhigh overhead for all operations, which\nis too slow. There is no escape: if you\nhave dropped, delayed duplicated\nor reordered packets, you have to\neffectively implement TCP. If we can\neliminate duplication and re-ordering,\nrecovery is far simpler, and removes the\noverhead from normal operations.\n(heal, send packets, fail, heal again, send more packets) – essential\nfor non-idempotent and non-commutative operations. (b) not drop\ncertain packets without notification – essential for recovery. And (c)\nmaintain complementary direction state – essential for distributed\nself-stabilizing algorithms with local rerouting rules for reliable trees.\nBipartite Integrity\nThe shared state property is strengthened by mechanisms to recover\nfrom each type of failure. The more types of failures, the more com-\nplex and intractable this becomes. Links are independent failure\ndomains, with (effectively) one failure hazard: disconnection12; which\n10 Links do not reorder or duplicate\npackets so we can now use a high-\nperformance udp-like protocol for\ncoherence; only paying the performance\ncost of TCP when it fails for real, i.e.\ndisconnection. Remarkably, this also\npaves the way for very high bandwidth\nutilization for datacenter to datacenter\napplication flows, because it eliminates\nthe most difficult aspects of reordering\nand duplication of packets\nis straightforward to recover from. Switched networks, on the other\nhand, have many more failure hazards: they indiscriminately The\nNetwork is Reliable An informal survey of real-world communications fail-\nures drop, delay, duplicate and reorder packets – that’s just the way\nnetworks behave – justified by the end to end argument13.\n11 Actually, a link can promise many\nmore than just these three things: what-\never property the agent or application\nwishes to attach to the bipartite link\nobject.\nThe shared state TIKTYKTIK property can also be used to mitigate\nbroadcast storms in network rendezvous, timeout storms in microser-\nvices, or reconstruction storms in erasure coded storage14. In IUI,\n12 In any physical system it is possible\nto drop packets, it will be much rarer\nbut it is still possible. links can recover\nfrom individually dropped or corrupted\npackets, and shared state integrity can be\nmaintained.\npackets are not merely dropped, they are replaced with special events\ndenoting failure, to maintain liveness. Because link failures are in-\næthernet: ultra low latency (ull)\n3\ndependent (unlike switched networks) we can successively recover\nindividual disconnection failures.\nThis single step recovery mechanism paves the way for IUI to\nreverse one or more steps in distributed systems which use non-\nidempotent or non-commutative data structures. 15.\n13 The end-to-end principle states that in\na general-purpose network, application-\nspecific functions ought to reside in the\nend hosts of a network rather than in\nintermediary nodes, provided that they\ncan be implemented “completely and\ncorrectly” in the end hosts. Our claim\nis that it is impossible to implement\nbidirectional synchronization primitives\n“completely and correctly” without\nIUI (or something very much like it).\nThe datacenter is not the Internet, and\nSaltzer, Reed, & Clark considered only\na careful (unidirectional) file transfer,\nnot the bidirectional synchronization of\nreplicas (coherency).\nDisconnection is the most likely failure hazard in links. Packets\ndelayed by disconnected links don’t threaten liveness or the\nintegrity of the shared state. Switched network hazards include:\nindiscriminately dropped, delayed, duplicated and reordered packets.\nConventional mitigations (e.g. TCP) add significant complexity\nand performance overheads, and still fail to solve the problem.\nExamples\nThe advantage of the shared state is that both sides know the link is\nbroken which can’t be done through a switched network with even\na single switch in series. links simplify some important distributed\nsystem algorithms such as two-phase commit, consensus and reliable\ntree generation:\nTwo-phase commit The prepare phase is asking if the receiving agent\nis ready to accept the token. This serves two purposes: communi-\ncation liveness and agent readiness. Links16 provide the communi-\n14 Links also coalesce heartbeats to\nmake microservices more scalable, and\nmake failure detectors reliable.\ncation liveness test, and we can avoid blocking on agent ready, by\nhaving the link store the token on the receiving half of the link.\nIf there is a failure, both sides know; and both sides know what to\ndo next.\nPaxos “Agents may fail by stopping, and may restart. Since all agents\nmay fail after a value is chosen and then restart, a solution is im-\npossible unless some information can be remembered by an agent\nthat has failed and restarted”. The assumption is when a node\nhas failed and restarted, it can’t remember the state it needs to\nrecover. With IUI, the other half of the link can tell it the state to\nrecover from. This avoids the performance cost of heavyweight\ntransactions and persistent storage.\nWhy can’t the sending side on Paxos keep the information the\nreceiving side needs in case it fails? The other side of the link\nknows: the state that was lost in the crash is maintained by the\nhalf of the link on the other side. In leader election a master sends\na request to a worker (prepare) and it doesn’t get the ack. With\nIUI, the master knows definitively, if it is a neighbor.\nIn two-phase commit (2PC) there is no safety proof. In three-phase\ncommit, there is no liveness proof. Can we also often eliminate the\næthernet: ultra low latency (ull)\n4\nprepare phase in consensus and 2PC? 17 which improves perfor-\n15 The shared state can be compromised\nby duplicated or reordered packets, but\nit is resilient to lost or delayed packets.\nmance.\nOne or more corner cases are eliminated where the replicated state\nmachine can get blocked due to the loss of an acknowledgement\npacket.\nAtomicity provides significant advantages in distributed comput-\ning by making corner cases disappear, it makes it simpler to im-\nplement those distributed algorithms correctly, and the number of\ncircumstances where things go wrong is reduced by (potentially)\nseveral orders of magnitude.\nReliable tree generation Binary link reversal algorithms18 work by\n16 Links exploit a unique combination\nof physics, electrical engineering and\ncomputer science. Think of IUI as\nthe distributed systems (message-\npassing based) equivalent of the atomic\nCompare And Swap (CAS) primitive\nused in shared memory architectures.\nThe result is handshake-free messaging\nwith strong liveness, recoverability and\nsecurity properties.\nreversing the directions of some edges. Transforming an arbitrary\ndirected acyclic input graph into an output graph with at least one\nroute from each node to a special destination node. The resulting graph\ncan thus be used to route messages in a loop-free manner19. Links\n17 And in three-phase commit, the\npre-prepare phase?\nstore the direction of the arrow (head and tail); IUI facilitates the\natomic swap of the arrow’s tail and head to maintain loop-free\nroutes during failure and recovery.\nEnd Notes:\n18. Charron-Bost et. al. generalize the Gafni-Bertsakas (GB) binary\nlink reversal algorithm. Which works by reversing the directions of\nsome edges. Transforming an arbitrary directed acyclic input graph\ninto an output graph with at least one route from each node to a special\ndestination node. Charron-Bost et. al.\n19. Link reversal algorithms don’t generate shortest paths, just\nsome paths. However, they do generate multiple loop-free routes. This\nallows the link to inform the agent (and the application, if needed)\nwhen switching to an alternate failover tree. As long as precomputed\nfailover paths are available, we used the Dynamic Tree Algorithm\n(DTA). Only when cells lose all their paths do they need to partici-\npate in the link-reversal algorithms, which means less communication\noverhead and more stability.\n20. The shared state integrity of the single physical link is a promise\nthat two NIC’s can make with each other only over a single physi-\ncal link. This is explicitly an anti-promise for conventional switched\nnetworks.\nConclusion: Atomic Ethernet Links require a single physical\nconnection; their benefits cannot be achieved over switched net-\nworks composed of a chain of unreliable links20.\næthernet: ultra low latency (ull)\n5\nCombining the TIKTYKTIK and Atomic properties with various\nclassical algorithms, provides a general foundation to solve many\ndistributed systems problems, and mitigate broadcast, timeout\nand reconstruction storms in networks and distributed storage.\n"
  },
  {
    "filename": "STANDALONE/CASE.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\næthernet and switched networks\n1\nThe Case for Reliable Atomic Links\nRcv\nSnd\nSnd\nRcv\nBob\nAlice\nGreen: Forward Evolution\nBlue: Reverse Evolution\nForward Progress (+1)\nReverse Progress (-1)\nTernary Logic Link\nEquilibrium = 0\nFigure 1: Two CELLs and a LINK with\nconserved quantities, epistricted with\nTernary, or Three-valued logic\nPROBLEM:\nMany latency, Inconsistency, and Unbounded problems encountered in\ndistributed systems today arise from our inability to distinguish between\na node that is merely slow from one that has failed or become unreach-\nable due to network failure.\nWe take the two most recognizable elements in datacenters today:\nservers and switches, and refactor them into simpler, fully independent\nfailure domains: CELLs and LINKs. A CELL is a universal node: an au-\ntonomous unit of compute, storage and packet processing. A LINK is\na bidirectional tunnel-element; an autonomous communication entity\nbetween two CELLs)1. Physically, the LINK comprises the cable and\n1 Think of CELLs in Cellular automata.\nThink of LINKs as compute elements\nwith their own autonomous and in-\ndependent failure domain (Local\nINformation and Knowledge). In the\nsame way devices within a single ex-\necution environment are considered\na single failure domain; the LINK can\ndetect device and cable errors and make\nthe machine stop. The challenge is how\nto get it started again. The solution is\ntriangle networks: Tripartite directly\nconnected graphs.\nSerDes’ on both ends to form a self contained execution environment.\nUnifying node elements makes things simpler because we have\nonly one type of node to manage instead of two. We raise the notion\nof a LINK to first order – a first-class citizen in the infrastructure – a\nbipartite element of conserved information with two complementary\nhalves – persistable through failure and recovery events. i.e., a com-\nmunication object that doesn’t rule out that some local fault-detection\nand computation is involved.\nPhysical LINKs Implement utilities that used to be in logical link\ndomains above L2: in L3, L4, or L7; composed into an abstraction of\nlogical links. This is an illusion. If the pairing of Shannon informa-\ntion is thrown away at layer 2, it cannot be recovered in higher layers.\nThis is addressed in more detail in the Key Issue section below.\nAn example2 LINK utility is The I Know That You Know That I Know\n2 Synchronization of timing domains\nin computers generally start from the\nprocessor clock on the motherboard,\nand fan out through the logic into the\nI/O subsystems. IUI lives in the LINK\nbetween two independent computers,\nand although it receives information\nfrom either side, it is not synchronized\nwith either side. This independent\nasynchronous domain (already ex-\nploited in the HFT Industry) – enables\nfailure independence and atomicity.\n(TIKTYKTIK) property; which enables us to address some of the most\ndifficult and pernicious problems in distributed systems today.\nAnother example LINK utility is Indivisible Unit of Information (IUI).\nUnlike replicated state machines (RSM’s) used throughout distributed\napplications today, LINKs are state machines: the two halves of which\nmaintain shared state through hidden packet exchanges. When a local\nagent or actor is ready, theIUI protocol transfers indivisible tokens\nacross the LINK to the other agent, atomically (all or nothing) 3.\n3 LINKs are exquisitely sensitive to packet\nloss. This is intentional: we turn the\nFLP result upside down, and use “a\nsingle unannounced process death” to\nguarantee the atomic property forIUI.\nTIKTYKTIK andIUI properties are mathematically compositional.\nTrees of LINKs provide a deterministic conserved quantities mech-\nanism to reliably distribute indivisible tokens among agents on an\napplication graph. Intermediate CELLs promise 4 to never loseIUI to-\n4 The alternative definition of Fu-\ntures/Promises also applies: execution\nis primed to create future liveness events.\nkens. This defends against lost tokens because if any part of the chain\n(or trtee) breaks. Alternate paths are available to seamlessly recover\nthe conserved quantity and continue operation5.\n5 LINKs t provide a more reliable foun-\ndation for distributed system services for\napplications: consensus, atomic broad-\ncast, leader election, cluster member-\nship and distributed arithmetic, Which,\nin-turn, enable higher level functions\nsuch as network-assisted-transactions\nwhich serve, for example, distributable\n(scale-out), persistable (durable), and\nlightweight (but-accurate) accounting\nof conserved quantities associated with\napplication state or resource usage.\næthernet and switched networks\n2\nFor maximum efficiency, both sides of the link should be ple-\nsiochronous; keeping snakes circulating at the same rate through both\ntransmit and receive channels.\nA New Law: Conservation of TOKENS\nBy strengthening the system model, LINK s and IUI tokens provide a\ngeneral foundation to solve many distributed-systems problems such as\nfailure detection, consensus, and atomic transactions.\nProblem\n• Sixteen years ago, CPU-Bound tasks, such as buffer pool and con-\n* OLTP Through the Looking Glass 16\nYears Later: Communication is the new\nBottleneck\ncurrency control, were the primary bottlenecks in OLTP databases.\nToday, communication overhead is the dominant factor affecting\nperformance*.\n• Timeouts & retries (TAR) are the “root of all evil\" in distributed\nsystems. They lead to Congestion, Cascade Slowdowns: Retry\nStorms, Metastable Failures, Limpware, Transaction Failure, and\nSilent Data Corruption – which leads to lost and corrupted trans-\nactions in all distributed systems, including databases.\nFailure Modes\nOne might imagine6 if each host (or its SmartNIC) maintains its half\n6 Such a recovery mechanism is not\navailable through conventional\nswitched networks; because of the\nuncertainty of how many packets\nwere lost, exactly where along the\npath through the switched network\nthey were lost, how many were dupli-\ncated, and how they might have been\nre-ordered in the switched network.\nof the shared state, then shouldn’t the switched network be able to\nact as a proxy for a single logical LINK? When a switched network\nfails, and reroutes, can’t the two sides (SmartNICs) just stitch the two\nhalves of the shared state back together again? we could achieve the\nproperties of LINKs over existing switched networks.\nThis simple hazard analysis7 misses a fundamental issue: networks\n7 Typical hazards: (1) Servers with a\nLINK to a single Top of Rack Switch\n(ToR) are unable to heal at all; there is\nonly one path from the server to anyone.\n(2) ToRs represent SPoFs; when they\nfail, many servers (in that rack) also\nbecome unavailable. Worse still: the\nservers don’t go down, they keep on\ncomputing but don’t know they are\nisolated. ToRs have also been known to\nexhibit complex cascade failures where\na firmware failure triggered in one will\ntake down many neighbor TORs.\ndon’t maintain state on behalf of applications. Switches drop packets (and\nstate) whenever they feel like it, so there are many more ways for log-\nical link ts to get confused over switched networks and compromise\nthe integrity of the shared state.8\n8 Even without failures, the behavior\nof switched networks forces us into a\nhigh overhead approach. If packets can\nbe indiscriminately dropped, delayed,\nduplicated and reordered, we have no\nchoice but to implement TCP/IP sender\ntimeouts, Even in optimal situations,\nTCP introduces high complexity and\noverhead and unbounded latency\nfor all operations, which is too slow.\nThere is no escape: if we drop, delay\nduplicate or reorder packets, you have\nto effectively implement TCP. If we can\neliminate duplication and re-ordering,\nrecovery is far simpler, and removes the\ntail latency from normal operations.\nKey issue: Switched networks drop packets anywhere along the\nnetwork path; eradicating state and events needed to maintain\npromises and liveness respectively. When a LINK fails, both sides\nare preserved. If there is an atomicity violation in the IUI it can\nalways be detected, and retransmissions occur only on a real fail-\nure (such as disconnection–where alternative routes are explicitly\ncoordinated with applications), thus enforcing that IUI tokens\nhave no duplicate or out of order deliveries on the LINK.\næthernet and switched networks\n3\nSwitched Networks\nWhen packets are dropped in a switched network, more than infor-\nmation is lost, events are lost, and it becomes extraordinarily difficult\nto recover both sides of a shared state that stretches across even a sin-\ngle switch. 9\n9 LINKs do not reorder or duplicate\npackets so we can now use a high-\nperformance payload operator in\nAtomic Ethernet for coherence; only\npaying the performance cost of TCP\nwhen it fails for real, i.e. disconnection.\nRemarkably, this also paves the way for\nvery high bandwidth utilization for dat-\nacenter to datacenter application flows,\nbecause it eliminates the most difficult\naspects of reordering and duplication\nof packets. In scale-out/massively\ndistributed architecture.\nNot sure dropped packets are the right hazard to mention here “the protocol is\nexquisitely sensitive to packet loss”. What really destroys state as shown in the\nAfek et al. paper was RACE CONDITIONS on every packet transmission (delay +\nreorder), with the proposed solution being essentially E2E Stop and wait\nA directly connected LINK can promise three things a switched net-\nwork cannot: (a) maintain an ordering of events (heal, send packets,\nfail, heal again, send more packets) – essential for non-idempotent\nand non-commutative operations. (b) not drop certain packets with-\nout notification – essential for recovery. And (c) maintain comple-\nmentary direction state – essential for distributed self-stabilizing algo-\nrithms with local rerouting rules for reliable trees. 10 11\n10 Actually, a LINK can promise many\nmore than just these three things: what-\never property the agent or application\nwishes to attach to the bipartite LINK\nobject.\n11 ReversibleIUI enables the rever-\nsal of non-idempotent structures in\ndistributed applications.\nWhat’s necessary is an entanglement between state machines – lock-\ning them together silently in normal operation, and failing locally at\nthe first failure. The entanglement cannot be recovered if information\nfrom events can disappear. This is the only solution to the problem\nin the latency–disconnection ambiguity [Ref: CAP Theorem Trade-\noffs]. To put it in terms an engineer can internalize, a system that\nfails instantly, can heal immediately.\nBipartite Integrity and the E2E Principle\nThe End-to-End (E2E Principle 12\n12 The end-to-end principle states that in\na general-purpose network, application-\nspecific functions ought to reside in the\nend hosts of a network rather than in\nintermediary nodes, provided that they\ncan be implemented “completely and\ncorrectly” in the end hosts. Our claim\nis that it is impossible to implement\nbidirectional synchronization primitives\n“completely and correctly” withoutIUI\n(or something very much like it). The\ndatacenter is not the Internet, and\nSaltzer, Reed, & Clark considered one-\nway (unidirectional) file transfer, not the\nbidirectional synchronization of replicas\n(token coherency) described here.\nThe shared state property is strengthened by mechanisms to re-\ncover from each type of failure. The more types of failures, the more\ncomplex and intractable this becomes. The LINK combines the fail-\nure domains of SerDes, cables, connectors and atomic rays?? (Idea\nis no matter what happens, the link freezes If anything is amiss, you\ncan remove if flow is better – into one failure hazard LINKs are in-\ndependent failure domains, with (effectively) one failure hazard:\ndisconnection13; which is straightforward to recover from. Switched\n13 In any physical system it is possible\nto drop packets, it will be much rarer\nbut it is still possible. LINKs can recover\nfrom individually dropped or corrupted\npackets, and shared state integrity can be\nmaintained through out the successive\nreversibility recovery – back to the\nequilibrium state.\nnetworks, on the other hand, have many more failure hazards: they\nindiscriminately The Network is Reliable An informal survey of real-world\ncommunications failures drop, delay, duplicate and reorder packets\n– that’s just the way networks behave – justified by the end to end\nargument\næthernet and switched networks\n4\nReversibility\nIn physics, time-symmetry is the universal property by which energy\nis conserved. In OAE, reversibility ensures the conservation ofIUI\ntokens because traffic on the link stops, and the complimentary state\non both sides of the link is preserved until higher level protocols\n(triangle relationships) where the 3rd CELL (Transaction Manager\nRole) is able to perform “successive reversibility\", heal the link, and\nreturn the protocol back to the equilibrium state.\nThe shared state TIKTYKTIK property can also be used to mitigate\nbroadcast storms in network rendezvous, timeout storms in microser-\nvices, or reconstruction storms in erasure coded storage14. InIUI,\n14 LINKs also coalesce heartbeats to\nmake microservices more scalable, and\nmake failure detectors reliable.\npackets are not merely dropped, they are replaced with special events\ndenoting failure, to maintain liveness. Because LINK failures are inde-\npendent (from node failures) we can successively recover individual\ndisconnection failures.\nThis single step recovery mechanism paves the way forIUI to\nreverse one or more steps in distributed systems which use non-\nidempotent or non-commutative data structures. 15.\n15 The shared state can be compromised\nby duplicated or reordered packets, but\nit is resilient to lost or delayed packets.\nDisconnection is the Most Likely Failure Hazard in LINKs\nPackets delayed by disconnected LINKs don’t threaten liveness or the\nintegrity of the shared state. Switched network hazards include: indiscrim-\ninately dropped, delayed, duplicated and reordered packets. Conventional\nmitigations (e.g. TCP) add significant complexity and performance over-\nheads, and still fail to solve the problem.\nExamples\nThe advantage of the shared state is that both sides know the LINK is\nbroken which can’t be done through a switched network with even\na single switch in series. LINKs simplify some important distributed\nsystem algorithms such as consensus ,two-phase commit, and reliable\ntree generation:\nPaxos 16 “Agents operate at arbitrary speed, may fail by stopping,\n16 Paxos is mentioned first because it\nis a clearer example how reliable L2\nimpacts the application consistency\ntradeoffs. Reliable Paxos probably\ncould be its own paper.\nand may restart. Since all agents may fail after a value is chosen\nand then restart, a solution is impossible unless some information\ncan be remembered by an agent that has failed and restarted”.\n17 The assumption is when a node has failed and restarted, it\n17 Prepare phase is not about bad\nnetworking, but to coordinate between\ncompeting proposals. It cannot be\neliminated, but its performance can\nbe improved by no longer relying on\ntimeouts.\ncan’t remember the state it needs to recover. WithIUI, the other\nhalf of the LINK can tell it the state to recover from. This avoids\nthe performance cost of heavyweight transactions and persistent\nstorage.\næthernet and switched networks\n5\nTwo-phase commit The prepare phase is asking if the receiving agent\nis ready to accept the token. This serves two purposes: communi-\ncation liveness and agent readiness. LINKs18 provide the communi-\n18 LINKs exploit a unique combination\nof physics, electrical engineering and\ncomputer science. Think ofIUI as the\ndistributed systems (network- based)\nequivalent of the atomic Compare And\nSwap (CAS or just plain SWAP) primitive\nused in shared memory architectures.\nThe result is handshake-free messaging\nwith strong liveness, recoverability and\nsecurity properties.\ncation liveness test, and we can avoid blocking on agent ready, by\nhaving the LINK store the token on the receiving half of the LINK. If\nthere is a failure, both sides (senders and receivers in both NICs)\nknow; and both sides know what to do next.\nWhy can’t the sending side on Paxos keep the information the\nreceiving side needs in case it fails? The other side of the LINK\nknows: the state that was lost in the crash is maintained by the\nhalf of the LINK on the other side. In leader election a master sends\na request to a worker (prepare) and it doesn’t get the ack. With\nIUI, the master knows definitively, if it is a neighbor.\nIn two-phase commit (2PC) there is no safety proof. In three-phase\ncommit, there is no liveness proof. Can we also often eliminate the\nprepare phase in consensus and 2PC? 19 which improves perfor-\n19 And in three-phase commit, the\npre-prepare phase?\nmance.\nOne or more corner cases are eliminated where the replicated state\nmachine can get blocked due to loss of acknowledgement .\nAtomicity\nAtomicity in IUI provides significant advantages in distributed com-\nputing by making corner cases disappear, it makes it simpler to im-\nplement those distributed algorithms correctly, and the number of\ncircumstances where things go wrong is reduced by (potentially)\nseveral orders of magnitude.\nReliable tree generation Binary LINK reversal algorithms20 work by\n20 Charron-Bost et. al. generalize the\nGafni-Bertsakas (GB) binary LINK\nreversal algorithm.\nreversing the directions of some edges. Transforming an arbitrary\ndirected acyclic input graph into an output graph with at least one\nroute from each node to a special destination node. The resulting graph\ncan thus be used to route messages in a loop-free manner21. LINKs\n21 LINK reversal algorithms don’t gen-\nerate shortest paths, just some paths.\nHowever, they do generate multiple\nloop-free routes. This allows the LINK\nto inform the agent (and the applica-\ntion, if needed) when switching to an\nalternate failover tree. As long as pre-\ncomputed failover paths are available,\nwe used the Dynamic Tree Algorithm\n(DTA). Only when CELLs lose all their\npaths do they need to participate in the\nLINK-reversal algorithms, which means\nless communication overhead and more\nstability.\nstore the direction of the arrow (head and tail);IUI facilitates the\natomic swap of the arrow’s tail and head to maintain loop-free\nroutes during failure and recovery.\nThose examples are applications using multiple links composed\ntogether, as depicted in our Atomic Ethernet logo.\nAlso, liveness becomes trivial in paxos. As long as a majority is\nup, progress is guaranteed. The real problem is cluster membership,\nwhen new nodes join, or when old nodes leave, either voluntarily or\ninvoluntarily.\næthernet and switched networks\n6\nFAQ\n[QUESTION I still do not understand how two devices connected us-\ning a full duplex Ethernet link can support reliable communications\nwithout time outs and retries\n[ANSWER] You are right at a conceptual level, but the reality\nof timeouts and retries is so different with a Stop-and-Wait (SaW)\nprotocol as to make you wrong. Let us explain.\n• In current networks, timeouts and retries are end to end concepts.\nAlice sends an application message to Bob with TCP, which at-\ntempts to guarantee delivery by sending ACKs. Those ACKs can\nbe lost on the way from Bob’s node to Alice’s. Alice has no way to\nknow if part of the message or the ACK was lost or delayed, so she\nretries after a timeout.\n• With Stop and Wait (SaW) (the alternating bit protocol) , reliability\nis at the link level, where the protocol provides sufficient common\nknowledge to address the majority of the issues. In particular, if\nthe link doesn’t break, the packets get through. There’s no need to\ndrop a packet due to a full buffer, because the SaW signal is credit\nbased flow control.\n• If the link breaks noisily (both sides get a signal), both sides know\nwhich phase of the protocol they are in, so they know which one is\nresponsible for forwarding the packet. I think you’d be stretching\nthe concept if you said A sending the packet on the new path is a\nTCP-like retry,\nIf the link breaks silently or even in only one direction, both sides\nknow that a SaW signal hasn’t arrived. Since both sides know that\nboth sides know (common knowledge), each can declare the link\ndead with full knowledge that the other side will eventually declare\nit dead too. Of course, knowing when to stop waiting for the signal is\nthe moral equivalent of a timeout, but there’s no need to coordinate\non a value. I’d say that’s quite different from the timeouts you’re\nthinking of.\nEnd Notes:\n18. Charron-Bost et. al. generalize the Gafni-Bertsakas (GB) binary\nLINK reversal algorithm. Which works by reversing the directions of\nsome edges. Transforming an arbitrary directed acyclic input graph\ninto an output graph with at least one route from each node to a special\ndestination node. Charron-Bost et. al.\næthernet and switched networks\n7\n19. Link reversal algorithms don’t generate shortest paths, just\nsome paths. However, they do generate multiple loop-free routes.\nThis allows the LINK to inform the agent (and the application, if\nneeded) when switching to an alternate failover tree. As long as\nprecomputed failover paths are available, we used the Dynamic Tree\nAlgorithm (DTA). Only when CELLs lose all their paths do they need\nto participate in the LINK-reversal algorithms, which means less\ncommunication overhead and more stability.\n20. The shared state integrity of the single physical LINK is a\npromise that two NIC’s can make with each other only over a single\nphysical LINK. This is explicitly an anti-promise for conventional\nswitched networks.\nConclusion\nÆthernet LINKs require a direct physical connection; their benefits cannot\nbe achieved over switched networks composed of a chain of unreliable\nlinks. Atomicity + Self-stabilizing algorithms, provide a general founda-\ntion to solve many distributed systems problems, and mitigate broadcast,\ntimeout and reconstruction storms in networks and distributed storage.\n22\n22 The shared state integrity of the\nsingle physical LINK is a promise that\ntwo NIC’s can make with each other\nonly over a single physical LINK.\nThis is explicitly an anti-promise for\nconventional switched networks.\n"
  },
  {
    "filename": "STANDALONE/Shannon.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\næthernet: ultra low latency (ull)\n1\nFrom Shannon to Metcalfe and Beyond\nShannon One-Way Channels\nFigure 1: Shannon One-Way Channels.\nShannon Channels are normally shown in one \"direction\" of flow\n– from Information souroce to Information Destination.. Here we\npoint out that for a two-way communication (signaling) we need to\nuse Back to Back Channels and feedback. Then the equations tell us\nsomething ineteresting\nMetcalfe Half-Duplex\nFigure 2: Full Duplex.\nMetcalfe Half-Duplex Channel\nFigure 3: The original Metcalfe + Boggs\nEthernet was a bus. A long cable where\n‘stations’ were TAPs on the bus. This\nmeant that each station had to both\nlisten, and transmit from teach tap.\næthernet: ultra low latency (ull)\n2\nFull-Duplex Bi-pipelined Shannon-Metcalfe Channel\nFigure 4: The full model: A Bi-\npipelined full duplex passage of an\nEthernet frame on each link. This shows\nthe full model of \"internal acknowl-\nedges\", where slices are sequenced with\ngreater depth inside the SerDes / FPGA\nShannon Slots (2nd half of document)\nSingle + Dual Channel\nTRANSMITTER\nINFORMATION\nSOURCE\nRECEIVER\nDESTINATION\nMESSAGE\nMESSAGE\nNOISE\nt\nTRANSMITTER\nINFORMATION\nSOURCE\nRECEIVER\nDESTINATION\nNOISE\n• A single Channel Shannon Channel is the conventional view of\nInformation\nKey aspects of Shannon Channels\nare already “reversible” based on\nmutual and consistent information;\nthese are symmetric in time in our\nmodel for Common Knowledge. [See JV\nStone: Information Theory: A Tutorial\nIntroduction]\n• The former is statistical (correlated only), the latter is 100% consis-\ntent.\n• Our Reversible Dual Channel Shannon model enables both full\nreversibility and provides new opportunities for Error detection\nand Correction\n• The theory is fully consistent with the scientific literature, but\napplying it to short cables provides a new opportunity - within\nracks, and chiplet meshes\n• This presentation is (we think) new IP, that can be patented.\n• It applies specifically to the “Sahas information model (see slides\nat end)\næthernet: ultra low latency (ull)\n3\n• This is the foundation for a new model for a Product: Link Failure\nDetector\nShannon Reversibility Levels\n• Information Slots (surprisal)\n• Knowledge Slots (captured information)\n• Semantic Slots (meaning)\nSlot Reconciliation Protocol\n[Reference Pat’s favorite paper, and wiki session he gave + Transcript\nOUT\nOutput\nTape\nUndo\nTape\nTape \nMain\nR0\nOUT\nR1\nR2\nR3\nOUT\nOUT\nHost Processor —  Irreversible Zone\nRegister Interface\nAlice\nTUO\nOutput\nTape\nUndo\nTape\nTape \nMain\nR0\nTUO\nR1\nR2\nR3\nTUO\nTUO\nHost Processor —  Irreversible Zone\nRegister Interface\nBob\nSAW Protocol Link\nPCIe Bus\nFPGA Logic - Reversibility Zones\nPCIe Bus\nFPGA Logic - Reversibility Zones\nINFORMATION\nDISCARD\nKNOWLEDGE\nDISCARD\nPROCESSING\nDISCARD\nINFORMATION\nDISCARD\nKNOWLEDGE\nDISCARD\nPROCESSING\nDISCARD\nFigure 5: Shannon Slots.\næthernet: ultra low latency (ull)\n4\nWhen Two Shannon Channels are connected Back to Back\nFigure 6: Shannon Slots.\nArchitectural Framework: Four Shannon-like Levels\nIn the proposal for subdividing a 64-byte packet into 8-byte slices, we\nintroduce partial acknowledgments (SACKs) at four boundaries (00,\n01, 10, 11). Each of these points reveals an incrementally deeper level\nof the receiver’s certainty about the data, the hardware, and the ap-\npropriate next step in the protocol. We can interpret this progressive\ncertainty in terms of four conceptual layers reminiscent of Shannon’s\ninformation theory, but extended to address knowledge, semantics,\nand understanding. This layering describes how a receiver (e.g., the\nSmartNIC) transitions from raw incoming bits to meaningful mes-\nsages that can be handed off to the host processor.\nBack-to-Back (B2B) Shannon Channels\nare (nearly) “perfect information\nfeedback” as senders see their own\ntransmitted packet returning back from\nthe receiver and thus can detect channel\nerrors. (Norm Abramson, “Packet\nswitching with satellites,” NCC, 1973\nLayer 1: Information (Surprisal)\nAt the first level, information refers to the direct \"yes/no\" answer\nto a question of interest: the arrival or non-arrival of bits, which\nShannon famously treated as the surprisal of a received symbol. At\nthe SACK 00 boundary, when the receiver detects the first 8-byte slice\næthernet: ultra low latency (ull)\n5\nwithout error, it learns that the link is alive and that the data matches\nexpectations (i.e., no immediate mismatch). This is pure information\nbecause it distinguishes the event \"we did receive slice #1 correctly\"\nfrom \"we did not.\" The mutual information gained here confirms a\nworking cable and a functional SerDes.\nAt this early stage, the question posed is binary: \"Did the hard-\nware see valid bits?\" The surprisal is that valid bits were received, as\nopposed to no signal or corrupted data.\nLayer 2: Knowledge (Captured Information)\nThe second layer, knowledge, arises when the raw bits are stored\nor captured in a meaningful structure. This could be as simple as\na recognized slice stored in buffer memory or a pipeline register.\nBy the time the second slice arrives, the receiver has captured more\nbits—16 bytes in total—and placed them into NIC-internal registers.\nIt can then perform further checks, such as alignment, partial CRC, or\nchecking for expected header fields. The SACK 01 confirms that the\nhardware not only saw valid bits but also placed them in the correct\nbuffer location.\nAt this point, the system has a partial understanding of the data.\nIt knows that the 16 bytes are recognized and safely stored, awaiting\ndeeper logic to interpret them.\nLayer 3: Semantics (Meaning)\nThe third layer, semantics, involves the system deciding what the bits\nmean in terms of subsequent action. This layer determines which\nstate machine or processing path is relevant for the given data. At the\nSACK 10 boundary, after 32 bytes have been received, the NIC has\ngathered enough information to partially decode the data. For exam-\nple, it might be able to determine which protocol or message type is\nindicated. The NIC can confirm that buffer slots or ring descriptors\nare available and that the correct state machine is loaded (e.g., state\nmachine A for small control frames, or state machine B for streaming\npayloads).\nOnce the NIC signals SACK 10, the sender learns that the hard-\nware has found the data coherent enough to continue. The semantics\nare recognized sufficiently to proceed without hazard. The receiver\nhas now moved from simply knowing the bits are correct (Layers\n1 and 2) to understanding how to proceed and which internal re-\nsources or state machines to activate.\næthernet: ultra low latency (ull)\n6\nLayer 4: Understanding (Syntax)\nThe final layer, understanding, refers to the recognition that the mes-\nsage fits into a finite set of concepts or message types that the NIC\naccepts. This implies that the message has a correct syntax recog-\nnized by the hardware. At the SACK 11 boundary, which occurs\nwhen slices 5–8 arrive, the full 64 bytes have been received and match\na legitimate frame or message layout. The NIC is now ready to push\nthe message onto the PCIe bus or an internal ring buffer for the host\nprocessor.\nAt this stage, the NIC has a full understanding of the message,\nknowing exactly how to finalize the packet, classify it, and pass it\nupstream for higher-level processing. No further layer-2 repairs are\nneeded, and the message is ready for the next step in the protocol.\nFigure 7: Complete perspective on the\nBack to Back Shannon Channels\nWhy the Four Layers Matter\n1. Information (Surprisal) ensures the physical channel is alive and\nbits can be reliably observed by the receiving SerDes.\n2. Knowledge (Captured Information) confirms the bits are cap-\ntured correctly in registers or buffers —no accidental misalign-\nment.\n3. Semantics (Meaning) ensures the logic knows how to synchronize\nthe appropriate state machines in their forward (or backward)\ndirection.\n4. Understanding (Syntax) verifies the packet’s higher-level consis-\ntency and classifies it for final delivery to the host.\næthernet: ultra low latency (ull)\n7\nEach SACK boundary (00, 01, 10, 11) maps neatly onto these four\nconceptual leaps. As soon as the sender receives each partial ACK,\nit gains confidence that the receiver has progressed one step deeper\nin turning raw signals (bits) into a fully understood data frame. This\nfour-layer design captures a more Shannon-like architecture in which\neach additional SACK message not only signals success so far, but\nalso narrows the set of potential failure modes and clarifies how the\ndata will be handled.\n"
  },
  {
    "filename": "STANDALONE/ChatGPT-Garner.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\nReview and Evaluation of the Argument for Unreli-\nable Ethernet vs ACK/NAK\nPaul Borrill\nApril 29, 2025\nIntroduction\nThis document provides a review and evaluation of an email ex-\nchange between Bill Lynch and Robert Garner regarding the use of\nthe alternating bit protocol (an ACK/NAK protocol) for Ethernet and\nits impact on throughput. Bill suggests that higher-level protocols can\nmitigate the throughput degradation caused by ACK/NAK overhead,\nwhile Robert counters with a detailed throughput model showing the\nsignificant impact of ACK/NAK in high-speed Ethernet scenarios.\nSummary of Arguments\nBill’s Argument for ACK/NAK and Higher-Level Protocols\nBill argues that ACK/NAK is not a fundamental limit on Ethernet\ntransmission efficiency. He asserts that a higher-level protocol can be\nemployed on top of the ACK/NAK protocol to achieve throughput\nnear the connection’s inherent capacity. Bill proposes the following\napproach:\n• De-multiplex the input stream into several sub-streams.\n• Transmit each sub-stream independently, using separate instances\nof an ACK/NAK protocol.\n• Re-multiplex the sub-streams back into the received data at the\nreceiving end.\nBill believes that this multiplexing approach, similar to TCP flow\ncontrol, will allow for significant improvement in throughput without\nbeing fundamentally constrained by ACK/NAK.\nRobert’s Counterargument: Throughput Degradation Due to ACK/NAK\nRobert counters Bill’s argument with a mathematical model based\non Metcalfe’s throughput equation. He suggests that when only one\npacket is outstanding on the link at a time, half of the packets are\nACKs, leading to a significant degradation of throughput. According\nto Robert’s calculation, the throughput degradation factor, M, due to\nreview and evaluation of the argument for unreliable ethernet vs ack/nak\n2\nACKs is:\nM =\n1\n1 + T\nTp\n,\nwhere T is the transmitter timeout and Tp is the packet transmission\ntime. Robert calculates that for a 100Gbps link with 64-byte packets\nand a round-trip propagation delay of 8 ns, the throughput degrada-\ntion factor due to ACKs is approximately 0.37, meaning only 37% of\nthe available bandwidth is achieved. If retransmission time is consid-\nered, the degradation worsens, resulting in only 33% of the available\nbandwidth.\nEvaluation of the Assumptions in the Argument\nImpact of ACK/NAK on Throughput\nBill’s argument that ACK/NAK overhead does not fundamentally\nlimit throughput assumes that higher-level protocols can efficiently\nmitigate the impact of ACK/NAK. However, Robert’s model pro-\nvides a more precise understanding of the significant impact of ACK-\n/NAK, especially when only one packet is allowed to be outstanding\nat a time. The calculation shows that ACKs introduce substantial\noverhead, reducing throughput to a fraction of the link’s capacity.\nThus, Robert’s analysis supports the idea that ACK/NAK overhead\nis a significant factor limiting throughput, particularly in high-speed\nnetworks.\nHigher-Level Protocols and Multiplexing\nBill suggests using multiple sub-streams to mask the impact of ACK-\n/NAK. While this approach can improve throughput by allowing\nmore parallelism, it does not eliminate the fundamental inefficiency\nof ACK/NAK at the link layer. The multiplexing of streams intro-\nduces additional complexity and may not be as effective in mitigating\nthe impact of ACK/NAK as Bill suggests. Furthermore, the efficiency\nof multiplexing may diminish as the number of streams increases,\ndue to the inherent limits of the physical link and the overhead of\nmanaging multiple streams.\nRealistic Link and ACK Packet Sizes\nThe assumptions about link speed (100Gbps) and packet sizes (64\nbytes) used in Robert’s calculation are reasonable for high-speed\nEthernet. However, in scenarios where larger packets (e.g., jumbo\nframes) are used, the relative overhead of ACKs may decrease, as the\ndata payload in each packet increases. This suggests that the impact\nreview and evaluation of the argument for unreliable ethernet vs ack/nak\n3\nof ACK/NAK may vary depending on the packet size, and larger\npackets may help reduce the effect of ACK overhead.\nError Detection and Retransmission Time\nRobert includes error detection and retransmission times in his calcu-\nlation, which are crucial for understanding the total impact of ACK/-\nNAK on throughput. If retransmission is delayed by 2 nanoseconds,\nas assumed by Robert, the throughput degradation increases further.\nThis highlights the importance of minimizing retransmission times\nand improving error detection efficiency to mitigate the performance\nhit from ACK/NAK protocols.\nConclusion and Recommendations\nBill’s argument that ACK/NAK is not a fundamental limit on through-\nput relies on the assumption that higher-level protocols can suffi-\nciently mitigate the overhead of ACK/NAK. While this may be effec-\ntive in practice, it does not address the core inefficiency introduced\nby ACK/NAK at the link layer. Robert’s analysis, using Metcalfe’s\nthroughput equation, shows that the impact of ACK/NAK can be\nsubstantial, especially when only one packet is outstanding at a time.\nTo improve the AE proposal, the following strategies should be\nconsidered:\n• Investigate mechanisms to reduce ACK/NAK overhead, such as\nbatch ACKs, selective ACKs, or moving to a different acknowledg-\nment mechanism (e.g., cumulative acknowledgments).\n• Use larger packets (e.g., jumbo frames) to reduce the relative over-\nhead of ACKs.\n• Consider advanced techniques like pipelining multiple outstand-\ning packets or adjusting timeouts to reduce retransmission delays.\nWhile higher-level multiplexing can improve throughput, it does\nnot eliminate the fundamental inefficiency caused by ACK/NAK\noverhead at the link layer.\nreview and evaluation of the argument for unreliable ethernet vs ack/nak\n4\nAppendix: Email Correspondence\nBill,\nIt is quite possible to use a higher level protocol ON TOP of an ACK/Nak protocol to achieve\nthroughput approaching the connection’s inherent throughput capacity.\nI think it is quite untrue that ACK/NAK is a severe and fundamental limit on transmission\nefficiency.\nI agree.\nI mentioned that in my Jan 15 email (before you were corralled into this debate)\nwhere I used Metcalfe’s throughput equation and obliquely assumed a single outstanding\npacket on the link.\nI parenthetically added:\n\"One way around this is to support multiple outstanding packets\nwith corresponding ACKs and queues.\nBut what of KISS (“Keep It Simple Stupid”)?\nWherein lies the boundary between sky-high i\ndealism and down-to-earth practically?”\n(Perhaps you only need one ACK in the case of multiple outstanding packets?)\nMy understanding gleamed from Borrill’s presentation of the AE proposal is that there’s\nonly one packet\noutstanding on the link at a time.\nIs this true??\nThe bottom line with single outstanding packets on the link is that half the packets are\nACKs.\nOptimistically, the sender’s timeout T for responding to the lack of an ACK is\ncalculated from the moment\nits last bit is on the link to the moment it reaches the receiver\nafter prop delay d,\nplus error detection time (assumed zero),\nplus the time for the receiver to transmit the entire ACK packet back to the sender,\nfor a total optimistic timeout interval T = 2d+Ack_packet_length.\nThis assumes there’s\nlittle variance\nin the receiver’s error detection processing time, otherwise the\ntimeout interval\nneeds be increased by the variance (or more).\nThe error detection time can be included in d.\nHere’s my summary of Metcalfe’s (cc’d) throughput equation updated to include multiple\noutstanding packets, per his thesis*, followed by a minor rewording of my calculation\nas applied to the proposed AE link\n(at least what I can make of it from Borrill’s presentation):\nEffective Capacity = (S/P) * (1 / (1+ CT/P)) * (1-L) * (C);\n= (protocol overhead)*(channel multiplexing factor M)*(error detection)*(channel raw capacity),\nreview and evaluation of the argument for unreliable ethernet vs ack/nak\n5\nwhere:\nC = channel Capacity (bits/sec)\nP = Packet size (bits)\nA = Acknowledge packet size (bits)\nS = Size of data in packet (bits)\nL = Probability of packet loss\nd = one-way channel propagation delay\nT = transmitter Timeout\n=\n2d + A/C\nThe channel multiplexing factor M = (1 / (1+ CT/P)) can represent either a single outstanding packet\non the line or multiple packets where P is the number of bits in the multiple outstanding packets.\nIf we let Tp = P/C be the duration of one or more packets, then\nM = 1 / (1+ CT/P) = 1 / (1+ T/Tp).\nFor the multiplexing factor to be near 1,\nT << Tp.\nFor the case of one outstanding packet on the AE link, we can calculate throughput degradation\nas follows:\nAssuming 64-byte packets on a 100-Gb/s 1.6-meter point-to-point link,\nthe roundtrip_prop_time = 2*1.6m*3ns/m = 8 ns.\nIf ACK packets are 8-byte flits, then ack_packet_length = 8*8b/100 Gb/s = 0.64 ns.\nSo T= transmitter_timeout = 8+0.64 = 8.64 ns, and the degradation factor M due to ACKs would be\nM = 1 / (1 + T/Tp) = 1 / (1 + 8.64/5.12) = 0.37.\nYou’re only achieving 2/5’th the available bandwidth.\nIn reality, it will take time for the transmitter state machine to respond to the lack of an ACK and\nretransmit the packet.\nIf recognition and retransmission takes say 2 nanoseconds, then the degradation factor due\nto the ACK protocol\nwould be\nM = 1 / (1 + T/Tp) =1 / (1 + 10.64/5.12) = 0.42. You’re only achieving 1/3’rd of the available bandwidth.\nI would be great if someone on the AE team could double check this calculation?\nBest,\n-- Robert\nreview and evaluation of the argument for unreliable ethernet vs ack/nak\n6\n* According to a reference in Metcalfe’s thesis, he discussed the “multiplexing factor” term in a\nconversation\nwith Will Crowther in May, 1972, as Crowther and his colleagues McQuillan et al\nat BBN had just redesigned the IMP-IMP interface to support multiple outstanding packets\n(“multi-packet messages”),\na performance upgrade after it initially supported just one packet\nat a time, as described in their 1972 FJCC paper “Improvements in the design and performance\nof the ARPA network.”\nThat paper (attached here) also describes in detail how to avoid message\n“reassembly lockup” in the IMP\nnodes and its performance.\n"
  },
  {
    "filename": "STANDALONE/OAE-Requirements-May08.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\nOpen Atomic Ethernet\nMay-08 Requirements\nMay 13, 2025\nMarket for a Sea of XPU’s are the closed hyperscalars\n#\nCandidate Requirement / Decision\nStatus / Rationale\nAction / Owner\nTransport layer\n1\nUse Ethernet-mode UA-Link (SFP SerDes, 64b/66b).\nReuses Algo-Logic MAC at 10–\n800 Gb/s.\nCheck license position\n(Paul)\n2\nAvoid PCIe Gen-6 680-byte flit for low latency.\nLarge flit forces FEC, adds delay.\nMark as Should-Not.\n3\nFEC must be switchable off for lane ≤25 Gb/s.\nProven in Arista/Synopsys tests.\nAdd bit in link FSM.\nFraming and flow control\n4\nFixed slices, 64 bits default (32/128 optional).\n64 bit slice ⇒160 ns frame\n@10 Gb/s.\nLock spec at 64 b.\n5\nHeader occupies first two slices (context + liveness).\nRemoves preamble and MAC hdr.\nFPGA demo (Sahas).\n6\nACK/NACK on slice 1,2,4,8,... (Hadamard cadence).\nBandwidth vs robustness knob.\nSimulate congestion.\nAddressing and security\n7\nDestination address only; source is optional/debug.\nUA-Link 10-bit SRC is spoofable.\nProvide 48-bit MAC pro-\nfile.\n8\nNo dynamic routing inside OAE fabric.\nSimplifies spoof defense.\nAdd to threat model.\nOpenness / IP\n9\nEntire stack (API →bits) royalty-free.\nCharter item; UA-Link IP risk.\nDraft legal FAQ (Paul).\nHigher-level semantics\n10\nExpose atomic load/store in slice 2.\nNeeded for cache-less accel.\nAlign with CXL verbs.\n11\nLiveness uses 4-bit qubit emulation per link pair.\nGives implicit error detect (no\nCRC).\nFormal proof\n(Paul+Alan).\nOpen items / Risks\nR1\nClarify OAE name vs OCP OAI/OAM.\nR2\nDecide if 64 B frame is mandatory or if 4 kB beat is pro-\nfiled.\nR3\nGauge NVIDIA commitment (Bill Lynch note).\nQuick take-aways (for draft spec):\n1. Prefer Ethernet-mode UA-Link PHY for first silicon.\n2. Frame size 64 bytes; header lives in first two 64-bit slices.\n3. ACK period is tunable (every slice during bring-up, then 2/4/8).\n4. Security: discard or authenticate source addr, static routes only.\n5. Keep the full stack open and royalty-free; prepare coexistence\nstory with UA-Link consortium.\n"
  },
  {
    "filename": "STANDALONE/OAE-Email.pdf",
    "content": "Email Correspondence on Network Reliability\nPaul Borrill\nMay 12, 2025\nOn 5/9/25 15:59, Alan Karp via groups.io wrote:\nI was thinking we were doing something simpler.\nImplement in the NIC a\nsmall number of QoS characteristics that applications could request, such as\n”reliable delivery,” while what you’re suggesting is more general, it requires a\nprogrammable smart NIC, which raises security concerns.\n————–\nAlan Karp\nOn Fri, May 9, 2025 at 3:52PM Kevin Cameron\nvia groups.io ¡kc=ieee.org@groups.io¿ wrote:\nWe can spend a lot of time arguing about whether a particular algorithm works\nor not, but that’s probably not useful if we want to program variable protocols\ninto the hardware dynamically. It would be better to describe the algorithms in\na way that a network compiler can understand them and do some kind of proof\nanalysis.\nKev.\nOn 5/9/25 14:58, Hesham via groups.io wrote:\nAlan,\nI am not convinced that your protocol works in all cases. MIT folks discussed\nthese issues before. The e2e argument paper says:\n“The end-to-end argument does not tell us where to put the early\nchecks, since either layer can do this performance-enhancement job.\nPlacing the early retry protocol in the file transfer application simpli-\nfies the communication system, but may increase overall cost, since\nthe communication system is shared by other applications and each\n1\napplication must now provide its own reliability enhancement. Plac-\ning the early retry protocol in the communication system may be\nmore efficient, since it may be performed inside the network on a\nhop-by-hop basis, reducing the delay involved in correcting a fail-\nure. At the same time, there may be some application that finds the\ncost of the enhancement is not worth the result but it now has no\nchoice in the matter.” [?]\nHesham\n[1] ”For example, real time transmission of speech has tighter con-\nstraints on message delay than on bit-error rate. Most retry schemes\nsignificantly increase the variability of delay.”\nOn Fri, May 9, 2025, 2:44PM Alan Karp via\ngroups.io wrote:\nThat’s an impressive summary. I’ve added comments inline.\n————–\nAlan Karp\nOn Fri, May 9, 2025 at 2:06AM Hesham via groups.io\nwrote:\nHere is Grok’s response to this question.\nHesham\nHop-by-hop reliability and end-to-end reliability\nserve different purposes in network communica-\ntion, and whether hop-by-hop reliability can re-\nplace end-to-end reliability as provided by TCP\ndepends on the context, requirements, and trade-\noffs involved.\nBelow, I’ll explain the concepts,\ncompare them, and assess the feasibility of replac-\ning TCP’s end-to-end reliability with hop-by-hop\nreliability.\nExactly right.\n2\nKey Concepts\n1. End-to-End Reliability (e.g., TCP)\nTCP (Transmission Control Protocol) ensures reliable data delivery between the\nsource and destination (endpoints) across a network. It achieves this through:\n• Sequence numbers: Tracks the order of packets.\n• Acknowledgments (ACKs): Confirms receipt of packets.\n• Retransmissions: Resends lost or corrupted packets.\n• Flow control: Manages data rates to prevent overwhelming the receiver.\n• Congestion control: Adjusts transmission rates to avoid network con-\ngestion.\nReliability is managed at the transport layer, end-to-end, meaning interme-\ndiate nodes (routers, switches) do not participate in ensuring reliability.\nAdvantages:\n• Simplifies intermediate nodes, as they only forward packets.\n• Guarantees delivery across the entire path, regardless of the number of\nhops or network conditions.\n• Well-suited for diverse, unreliable networks like the Internet.\nDisadvantages:\n• Higher latency for retransmissions, as errors are only detected and cor-\nrected at the destination.\n• Overhead from maintaining state (e.g., sequence numbers, timers) at end-\npoints.\n2. Hop-by-Hop Reliability\nIn hop-by-hop reliability, each intermediate node (e.g., router, switch) ensures\nreliable data transfer to the next hop in the path. If a packet is lost or corrupted\nbetween two nodes, the sending node retransmits it to the next node.\nExamples include:\n• Link-layer protocols like Ethernet with CRC checks and retransmissions\n(e.g., in Wi-Fi’s MAC layer).\n• Some network-layer protocols in specific contexts, like MPLS or certain\nIoT protocols.\nAdvantages:\n3\n• Faster error recovery, as errors are detected and corrected at each hop,\nreducing end-to-end latency for retransmissions.\n• Can leverage local knowledge (e.g., link conditions) to optimize reliability.\n• Potentially simpler endpoint implementation, as reliability is offloaded to\nthe network.\nDisadvantages:\n• Increases complexity and state maintenance at intermediate nodes, which\nmust track packets, send ACKs, and handle retransmissions.\n• May not guarantee end-to-end delivery if a node fails or misbehaves after\nacknowledging a packet.\nCan Hop-by-Hop Reliability Replace TCP’s End-to-End\nReliability?\nTo evaluate whether hop-by-hop reliability can replace TCP’s end-to-end relia-\nbility, let’s consider several factors:\n1. Reliability Guarantees\n• TCP (End-to-End): Guarantees that data is delivered correctly from\nsource to destination, even if intermediate nodes drop packets or links fail.\n• Hop-by-Hop: Ensures reliability only between consecutive nodes. If each\nhop is reliable, the overall path is likely reliable, but issues like node fail-\nures, misrouting, or buffer overflows could still cause packet loss without\nend-to-end verification.\nConclusion: Hop-by-hop reliability alone cannot fully guarantee end-to-\nend delivery in unreliable or complex networks like the Internet, where node\nfailures or misconfigurations are possible. End-to-end verification (like TCP’s)\nis needed for absolute reliability.\n2. Performance and Latency\n• TCP: When a packet is lost, TCP detects it at the destination and re-\nquests retransmission from the source, which can introduce significant\nlatency, especially over long paths or high-latency networks.\n• Hop-by-Hop: Detects and corrects errors at each hop, potentially reduc-\ning retransmission latency since errors are resolved closer to where they\noccur.\nConclusion: Hop-by-hop reliability can offer lower latency for error recov-\nery, making it attractive for low-latency applications. However, this advantage\ndiminishes if the network is stable and losses are rare.\n4\n3. Network Complexity\n• TCP: Keeps intermediate nodes simple, as they only forward packets\nwithout maintaining reliability state.\n• Hop-by-Hop: Requires intermediate nodes to implement reliability mech-\nanisms, increasing their complexity, processing overhead, and cost.\nConclusion: Hop-by-hop reliability shifts complexity to the network, which\nmay be impractical for general-purpose networks like the Internet but feasible\nin controlled environments.\nConclusion\n• Hop-by-hop reliability cannot fully replace TCP’s end-to-end reliability\nin general-purpose networks like the Internet due to the lack of guaran-\nteed end-to-end delivery without endpoint verification and the increased\ncomplexity at intermediate nodes.\n• However, hop-by-hop reliability can replace TCP in specific, controlled\nenvironments (e.g., data centers, industrial IoT, or private 5G networks)\nwhere low latency and fast local error recovery are prioritized.\n• A hybrid approach combining hop-by-hop reliability at lower layers with\nend-to-end reliability (e.g., TCP or QUIC) is optimal for most applica-\ntions.\n5\n"
  },
  {
    "filename": "STANDALONE/ZPU-Market.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\nMarket for XPUs\nHarry V. Quackenboss, Alan Karp, Kevin Cameron\nMay 12, 2025\nMarket for XPU’s is all the closed hyperscalars\nFigure 1: The SmartNIC Revolution\ndied, long live the XPU Revolution.\nCourtesy: Harry V. Quackenboss\nAlan, since the picture didn’t come through on groups.io, I sent it\nto your gmail address.\nThe FPGA NICs aren’t cheap compared to a standard NIC. The\nonly ones our use cases would work with were RISC-based Linux\nones with, if not currently, at least planned, per-core (single-thread)\nperformance close to single-thread performance of a Xeon core.\nBroadcom’s Stingray II (shelved), Marvell’s high-end Arm processor\n(never produced in volume), and Intel’s Mt. Evans roadmap (never\npursued for anybody other than hyperscalers). NVIDIA’s BlueField 4\n(not yet released – maybe shelved) looked good on paper.\nThe really high-volume prices of the SmartNICs in the BlueField-3\nclass were probably as low as $700 per unit, which I suspect is still\nless way than FPGA NICs.\nFor our use cases, price/performance was better on these types of\nSmartNICs because the data in flight nature of the workloads meant\nless DRAM/core, and the RISC versus X86 advantage of 70% in\nMIPS/Watt meant it made sense to offload those. However, if the\nSmartNICs couldn’t keep up with he geometry shrink from 3nm ->\n2nm and so on that the CPUs were on, the per-core performance and\nMIPS/Watt advantage evaporated.\n————– Harry Quackenboss\nmarket for xpus\n2\nAre these honking big, expensive smart NICs you’re talking about?\nI think we can implement our protocol in a pretty simple FPGA. (It\ncan be really simple if we do failure recovery with the CPU.) In fact,\nthere was an FPGA implementation. John Lockwood may know the\ndetails.\nYears ago we spoke to a NIC vendor. We could implement 99% of\nthe protocol with small changes to their standard product. There was\none corner case that required a change to their pico-code that was\nthe showstopper for them. None of those changes would have been\nvisible to customers not using our protocol.\n————– Alan Karp\nI’d say the future is highly interconnected processors that have\nspecialized computing support, SmartNICs fall in the specialized\ncomputing category if they have engines for things like encryption\nand compression, or something general purpose like an FPGA.\n————– Kev.\nThanks for this perspective. I had thought that smart NICs every-\nwhere was the wave of the future.\nThat being said, I’m not sure we need smart NICs for the basic\nprotocol. I believe that the happy path can be handled by simple state\nmachine logic in the NIC. Recovery from a broken link or node is\nprobably too complex for that, so it would have to be handled by the\nCPU. Recovery would certainly take longer, perhaps ms instead of\nmicroseconds.\n————– Alan Karp\nIt strikes me that among Kevin, Alan, and Hesham, there is no\ncommon understanding of what the minimum NIC feature set is that\nthis future protocol suite would run on (or, for that matter, possible\nmiddle boxes such as L2 switches)\nAdrian is current on this stuff, and I am not, but my understand-\ning is that SmartNICs, to summarize, are used by AWS, Google,\nMicrosoft, and Meta (and as a first approximation, Meta is less than\n1/5 the size of the others), but each vendor controls the SW stack\nincluding host drivers, and firmware on the SmartNIC, and even at\nleast some HW features. And, at least for now, none of the public\ncloud subset is making programmability available to customers.\nI don’t see how this effort is going to impact that, but maybe\nAdrian has a different opinion.\nOther than niches (and compared to markets big enough to sup-\nport new silicon at the rate CPUs evolve, even FPGA NICs are in my\ntaxonomy, niches). NVIDIA’s adaption of their DPU family to allow\ntuning for RDMA in AI and HPC clusters (that NVIDIA calls “Super-\nNIC”) isn’t really an exception in my view. There isn’t a significant\nmarket for xpus\n3\ninstalled base. If you scrutinize the forecasts and separate out ven-\ndors obfuscating to situation by declaring their high-end server NICs\nas SmartNICs, none are forecast big growth in the future (again, ex-\ncluding hyperscalers).\nA conclusion I draw from that is that trying to create new broad\nindustry standards is inconsistent with depending on hardware\nroadmaps for NIC features that aren’t forecast to be big volumes\n(excluding the hyperscalers that are going to be difficult to influence.\nTranslation: if this effort depends on custom programmable NICs\n(SmartNICs) isn’t going to lead to broad interest.\nThe sooner this group can come to a common understanding\nabout whether SmartNICs are in or out of scope, the sooner the de-\nbate can be narrowed.\nI personally would love to see SmartNICs be widely adopted. As\nKevin intimates, there are a bunch of things one can do.\nI just think unless and until factors beyond this group’s ability\nto influence change, it’s like trying to start a campfire with damp\nkindling in the rain. Smoke, with effort. But not much fire.\n————– Harry\n"
  },
  {
    "filename": "STANDALONE/Bandwidth.pdf",
    "content": "PA U L B O R R I L L\nA N I N - D E P T H E S S AY O N\nVA R I O U S N O T I O N S O F\n\" B A N D W I D T H \" I N N E T-\nW O R K S\nIntroduction\nIn the realm of computer networks, the term \"bandwidth\" is fre-\nquently used, but its meaning can vary depending on context. At its\ncore, bandwidth generally refers to the capacity of a channel to carry\ndata. However, the term can be misleading if not precisely defined or\ndifferentiated based on the different phases or aspects of data trans-\nmission. This essay explores various notions and misconceptions\nof \"bandwidth\" in networks, discussing concepts like SerDes band-\nwidth, sent bit-bandwidth, received bit bandwidth, goodput, badput,\neffective bandwidth, and others.\n1. SerDes Bandwidth\nThe SerDes (Serializer/Deserializer) bandwidth refers to the\nspeed at which data can be serialized (converted into a serial bit\nstream) and deserialized (converted back into parallel data). SerDes\nis a critical component in many high-speed communication systems,\nincluding Ethernet, Fibre Channel, and PCIe. SerDes bandwidth is\noften quoted as a rate, such as 25 Gbps or 100 Gbps, which repre-\nsents the rate at which bits are transmitted across the link.\nMisconception: People sometimes assume that the SerDes band-\nwidth directly reflects the available throughput for user data. While\nSerDes bandwidth defines the raw data transmission capacity of the\nhardware, it does not account for various inefficiencies such as over-\nhead, protocol framing, or error correction, which are factored into\nmore accurate measures like goodput.\n2. Sent Bit-Bandwidth\nSent bit-bandwidth refers to the total number of bits transmit-\nted by a sender, including both useful payload and all associated\noverhead such as headers, trailers, and retransmissions. This metric\ntypically refers to the raw transmission capacity in terms of total bits\nsent over the network.\nSent bit-bandwidth = Sent bits\nTime\nMisconception: Sent bit-bandwidth is often confused with through-\nput, but they are not the same. Throughput refers to the effective\ncapacity used for transmitting useful data, while sent bit-bandwidth\nalso includes protocol overhead and any retransmissions that may\noccur due to packet loss.\n3. Received Bit-Bandwidth\nOn the receiving side, received bit-bandwidth is the total number\nof bits received, again including both the useful data and any over-\nhead or retransmissions. While it might seem like an equivalent con-\ncept to sent bit-bandwidth, it is typically not used to directly measure\nperformance since it’s just the opposite of the sender’s perspective.\nMisconception: People might mistake the received bit-bandwidth\nfor the actual throughput available to the application layer. However,\nlike sent bit-bandwidth, it includes overhead data that isn’t counted\ntoward the \"useful\" capacity.\n4. Goodput\nGoodput is one of the most important and often confused metrics\nin network performance. It is defined as the rate at which useful data\nis successfully delivered over a network to the destination, excluding\nall protocol overhead, retransmissions, and error correction data.\nGoodput = Total Data Payload\nTime\nMisconception: The term \"goodput\" is often incorrectly used in-\nterchangeably with \"bandwidth.\" While goodput measures actual\napplication-level throughput, many people mistakenly equate good-\nput with the raw bandwidth capacity of a link, which overlooks\noverhead and retransmissions.\nFor example, a high-speed connection that experiences frequent\npacket loss and retransmissions may have a very low goodput, even\nthough its raw bandwidth is quite high.\n5. Badput\nBadput refers to the opposite of goodput and encompasses any\ndata that is transmitted but is deemed \"ineffective.\" This includes\nretransmitted data, error-corrected data, and packets that fail to con-\ntribute to successful communication. In essence, badput is the wasted\nbandwidth.\nBadput = Retransmitted Data + Protocol Overhead + Errors\nTime\nMisconception: Many network engineers focus primarily on good-\nput when measuring performance, which can lead to an incomplete\nunderstanding of the true efficiency of a network. For instance, a\nnetwork with high goodput but significant badput may still be inef-\nficient, leading to poor user experiences due to network congestion\nand delays.\n6. Effective Bandwidth\nEffective bandwidth is a more holistic metric that takes into ac-\ncount various factors like protocol overhead, link utilization, and\neven retransmissions. It typically reflects the real-world performance\nof a network, factoring out the inefficiencies such as headers, idle\nperiods, and protocol-based delays.\nEffective bandwidth =\nUseful Data\nTime + Overhead Time + Retransmission Time\nMisconception: Effective bandwidth is not always clearly distin-\nguished from goodput. However, effective bandwidth can sometimes\nbe a more comprehensive metric because it factors in the time lost\ndue to overhead and retransmissions, thus providing a better under-\nstanding of the real throughput available for application data.\n7. Link Capacity\nLink capacity refers to the maximum amount of data that can be\ntransmitted over a network link in a given amount of time, under\nideal conditions. This is typically represented in bits per second\n(bps), kilobits per second (kbps), megabits per second (Mbps), or\ngigabits per second (Gbps). The link capacity is often advertised by\nnetwork providers and refers to the maximum theoretical bandwidth\nof the network.\nMisconception: Link capacity is frequently confused with actual\nnetwork performance. While the link capacity provides an upper\nlimit, it is not the same as the available bandwidth in practice due to\nfactors such as network congestion, protocol overhead, and physical\nlayer impairments.\n8. Protocol Overhead\nProtocol overhead includes any extra bits that are required by the\nnetwork protocols to ensure successful transmission. This includes\npacket headers, error-checking bits, acknowledgment frames, and any\nother protocol data that does not contribute directly to the payload.\nMisconception: People often overlook the impact of protocol over-\nhead on bandwidth efficiency. A high proportion of protocol over-\nhead can drastically reduce the amount of bandwidth available for\nactual application data, especially in low-latency or high-throughput\napplications.\nFor example, in Ethernet, each packet includes headers for the\nMAC address, the IP layer, TCP/UDP headers, and sometimes addi-\ntional features such as VLAN tags, all of which consume bandwidth\nwithout contributing to the user’s data payload.\n9. Raw Bandwidth vs. Usable Bandwidth\nRaw bandwidth refers to the maximum theoretical transmission\ncapacity of a network medium, such as the data rate supported by a\nphysical link or a SerDes channel. Usable bandwidth, on the other\nhand, refers to the actual bandwidth available for application data af-\nter accounting for overhead, retransmissions, and other inefficiencies.\nMisconception: Raw bandwidth is often presented in marketing\nmaterials as a performance metric for networking hardware, which\ncan mislead consumers into thinking they are getting the full capacity\nfor user data. However, the real available bandwidth for applications\nis often significantly lower.\n10. Queueing and Latency Effects on Bandwidth\nQueueing delays can also affect the effective bandwidth expe-\nrienced by applications. Even if a network link has a high theoret-\nical bandwidth, congestion at intermediate devices like routers or\nswitches can introduce delays that reduce the available bandwidth.\nMisconception: Bandwidth measurements taken in a laboratory\nunder controlled conditions may not fully reflect the real-world ex-\nperience of users on a congested network. Queueing and latency\ncan significantly affect bandwidth in high-traffic scenarios, even on\nhigh-speed links.\nConclusion\nThe term \"bandwidth\" in networking is often used without a clear\nunderstanding of the various metrics and factors that contribute to\nthe overall performance of a network. From SerDes bandwidth to\ngoodput, badput, effective bandwidth, and beyond, each concept pro-\nvides a different perspective on how data is transmitted and utilized.\nTo avoid misconceptions, it is essential to distinguish between raw\ntheoretical bandwidth and the actual bandwidth that impacts real-\nworld applications, factoring in elements such as protocol overhead,\ncongestion, and retransmissions. By understanding the nuances of\neach bandwidth metric, network engineers and system architects can\nbetter design networks that are optimized for performance, efficiency,\nand reliability.\n"
  },
  {
    "filename": "STANDALONE/Trees-DAGs-Graphs.pdf",
    "content": "Distributed Systems are Trees on Top of DAGs on\nTop of Graphs\nAlan Karp, Paul Borrill, et. al.\nMay 20, 2025\nAbstract\nThis essay explores the layered graph-theoretic nature of distributed\nsystems. At the lowest layer, physical and logical interconnects form\nundirected graphs. On top of this lie DAGs representing depen-\ndency, scheduling, and locking relationships. At the top, application-\nlevel consistency and authority are imposed via trees such as names-\npace hierarchies, leadership structures, and commit chains. We fur-\nther examine how modern datacenters, populated by diverse xPUs\n(CPUs, GPUs, IPUs, DPUs), break the illusion of shared memory and\nnecessitate protocol designs that exploit the native graph structure\nusing mechanisms such as RDMA.\nGraphs: The Physical and Logical Fabric\nThe physical topology of a datacenter is a graph: nodes represent\ncompute units (CPUs, GPUs, IPUs, etc.) and edges represent commu-\nnication links (Ethernet, NVLink, InfiniBand, etc.). These links may\nhave diverse properties:\n• Bandwidth and latency asymmetries\n• Failures or congestion under load\n• Scheduled or dynamic routing paths\nUnlike the shared memory abstraction, these links form a non-\nuniform, fault-prone, and inherently asynchronous substrate. Real\ncomputation in modern datacenters occurs on this graph—not above\nit.\nDAGs: Causality and Locking\nOn top of the physical graph lies a directed acyclic graph (DAG)\nrepresenting causality, scheduling, and consistency constraints.\nDAGs arise in:\n• Transaction dependencies: Operations must follow a directed\norder to preserve causality.\n• Lock hierarchies: Preventing deadlock requires acquiring locks in\na fixed topological order.\ndistributed systems are trees on top of dags on top of graphs\n2\n• Build systems and job schedulers: Tasks must respect dependen-\ncies.\nLocking as a DAG\nDatabases employ lock hierarchies structured as DAGs to prevent\ncircular waits. For example, the following might form a hierarchy:\n1. Lock table\n2. Then row\n3. Then field\nEach level narrows scope and follows a partial order. Enforcing that\nlocks are acquired in topological order avoids cycles and hence dead-\nlock.\nTrees: Names, Commit Chains, and Leaders\nAt the top of the stack are trees. These structures are usually logical:\n• Namespace hierarchies: e.g., file systems, DNS.\n• Leadership trees: elected leaders per region, rack, or quorum.\n• Consensus and commits: commit chains or logs form trees (or\nmore precisely, forests with fork resolution).\nThese trees impose structure on the otherwise messy DAGs and\ngraphs below, enabling:\n• Easier authority delegation\n• Fault domain containment\n• Clear lineage and rollback support\nBreaking the Shared Memory Illusion\nShared memory simplifies programming but breaks down in dis-\ntributed xPU environments:\n• Memory isn’t uniformly addressable\n• Coherence protocols are expensive or infeasible\n• Latency variance introduces uncertainty in synchronization\nRDMA: Network as Memory Bus\nRemote Direct Memory Access (RDMA) partially restores shared\nmemory semantics:\n• Allows direct writes/reads between NICs with low latency\ndistributed systems are trees on top of dags on top of graphs\n3\n• Bypasses kernel and CPU involvement\n• Supports zero-copy semantics for performance\nBut RDMA also forces a shift:\n• You must think asynchronously\n• Buffers must be explicitly registered and tracked\n• Failures are explicit, not hidden\nExploiting the Graph: The Path Forward\nTo fully exploit xPU networks:\n• Treat communication paths as first-class citizens\n• Build coordination mechanisms that reflect graph topology\n• Favor protocols that can adapt dynamically to congestion and\npartitioning\nNew system designs should:\n1. Replace locking with message-passing wherever feasible\n2. Encode application semantics in DAGs, not linear logs\n3. Use explicit versioning and conflict resolution mechanisms\nConclusion\nDistributed systems are not built on the abstraction of shared mem-\nory. They are constructed on a layered composition:\nGraphs: physical connectivity\nDAGs: causal and logical dependencies\nTrees: naming, consensus, and leadership\nThe challenge of distributed systems is to harmonize these layers\nwhile respecting the physical realities of the system. To do so, we\nmust leave behind illusions of synchrony and embrace graph-native\nprogramming models.\n"
  },
  {
    "filename": "STANDALONE/Mathematica-Spec-Language.pdf",
    "content": "Mathematica as a Specification Language\nFormally Executable Specifications in Datacenter Architecture\nExploring formally executable specifications in datacenter architec-\nture touches the core of verifiability, reproducibility, and automation\nin modern systems.\nDefinition: Formally Executable Specification\nA formally executable specification is:\n• Precise and unambiguous:\ndefined mathematically or via\nformal syntax.\n• Executable: interpretable or\nsimulatable.\n• Deterministically testable:\nconsistent output for consistent\ninput.\nIn datacenter contexts, this implies that hardware, networking, stor-\nage, and compute orchestration policies are:\n• Executable in simulation or emulation environments,\n• Amenable to formal verification for correctness, safety, and perfor-\nmance.\nWhy It Matters in Datacenters\n• Correctness: validate failover, routing, and policy enforcement.\n• Optimization: evaluate configurations automatically.\n• Security: prove isolation and policy compliance.\n• Confidence: ensure safe deployment at scale.\nRelevant Tools and Technologies\nDomain\nTools\nNetwork Architecture\nP4, TLA+,\nNetKAT, Bat-\nfish\nStorage Systems\nTLA+, Ivy,\nAlloy, Z3 SMT\nOrchestration\nKubernetes\nCRDs, Pulumi,\nOPA, Nomad\nFormal Languages\nTLA+, Coq,\nLean, Dafny,\nAlloy\nExecution\nMininet, NS-3,\nOMNeT++,\nQEMU, Verila-\ntor\nFigure 1: Selected tools for formally\nmodeling datacenter systems\nExample: Rack-Aware Topology Specification\nImagine a model with:\n• Compute nodes linked via ToR (Top-of-Rack) switches,\n• Spine switches in a leaf-spine topology,\n• Multi-path routing and QoS,\n• VM placement and replication constraints.\nThe spec could:\n• Simulate failures and load distribution,\n• Detect routing loops or black holes,\n• Evaluate bandwidth and latency guarantees,\n• Prove placement constraints meet SLAs.\nmathematica as a specification language\n2\nVision: “Datacenter-as-Code” Verified\n• High-level specs compile into deployable artifacts,\n• Every change is property-checked and testable,\n• Infrastructure becomes version-controlled logic, replacing spread-\nsheets and tribal lore.\nEvaluating Mathematica for Executable Specification\nMathematica is a powerful computational platform. Its value de-\npends on whether expressiveness or formal rigor is the priority.\nStrengths of Mathematica\nCategory\nCapability\nSymbolic Computation\nExcellent for\npipelines, graphs,\nlatency models\nExecutability\nImmediate execu-\ntion and visualiza-\ntion\nExpressiveness\nSupports discrete,\ncontinuous, alge-\nbraic models\nRapid Prototyping\nRich in units,\nsemantics, interac-\ntivity\nLogic Tools\nFirst-order logic,\nSAT solving, quan-\ntifiers\nDocumentation\nNotebooks are\nself-contained and\nreproducible\nFigure 2: Strengths of Mathematica in\nsystem modeling\nLimitations Compared to Formal Languages\n• Formal Semantics: lacks type theory foundations (Coq, Lean).\n• Verification: no native model checking or invariant proofs.\n• Concurrency: no Lamport clocks or message-passing models.\n• Determinism: pattern matching may be nondeterministic.\n• Refinement: lacks formal spec-to-implementation pathways.\nSuitable Use Cases\n• Modeling tradeoffs in resource allocation,\n• Simulating flows using graph theory,\n• Prototyping performance constraints,\n• Symbolic scheduling and placement logic,\n• Writing executable whitepapers with computation and code.\nWhere It Falls Short\n• Verifying safety and liveness across all states,\n• Proving conformance or refinement,\n• Modeling concurrency and faults rigorously,\n• Integrating with RTL verification pipelines,\n• Participating in formal proof communities.\nmathematica as a specification language\n3\nSummary Judgment\nMathematica is:\n• Excellent for exploratory, high-level modeling and simulation,\n• Weak for formal verification, proofs, and correctness guarantees,\n• Valuable as a literate architecture spec tool, but not a full formal\nmethods platform.\nmathematica as a specification language\n4\nAppendix A: TLA+ Model – Rack-Aware Topology\nRackAwareSpec.tla\n------------------------------ MODULE RackAwareSpec ------------------------------\nEXTENDS Naturals, Sequences\nCONSTANTS Racks, Nodes, Links\nVARIABLES rackStatus, linkStatus, trafficMap\n(*--algorithm RackAware\nvariables rackStatus \\in [Racks -> {\"up\", \"down\"}],\nlinkStatus \\in [Links -> {\"up\", \"down\"}],\ntrafficMap \\in [Nodes -> [Nodes -> {\"ok\", \"blocked\", \"reroute\"}]];\ndefine\nIsAvailable(n) == \\E r \\in Racks: rackStatus[r] = \"up\" /\\ n \\in Nodes /\\ TRUE\nend define;\nbegin\nInit ==\n/\\ \\A r \\in Racks: rackStatus[r] = \"up\"\n/\\ \\A l \\in Links: linkStatus[l] = \"up\"\n/\\ \\A s, d \\in Nodes: trafficMap[s][d] = \"ok\";\nNext ==\n\\E r \\in Racks:\n/\\ rackStatus[r] = \"up\"\n/\\ rackStatus’ = [rackStatus EXCEPT ![r] = \"down\"]\n/\\ UNCHANGED <<linkStatus, trafficMap>>\n\\/ \\E l \\in Links:\n/\\ linkStatus[l] = \"up\"\n/\\ linkStatus’ = [linkStatus EXCEPT ![l] = \"down\"]\n/\\ UNCHANGED <<rackStatus, trafficMap>>;\nend algorithm;\n===============================================================================\nmathematica as a specification language\n5\nAppendix B: Alloy Model – Storage Placement Constraints\nStorageModel.als\nmodule StorageModel\nabstract sig Rack {}\nsig Node {\nhostRack: one Rack,\nstores: set Volume\n}\nsig Volume {\nreplicas: some Node\n}\nfact ReplicationFactor {\nall v: Volume | #v.replicas = 3\n}\nfact NoReplicaOnSameRack {\nall v: Volume |\nall disj n1, n2: v.replicas |\nn1.hostRack != n2.hostRack\n}\npred ShowExample {}\nrun ShowExample for 3 Rack, 6 Node, 2 Volume\n"
  },
  {
    "filename": "STANDALONE/TAR.pdf",
    "content": "Timeouts and Retries (TAR) are the Root of All Evil\nIntroduction\nTimeouts and retries, often abbreviated as TAR, are a ubiquitous\nmechanism used in database systems, distributed systems, and net-\nwork protocols to handle the inherent uncertainty of real-time and\ndistributed environments. While they seem to be essential for pro-\nviding fault tolerance and resilience, they can introduce significant\nanomalies, inefficiencies, and complexities into transaction systems,\noften leading to unintended consequences. This essay explores the\ninherent dangers and drawbacks of using timeouts and retries in\ndistributed systems and databases, with references to transaction\nanomalies such as deadlocks, inconsistent states, and race conditions.\nTransaction Anomalies in Database and Distributed Systems\nDistributed systems are inherently complex due to the need to coor-\ndinate and synchronize actions across multiple independent compo-\nnents. When an operation or transaction is executed in such systems,\ntimeouts and retries often serve as a safety net. However, these mech-\nanisms can create situations where the assumptions made about sys-\ntem state, consistency, and ordering are violated, leading to various\nanomalies.\n1. Deadlocks\nDeadlocks are a classic example of how retries can exacerbate sys-\ntem inefficiency and lead to the collapse of transaction systems. In\nthe context of databases and distributed systems, a deadlock oc-\ncurs when two or more transactions are waiting on each other to\nrelease resources, creating a cycle of dependencies that prevents any\nprogress.\nIn systems where timeouts and retries are implemented, retrying\na transaction without proper checks may inadvertently reintroduce\ndeadlock conditions. For example, if a transaction is retried after a\ntimeout, it may again attempt to lock resources that are already held\nby other transactions that have also been retried. This circular locking\ncan block all progress, making the system unresponsive.\nA well-known example of this is found in the two-phase locking\n(2PL) protocol, which ensures serializability by locking resources in\ntwo phases: growing and shrinking. However, when a retry mech-\nanism is used, it can trigger new locks in the growing phase, po-\ntentially creating cycles of contention. Researchers such as Korth-\ntimeouts and retries (tar) are the root of all evil\n2\nSilberschatz1986 in their paper on transaction management pointed\nout that deadlocks become more likely as retries increase without a\nsophisticated handling mechanism such as deadlock detection and\nresolution.\n2. Inconsistent States and Partial Transactions\nAnother significant issue that arises from timeouts and retries is\nthe risk of leaving the system in an inconsistent state. This happens\nwhen a transaction is retried after a timeout, but the system does not\nfully recover to a consistent state from the previous transaction. This\nis particularly problematic in databases that rely on ACID (Atomicity,\nConsistency, Isolation, Durability) properties.\nConsider a case in which a transaction performs multiple up-\ndates across several nodes in a distributed system. If the transaction\ntimes out during one of the updates, a retry may lead to some nodes\nprocessing the update while others do not. This results in a par-\ntial update that leaves the system in an inconsistent state, violating\nthe consistency property. In such cases, the system might end up\nwith conflicting data, where one part of the system believes the up-\ndate succeeded and another part believes it failed. Lamport1978 and\nBrewer2000 highlighted the challenges of maintaining consistency in\nthe face of network partitions and timeouts, especially in partitioned\nnetworks.\n3. Race Conditions\nRace conditions occur when the outcome of a transaction depends\non the non-deterministic ordering of events. In distributed systems,\ntimeouts and retries can inadvertently trigger race conditions, espe-\ncially when retries are not carefully synchronized with the system\nstate.\nFor example, in a distributed key-value store, a transaction might\nattempt to update a value after a timeout. If another transaction\nmodifies the value between the timeout and the retry, the retry might\noverwrite the changes made by the other transaction, resulting in lost\nupdates or incorrect states.\nThis situation is particularly problematic in distributed sys-\ntems that use eventual consistency models, such as in AmazonDy-\nnamo2007. These systems allow for some level of inconsistency dur-\ning network partitions, but if retries are triggered indiscriminately\nwithout checking for the most up-to-date state, it can lead to lost\nupdates, read anomalies, and inconsistent data across replicas.\ntimeouts and retries (tar) are the root of all evil\n3\n4. Resource Contention and Overload\nRetries, especially when triggered frequently, can lead to resource\ncontention and system overload. Systems with limited resources—whether\nCPU, memory, or I/O bandwidth—can be overwhelmed when mul-\ntiple retries are initiated simultaneously, especially in high-load sce-\nnarios. This can exacerbate performance issues, leading to increased\nlatency and slower response times, which in turn may lead to more\ntimeouts and retries, creating a vicious cycle.\nSystems such as GoogleSpanner2012, which provide distributed\ntransaction management and strong consistency, implement sophisti-\ncated mechanisms to avoid overloading nodes and ensure that retries\nare done in a manner that respects the system’s resources. Without\nthese controls, however, retries can amplify load on individual nodes,\nleading to cascading failures or congestion that degrades system\nperformance.\nMitigating the Risks of TAR\nTo avoid the pitfalls of timeouts and retries, several strategies can be\nemployed in distributed and database systems:\n• Exponential Backoff: One technique to prevent resource over-\nload and cascading failures is exponential backoff, where the delay\nbetween retries increases exponentially with each failure. This pre-\nvents retries from overwhelming the system and allows time for\ntransient failures to be resolved.\n• Idempotent Operations: Ensuring that retries are idempotent—that\nis, performing the same operation multiple times does not lead to\ndifferent results—can mitigate the risk of inconsistent states. This\nis especially important in distributed systems where retries might\nbe initiated by different nodes in the system.\n• Deadlock Detection and Resolution: Mechanisms for deadlock\ndetection and deadlock resolution (such as timeout-based aborts or\ntransaction rollback) can help manage the risks of retries leading\nto cyclic dependencies.\n• Optimistic Concurrency Control: Instead of relying on strict lock-\ning mechanisms, optimistic concurrency control (OCC) can allow\ntransactions to proceed without locking resources initially, and\nonly check for conflicts at commit time. This reduces the likeli-\nhood of deadlocks while still ensuring consistency.\ntimeouts and retries (tar) are the root of all evil\n4\nConclusion\nWhile timeouts and retries are essential for fault tolerance and re-\nsilience in distributed systems, they are not without significant\nrisks. By introducing potential deadlocks, inconsistent states, and\nrace conditions, these mechanisms can wreak havoc on the stability\nand correctness of systems, especially when not implemented with\ncare. As we continue to build more complex distributed systems and\ndatabases, it is crucial to design retry mechanisms that respect the\nconsistency, isolation, and atomicity of transactions to avoid the root\nof all evil: the transaction anomalies introduced by timeouts and\nretries.\nReferences\nH. F. Korth and A. Silberschatz, “Transaction management,” ACM\nComputing Surveys, vol. 18, no. 1, pp. 45–80, 1986.\nL. Lamport, “Time, clocks, and the ordering of events in a distributed\nsystem,” Communications of the ACM, vol. 21, no. 7, pp. 558-565,\n1978.\nE. Brewer, “CAP twelve years later: How the \"rules\" have changed,”\nComputer, vol. 45, no. 2, pp. 23–29, 2000.\nG. DeCandia et al., “Dynamo: Amazon’s highly available key-value\nstore,” ACM SIGOPS Operating Systems Review, vol. 41, no. 6, pp.\n205–220, 2007.\nJ. C. Corbett et al., “Spanner: Google’s globally distributed database,”\nACM Transactions on Computer Systems, vol. 31, no. 3, pp. 1–17, 2012.\n"
  },
  {
    "filename": "STANDALONE/Link-beat.pdf",
    "content": "Understanding Link Beat in Ethernet\nPaul Borrill\nMay 14, 2025\nWhat is Link Beat?\nLink beat is a continuous signal sent at the physical layer between\ntwo Ethernet devices to verify the presence and readiness of a work-\ning connection. It originated in the 10BASE-T standard and evolved\nacross Fast Ethernet, Gigabit Ethernet, and beyond.\nFigure 1: Link beat at the Physi-\ncal Layer. One device transmits\nperiodic link beat signals to\nconfirm cable and device pres-\nence.\nFunctions of Link Beat\n• Cable Detection: If link beat is missing, the remote device may be\npowered off or disconnected.\n• Link Status Monitoring: Loss of link beat causes the NIC to re-\nport the link as down.\n• Auto-Negotiation Support: In Fast Ethernet (100BASE-TX) and\nbeyond, link beat pulses are replaced or augmented by encoded\nsignals supporting speed and duplex negotiation.\nHistorical Context\n• 10BASE-T: Used Normal Link Pulses (NLP) every 16 ms to maintain\nlink integrity.\n• 100BASE-TX: Introduced Fast Link Pulses (FLP) for auto-negotiation.\n• 1000BASE-T and beyond: Replaced pulses with continuous idle\ndata streams, but the principle of keeping the link alive remained.\nPractical Implications\n• LED Indicators: Link LEDs on NICs and switches depend on link\nbeat to indicate status.\n• Diagnostics: Network diagnostic tools check for link beat when\ntroubleshooting.\n• Power-Saving Modes: Some PHYs shut down when no link beat is\nreceived.\nunderstanding link beat in ethernet\n2\nConclusion\nThe concept of link beat is foundational to Ethernet’s ability to man-\nage and maintain physical connectivity. While implementations have\nevolved, the idea of a heartbeat signal between peers to confirm link\nhealth remains central to Ethernet’s design.\nunderstanding link beat in ethernet\n3\nLink Negotiation\nNo More Half-Duplex\nStarting at 1Gbps and above, Ethernet standards began to deprecate\nhalf-duplex operation. For 25GbE, 50GbE, 100GbE, and beyond,\nonly full-duplex is supported. Half-duplex behavior and its associ-\nated collision detection mechanism (CSMA/CD) are not needed in\nmodern point-to-point links.\nethernet-autoneg-diagram.png\nFigure 2: Auto-negotiation and\nlink training in modern Ether-\nnet determine lane count, FEC,\nand electrical adaptation—not\nduplex.\nAuto-Negotiation Still Exists\nModern high-speed Ethernet continues to use auto-negotiation, but\nfor different parameters:\n• Lane count and mapping (1-lane vs 4-lane)\n• FEC (Forward Error Correction) capability negotiation\n• Link training sequences (e.g., PAM4 adaptation)\n• Power management (EEE)\nThis is defined in IEEE 802.3 Clause 73 and is widely used in\n25G/50G/100G Ethernet deployments, especially on copper direct-\nattach and backplane links.\nCrossover Cables Are Obsolete\nThe old issue of needing crossover cables (Tx/Rx mismatches) was\nsolved in two ways:\n1. Auto-MDI/MDI-X for twisted pair links (up to 10GBASE-T)\n2. Dedicated SerDes lanes for 25Gbps and higher speeds—each\ndirection has a dedicated lane\nModern SFP+/QSFP+/OSFP modules and DACs are engineered\nto prevent miswiring. There’s no concept of \"crossing\" in high-speed\nserial links.\nSummary Table\nConclusion\nIn modern Ethernet, the duplex mode is always full, and crossover\nissues have been eliminated. Negotiation now focuses on electri-\ncal characteristics, coding options, and forward error correction,\nunderstanding link beat in ethernet\n4\nFeature\n1GbE and Below\n10GbE\n25GbE and Above\nHalf-Duplex Support\nYes\nNo\nNo\nCSMA/CD\nYes\nNo\nNo\nAuto-Negotiation\nSpeed, Duplex\nFEC, Training\nLanes, FEC, Training\nAuto-MDI/MDI-X\nYes\nYes (10GBASE-T)\nN/A (SerDes only)\nCrossover Cable Required\nSometimes\nNo\nNo\nTable 1: Comparison of Du-\nplex and Negotiation Features\nAcross Ethernet Speeds\nallowing Ethernet to scale smoothly beyond 100Gbps and into the\n800Gb/1.6Tb era.\nunderstanding link beat in ethernet\n5\nSection THREE\nWhat is a Unidirectional Failure?\nA unidirectional failure occurs when one side of a full-duplex Ether-\nnet link can transmit but cannot receive—or vice versa. This results in\nasymmetric link perception: one endpoint may believe the link is up,\nwhile the other detects failure.\nunidirectional-failure.png\nFigure 3: In this scenario, Side\nB cannot receive from Side A,\nbut Side A is still receiving\nB’s signal. Side B transmits a\nRemote Fault Indication (RFI)\nback to Side A, which then\nmarks the link as down.\nDetection and Recovery Mechanisms\nModern Ethernet (10G and above) uses multiple layered mechanisms\nto detect and propagate unidirectional failures:\n• Loss of Signal (LOS) and Loss of Block Lock (LoBL) are detected\nat the receiver.\n• The receiver experiencing failure sends a Remote Fault Indication\n(RFI) back to the peer.\n• Upon receiving RFI, the transmitter’s side also drops the link,\npreventing inconsistent link states.\nWhy Half-Duplex Is Irrelevant\nIn legacy Ethernet, half-duplex could allow for ambiguous fault\nstates. Modern Ethernet is strictly full-duplex and point-to-point,\nmeaning both transmit and receive paths must function simultane-\nously for the link to remain up.\nStandard Behaviors\n• During link training: failure to receive training sequences causes\ntimeout and abort.\n• During normal operation: missing control blocks, misalignment,\nor failed FEC triggers fault signaling.\nConclusion\nUnidirectional failures are an important consideration in high-speed\nlinks. Modern Ethernet handles these failures through robust fault\nsignaling, ensuring that a failed receive path leads to a complete link\nshutdown—eliminating the possibility of silent blackholing of traffic.\n"
  },
  {
    "filename": "STANDALONE/Ethernet-extended.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\nextending ethernet\n1\nFig.1. Two-segment Ethernet\nTERMINATOR\nETHER SEGMENT #2\nTAP\nREPEATER\nI\nN\nT\nE\nR\nF\nA\nC\nE\nC\nO\nN\nT\nT\nR\nO\nL\nL\nE\nR\nSTATION\nE\nT\nH\nE\nR\nS\nE\nG\nM\nE\nN\nT\n#\n1\nTRANS-\nCEIVER\nI\nN\nT\nE\nR\nF\nA\nC\nE\nC\nO\nN\nT\nT\nR\nO\nL\nL\nE\nR\nSTATION\nTRANS-\nCEIVER\nTRANS-\nCEIVER\nTRANS-\nCEIVER\nSTATION\nINTERFACE\nCONTROLLER\nTRANS-\nCEIVER\nINTERFACE\nCABLE\nFigure 1: Original Ethernet Repeater )\n8-WAY \nREPEATER\nTRANS-\nCEIVER\nTRANS-\nCEIVER\n8-WAY \nREPEATER\nTRANS-\nCEIVER\nTRANS-\nCEIVER\nTRANS-\nCEIVER\nTRANS-\nCEIVER\nTRANS-\nCEIVER\nTRANS-\nCEIVER\nTRANS-\nCEIVER\nFigure 2: Original Ethernet Repeater\nextended from valency-2 to valency-8)\nExtending Ethernet\nRepeater, not Switch, not Router\n• “The Parc Ethernet was Manchester, but not high voltage alter-\nnating with low voltage. The cable was not driven or driven, on\nor off, leaving the cable off/undriven half the time, so that colli-\nsions could be detected. Half the time during a packet the cable\nwould be undriven. Clock was recovered from transitions to or\nfrom driven state in the middle of each bit cell.”\n• “I remember waking up, screaming in the night, terrified we\ncouldn’t get our transceivers under 4 picofarads”\n• “Wondering if some sort of BACKOFF THEORY would be deep\nenough for a talk at Ethernet’s 50th and the SmartNIC keynote\nand . . . ”\n• “Ethernet doesn’t work in Theory, it only works in Practice”\n• “Close the Loop”\n"
  },
  {
    "filename": "STANDALONE/Thermodynamics.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\næthernet: ultra low latency (ull)\n1\nTHERMODYNAMICS\nFinite State Automata\nThermodynamics of deterministic finite automata operating locally\nand periodically\nDavid Wolpert et al. We claim that if a minimal DFA is non-\ninvertible, any DFA that accepts the same language must also be\nnon-invertible.\n"
  },
  {
    "filename": "STANDALONE/Derecho.pdf",
    "content": "Should Ethernet 25 Implement Endpoint Status\nTracking?\nKen Birman — Cornell University\nPaul Borrill — DÆDÆLUS\n“Please review this document, and provide a full LATEX (Tufte) docu-\nment from this (not a summary).”\nConcept: A Membership Tracking Service\nDerecho: Fast State Machine Replication for Cloud Services\nS. Jha et al., ACM TOCS, 2019.\nhttps://doi.org/10.1145/3302258\nSuppose that Ethernet 25 Network Interface Cards (NICs) could\nreport the health status of IP endpoints within a datacenter, distin-\nguishing\nhealthy\n/\n{ unreachable or failed }\nwhere the latter class conflates link failures and node failures.\nThis capability can be realized by running a partition-tolerant con-\nsensus protocol on the membership list itself. Should a “primary parti-\ntion” fragment (e. g. the entire FAT-tree router spine loses power), the\nsystem reports loss of primary partition to all datacenter nodes.\nAn optimal fault-tolerant protocol of this kind is implemented in\nDerecho. Sub-optimal but familiar alternatives include ZooKeeper,\nRaFT, Paxos, and others. (Note: crash failures only; this is not a\nBFT proposal.) All center on a three-phase transition that requires a\nquorum to change the membership list from A to B. The protocol and\nthe list itself could reside directly in Ethernet 25 NICs.\nHow Would We Use This Data?\n• TCP could proactively break connections to endpoints flagged\nunreachable.\n• Ethernet drivers could signal applications to reread data whenever\nit changes.\n• As with ZooKeeper, applications would normally view a filtered\nsubset (their own peering pattern) and re-configure if a critical\ncomponent crashes.\nshould ethernet 25 implement endpoint status tracking?\n2\nThe Virtual Synchrony model—deployed in the French Air-Traffic-Control\nsystem since 1996 with zero disruption and in the NYSE trading\nfloor (1997–2007)—illustrates decades of operational success. “Virtu-\nally Synchronous Paxos” is a Vertical-Paxos variant that builds on the\nsame ideas.\nValue Add\n• Datacenter-wide consistency on service health.\n• Eliminates hung endpoints due to link or software faults; both\ncollapse to clean shutdown, repair, and restart.\n• Enables atomic primitives (compare-and-swap, token passing),\nfault-tolerant replication (Paxos-style logs), and database transac-\ntions.\n• Combined with NIC-level synchronized clocks (a separate proposal)\nit simplifies fault-tolerant sensors, actuators, and high-precision\nhardware control.\n• Particularly valuable for GPU-to-GPU RDMA bypass or any\n“data-path offload” fabric communications.\nDerecho Protocols\n• Open source, fully implemented in C++: https://github.com/\nDerecho-Project\n• Underwent rigorous ACM TOCS peer review; formal proofs are\nmachine-verified by multiple groups.\n• Membership tracking is a tiny portion of the code base and remark-\nably simple.\n• Lightweight enough for a small NIC coprocessor.\n• Can extend to track rack-level topology, enabling latency-aware or\nfault-independent placement policies.\nWhich NICs Would Run the Protocol?\n• Conceptually, every NIC could participate, yet functionality can be\ndelegated to a capable subset.\n• Bootstrap via a self-stabilizing algorithm (e. g. Dolev’s ring forma-\ntion). The first N processes in the ring then run the membership\nservice.\nshould ethernet 25 implement endpoint status tracking?\n3\n• Extension: allow minority partitions to form and self-heal (Transis\nwork, 1990s). Not advocated for typical datacenters but applicable\nelsewhere.\n• Failure detection is pluggable: hardware sensors, OS heartbeats,\nmissing keep-alives, etc.\nSecurity Implications\n1. Today’s datacenters often expose a Virtually Private Cloud (VPC)\nabstraction, whereas rack-scale systems may offer bare metal. Both\nmust be supported.\n2. Within a VPC, the NIC filters membership and topology data,\nrevealing only resources owned by the tenant.\n3. Topology schemas are configurable; undisclosable properties are\nreported as “not available.”\n4. The proposal standardizes membership tracking; it does not leak\nnew information beyond what operators already gather.\nWhy Derecho Instead of RaFT, MPI, LibPaxos, etc.?\n• The standard could remain agnostic and allow plug-and-play proto-\ncols.\n• Derecho excels where others fall short:\n– Stronger model than MPI.\n– Scales far beyond typical RaFT or LibPaxos deployments.\n– Provably optimal; extremely efficient over RDMA or comparable\nfabrics.\n• Ethernet 25 would standardize only the membership element;\nhigher-layer libraries (MPI, NCCL, etc.) continue exactly as today.\nReferences\n1. S.Jha, K. Birman, et al “Derecho: Fast State Machine Replication\nfor Cloud Services,” ACM Transactions on Computer Systems,\nvol. 36, no. 2, 2019.\nDOI: https://doi.org/10.1145/3302258\n2. Derecho Project Repository.\nhttps://github.com/Derecho-Project\n"
  },
  {
    "filename": "STANDALONE/Promiscuous-Bandwidth.pdf",
    "content": "Toward Understanding Bandwidth on Ethernet\nAnjali Singhai-Jain, Paul Borrill, Sahas Mulamala, et. al.\nEthernet, the omnipresent fabric of modern digital communication,\nconceals a fragile dance of assumptions about time, causality, and\natomicity. This essay explores evolving notions of bandwidth—from\nMetcalfe’s original insights to today’s speculative sprays—and pro-\nposes new terminology to characterize pathological inefficiencies like\n“promiscuous bandwidth” and “imposition mode.” We argue that such\ninefficiencies not only waste energy but can induce metastable failures\nand “limpware” phenomena in datacenter systems.\nHistorical Context: Metcalfe’s Bandwidth\nIn the earliest days of Ethernet, bandwidth was understood as a\nshared medium—coaxial, half-duplex, and best-effort. Bob Met-\ncalfe’s classic cartoon of a chaotic Ethernet bus reflects an intuitive\nyet powerful model: when many nodes contend for access, the ef-\nfective throughput is not the raw link speed but something lower,\nshaped by collisions, backoff, and fairness.\nOver time, Ethernet evolved—switched fabrics, full-duplex links,\nand link-layer flow control increased raw throughput. But Metcalfe’s\ninsight remains: effective bandwidth is always lower than physical band-\nwidth.\nThis difference between ideal and real motivates two critical dis-\ntinctions:\n• Goodput: the rate of successful, meaningful delivery of data.\n• Badput: the rate of packets dropped, retransmitted, misordered, or\notherwise wasted.\nWe argue that new networking behaviors—particularly speculative\ntransmission and packet spraying—have inverted these ratios in\ncertain systems, creating what we call “promiscuous bandwidth.”\nPromiscuous Bandwidth and Speculative Spraying\nIn modern hyperscale datacenters, many protocols attempt to outwit\ncongestion using speculative packet spraying: duplicate packets\nare sent along multiple paths, with the hope that one will arrive\nfaster or avoid congestion. Homa and variants of ECMP (Equal-Cost\nMultipath) embody this.\nBut such schemes:\n(a) Waste link capacity on duplicates,\ntoward understanding bandwidth on ethernet\n2\n(b) Increase buffer pressure on intermediate switches,\n(c) Confuse receiver-side recovery buffers,\n(d) Impose significant energy costs per dropped packet.\nWe call the result promiscuous bandwidth—capacity consumed\nwithout commitment. Just as a promiscuous node listens to all traffic,\na promiscuous flow consumes as much bandwidth as it can without\nguaranteeing completion.\nImposition Mode and Receiver Black Holes\nFurther, we observe that in speculative or disordered environments,\nthe receiver may become a black hole for bandwidth: accepting\npackets that are out-of-order, unschedulable, or awaiting reassembly\nbehind a missing segment.\nWe define:\nImposition Mode\nA mode in which the sender imposes responsibility for re-\ncovery on the receiver—delivering partial or disordered data\nwithout regard for atomicity or semantic alignment.\nIn Imposition Mode:\n• Buffers fill with speculative or unordered fragments.\n• CPU and DMA cycles are consumed by data that may never be\nuseful.\n• Retry logic may interfere with RDMA or shared memory seman-\ntics.\nAtomicity and the Myth of Recoverable Order\nEthernet offers no guarantee of atomicity. When packets are sprayed\nor reordered, the receiver must reconstruct intent from fragments.\nBut recovery buffers, such as those in TCP stacks, RDMA NICs, or\napplication-level state machines, often require assumptions of causal\nor temporal order.\nWe summarize a key failure:\nYou can’t replay order from entropy.\nWithout reliable atomicity or ordering signals (e.g., ACKs, times-\ntamps, causal fencing), recovery becomes probabilistic and error-\nprone. And as retry storms begin, energy is wasted not only in trans-\nmission but also in retransmission.\ntoward understanding bandwidth on ethernet\n3\nTimeouts and Retries: The TAR Trap\nThis brings us to the TAR syndrome: Timeouts and Retries.\nIn high-speed networks, a small delay can trigger large-scale re-\ntries. This creates the risk of:\n• Limpware: Systems slow down under partial failure conditions,\nrather than crashing. Performance becomes non-deterministic and\nunbounded.\n• Metastable Failure: Feedback loops in retry logic can lead to\nprolonged states where recovery is impossible without human\nintervention.\nThese effects are especially toxic in distributed systems that rely\non strict message ordering, such as transactional databases or consen-\nsus protocols.\nConclusion: Toward Epistemic Bandwidth\nWe propose a new direction: Epistemic Bandwidth—the fraction\nof link capacity used to transmit knowable, actionable, and confirmed\ninformation. This echoes the epistemic models of quantum theory,\nwhere what matters is not the reality of the packet, but what the\nreceiver knows has been received.\nTo recover Ethernet’s future, we must:\n• Reject speculative excess.\n• Embrace causality and atomic transmission units.\n• Embed acknowledgment, reversibility, and trust into the fabric\nitself.\nBandwidth is not just bits per second. It is bits that matter. Under-\nstanding—and designing for—that distinction will define the next era\nof networking.\n"
  },
  {
    "filename": "STANDALONE/Triangle.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\næthernet: ultra low latency (ull)\n1\nTriangle Networks to the Rescue\nFigure 1: Triangle Networks [Ref]\nÆthernet requires directly connected networks, it will fail if we con-\nnect through a switched (Clos) Network instead of connecting di-\nrectly.1\nIt is not possible to achieve reliability\nthrough a switch. Temporal intimacy\nrequires immediate link knowledge. We\nlose Temporal Intimacy, and the paired\nShannon Information, when switches\nDrop, Reorder, Duplicate and delay\nmessages.\n1 Add to Glossary\nFigure 2: Quantum Triangle Tree A\nFigure 3: Quantum TriangleTree B\nFigure 4: Quantum Triangle Tree C\nQuantum Networking folks discovered Triangle Networks\nThe Æthernet protocol is designed to be exquisitely sensitive to\npacket loss and corruption.\nIt can monitor, detect, diagnose link failures, and recover re-\nversibly and automatically locally using triangle networks.\n• It takes two to tango. It takes three to party.\n• Problem: Status of each link is unknown\n• Use-case: PTP Trees. How do you spot the “signatures of loss of\nsynchronization”?\n• Solution: Self-Healing Communication Trees2\n2 Self-Healing Communication Trees\n(Patented 2005)\n• Three Trees (Blue, Green Red) are shown on the right. Without\nat least 3 directly connected nodes, it is impossible to guarantee\nTemporal intimacy, and with it:\n– Exactly-Once Semantics\n• IEEE 1588 has 256 Trees\nkeynote\n"
  },
  {
    "filename": "STANDALONE/ML-operands.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\nOperand Sizes in Sliceable Ethernet and Machine\nLearning Alignment\nChatGPT, Paul Borrill, et. al.\nThis document explores the operand sizes made available by a re-\ndesigned sliceable Ethernet frame format and compares them with\noperand granularities common in machine learning (ML) workloads,\nespecially in the context of tensor and vector operations used in accel-\nerators such as GPUs, TPUs, and NPUs.\nEthernet Operand Framing\nWe propose a fixed 64-byte Ethernet frame that is:\n• Pre-emptible on 8-byte slice boundaries, and\n• Extensible via beat multiples (2, 4, 8 slices).\nEach frame reserves 4 bytes for an operator tag. The remaining\nspace (after operator) constitutes the operand payload:\nPayload  (60B)\nOperator (4B)\n8 Slices\nOperand\nFigure 1: Illustrative slicing: 64-byte\nframe divided into 8-byte slices [See\nfull set of operand sizes in protocol\ndocument].\nSlices\nOperand Size\nInterpretation\n1 slice\n4 bytes\nFP32 scalar\n2 slices\n12 bytes\n3 × FP32 (RGB or XYZ vector)\n4 slices\n28 bytes\n7 × FP32 or 14 × FP16\n8 slices\n60 bytes\n15 × FP32 or 60 × INT8\nMachine Learning Operand Patterns\nCommon operand formats in machine learning include:\n• FP32 (4 bytes): Standard for training.\n• FP16/BF16 (2 bytes): Popular for inference and memory efficiency.\n• INT8 (1 byte): Quantized inference, widely adopted in edge and\ncloud ML.\nOperand Size Alignment\n• 4 bytes: Matches FP32 scalar inputs for neural units or simple\noperations.\n• 12 bytes: Ideal for 3-component vectors (e.g., color, motion, geom-\netry).\n• 28 bytes: Fits odd vector lengths—7 FP32, 14 FP16. Useful for\nSIMD batch ops.\noperand sizes in sliceable ethernet and machine learning alignment\n2\n• 60 bytes: Aligns well with:\n– Tensor tiles: 15× FP32 (15-wide row in matrix multiply),\n– 30× FP16, or\n– 60× INT8—common in INT8 matrix multiplication blocks.\nArchitectural Fit\nThese sizes offer strong alignment with:\n• SIMD/SIMT register widths, such as AVX-512 (64-byte lanes),\n• Tile-based ML accelerators, e.g., TPU systolic cells or NVIDIA\nTensor Cores,\n• Network-on-Chip (NoC) optimizations in AI SoCs,\n• Efficient coalescing and alignment for RDMA and SmartNIC of-\nfload operations.\nConclusion\nThe operand sizes in this sliceable Ethernet design match surpris-\ningly well with operand block structures commonly used in ma-\nchine learning. This suggests the protocol could serve dual purposes:\ngeneral-purpose communication and operand dispatch for compute\nfabrics with integrated ML acceleration.\n"
  },
  {
    "filename": "STANDALONE/Zero-Not-Natural.pdf",
    "content": "Zero: The Natural Number That Isn’t\nDÆ Team, et. al.\nMay 20, 2025\nZero is arguably the most fascinating number in mathematics, occupy-\ning a uniquely paradoxical position in our number systems. It serves\nas both a placeholder and a quantity in its own right, a concept that\nrevolutionized mathematics when fully developed. Yet despite its\nfundamental importance, zero’s classification remains a point of con-\ntention, particularly regarding whether it belongs among the natural\nnumbers.\nA\nFigure 1: Various historical representa-\ntions of zero across civilizations.\nThe question of zero’s status as a natural number isn’t merely\nsemantic—it reflects deeper mathematical principles and has practical\nimplications for how we define foundational concepts.\nHistorical Development\nThe concept of zero emerged independently in several ancient civ-\nilizations. The Babylonians used a placeholder symbol for zero\naround 300 BCE, while the Mayans developed a complete zero sym-\nbol around 350 CE. However, it was in India where zero was first\ntreated as a proper number, with Brahmagupta establishing formal\narithmetic rules for zero in the 7th century CE.\nB\nrahmagupta’s rules included defining a −a = 0 and a × 0 = 0,\nbut he struggled with division by zero, a problem that continues to\nchallenge students today.\nMathematicians throughout history have disagreed about zero’s\nclassification. The ancient Greeks, whose work heavily influenced\nWestern mathematics, had no concept of zero as a number. When\nEuropean mathematics eventually incorporated zero, disagreements\nabout its nature persisted.\nSet-Theoretic Foundations\nIn modern mathematics, natural numbers are typically defined using\nset theory. The two predominant approaches yield different results\nregarding zero:\n1. Von Neumann ordinals: Define natural numbers recursively\nwhere 0 = ∅(the empty set), 1 = {0} = {∅}, 2 = {0, 1} =\n{∅, {∅}}, and so on. In this construction, zero is the first natural\nnumber.\n2. Zermelo ordinals: Define 1 as {∅}, 2 as {{∅}}, etc. Here, count-\ning begins at 1, excluding zero from the natural numbers.\nzero: the natural number that isn’t\n2\nT\nhe choice between these constructions reveals a fundamental\nquestion: Is mathematics primarily about counting (starting at 1) or\nabout formal structures (where starting at 0 offers advantages)?\nThis fundamental distinction reflects different mathematical\nperspectives on what counting means.\nMathematical Arguments\nSeveral compelling mathematical arguments support excluding zero\nfrom the natural numbers:\n1. Etymology and intuition: “Natural numbers” traditionally refer\nto the counting numbers used in everyday life. When counting\nobjects, we begin with one, not zero.\n2. Multiplicative properties: The natural numbers form a monoid\nunder multiplication with identity element 1. Including zero\nbreaks this structure since zero lacks a multiplicative inverse.\n3. Division: In the natural numbers excluding zero, division (when\ndefined) always yields a unique result. Including zero introduces\ncomplications, as division by zero is undefined.\n4. Induction principle: Mathematical induction typically starts with\na base case of n = 1, implicitly excluding zero from consideration.\nB\nFigure 2: Visualization of the multi-\nplicative monoid structure of natural\nnumbers without zero.\nNotational Clarity\nTo avoid ambiguity, mathematicians have developed notational\nconventions:\n• N or N1: Natural numbers starting from 1\n• N0 or N ∪{0}: Natural numbers including zero\nThis notation allows mathematicians to be precise about whether\nthey include zero when referring to natural numbers.\nThe International Standards Organiza-\ntion (ISO 80000-2) defines N as starting\nfrom 1, while many computer scientists\nand set theorists prefer to include 0.\nPractical Implications\nWhether zero is included among the natural numbers has substantial\nimplications in various mathematical contexts:\n• In combinatorics, excluding zero aligns with counting principles\n(you can’t have zero of something when counting discrete objects)\nzero: the natural number that isn’t\n3\n• In number theory, including zero simplifies many formulations\n• In computer science, zero-based indexing (starting array indices at\n0) has proven advantageous for algorithm implementation\nC\nFigure 3: Example of zero-based\nindexing in computer programming.\nThe Deeper Meaning\nThe debate about zero’s status reveals a profound truth: mathemat-\nical classifications aren’t discovered in nature but constructed by\nhumans based on utility and consistency. The question “Is zero a\nnatural number?” ultimately depends on the mathematical context\nand purpose.\nThis ambiguity isn’t a flaw in mathematics but a reflection of its\nadaptability. Mathematical structures can be defined in different\nways to serve different purposes, and these definitions are judged by\ntheir usefulness and elegance rather than absolute correctness.\nZero remains the bridge between positive and negative num-\nbers, neither fully belonging to either domain yet essential to both.\nPerhaps this liminal position is precisely what makes zero so mathe-\nmatically powerful—it stands at the boundary, connecting different\nmathematical realms.\nThe natural numbers may have begun as simple counting tools,\nbut mathematics has evolved into a sophisticated framework where\neven our most basic numerical concepts reveal surprising complexity.\nZero’s contested status reminds us that mathematics, despite its\nreputation for certainty, contains fundamental questions whose\nanswers depend on perspective.\n"
  },
  {
    "filename": "STANDALONE/Counting-Protocols-tufte.pdf",
    "content": "Beyond One-Way Counting: A Conserved Quanti-\nties Framework for Network Communication\nDÆDÆLUS Team. See acknowledgements for contributors\nMay 20, 2025\nCurrent network protocols predominantly rely on monotonically in-\ncreasing sequence numbers to track packet delivery and ordering. This\npaper presents a fundamental critique of this approach, particularly\nfocusing on TCP’s one-way counting mechanism, and proposes an\nalternative framework based on conserved quantities (CQ). We demon-\nstrate how a symmetrical accounting system using the balanced set of\nvalues {−∞, −1, −0, +0, +∞} can address fundamental limitations in\ncurrent protocols. The CQ framework provides a more robust mathe-\nmatical foundation for handling communication imbalances, enabling\nmore efficient error recovery, and supporting deterministic implemen-\ntations in hardware. Mathematical analysis shows that this framework\nreduces state complexity while increasing the protocol’s expressive\npower. An implementation specification suitable for FPGA testing is\nprovided in the appendix.\nIntroduction\nNetwork protocols, particularly the Transmission Control Protocol\n(TCP), have served as the backbone of internet communication for\ndecades. TCP’s reliability mechanism depends fundamentally on\nmonotonically increasing sequence numbers—a one-way counting\nprotocol that only increments. While serviceable, this approach has\ninherent mathematical and practical limitations that become increas-\ningly apparent as network environments grow more diverse and\ndemanding.\nThis paper examines these limitations and proposes an alterna-\ntive mathematical framework based on conserved quantities (CQ).\nThe CQ approach utilizes a symmetrical accounting system where\nimbalances between communicating entities are tracked using the\nset {−∞, −1, −0, +0, +∞}, representing states of information deficit,\nbalance, and surplus.\nLimitations of One-Way Counting Protocols\nMathematical Limitations\nTCP’s sequence number mechanism can be represented as a mono-\ntonically increasing function S : N →Z232, where S(p) is the se-\nquence number assigned to packet p. This creates several mathemati-\ncal constraints:\n1\nAll Rights Reserved — Atomic Ethernet Industry Association (AEIA) 2025\nbeyond one-way counting: a conserved quantities framework for network communication\n2\n1. Wrapping Ambiguity: Since S maps into a finite cyclic group\n(Z232), distinguishing between sequence number wrap-around and\npacket reordering requires additional mechanisms.\n2. Asymmetric Information Model: When a packet is lost, the\nsender and receiver develop different views of the communica-\ntion state that cannot be directly reconciled through the sequence\nnumbers alone.\n3. Incomplete State Representation: The current state of communi-\ncation is represented as a point on a single axis (the next expected\nsequence number), which fails to capture the multidimensional\nnature of the actual communication state.\nLet us define a packet transmission event as a tuple (s, r, i) where s\nis the sender state, r is the receiver state, and i is the information con-\ntent. In TCP, the states s and r are simply the next sequence numbers\nto send and receive, respectively. This limited representation forces\ncomplex state reconstruction during failure recovery.\nPractical Limitations\nThe one-way counting model creates several practical issues:\n1. Complex Recovery Logic: After packet loss, extensive buffering\nand retransmission logic is required to reconstruct the intended\nstate.\n2. Inefficient Resource Utilization: The sender must maintain copies\nof all unacknowledged data, regardless of whether the receiver\nactually needs it.\n3. Implementation Complexity: Hardware implementations (e.g.,\nin FPGAs) must handle complex corner cases arising from the\nasymmetric information model.\n4. Non-deterministic Behavior: The recovery process often in-\ncorporates timeout-based mechanisms which introduce non-\ndeterminism.\nConserved Quantities Framework\nMathematical Foundation\nWe propose a framework based on conserved quantities, where the\ncommunication state is represented as a balance between sender and\nreceiver. Define:\nAll Rights Reserved — Atomic Ethernet Industry Association (AEIA) 2025\nbeyond one-way counting: a conserved quantities framework for network communication\n3\nDefinition 1 (Information Balance). Let B(t) represent the information\nbalance between sender and receiver at time t, where:\n• B(t) < 0 indicates the receiver needs information from the sender\n• B(t) = 0 indicates perfect balance\n• B(t) > 0 indicates the sender has transmitted information not yet\nprocessed by the receiver\nRather than monotonically increasing counters, we use a set of dis-\ncrete values {−∞, −1, −0, +0, +∞} to represent the state of balance:\n• −∞: Receiver has no knowledge of sender’s state\n• −1: Receiver needs specific information from sender\n• −0: Receiver is in balance but anticipates negative imbalance\n• +0: Receiver is in balance but anticipates positive imbalance\n• +∞: Receiver has complete knowledge of sender’s state\nMathematical Properties\nThe CQ framework exhibits several important mathematical proper-\nties:\nTheorem 1 (Conservation Law). In an ideal network with no packet loss,\nthe sum of all information balances across the network remains constant\nover time.\nProof. Consider two nodes A and B with initial balance BAB(0) =\n0. For any information i sent from A to B, we have BAB(t + 1) =\nBAB(t) + |i| and BBA(t + 1) = BBA(t) −|i|. Therefore, BAB(t + 1) +\nBBA(t + 1) = BAB(t) + BBA(t).\nLemma 1 (Balance Transitivity). If node A is balanced with node B, and\nnode B is balanced with node C, then A and C can achieve balance with\nexactly one exchange of information.\nThis property allows for efficient multi-hop protocols that main-\ntain balance throughout the network.\nAlgebraic Structure\nThe imbalance states form a group-like structure with operations:\n• Addition: Combining two imbalances, e.g., (−1) + (−1) = −∞\n• Inversion: Reversing an imbalance, e.g., −(+1) = −1\nAll Rights Reserved — Atomic Ethernet Industry Association (AEIA) 2025\nbeyond one-way counting: a conserved quantities framework for network communication\n4\n• Identity: The states {−0, +0} operate as near-identity elements\nThe algebraic structure is not a traditional group because it has\ntwo near-identity elements, but it forms a richer structure that more\naccurately captures network communication states.\nProtocol Design\nFrame Format\nEach frame in the CQ protocol contains:\n• Source and destination identifiers\n• Current balance indicator ({−∞, −1, −0, +0, +∞})\n• Operation type (data, acknowledgment, request, response)\n• Payload (if applicable)\n• Integrity check\nState Transitions\nState transitions in the CQ framework follow a more symmetric pat-\ntern than in TCP. Let SA and SB be the states of nodes A and B, re-\nspectively:\n• When A sends data to B: SA changes from +0 to +1 and eventu-\nally back to +0 upon acknowledgment\n• When B requests data from A: SB changes from +0 to −1 and\nback to +0 upon receiving data\nMathematical Analysis of Efficiency\nLet us analyze the communication overhead in both TCP and CQ\nframeworks:\nFor TCP, to transmit n packets with no loss requires:\nCTCP = n + ⌈n\nw⌉\n(1)\nwhere w is the window size and the second term represents acknowl-\nedgments.\nFor the CQ framework:\nCCQ = n + δ(n)\n(2)\nwhere δ(n) represents the imbalance correction messages, which\napproach a constant value as n increases.\nAll Rights Reserved — Atomic Ethernet Industry Association (AEIA) 2025\nbeyond one-way counting: a conserved quantities framework for network communication\n5\nTherefore, asymptotically:\nlim\nn→∞\nCCQ\nCTCP\n< 1\n(3)\nError Handling and Recovery\nMathematical Model of Failure Recovery\nIn TCP, recovering from packet loss requires retransmitting from the\nlast acknowledged sequence number, potentially sending already-\nreceived packets.\nIn the CQ framework, recovery is more precise. When a balance\nof −1 is detected, only the specific missing information is requested.\nThis can be modeled as a graph traversal problem:\nLet G = (V, E) be a directed graph where vertices V represent\ncommunication states and edges E represent possible transitions.\nTCP recovery requires traversing back to the last known good state\nand replaying all edges. CQ recovery can directly traverse to the\ndesired state.\nThe expected number of transmissions for recovery in TCP is:\nE[RTCP] = E[L] + w\n2\n(4)\nwhere E[L] is the expected number of lost packets and w\n2 is the aver-\nage window size.\nFor CQ:\nE[RCQ] = E[L] + 1\n(5)\nThis represents a significant reduction in recovery overhead.\nImplementation Considerations\nFPGA Implementation\nThe CQ framework is particularly suitable for hardware implementa-\ntion due to:\n1. Finite State Machine Representation: The limited set of balance\nstates {−∞, −1, −0, +0, +∞} maps efficiently to hardware state\nmachines.\n2. Deterministic Behavior: The absence of timeouts in normal opera-\ntion makes the protocol timing-independent.\n3. Reduced Memory Requirements: Since only imbalances need\nto be tracked rather than absolute sequence positions, memory\nrequirements are lower.\nAll Rights Reserved — Atomic Ethernet Industry Association (AEIA) 2025\nbeyond one-way counting: a conserved quantities framework for network communication\n6\nPerformance Analysis\nTheoretical analysis and preliminary simulations show that the CQ\nframework can reduce:\n• Average latency by 15-30% under normal conditions\n• Recovery time after packet loss by up to 60%\n• State storage requirements by 40-70%\nConclusion\nThe conserved quantities framework represents a fundamental shift\nin how we think about network communication protocols. By re-\nplacing the one-way counting model with a symmetrical accounting\nsystem, we achieve mathematically provable improvements in effi-\nciency, error recovery, and implementation complexity.\nThe framework’s mathematical foundation in conservation princi-\nples provides a more natural representation of the actual information\nflow between communicating entities. This enables more efficient\nprotocols that minimize unnecessary transmissions and recover more\ngracefully from failures.\nFuture work will explore extensions to the framework for multi-\nparty communication and integration with existing network infras-\ntructure.\nAll Rights Reserved — Atomic Ethernet Industry Association (AEIA) 2025\nbeyond one-way counting: a conserved quantities framework for network communication\n7\nFPGA Implementation Specification (Conventional Ethernet)\nThis appendix provides detailed specifications for implementing the\nCQ protocol in a Conventional Ethernet packet format in an FPGA,\nsuitable for testing and evaluation.\nFrame Format (Conventional Ethernet)\nField\nSize (bits)\nDescription\nPreamble*\n64\nStandard Ethernet preamble with SFD\nDestination MAC*\n48\nDestination MAC address\nSource MAC*\n48\nSource MAC address\nEtherType*\n16\nCustom EtherType (0xCQ01)\nBalance Indicator\n3\nEncoded balance state\nOperation Code\n5\nOperation type\nTransaction ID\n16\nUnique transaction identifier\nPayload Length\n16\nLength of payload in bytes\nPayload\nVariable\nData payload (if applicable)\nCRC\n32\nFrame check sequence\nTable 1: CQ Protocol Frame Format.\n*Not Needed in Æ-Link Interconnects.\nSource & destination identifiers are\nredundant between adjacent Æ Cells.\ni.e. Software Endpoints Directly Con-\nnected over a single link where (private\nidentities and identifiers are in pre-\nframe negotiation).\nBalance Indicator Encoding\nValue\nMeaning\n000\n−∞(Complete deficit)\n001\n−1 (Specific deficit)\n010\n−0 (Balance with negative tendency)\n011\n+0 (Balance with positive tendency)\n100\n+1 (Specific surplus)\n101\n+∞(Complete surplus)\n110-111\nReserved\nTable 2: Balance Indicator Encoding\nOperation Code Encoding\nState Machine Definition\nThe core state machine for the CQ protocol implementation is de-\nfined as follows:\nAll Rights Reserved — Atomic Ethernet Industry Association (AEIA) 2025\nbeyond one-way counting: a conserved quantities framework for network communication\n8\nValue\nOperation\n00000\nNOP (No Operation)\n00001\nDATA (Data Transfer)\n00010\nACK (Acknowledgment)\n00011\nREQ (Request for Data)\n00100\nRSP (Response to Request)\n00101\nSYNC (Synchronization)\n00110\nSYNC_ACK (Synchronization Acknowledgment)\n00111\nRESET (Connection Reset)\n01000-11111\nReserved\nTable 3: Operation Code Encoding\nINIT\n+0\n+1\n−1\n−0\n+∞\n−∞\nSYNC\nSend\nACK\nRequest\nReceive\nSYNC_ACK\nReceive\nProcess\nRequest\nSend\nTimeout\nTimeout\nFigure 1: CQ Protocol State Machine\nFPGA Implementation Architecture\nRegisters and Memory Structure\nMemory Organization\nThe Transaction Memory should be implemented as dual-port RAM\nwith the following structure:\nPseudo-Verilog for Core State Machine\n1 module cq_state_machine (\n2\ninput wire clk,\n3\ninput wire reset,\n4\ninput wire [2:0] rx_balance,\n5\ninput wire [4:0] rx_operation,\n6\ninput wire [15:0] rx_transaction_id,\n7\ninput wire frame_valid,\n8\noutput reg [2:0] tx_balance,\n9\noutput reg [4:0] tx_operation,\n10\noutput reg [15:0] tx_transaction_id,\n11\noutput reg tx_request,\n12\noutput reg [2:0] current_state\n13 );\n14\n15 // State definitions\n16 localparam STATE_INIT = 3’b000;\n17 localparam STATE_PLUS_ZERO = 3’b001;\n18 localparam STATE_PLUS_ONE = 3’b010;\n19 localparam STATE_MINUS_ONE = 3’b011;\n20 localparam STATE_MINUS_ZERO = 3’b100;\n21 localparam STATE_PLUS_INF = 3’b101;\nAll Rights Reserved — Atomic Ethernet Industry Association (AEIA) 2025\nbeyond one-way counting: a conserved quantities framework for network communication\n9\nMAC RX\nMAC TX\nFrame Parser\nFrame Builder\nState Machine\nBalance Tracker\nTransaction Memory\nFigure 2: FPGA Implementation Archi-\ntecture\nRegister\nWidth (bits)\nDescription\nSTATE_REG\n3\nCurrent protocol state\nBALANCE_REG\n3\nCurrent balance indicator\nTRANS_ID_REG\n16\nCurrent transaction ID\nTIMEOUT_COUNTER\n32\nTimeout counter\nCONTROL_REG\n8\nControl register\nSTATUS_REG\n8\nStatus register\nTable 4: Register Definitions\n22 localparam STATE_MINUS_INF = 3’b110;\n23\n24 // Operation codes\n25 localparam OP_NOP = 5’b00000;\n26 localparam OP_DATA = 5’b00001;\n27 localparam OP_ACK = 5’b00010;\n28 localparam OP_REQ = 5’b00011;\n29 localparam OP_RSP = 5’b00100;\n30 localparam OP_SYNC = 5’b00101;\n31 localparam OP_SYNC_ACK = 5’b00110;\n32 localparam OP_RESET = 5’b00111;\n33\n34 // Internal registers\n35 reg [31:0] timeout_counter;\n36 reg timeout_occurred;\n37\n38 // State machine logic\n39 always @(posedge clk or posedge reset) begin\n40\nif (reset) begin\n41\ncurrent_state <= STATE_INIT;\n42\ntx_balance <= 3’b000;\n43\ntx_operation <= OP_NOP;\n44\ntx_transaction_id <= 16’h0000;\n45\ntx_request <= 1’b0;\n46\ntimeout_counter <= 32’h00000000;\n47\ntimeout_occurred <= 1’b0;\n48\nend else begin\nAll Rights Reserved — Atomic Ethernet Industry Association (AEIA) 2025\nbeyond one-way counting: a conserved quantities framework for network communication\n10\nField\nWidth (bits)\nDescription\nTransaction ID\n16\nKey for the entry\nBalance State\n3\nAssociated balance state\nOperation\n5\nAssociated operation\nTimestamp\n32\nTimestamp of last activity\nData Pointer\n16\nPointer to data in payload memory\nData Length\n16\nLength of associated data\nTable 5: Transaction Memory Structure\n49\n// Default values\n50\ntx_request <= 1’b0;\n51\n52\n// Timeout detection\n53\nif (timeout_counter > 0) begin\n54\ntimeout_counter <= timeout_counter - 1;\n55\nif (timeout_counter == 1) begin\n56\ntimeout_occurred <= 1’b1;\n57\nend\n58\nend\n59\n60\n// State transitions based on received frames and timeouts\n61\ncase (current_state)\n62\nSTATE_INIT: begin\n63\nif (frame_valid && rx_operation == OP_SYNC) begin\n64\ncurrent_state <= STATE_PLUS_ZERO;\n65\ntx_balance <= 3’b011; // +0\n66\ntx_operation <= OP_SYNC_ACK;\n67\ntx_transaction_id <= rx_transaction_id;\n68\ntx_request <= 1’b1;\n69\ntimeout_counter <= 32’d100000; // Set appropriate\ntimeout value\n70\nend\n71\nend\n72\n73\nSTATE_PLUS_ZERO: begin\n74\nif (frame_valid) begin\n75\ncase (rx_operation)\n76\nOP_DATA: begin\n77\ncurrent_state <= STATE_PLUS_ONE;\n78\ntx_balance <= 3’b100; // +1\n79\ntx_operation <= OP_ACK;\n80\ntx_transaction_id <= rx_transaction_id;\n81\ntx_request <= 1’b1;\n82\nend\n83\nOP_REQ: begin\n84\ncurrent_state <= STATE_MINUS_ONE;\n85\ntx_balance <= 3’b001; // -1\n86\ntx_operation <= OP_RSP;\n87\ntx_transaction_id <= rx_transaction_id;\n88\ntx_request <= 1’b1;\n89\nend\n90\nOP_SYNC_ACK: begin\n91\ncurrent_state <= STATE_MINUS_ZERO;\n92\ntx_balance <= 3’b010; // -0\n93\nend\n94\n// Handle other operations...\n95\nendcase\n96\nend else if (timeout_occurred) begin\nAll Rights Reserved — Atomic Ethernet Industry Association (AEIA) 2025\nbeyond one-way counting: a conserved quantities framework for network communication\n11\n97\n// Handle timeout in +0 state\n98\ntimeout_occurred <= 1’b0;\n99\ntx_operation <= OP_SYNC;\n100\ntx_transaction_id <= tx_transaction_id + 1;\n101\ntx_request <= 1’b1;\n102\ntimeout_counter <= 32’d100000;\n103\nend\n104\nend\n105\n106\n// Additional states and transitions...\n107\n// STATE_PLUS_ONE, STATE_MINUS_ONE, etc.\n108\n109\nendcase\n110\nend\n111 end\n112\n113 endmodule\nTest Vectors (Conventional Ethernet)\nThe following test vectors can be used to verify the implementation:\n1. Connection Establishment:\n• Node A sends SYNC with balance +0\n• Node B responds with SYNC_ACK with balance −0\n• Expected outcome: Both nodes establish connection\n2. Basic Data Transfer:\n• Node A sends DATA with balance +1\n• Node B responds with ACK with balance +0\n• Expected outcome: Data successfully transferred\n3. Data Request:\n• Node A sends REQ with balance −1\n• Node B responds with RSP with balance +0\n• Expected outcome: Requested data successfully received\n4. Error Recovery:\n• Node A sends DATA with balance +1\n• Frame is lost (not injected in test)\n• Timeout occurs at Node A\n• Node A sends SYNC with balance +0\n• Node B responds with state information\n• Node A resends missing data\n• Expected outcome: Error recovered with minimal retransmis-\nsion\nAll Rights Reserved — Atomic Ethernet Industry Association (AEIA) 2025\nbeyond one-way counting: a conserved quantities framework for network communication\n12\nImplementation Guidelines (Conventional Ethernet)\nWhen implementing the CQ protocol in an FPGA, consider the fol-\nlowing:\n1. Use a pipelined architecture to achieve high throughput\n2. Implement the transaction memory as dual-port RAM for simulta-\nneous access\n3. Use a parameterized design to allow configuration of buffer sizes,\ntimeout values, etc.\n4. Include comprehensive error detection and reporting mechanisms\n5. Add debug ports to monitor internal state transitions\n6. Implement the CRC calculation using parallel techniques for high\nperformance\n7. Consider using a dedicated timeout counter for each active trans-\naction\nVerification Plan (Conventional Ethernet)\nTo verify the implementation:\n1. Use simulation with the provided test vectors to verify basic func-\ntionality\n2. Test edge cases such as simultaneous transmissions and maximum-\nsize frames\n3. Measure performance metrics including latency, throughput, and\nresource utilization\n4. Conduct stress testing with high packet rates and induced errors\n5. Verify interoperability between multiple implementations\nAll Rights Reserved — Atomic Ethernet Industry Association (AEIA) 2025\nbeyond one-way counting: a conserved quantities framework for network communication\n13\nAtomic Ethernet Frame Format: Æ-Link CQ Interactions\nField\nSize (bits)\nContext\nSlice 1\n8\nOPCODE (Protocol Specifier)\nSlice 1\n8\nLiveness (TIKTIKTIK)\nSlice 1\n8\nState (State Machine Specifier)\nSlice 1\n8\nTransition (State Machine Transition)\nSlice 1\n32\nOperand (One-shot CQ Interactions)\nSlice 2-8\n512\nOperand (One-Shot CQ Interactions)\nTable 6: Æ Minimalist CQ Protocol See:\nSlice Engine: Frame Format Spec.\nSlice 1 – Byte 1Protocol\nField\nSize (bits)\nOPCODE\nSlice 1\n8\nContext (Protocol Specifier)\nTable 7: Protocol Specifier.\nSlice 1 – Byte 2 Liveness\nField\nSize (bits)\nLIVENESS\nSlice 1\n8\nIKTYKTIKT (Liveness Specifier)\nTable 8: Liveness Specifier.\nAcknowledgements\nDirect contributors\nThanks\nAll Rights Reserved — Atomic Ethernet Industry Association (AEIA) 2025\n"
  },
  {
    "filename": "STANDALONE/HFT.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\næthernet: ultra low latency (ull)\n1\nEthernet Overhead\nStandard Ethernet framing includes:\nSee IEEE 802.3 standard; also Ethernet:\nThe Definitive Guide by C. Spurgeon\n• Preamble: 7 bytes of 0x55 + 1 byte SFD\n• Destination MAC: 6 bytes\n• Source MAC: 6 bytes\n• Type/Length field: 2 bytes\n• Payload: 46–1500 bytes\n• Frame Check Sequence (FCS): 4 bytes\n• Inter-frame Gap (IFG): 12 bytes idle\nIn static point-to-point HFT environments, nearly all of this can be\nviewed as redundant overhead. When link endpoints and roles are\nfixed, headers and metadata convey no new information.\nTechnical Feasibility\nEliminating traditional Ethernet elements requires a different framing\nmodel—a contract between hardware endpoints.\nNo Preamble / SFD\nThe preamble synchronizes clocks in legacy systems. In modern\nSerDes links with embedded clock recovery, this is already managed.\nCompare to PCIe, which uses\n128b/130b encoding without explicit\npreambles\nFeasibility: Yes, with stable point-to-point SerDes links or slotted\nclocks.\nTradeoff: Reduced robustness. In noisy environments, lack of fram-\ning risks misalignment or data corruption. This is acceptable in\nsealed environments like short DAC cables or on-board links.\nNo MAC Addresses\nHFT links are fixed. The source and destination are implicitly known.\nUsed in protocols like NVLink or Intel\nUPI, where links are directly mapped.\nFeasibility: Yes, especially in sealed, controlled deployments.\nTradeoff: Loss of dynamic addressing or discovery. Requires physical\nlink provisioning. Cannot reroute or adapt without external orches-\ntration.\næthernet: ultra low latency (ull)\n2\nNo Inter-frame Gap\nIFGs were designed to give PHYs time to reset. In engineered envi-\nronments using continuous signaling, these are unnecessary.\nSimilar techniques are used in FPGAs\nwith streaming AXI interfaces or in\n100G optical transport\nFeasibility: Yes, if physical layer supports continuous or slotted\nframing.\nTradeoff: Thermal and electrical stress. Removing idle periods may\nincrease power draw or reduce link lifespan. Needs low-jitter preci-\nsion timing.\nNo Headers at All\nHeader fields can be eliminated if:\n• Frame size is known a priori or fixed\n• Error detection is moved to another layer (e.g., optical layer or\npersistent memory logic)\n• Transaction context is inferred\nFeasibility: Yes, in tightly coupled systems with fixed-length trans-\nactions.\nUsed in Time-Triggered Ethernet (TTE),\nand in DRAM command buses\nTradeoff: Loss of introspection and self-description. Makes debugging\nand monitoring difficult. May require separate control channel for\ndiagnostics.\nSecurity and Fault Isolation\nThis design assumes:\n• No dynamic routing or discovery\n• No reconfiguration or rerouting\n• Total operational control over both endpoints\nCompare to InfiniBand RC mode:\nreliable connections with fixed end-\npoints and explicit path setup RDMA\nTransport Modes\nTradeoff: Operational fragility. Misconfiguration can lead to silent\nfailure. But the simplification pays dividends in latency-critical de-\nployments.\nPhysical Layer Considerations\nKey enablers of this model include:\n• SerDes-level framing (e.g., 64b/66b)\n• Slotted time-based framing\n• Sideband channels for negotiation and integrity checking\næthernet: ultra low latency (ull)\n3\nSee also: HFT deployments using cut-\nthrough switches and FPGA SmartNICs\nwith bypass logic\nEach slot corresponds to a transaction. Bidirectional acknowledg-\nments (e.g., Slot ACKs or “SACKs”) can be used to indicate success\nor trigger reversal of actions.\nReference: Early reversible protocols in Hot Interconnects (2005–2012)\nand dataflow routing in on-chip networks.\nProtocol Design Implications\nThis minimalist interaction protocol:\n• Removes legacy structures optimized for routing and error correc-\ntion\n• Requires extreme pre-coordination of endpoints\n• May use application-specific framing or alignment\n• Demands an invariant frame format and timing agreement\nTradeoff: Loss of generality. However, when the application is nar-\nrow (e.g., HFT price updates), the gains in determinism and effi-\nciency vastly outweigh flexibility.\nConclusion: Post-Ethernet\nThis proposal represents a departure from Ethernet’s historical flexi-\nbility. It may at first seem to not be backwards compatible with 802.3,\nbut compatibility is provided by the escape bits and codes), and the\nthe Address fields can be compatible, not only with the two 48-bit\nMAC Addresses, but the 32-Bit IP and 64-Bit IP address also. This is\njust a matter of mapping the encoding from the encoding field.\nFor HFT, or similar environments, it represents a return to the\ncore of information transmission: symbols sent from A to B with zero\nambiguity.\nEthernet began as a way to share a cable. Today, it must become a way to share\ncertainty.\nWould Shannon approve? Perhaps. But\nonly if we prove we need fewer bits to\ntransmit the same certainty.\nRemoving headers, gaps, addresses, and preambles is not only\npossible—it is essential for ultra-fast applications where every bit\ncounts.\nWould Metcalfe approve? Perhaps. But\nonly if we coordinate with the current\nEthernet consortia including 802?\nThis proposal captures the main idea of using the minimalist ap-\nproach to transporting data over copper or fiber links.\nHFT payloads can be as small as a bit to confirm that a price level\nwas hit, more practically a few bytes to encode a message, or tens of\nbytes to convey market data or orders.\n"
  },
  {
    "filename": "STANDALONE/syncnronous-review.pdf",
    "content": "Review of “Synchronous, Asynchronous and Causally\nOrdered Communication” (Charron-Bost, Mat-\ntern & Tel, 1992)\nPrepared for Paul Borrill\nCompiled on May 12, 2025\nUser request (verbatim)\n“Please review: ‘Synchronous . . . communication’. . . [full text elided for\nbrevity]\nWhy this paper still matters\n• Unifies three delivery disciplines—synchronous, FIFO, and causal—under\none axiomatic roof.\n• Establishes the strict inclusion chain\nRSC ⊂CO ⊂FIFO ⊂A,\nclarifying what extra guarantees are purchased (and at what cost).\n• Introduces the crown criterion: a linear-time test to decide whether\nan execution can be replayed with rendezvous semantics.\n• Demonstrates that classic control algorithms (e.g. Dijkstra–Feijen–van Gasteren\ntermination detection) remain safe under the weaker CO model.\nCore concepts and results\nModel vocabulary\nA-computation\nFully asynchronous; Lamport’s three happens-before axioms.\nFIFO-computation\nAdds per-channel ordering (send order ⇒receive order).\nCO-computation\nGlobalises FIFO: if send1 ≺send2 (causally), then recv1 ≺recv2.\nRSC-computation\nThere exists a non-separated linear extension where every send is\nimmediately followed by its receive.\nCrown\nAlternating sequence ⟨s0, r0, s1, r1, . . . , sk, rk⟩forming a dependency\ncycle; its presence precludes synchronous realisation.\nreview of “synchronous, asynchronous and causally ordered communication”\n(charron-bost, mattern & tel, 1992)\n2\nHierarchy (all containments strict)\nRSC\n⊂\nCO\n⊂\nFIFO\n⊂\nA\nTermination-detection case study\nCO suffices for the Dijkstra ring-token detector because any basic\nmessage can cross at most one wave; the colouring rule then guaran-\ntees safety.\nImplementation guidance (1992 vintage)\n• FIFO: Per-link sequence numbers plus buffering.\n• CO: Vector (or matrix) clocks, or handshake I/O buffers that for-\nbid indirect overtakes.\n• RSC: FIFO + per-message acknowledgement that blocks the\nsender (classic rendezvous).\nStrengths and limitations\nStrengths\n• Fully axiomatic—no reliance on wall-clock bounds.\n• Crown test is linear-time and graph-theoretic.\n• Bridges theory and practice with concrete protocols.\nLimitations\n• Assumes reliable point-to-point channels (no loss, duplication, or\nByzantine faults).\n• Vector/matrix metadata scales poorly for thousands of nodes;\nmodern systems use compaction.\nFITO perspective\nFITO lens: Every step up the hierarchy\nembeds more irreversible forward-time\ncoupling.\n1. A: progress driven by timeouts and retries—quintessential Forward-In-Time-Only\nthinking.\n2. CO: removes physical-time dependence; ordering relies only on\ncausal DAG, admitting limited reversibility of buffering.\n3. RSC: rendezvous collapses send/receive into a single spacetime\npoint, eliminating alternative orders.\nComparative note\nLamport (1978)\nreview of “synchronous, asynchronous and causally ordered communication”\n(charron-bost, mattern & tel, 1992)\n3\nHappened-before for totally asynchronous systems.\nBirman & Joseph (1987)\nCausal broadcast within groups; present paper generalises to\npoint-to-point and situates it in the hierarchy.\nFidge (1991)\nVector clocks; adopted here as one implementation route.\nKey takeaways\n1. Ordering guarantees form a strict lattice; algorithm soundness\ndepends on picking the right rung.\n2. “Crown-free ⇐⇒synchronisable”: if no crowns exist, rendezvous\nreplay is possible.\n3. Many rendezvous-based algorithms work under CO, avoiding\nblocking latency.\n4. FIFO alone is insufficient for algorithms that assume “no messages\nin flight.”\n5. Implementation cost rises sharply: RSC →latency; CO →meta-\ndata; FIFO →buffer space.\nBibliographic reference\nB.Charron-Bost, F.Mattern, and G.Tel.\n“Synchronous, Asynchronous, and Causally Ordered Communica-\ntion.”\nDistributed Computing 6(1992): 173–191.\n"
  },
  {
    "filename": "STANDALONE/slice-table.pdf",
    "content": "1\nFirst Slice Encodings\nProtocol\nLiveness\nState Machine\nTransition\nAcknowledge\nAlive\nWait for Retry\nTo Retry\nRetry Class 1\nTimeout\nCommit\nTo Abort\nSACK Request\nSilent\nSynced\nStay Ready\nNACK Class 2\nUncertain\nListening\nReset\n"
  },
  {
    "filename": "STANDALONE/ATM.pdf",
    "content": "Flow Control in ATM: A Tale of Two Visions\nIntroduction\nIn the early 1990s, the ATM Forum became the battleground for a\npivotal debate in networking: how to manage congestion in a cell-\nbased fabric designed to unify voice, video, and data traffic. The two\nmain contenders were Hop-by-Hop Flow Control and Rate-Based\nFlow Control. Each represented a fundamentally different view of\nhow best to achieve performance guarantees and fairness across a\nheterogeneous, multi-hop network composed of 53-byte cells.\nThe Challenge: ATM’s Dual Mandate\nATM was envisioned as the unifying transport for all digital commu-\nnication, requiring it to offer both the deterministic timing of circuit-\nswitched networks and the efficiency of statistical multiplexing. This\nmeant that congestion control was not merely a performance tweak,\nbut a contractual necessity to maintain promised QoS levels.\nATM’s cut-through switching and small fixed-size cells eliminated\nmuch of the buffering flexibility available to IP networks. It had to\nprevent congestion, not recover from it.\nHop-by-Hop Flow Control\nHop-by-hop flow control works by applying local backpressure: each\nswitch monitors its output buffers and signals its upstream neighbor\nto slow or stop traffic as congestion builds.\nFigure 1: Hop-by-hop flow control:\nfeedback loops are short but propagate\nslowly end-to-end.\nAdvantages\n• Immediate local reaction to congestion.\n• Fine-grained control over buffer occupancy.\n• Simple logic for small or low-diameter networks.\nDrawbacks\n• Scalability concerns: lacks consistent end-to-end semantics.\n• Head-of-line blocking and poor latency propagation in long paths.\n• Fragile under path diversity and route reconfiguration.\nflow control in atm: a tale of two visions\n2\nRate-Based Flow Control\nRate-based flow control, standardized as part of the ATM ABR\n(Available Bit Rate) service class, aimed to regulate traffic from\nthe edge. Sources declare a desired transmission rate, and switches\ngenerate Resource Management (RM) cells containing congestion\nfeedback. These RM cells traverse the path forward and backward,\ncarrying fields such as Explicit Rate (ER) that guide sender behavior.\nAdvantages\n• End-to-end perspective scales better with network size.\n• Enables policy-driven traffic contracts and rate shaping.\n• Compatible with QoS-aware routing and admission control.\nDrawbacks\n• More complex per-switch logic and state maintenance.\n• Relies on timely and reliable RM cell feedback.\n• Convergence time can be slow in bursty or highly dynamic condi-\ntions.\nThe Verdict: Standardization\nAfter extensive debate, the ATM Forum chose Rate-Based Flow Con-\ntrol as the official standard. This decision reflected a belief in the\nend-to-end model of networking, better alignment with telco adminis-\ntration, and superior support for SLAs (Service Level Agreements).\nSwitch vendors also favored rate-based schemes for their reduced\nbuffer requirements and predictability.\nLegacy and Modern Echoes\nAlthough ATM faded from prominence, the ideas from its flow con-\ntrol debate echo through modern networking:\n• InfiniBand and credit-based Ethernet revived hop-by-hop flow\ncontrol for low-latency datacenter fabrics.\n• TCP Vegas and XCP extended the rate-based idea into congestion-\naware transport.\n• PFC and QCN in Data Center Bridging (DCB) illustrate hybrid\napproaches that combine both paradigms.\nflow control in atm: a tale of two visions\n3\nIn hindsight, both models have value—hop-by-hop for tight fabrics\nwith predictable topology; rate-based for scalable, heterogeneous\nsystems. The ATM Forum chose well for its assumptions—but the\nfuture fragmented.\nConclusion\nThe ATM Forum’s choice to standardize rate-based flow control\nwas less a dismissal of hop-by-hop than a reflection of the broader\nambitions of the ATM architecture. It aimed to build a global, carrier-\ngrade network substrate. In contrast, datacenters—where predictabil-\nity and tight control dominate—would later rediscover the strengths\nof localized flow control.\nRate-based flow control won the standard. But hop-by-hop flow control won\nthe datacenter.\n"
  },
  {
    "filename": "STANDALONE/FMS-CTO-Panel-2025.pdf",
    "content": "Energy–Efficient Memory, Storage & Networks\nCTO Vision Panel at FMS (Future of Memory and Storage)\n02025-Aug-06. Santa Clara Convention Center\n“It costs over 1000× more energy to move a byte than to compute on it.”\n— Bill Dally, NVIDIA Chief Scientist*\nPanelists\nPanelist\nCompany\nHannah Earley (CTO)\nVaire\nJason Hardy (CTO)\nHitachi Vantara\nMichael Kagan (CTO)\nNVIDIA\nRob Lee (CTO)\nPure Storage\nSven Oehme (CTO)\nDDN\nAlex Veprinsky (CTO)\nHPE\nTheme\n*A 64-bit floating-point operation\nconsumes ∼5 −20pJ per operation in\nmodern silicon—significantly less than\nthe 10s of nJ required to ship a single\nbit across a data center link.\nBill Dally emphasizes that optimizing\nfor data locality—i.e., keeping data\nas close to the compute as possible\n– can save huge amounts of energy\ncompared to frequently pulling data\nfrom far-flung locations in a data center.\nThis guides our architectural deci-\nsions. Knowing that data center-scale\ncommunication can cost over 1,000x\nmore than on–chip data movement\ninfluences how datacenter systems and\nsoftware are designed.\nAs artificial intelligence (AI) workloads grow exponentially, energy\nconsumption has become the paramount challenge in datacenter\noperations. In April 2025 International Energy Agency (IEA) projects\nthat electricity demand from datacenters worldwide will more than\ndouble by 2030, reaching approximately 945 terawatt-hours (TWh)\n— exceeding Japan’s total electricity consumption today.\nNVIDIA’s Bill Dally highlights* that while a floating-point opera-\ntion requires about 20 picojoules, reading 64 bits from mobile DRAM\nconsumes approximately 1,200 picojoules—a 60× difference.\nSimilarly, moving data across racks and interconnects now dom-\ninates energy budgets, especially in AI training clusters where over\n80% of power may go toward memory and communication rather\nthan compute.\nDiscussion Points\nThis panel will bring together CTOs from across the compute, mem-\nory, and networking domains to explore:\nThe scale of a single AI datacenter is\nconstrained by its power plant sup-\nply capacity. As demand for training\nresources grows, hyperscalers are ex-\nploring strategies to utilize the compute\ncapacity of multiple datacenters within\na single pre-training job [SDR-RDMA.]\nhttps://arxiv.org/pdf/2505.05366\n• The energy cost of data movement vs. computation\n• Interconnect bottlenecks and disaggregated chiplet architectures\n• Innovations in XPUs/SmartNICs, memory, storage, & CXL fabrics\n• What software can do to address these challenges\n• Prospects for Reversible and Quantum Computing\n• System-level energy accountability: Can we meter what matters?\nConclusion\nThe stakes are existential. Without a fundamental redesign of how\nwe move and process data, AI infrastructure and cloud scale-out\narchitectures will hit energy ceilings well before reaching their full\npotential.\n"
  },
  {
    "filename": "STANDALONE/FMS-CTO-Panel.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\nEnergy–Efficient Memory, Storage & Networks\nCTO Vision Panel at FMS (Future of Memory and Storage)\nAugust 06 2025. Santa Clara Convention Center\n“It costs over 1000× more energy to move a byte than to compute on it.”\n— Bill Dally, NVIDIA Chief Scientist*\nTheme\n*A 64-bit floating-point operation\nconsumes ∼5 −20pJ per operation in\nmodern silicon—significantly less than\nthe 10s of nJ required to ship a single\nbit across a data center link.\nBill Dally emphasizes that optimizing\nfor data locality—i.e., keeping data\nas close to the compute as possible\n– can save huge amounts of energy\ncompared to frequently pulling data\nfrom far-flung locations in a data center.\nThis guides our architectural deci-\nsions. Knowing that data center-scale\ncommunication can cost over 1,000x\nmore than on–chip data movement\ninfluences how datacenter systems and\nsoftware are designed.\nAs artificial intelligence (AI) workloads grow exponentially, energy\nconsumption has become the paramount challenge in datacenter\noperations. In April 2025 International Energy Agency (IEA) projects\nthat electricity demand from datacenters worldwide will more than\ndouble by 2030, reaching approximately 945 terawatt-hours (TWh)\n— exceeding Japan’s total electricity consumption today.\nNVIDIA’s Bill Dally highlights* that while a floating-point opera-\ntion requires about 20 picojoules, reading 64 bits from mobile DRAM\nconsumes approximately 1,200 picojoules—a 60× difference.\nSimilarly, moving data across racks and interconnects now dom-\ninates energy budgets, especially in AI training clusters where over\n80% of power may go toward memory and communication rather\nthan compute.\nDiscussion Points\nThis panel will bring together CTOs from across the compute, mem-\nory, and networking domains to explore:\n• The energy cost of data movement vs. computation\n• Interconnect bottlenecks and disaggregated chiplet architectures\n• Innovations in XPUs/SmartNICs, memory, storage, & CXL fabrics\n• What software can do to address these challenges\n• Prospects for Reversible and Quantum Computing\n• System-level energy accountability: Can we meter what matters?\nConclusion\nThe stakes are existential. Without a fundamental redesign of how\nwe move and process data, AI infrastructure and cloud scale-out\narchitectures will hit energy ceilings well before reaching their full\npotential.\n"
  },
  {
    "filename": "STANDALONE/Octavalent-Mesh.pdf",
    "content": "Illustration of an Octavalent Mesh\nMay 23, 2025\ndeg(c) = 8\nFigure 1: A minimal octavalent mesh:\none central vertex of degree 8 connected\nto eight neighbours (each of degree 1).\nLarger networks may be built by\nstitching together many such stars or\nby adding further links, provided no\nvertex exceeds degree 8.\n"
  },
  {
    "filename": "STANDALONE/Reliable-Transport.pdf",
    "content": "Why Ethernet Isn’t a Reliable Transport Protocol\nMay 5, 2025\nIntroduction\nEthernet was designed for stateless, best-effort delivery at Layer 2.\nThis section outlines why that simplicity persists and the trade-offs\ninvolved.\nIndustry Timeline\n1973–1980:\nEthernet created as a stateless LAN.\n1983:\nTCP/IP stack becomes standard.\nReliability added at Layer 4.\n1988:\nTCP congestion collapse leads to\nJacobson’s TCP Reno.\n1999–2005:\nInfiniBand emerges: reliable by\ndesign.\n2010–2012:\nRoCEv1 (L2) and RoCEv2 (L3 over\nUDP) extend RDMA over Ethernet.\n2020–2025:\nSmartNICs and the Ultra Ethernet\nConsortium explore adding fabric-\nlevel reliability.\nStraw-man Barriers to Reliability\n– Layering Violation: Ethernet is Layer 2; adding reliability breaks\nabstraction boundaries.\n– Hardware Complexity: Per-flow state and retransmission logic are\nexpensive in silicon.\n– Scalability: Reliable protocols need congestion windows, ACKs,\ntimers—hard to scale in switches.\n– Multicast Chaos: Ethernet’s broadcast model complicates stateful\ndelivery.\n– TCP’s Success: TCP already solves reliability at Layer 4—why\nduplicate?\n– Backwards Compatibility: Billions of devices expect today’s Eth-\nernet behavior.\nComparison Table\nFeature\nTCP/IP over Ethernet\nInfiniBand\nReliability Layer\nSoftware (L4)\nHardware-integrated\nAcknowledgments\nTCP ACKs\nPer-packet HW ACKs\nCongestion Control\nReno / Cubic / BBR\nCredit + ECN\nOrdering\nTCP sequence numbers\nStrict by QP\nFlow Control\nSliding window\nVirtual lane credits\nLoss Recovery\nSACKs, timeouts\nFast retry in silicon\nLatency\nHigher (host stack)\nUltra-low, no copies\nCPU Involvement\nHigh\nVery low (zero-copy)\nTable 1: Reliability: TCP/IP vs Infini-\nBand\nwhy ethernet isn’t a reliable transport protocol\n2\nProtocol\nReliability\nACKs\nCongestion Control\nEthernet (L2)\nNone\nNo\nNo\nTCP/IP\nEnd-to-End\nYes\nYes (TCP)\nInfiniBand\nHardware\nYes\nCredit + ECN\nRoCE\nHybrid\nPartial\nDCB / ECN\nSmartNIC Fabrics\nProgrammable\nOptional\nCustom / P4-based\nTable 2: Reliability Feature Comparison\nAcross Technologies\nSummary Matrix\nHere is a structured comparison chart that includes Ethernet, TCP/IP\nover Ethernet, and InfiniBand, focusing on their reliability, acknowl-\nedgments, and congestion control:\nFeature\nEthernet (L2)\nTCP/IP over Ether-\nnet (L3+L4)\nInfiniBand (L1–L4\nequivalent)\nLayer\nData Link\nIP + TCP\nPhysical–Transport\nStack\nDelivery Model\nBest-effort\nReliable (via TCP)\nReliable (by de-\nsign)\nAcknowledgments\nNone\nTCP ACKs\nHardware ACKs\n(per packet/WQE)\nCongestion Control\nNone\nReno, Cubic, ECN\nCredit-based,\nECN, BECN\nOrdering Guaran-\ntees\nNone\nTCP-ordered\nIn-order within\nQPs\nFlow Control\nNo (some pause-\nframe)\nSliding window\nPer-virtual lane\ncredits\nLoss Detec-\ntion/Recovery\nNone\nTimeouts, SACK,\ndupACKs\nHardware-\nmanaged\nTimeouts and Re-\ntransmits\nNot present\nRequired\nTunable and deter-\nministic\nLatency\nLow\nHigher (software\ncost)\nVery low (zero-\ncopy)\nCPU Involvement\nStateless\nHigh (kernel/user)\nMinimal (of-\nfloaded)\nCongestion Visibility\nLocal only\nPartial (ECN-based)\nExplicit\n(FECN/BECN)\nDeployment Context\nGeneral-purpose\nnetworks\nWAN/Datacenter\nHPC, low-latency\nfabrics\nBackward Compati-\nbility\nVery high\nHigh\nLow (controlled\ndomains)\nStandards Body\nIEEE 802.3\nIETF\nIBTA\nTable 3: Structured Comparison of\nEthernet, TCP/IP, and InfiniBand\nwhy ethernet isn’t a reliable transport protocol\n3\nKey Observations\n• Ethernet was built to be simple, fast, and stateless, ideal for flexible\ninterconnects but not intrinsically reliable.\n• TCP/IP over Ethernet overlays reliability, but with CPU and soft-\nware stack penalties, making it unsuitable for ultra-low-latency use\ncases.\n• InfiniBand achieves hardware-level reliability, congestion control, and\nflow control, making it the benchmark for deterministic low-latency\ncommunication in tightly coupled systems.\n• Atomic Ethernet achieves transactional atomicity, Ultra-Low Latency,\nmaking it ideal for rack-scale and chiplet scale microdatacenter\ndeployments.\n• Ultra Ethernet .\nBarriers to Reliability in Ethernet\n– Layering Violation: Ethernet is Layer 2; adding reliability breaks\nabstraction boundaries.\n– Hardware Complexity: Per-flow state and retransmission logic are\nexpensive in silicon.\n– Scalability: Reliable protocols need congestion windows, ACKs,\ntimers—hard to scale in switches.\n– Multicast Chaos: Ethernet’s broadcast model complicates stateful\ndelivery.\n– TCP’s Success: TCP already solves reliability at Layer 4—why\nduplicate?\n– Backwards Compatibility: Billions of devices expect today’s Eth-\nernet behavior.\nTransport Reliability Comparison\nNVLink and NVSwitch\nNVLink and NVSwitch are the building blocks of high-speed, multi-\nGPU communication for feeding large datasets faster into models\nand rapidly exchanging data between GPUs.\nwhy ethernet isn’t a reliable transport protocol\n4\nFeature\nTCP/IP over Ethernet\nInfiniBand\nReliability Layer\nSoftware (L4)\nHardware-integrated\nAcknowledgments\nTCP ACKs\nPer-packet HW ACKs\nCongestion Control\nReno / Cubic / BBR\nCredit + ECN\nOrdering\nTCP sequence numbers\nStrict by QP\nFlow Control\nSliding window\nVirtual lane credits\nLoss Recovery\nSACKs, timeouts\nFast retry in silicon\nLatency\nHigher (host stack)\nUltra-low, no copies\nCPU Involvement\nHigh\nVery low (zero-copy)\nTable 4: TCP/IP vs InfiniBand Reliabil-\nity Mechanisms\nUA Link\nThe UA Link Consortium was formed with the goal of developing\ninterconnect technical specifications that facilitate direct load, store,\nand atomic operations between AI Accelerators.\nUALink primary areas of focus:\n• Enable low latency/high bandwidth fabric\n• Support hundreds of accelerators in a pod\n• Facilitate simple load and store semantics with software coherency\nUltra Ethernet\nFrom: Ultra-Ethernet Consortium\nGoals\n• Deliver a complete architecture that optimizes Ethernet for high\nperformance AI and HPC networking, exceeding the performance\nof today’s specialized technologies. UEC specifically focuses on\nfunctionality, performance, TCO, and developer and end-user\nfriendliness, while minimizing changes to only those required and\nmaintaining Ethernet interoperability. Additional goals:\n• Improved bandwidth, latency, tail latency, and scale, matching\ntomorrow’s workloads and compute architectures. Backwards\ncompatibility to widely-deployed APIs and definition of new APIs\nthat are better optimized to future workloads and compute archi-\ntectures.\nwhy ethernet isn’t a reliable transport protocol\n5\nAtomic Ethernet\n• Ultra-Low Latency (limited only by the speed of light)\n• Ultra-High Reliability (Perfect Information transfer over each LINK;\ncompositional over any number of LINKs)\n• Higher useful bandwidth than all other approaches. Limited only\nby the total number LINKs)\n• Higher useful bandwidth than all other approaches. Limited only\nby the total number of application scheduled trees of application\nscheduled dense trees\n• Scale-Independent sea of XPUs (no limit to scale on 2D plane, with\n3rd dimension for stacked chiplets)\n• Ready for the next generation of modular miniaturization in the\nChiplet Economy.\n• SWAP architecture (subsumes reads and writes) facilitates atomic\ntoken indivisibility for transactional integrity\n• Ready for Interface to Quantum Computers\n"
  },
  {
    "filename": "STANDALONE/hlc_common_knowledge.pdf",
    "content": "Hybrid Clocks and Common Knowledge\nChatGPT, fact checked by Paul Borrill\nPrompt: Please review the work of Kulkarni, especially Hybrid clocks,\nand its implications to understanding \"common knowledge\"\nOverview\nHybrid clock research, led by S. S. Kulkarni and collaborators, welds\na physical-time estimate to a Lamport-style logical counter. The result\nis a timestamp that (i) respects causality, (ii) stays within a known\nskew ε of wall time, and (iii) avoids the commit-wait penalties of\nsystems such as Google Spanner. This handout summarizes the key\npapers, explains how Hybrid Logical Clocks (HLC) operate, and\nanalyzes their impact on the epistemic concept of common knowledge.\nTable 1: Kulkarni hybrid-clock lineage\nYear\nWork\nKey idea\n2012\nHybridTime\nPhysical time ⊕counter;\nbounds skew.\n2014\nHybrid Logical Clock\n64-bit HLC preserves\ne →\nf\n⇒\nHLC(e)\n<\nHLC( f ).\n2015\nHybrid Vector Clock\nVector form; prunes\nentries older than ε.\n16–20\nSystem integrations\nHLC in GentleRain+,\nCausalSpartanX, NuKV.\nHow Hybrid Logical Clocks Work\nEach node maintains\nHLC = (pt, ctr)\nwhere pt mirrors physical time and ctr counts logical ties.\n1. Local event\npt ←now();\npt ←max(pt, pt);\nctr ←(pt==pt) ?\n0 :\nctr+1;\n2. Message receive (m.HLC)\npt ←now();\npt ←max(pt, m.pt);\nctr ←(pt==m.pt) ?\nmax(ctr, m.ctr) + 1 :\n0;\nGuarantees:\n• If event e happens before f, then HLC(e) < HLC( f ).\n• Absolute error |pt −HLC| ≤ε as long as the underlying clock\ndiscipline meets that bound.\nEpistemic Implications\nClassical limit\nHalpern and Moses proved that in asynchronous systems absolute\ncommon knowledge is impossible; only an infinite tower Eφ, E Eφ, . . .\nis attainable.\nhybrid clocks and common knowledge\n2\nHybrid-clock shift\nBecause every timestamp deviates from real time by at most ε, a node\nthat observes HLC ≥T can deduce that all events with timestamp\n< T −ε are in its past. That turns the impossibility into a quantitative\nstatement: facts can become ε-common knowledge.\nPractical upshot\nLinearizable commits, causal session guarantees,\nand wait-free consistent snapshots become feasible after one round\ntrip, provided the skew bound holds.\nLimitation\nIf ε blows up (GPS loss, NTP outliers, relativistic links)\nthe deduction fails and classical uncertainty returns. Hybrid clocks\ndo not escape Forward-In-Time-Only thinking; they merely bound its\nerror.\nRelation to FITO Perspective\nYour Forward-In-Time-Only critique argues that Newtonian time\nis a hidden axiom. Hybrid clocks expose—rather than erase—this\naxiom by making ε explicit. They therefore align with FITO analysis:\nprogress requires either\n• shrinking ε (better hardware sync), or\n• replacing deterministic bounds with probabilistic or reversible\nnotions of order.\nOpen Problems\n1. Dynamic ε. Adapt clocks when skew drifts.\n2. Probabilistic knowledge. Treat timestamps as confidence inter-\nvals.\n3. ICO-aware clocks. Design schemes that tolerate indefinite causal\norder and reversible transactions.\n4. Eventual common knowledge. Combine HVC pruning with DAG\ngossip in partitioned networks.\nTakeaways\nHybrid clocks bridge logical causality and imperfect wall time,\nachieving the effect of common knowledge after a bounded delay\nhybrid clocks and common knowledge\n3\nε. They power modern geo-replicated stores without heavy coordi-\nnation cost, but remain inside the FITO worldview. Future work will\nloosen or replace the global arrow of time.\nReferences\n[1] S. S. Kulkarni and N. Mittal. HybridTime: A decoupling of coordi-\nnation and time in distributed systems. TR, 2012.\n[2] S. S. Kulkarni, et al. Logical Physical Clocks and Consistent Snap-\nshots. 2014.\n[3] V. Karmarkar and S. S. Kulkarni. Bounds on Hybrid Vector Clocks.\nIEEE SRDS, 2015.\n[4] H. Wu, et al. CausalSpartanX: Causal consistency over HLC. Mid-\ndleware, 2016.\n[5] J. Su, et al. NuKV: Building a scalable and reliable KV store. SoCC,\n2020.\n[6] J. Y. Halpern and Y. Moses. Knowledge and common knowledge in\ndistributed environments. JACM 37(3), 1990.\n"
  },
  {
    "filename": "STANDALONE/DaedaelusHandout.pdf",
    "content": "Open Atomic Ethernet\nYour Name\nMay 2025\nExample Box\nThis is a highlighted callout box.\nLorem ipsum CELL, LINK, IUI...\n"
  },
  {
    "filename": "STANDALONE/Chiplet-Ethernet.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\nchiplet ethernet\n1\nChiplet Ethernet\nChiplet Infrastructures are like minia-\nture 2.5 or 3D cities\nWe begin with the work of Martha Allen Kim\n2D Clos Network on a Chip\nModel: A Sea of xPUs\n\u0003\u0019\u0019\u0015\u0013\r\u000b\u001c\u0013\u0018\u0017\n\u0004\u001a\u0013\r\u0014\n\u0007\u0002\b \r\u000b\u0019\n\u0005\u0015\u0013\u0019\u0001\r\u0012\u0013\u0019\u0001\f\u0018\u0017\u000e\u001b\n\n\u0018\u0010\u001c\u001d\u000b\u001a\u000f\n\u0006\u000b\u001a\u000e\u001d\u000b\u001a\u000f\n\t\u000b\u001a\u001c\u0013\u001c\u0013\u0018\u0017\u0013\u0017\u0011\u0001\u000b\u0017\u000e\u0001\n\u0019\u0015\u000b\r\u000f\u0016\u000f\u0017\u001c\nFigure 1: Figure 1.1 from Thesis. Cross\nsection of brick and mortar chip\nPolymorphic on-chip network\nNew Stuff\n\u0000\u0002\u0000\u000e\u0000\r\u0000\u000f\u0000\u000f\u0000\u0006\u0000\u0005\u0000\u000e\n\u0000\u0003\u0000\b\u0000\t\u0000\n\u0000\r\u0000\f\n\u0000\u0002\u0000\u000e\u0000\r\u0000\u000f\u0000\u000f\u0000\u0006\u0000\u0005\u0000\u000e\n\u0000\u0003\u0000\b\u0000\t\u0000\n\u0000\r\u0000\f\n\u0000\u0002\u0000\u000e\u0000\r\u0000\u000f\u0000\u000f\u0000\u0006\u0000\u0005\u0000\u000e\n\u0000\u0003\u0000\b\u0000\t\u0000\n\u0000\r\u0000\f\n\u0000\u0002\u0000\u000e\u0000\r\u0000\u000f\u0000\u000f\u0000\u0006\u0000\u0005\u0000\u000e\n\u0000\u0002\u0000\u000e\u0000\r\u0000\u000f\u0000\u000f\u0000\u0006\u0000\u0005\u0000\u000e\n\u0000\u0002\u0000\u000e\u0000\r\u0000\u000f\u0000\u000f\u0000\u0006\u0000\u0005\u0000\u000e\n\u0000\u0003\u0000\b\u0000\t\u0000\n\u0000\r\u0000\f\n\u0000\u0002\u0000\u000e\u0000\r\u0000\u000f\u0000\u000f\u0000\u0006\u0000\u0005\u0000\u000e\n\u0000\u0003\u0000\b\u0000\t\u0000\n\u0000\r\u0000\f\n\u0000\u0002\u0000\u000e\u0000\r\u0000\u000f\u0000\u000f\u0000\u0006\u0000\u0005\u0000\u000e\n\u0000\u0003\u0000\b\u0000\t\u0000\n\u0000\r\u0000\f\n\u0000\u0001\u0000\u0002\u0000\u0003\u0000\u0004\u0000\u0006\u0000\u0005\n\u0000\u0004\u0000\u000b\u0000\n\u0000\u0007\u0000\b\n\u0000\u0004\u0000\u000b\u0000\n\u0000\u0007\u0000\b\n\u0000\u0004\u0000\u000b\u0000\n\u0000\u0007\u0000\b\n\u0000\u0004\u0000\u000b\u0000\n\u0000\u0007\u0000\b\n\u0000\u0004\u0000\u000b\u0000\n\u0000\u0007\u0000\b\n\u0000\u0004\u0000\u000b\u0000\n\u0000\u0007\u0000\b\n\u0000\u0004\u0000\u000b\u0000\n\u0000\u0007\u0000\b\n\u0000\u0004\u0000\u000b\u0000\n\u0000\u0007\u0000\b\n\u0000\u0001\n\u0000\u0003\nFigure 2: Figure 3.2 from Thesis. Mi-\ncroarchitecture of the polymorphic\non-chip network\nHaving empirically realized that no single fixed-design on-chip net-\nwork efficiently communicates different styles of traffic, we have\ndesigned the polymorphic on-chip network. This network can be\nconfigured at runtime to mimic traditional fixed-function networks.\nFrom a hardware standpoint, the network is built from a sea of re-\nsources, namely buffers and cross-bars. Careful design allows post-\nfabrication or even runtime configuration of these resources to form\nan interconnect with a custom topology, buffer allocation, and packet\nsize.\nIn the case of random adversarial traffic, Figure 3.1 indicates that\na fat tree once again offers the lowest-latency communication option.\nAs with uniform random communication, some communicating\nnodes are going to be at a distance in the network, and thus, the non-\nneighbor connections proffered by the higher levels of the tree speed\nthat traversal.\nchiplet ethernet\n2\nThe differences in throughput amongst the fat tree designs on this\nworkload are entirely attributable to packet size: the larger the packet\nthe higher the throughput. This is feasible under the area budget,\nbecause the network does not require particularly deep queues on\nthis workload. The same is true of the mesh network, for which the\nbest designs incorporate large packets (128 bits) and short queues (4\nentries) to maximize throughput under the area budget. However, on\naverage, the packet latency through the mesh is slightly higher than\nthe fat tree due to the neighbor-only links.\nBy contrast, the local adversarial traffic experiences exactly the\nopposite result. While random traffic latency suffered on neighbor-\nonly topologies, the local adversarial traffic, which is neighbor-only,\ntook good advantage of those topologies. Thus, for this workload, the\nmesh topologies are optimal, with the ring not far behind. While we\nsee that there is a network to fit each workload, there is no network\nto fit\nall workloads. In other words, no network in the design space is\noptimal across all three workloads. The optimal designs often differ\nin topology, and, when the topologies are the same, the resource\nprovisioning is very different.\nAlthough these workloads are synthetic, it would not be far-\nfetched to encounter three similar patterns in the I/O cap, depending\non the brick selection and the application or input data set that is\nrunning. Unfortunately, in selecting a single network, one will neces-\nsarily have to sacrifice performance on one or more workloads.\nFigure 3: Multitree\n"
  },
  {
    "filename": "STANDALONE/Mathematical-Foundation.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\næthernet: ultra low latency (ull)\n1\nMathematical Foundation\nThis document explores a quantum-inspired approach to timing se-\nmantics for next-generation network fabrics. The aim is to replace\ntraditional, clock-based time assumptions in networking with a\nmodel based on causal relationships, partial orders, and epistemic\nlimitations—drawing inspiration from quantum foundations such as\nprocess matrices and indefinite causal order.\nI. Fundamental Entities\n1. Events (E)\nEach interaction in the network—send, receive, memory read/write—is\ndefined as an event.\nE = {e1, e2, . . . , en}\nEvents include:\nnoitemsep Local actions (send, receive, read, write)\nnoitemsep External interventions (application-level triggers)\nnoitemsep Transformations (e.g., protocol operations or rollbacks)\n2. Causal Relations (≺)\nWe define a partial order ≺over E, where:\nei ≺ej\nmeans event ei causally precedes event ej\nThe causal structure forms a directed acyclic graph (DAG):\nC = (E, ≺)\n3. Knowledge States (K)\nEach node N maintains a view of the causal DAG it has observed:\nKN ⊆C\nThis represents the epistemic state—what node N knows about the\nglobal causal structure.\næthernet: ultra low latency (ull)\n2\n4. Process Matrices (W)\nInspired by quantum process matrix formalism, we define:\nW : OA × IA × OB × IB →[0, 1]\nWhere:\nnoitemsep IX: Input space at node X\nnoitemsep OX: Output space at node X\nThe matrix W encodes the probabilistic behavior of the network\nunder intervention, generalizing classical protocols to causally uncon-\nstrained transformations.\nII. Operations and Semantics\n1. Interventions (IN)\nAn intervention is an operation applied by node N to its local state\nand input messages. It may:\nnoitemsep Modify local memory or state\nnoitemsep Emit messages\nnoitemsep Change KN, the local causal graph\n2. Reversible Operations\nAn operation α is reversible if:\n∃α−1 such that α−1(α(s)) = s\nThis enables speculative operations that can be rolled back if\ncausality later contradicts them.\n3. Composable Channels\nNetwork channels are modeled as morphisms in a symmetric monoidal\ncategory. Channels f : A →B preserve causal structure and compose\nas:\nf ◦g : A →C\nThis provides an algebraic framework for expressing message\npassing and network routing.\næthernet: ultra low latency (ull)\n3\nIII. Derived Structures\n1. Causal Metric\nDefine a causal distance d(ei, ej) as the shortest path in the causal\ngraph C from event ei to event ej, if ei ≺ej; otherwise, define it as ∞:\nd(ei, ej) =\n\n\n\nlength of shortest path from ei to ej,\nif ei ≺ej\n∞,\notherwise\nThis causal metric replaces wall-clock time as a measure of tempo-\nral separation.\n2. Causal Cones\nDefine the past cone and future cone of an event e as:\n• Past cone of e: all events ei ∈E such that ei ≺e\n• Future cone of e: all events ej ∈E such that e ≺ej\nThese causal cones are analogous to light cones in relativity and\ndefine the scope of an event’s potential influence and observability.\n3. Causal Consistency Conditions\nA protocol is said to be causally consistent if the following condition\nholds:\n∀ei, ej ∈protocol trace :\nei ≺ej ⇒effect(ei) is visible to ej\nIn this model, consistency is derived from graph traversal over the\ncausal DAG C, rather than from synchronized physical clocks.\n"
  },
  {
    "filename": "STANDALONE/Spekkens.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\næthernet: ultra low latency (ull)\n1\nFor FAQ based on this White paper\nSpekkens’ toy model is a non-contextual hidden variable model with\nan epistemic restriction, a constraint on what an observer can know\nabout reality. The aim of the model, developed for continuous and\ndiscrete prime degrees of freedom, is to advocate the epistemic view\nof quantum theory, where quantum states are states of incomplete\nknowledge about a deeper underlying reality. Many aspects of quan-\ntum mechanics and protocols from quantum information can be\nreproduced in the model. In spite of its significance, a number of\naspects of Spekkens’ model remained incomplete. Formal rules for\nthe update of states after measurement had not been written down,\nand the theory had only been constructed for prime-dimensional,\nand infinite dimensional systems. In this work, we remedy this, by\nderiving measurement update rules, and extending the framework to\nderive models in all dimensions, both prime and non-prime. Stabi-\nlizer quantum mechanics is a sub-theory of quantum mechanics with\nrestricted states, transformations and measurements. First derived\nfor the purpose of constructing error correcting codes, it now plays\na role in many areas of quantum information theory. Previously, it\nhad been shown that Spekkens’ model was operationally equivalent\nin the case of infinite and odd prime dimensions. Here, exploiting\nknown results on Wigner functions, we extend this to show that\nSpekkens’ model is equivalent to stabilizer quantum mechanics in all\nodd dimensions, prime and non-prime. This equivalence provides\nnew technical tools for the study of technically difficult compound-\ndimensional stabilizer quantum mechanics.\nFrom: https://arxiv.org/abs/1701.07801\nSpekkens’ toy model in all dimensions and its relationship with\nstabilizer quantum mechanics\nLorenzo Catani, Dan E. Browne\n=========================\nHow it ties in to Spekkens.\nFrom: https://arxiv.org/pdf/1411.1618.pdf\nA complete graphical calculus for Spekkens’ toy bit theory Miriam\nBackens Department of Computer Science, University of Oxford, Ox-\nford, United Kingdom miriam.backens@cs.ox.ac.uk Ali Nabi Duman\n"
  },
  {
    "filename": "STANDALONE/Conveyor-Belt.pdf",
    "content": "Discussion with Kevin Stanton\nand ChatGPT\nContents\nIntroduction: The Conveyor Belt Metaphor\n1\nConveyor Belt as Time (Special and General Relativity)\n2\nThe Conveyor Belt and Quantum Mechanics\n2\nWhy the Conveyor Belt Breaks with Indefinite Causal Order\n2\nIndefinite Causal Order\n3\nCompare to Lingua Franca\n5\nCompare to Lamport Clocks\n8\nIntroduction: The Conveyor Belt Metaphor\nLet’s use Kevin’s conveyor belt metaphor to describe time and its\nbehavior under special relativity, general relativity, and contrast it\nwith quantum mechanics and indefinite causal order.\nConveyor Belt as Time (Special and General Relativity)\nImagine time as a conveyor belt moving in one direction—forward.\nObjects, people, and events sit on this belt, carried steadily from past\nto future. The speed of the belt is consistent for everyone in classical\nphysics. However, in special relativity, the speed at which individ-\nuals experience this conveyor belt can vary depending on how fast\nthey are moving. If you’re moving quickly relative to someone else,\nyour conveyor belt slows down relative to theirs. You’re still moving\nforward on your own belt, but the difference in speeds between the\nbelts means time passes more slowly for you (this is time dilation).\nIn general relativity, gravity also affects the conveyor belt’s speed.\nThe closer you are to a massive object, the slower your conveyor\nbelt moves compared to someone farther away. This is due to grav-\nitational time dilation. Each person is on their own conveyor belt\nof time, but the rate of movement can change depending on their\nproximity to mass or their velocity. However, no matter the speed or\nhow warped the conveyor belt becomes, time still moves consistently\nforward for each individual, even if it does so at different rates.\ndiscussion with kevin stanton and chatgpt\n2\nThe Conveyor Belt and Quantum Mechanics\nQuantum mechanics disrupts this conveyor belt metaphor. In the\nquantum world, things don’t behave in a neatly predictable way, and\ntime doesn’t always behave like a simple forward-moving belt. Quan-\ntum systems can exist in superpositions, meaning they are in mul-\ntiple states at once. If you try to apply the conveyor belt metaphor\nhere, you’d have to imagine a belt where objects are not just moving\nforward but might also exist at multiple points along the belt at the\nsame time. The simple idea of one thing following another breaks\ndown because quantum mechanics deals with probabilities rather\nthan certainties.\nMoreover, events at the quantum scale don’t always happen in a\ndefinite order. This leads to the concept of indefinite causal order.\nWhy the Conveyor Belt Breaks with Indefinite Causal Order\nIn indefinite causal order, the very idea of a consistent forward-\nmoving belt doesn’t hold. Imagine you’re now dealing with multi-\nple conveyor belts, but these belts can become entangled and swap\npositions. A key feature of indefinite causal order is that it is impos-\nsible to say whether event A happens before or after event B with\ncertainty.\nTo continue the metaphor:\n• Instead of a single conveyor belt that everyone rides, imagine a\nconveyor belt that can fork, loop, or even reverse for some events.\nOn this belt, two events (say, picking up two different objects)\nmight not have a clear sequence. You could pick up Object A\nbefore Object B, or Object B before Object A, or some mixture of\nboth where the order isn’t fixed until you observe it.\nIn quantum mechanics, particularly with indefinite causal order,\ntime isn’t a well-defined forward flow. Events can occur in a superpo-\nsition of orders, defying the classical notion of a consistent timeline.\nThere’s no global, shared belt moving forward—some events might\nnot even have a clear “before” and “after.”\nSpecial and General Relativity Work with the Conveyor Belt:\n• Special Relativity: The belts are still mostly linear but stretch or\ncompress based on speed, meaning time passes differently for\nobservers in motion relative to one another.\ndiscussion with kevin stanton and chatgpt\n3\n• General Relativity: The belts warp under gravity, slowing down\nnear massive objects but still remaining orderly, with a clear flow\nfrom past to future.\nIndefinite Causal Order Breaks the Metaphor:\n• In quantum mechanics, particularly in scenarios involving indef-\ninite causal order, the metaphor falls apart. The belts aren’t just\nstretching or warping—they no longer move in a straightforward,\nfixed order. Time becomes a superposition of possible orders, and\nthe concept of a simple, directional flow of events can no longer\napply.\nThe conveyor belt metaphor works well for special and general\nrelativity because it reflects the relative nature of time: it still flows\nin one direction but at varying rates. For quantum mechanics and\nindefinite causal order, the metaphor breaks down, as time and\ncausality become fluid, probabilistic, and not bound to a definite\nsequence.\nIndefinite Causal Order\nIndefinite causal order is a concept that comes from quantum me-\nchanics and challenges the traditional notion that events occur in a\ndefinite sequence. In classical physics and most of computer science,\nevents are understood to happen in a fixed, linear order—first A,\nthen B, then C. However, indefinite causal order allows for scenarios\nwhere the order of events is not set in stone, meaning that, in cer-\ntain quantum processes, it’s impossible to say definitively whether A\nhappened before B or vice versa.\nWhen applied to computer science, particularly in areas like dis-\ntributed systems, quantum computing, or complex event processing,\nindefinite causal order could have profound implications. Here’s how\nit connects:\nDistributed Systems:\nIn classical distributed systems, events are often coordinated using\nsynchronized clocks or timestamps (like in Lamport clocks) to estab-\nlish the order of events. But this assumes a definite, forward-in-time\nprogression. In a world where causality can be indefinite, such as\nin quantum communication protocols, the assumption that events\noccur in a strict order breaks down. This could affect how we model\nconsistency, causality, and concurrency in distributed systems.\ndiscussion with kevin stanton and chatgpt\n4\nFor example, most distributed systems assume that causal rela-\ntionships between events can be traced back in time (e.g., message\nA must have been sent before message B). Indefinite causal order\ncould complicate this by introducing scenarios where it’s unclear in\nwhat order events happened, leading to new ways to think about\nsynchronization, coordination, and consistency.\nQuantum Computing:\nIn quantum computing, the idea of indefinite causal order directly\ntranslates to certain computational advantages. One prominent ex-\nample is the Quantum SWITCH, where two operations are performed,\nbut their order is determined by the quantum state. This can lead to\nmore efficient algorithms because the system doesn’t need to follow\na strict causal sequence of operations. For example, in some cases,\ntasks can be performed more efficiently by allowing operations to\nexist in a superposition of different causal orders.\nEvent-Driven Systems and Reactive Programming:\nIn event-driven or reactive systems, we often deal with streams of\nevents and have to react to them in a specific order. If indefinite\ncausal order were applicable, it would mean rethinking how systems\nreact to events because the sequence of those events might not be\nfixed. This might lead to more flexible systems, but also requires new\nmodels of computation that can handle ambiguity in event timing\nand ordering.\nLogical Time and Causal Models:\nOne key area where indefinite causal order could be explored in\ncomputer science is in extending the concept of “logical time” used\nin distributed systems. Today, we have models like vector clocks and\nLamport clocks to track causal relationships between events. If we\nconsider indefinite causal order, it might require developing new\nabstractions of time that are capable of representing ambiguous or\nsuperposed causal sequences. This could impact algorithms that rely\non strict ordering, like consensus algorithms or conflict resolution\nmechanisms.\nFuture Implications:\nIncorporating indefinite causal order into computer science, partic-\nularly in quantum computing and communication systems, might\nchallenge foundational assumptions about how programs execute,\ndiscussion with kevin stanton and chatgpt\n5\nhow data is shared, and how systems coordinate. Researchers are\nbeginning to explore how these ideas could lead to new architec-\ntures that embrace uncertainty or non-linearity in causality, pushing\nbeyond the limits of classical synchronization methods.\nCompare to Lingua Franca\nEdward Lee’s Lingua Franca (LF) and the Reactors programming\nmodel are built around very different assumptions about time and\ncausality than those implied by indefinite causal order in quantum\nmechanics. To explore the comparison, let’s break down how each\nframework approaches time and causality and where they diverge.\n1. Lingua Franca and Reactors: Assumptions About Time\n• Deterministic Logical Time:\nLingua Franca (LF) is designed to deal with time explicitly in dis-\ntributed systems and cyber-physical systems (CPS). Its model\nassumes deterministic logical time, meaning the sequence of\nevents is well-defined and unambiguous. The idea is to provide a\nclean, deterministic model where events are processed according\nto a well-ordered timeline.\nIn the Reactors programming model, time is also central. Events\nare triggered in response to other events based on strict logical\ndependencies and causal relationships. Reactors operate under a\ncausality principle, where one event triggers another, creating a\ndeterministic flow of information. LF provides a way to manage\nthis using timestamps, ensuring that events execute in a known\norder, even in distributed systems where physical time (real-world\nclock time) may vary.\nThis focus on logical determinism means that in LF, all partic-\nipants in a distributed system have a consistent understanding\nof the event ordering, even if they are physically separated. The\nsystem explicitly synchronizes on logical time to ensure causal\nrelationships are respected.\n2. Indefinite Causal Order:\n• Causal Ambiguity:\nIndefinite causal order is fundamentally different. In quantum\nmechanics, particularly in processes like the Quantum SWITCH,\nevents can occur in a superposition of orders. There is no clear\ndistinction between “before” and “after” for certain events. This is\nbecause quantum mechanics allows for a superposition of states,\ndiscussion with kevin stanton and chatgpt\n6\nwhich can include superpositions of different causal orders. As a\nresult, the causal relationships between events can be indefinite or\nnon-deterministic.\nIn the framework of indefinite causal order, the assumption of\ndeterministic logical time breaks down. The sequence of events\nmight not be clearly defined until some measurement or interac-\ntion occurs, and the system could be in a state where causality\nitself is undefined or ambiguous. This introduces a fundamental\nuncertainty about which events caused others, contrary to the\ndeterministic approach taken by LF.\n3. Comparing Assumptions on Time and Causality:\n• Lingua Franca assumes that:\n– Time is deterministic, meaning every event has a clear cause\nand effect, and that logical time is the primary tool to ensure\nconsistency in distributed systems.\n– Logical causality can always be enforced and preserved through\ncareful design of time-triggered reactions and event-driven\ncomputations.\n– The real world might have uncertainties in physical clocks\n(due to relativity or synchronization issues), but logical time\ncan compensate for those discrepancies and create a shared\ntemporal framework that all parts of the system agree upon.\n• Indefinite Causal Order, in contrast:\n– Rejects the idea that all events can be ordered definitively.\nThere may be no clear “cause” or “effect” in certain quantum\nprocesses.\n– Embraces the possibility that causality itself can be indetermi-\nnate, allowing for events to be in superpositions of different\ncausal orders.\n– Cannot be modeled with strict logical timestamps because the\nvery concept of time order may be undefined until measure-\nment occurs.\n4. Where Lingua Franca Works and Where it Struggles:\n• Lingua Franca’s conveyor belt analogy:\nIn LF, time is much like a carefully managed conveyor belt.\nEvents flow forward in time, and the system is designed to ensure\nthat no matter how distributed or asynchronous the components\nare, they will agree on the causal order of events. This works\ndiscussion with kevin stanton and chatgpt\n7\nbeautifully in systems where deterministic behavior is crucial, like\nin CPS, real-time systems, or distributed computing where timing\nguarantees are needed.\n• Indefinite Causal Order breaks this model:\nThe assumption behind LF that all events can be determinis-\ntically ordered along a logical timeline fundamentally breaks\ndown when applied to scenarios involving indefinite causal order.\nQuantum systems with indefinite causality cannot be modeled us-\ning LF’s deterministic logical time, as there may not be any single\n“correct” timeline.\n5. The Conveyor Belt vs. Forked Paths:\n• Lingua Franca:\nThe conveyor belt metaphor works well for LF. The belt may be\nfast or slow, but it always moves in a clear direction, and events\nare placed in a strict order on it. Logical time is like a regulating\nmechanism that ensures the belts of different agents are synchro-\nnized in the right sequence.\n• Indefinite Causal Order:\nInstead of a simple conveyor belt, imagine a system where multi-\nple belts can split, re-merge, and sometimes create loops. Events\nmay occur in superpositions of these different belts. When you\ntry to observe them, you might find that two events could have\nhappened in either order, or perhaps simultaneously in different\norders depending on how you measure.\n6. Conclusion:\n• Lingua Franca and Reactors are built on the classical assump-\ntions of time: causality is strict, logical, and deterministic. Events\ncan be ordered using logical time, and causality can always be\nrespected across distributed systems. LF succeeds in providing\na structured, well-defined temporal model that works in a wide\nrange of practical applications.\n• Indefinite Causal Order challenges the very foundation of these\nassumptions. In quantum systems with indefinite causality, events\ndon’t necessarily have a strict temporal order. Causality becomes\nprobabilistic or even undefined until observed. This fundamen-\ntally contradicts LF’s reliance on determinism and logical times-\ntamps. If LF were to be applied in a system where causal order is\nindefinite, the model would need to be rethought to accommodate\nthe ambiguity and superposition of events.\ndiscussion with kevin stanton and chatgpt\n8\nThe core difference between Edward Lee’s Lingua Franca and\nquantum-based indefinite causal order lies in how they treat time: LF\nenforces strict, deterministic event ordering, while indefinite causal\norder introduces a probabilistic, non-linear flow of events where time\nand causality can be ambiguous and undefined.\nCompare to Lamport Clocks\nLamport’s notion of logical time and the concept of indefinite causal\norder represent two very different approaches to understanding\ntime and causality in distributed systems and quantum mechanics,\nrespectively. Let’s compare these concepts in detail:\n1. Lamport’s Logical Time:\nLamport introduced logical clocks to address the problem of order-\ning events in distributed systems, where physical clocks cannot be\nperfectly synchronized due to the limits of speed, network latency,\nand other issues. Logical time doesn’t rely on actual clock time but\ninstead on the happens-before relation, which captures the causal\nrelationships between events. The main features of Lamport’s logical\ntime are:\n• Happens-Before Relation (→):\nIf event A causes event B (e.g., by sending a message), we say\nA →B. This relation defines the causal structure in the system.\n• Event Ordering:\nEvery process maintains a logical clock. When an event occurs,\nit increments its clock and attaches this timestamp to any mes-\nsage sent. When another process receives the message, it updates\nits logical clock to reflect that the event has already happened,\nensuring that causality is respected.\n• Total Ordering:\nWhile logical time can establish a partial ordering of events based\non causal relationships, Lamport’s logical clocks do not give a\ncomplete global time ordering. However, vector clocks and other\nmechanisms can extend logical clocks to achieve more precise\ncausal tracking.\nThe key idea is that Lamport’s logical time helps enforce causal\nconsistency across distributed systems, ensuring that events are\nordered in a way that respects causal relationships between them.\nHowever, the system still assumes a definite sequence of events—either\nevent A happens before B, or B happens before A.\ndiscussion with kevin stanton and chatgpt\n9\n2. Indefinite Causal Order:\nIndefinite causal order, originating from quantum mechanics, breaks\nthe classical assumption of definite event ordering. In certain quan-\ntum processes, events can exist in a superposition of different causal\norders. This means:\n• No Definite Ordering:\nTwo events, A and B, can occur in a superposition of different se-\nquences. It’s not clear whether A happens before B or vice versa.\nBoth possibilities can exist simultaneously until an observation is\nmade.\n• Quantum SWITCH Example:\nA quantum protocol like the Quantum SWITCH allows two op-\nerations to be performed in such a way that the order in which\nthey occur is not definite. For example, A might influence B and\nvice versa, but the precise causal sequence is only determined\nprobabilistically upon measurement.\n• Causal Superposition:\nIndefinite causal order challenges the classical notion of time and\ncausality by allowing for events that don’t have a single, well-\ndefined causal relationship. This differs radically from classical\nmodels like Lamport’s logical time, where the goal is to create a\ndefinite order for every event based on causal relationships.\n3. Comparison of Causality:\n• Lamport’s Logical Time:\nIn distributed systems, causality is explicit and must be pre-\nserved. Event A either happens before or after event B, and Lam-\nport’s logical clocks enforce this by ensuring all processes agree\non the causal order of events, even in the absence of synchronized\nphysical clocks. The aim is to create a consistent and well-defined\ntimeline.\n• Indefinite Causal Order:\nIn quantum mechanics, causality can be indefinite, and events\ncan exist in a superposition of causal orders. This is fundamen-\ntally different from Lamport’s approach, where causality is strict\nand must be maintained. In quantum systems, there may not be a\nclear, observable sequence of events until they are measured.\n4. Time and Event Ordering:\n• Lamport’s Logical Time:\ndiscussion with kevin stanton and chatgpt\n10\n– Relies on the happens-before relation to preserve a well-\ndefined, consistent causal order between events.\n– Logical timestamps are assigned to events based on causal\ndependencies, so we can always say A happened before B, or B\nhappened before A.\n– The focus is on ensuring causal consistency, even in asyn-\nchronous, distributed systems.\n• Indefinite Causal Order:\n– Time is not well-defined. Events can occur in a superposition\nof causal orders, meaning A and B might have happened in\nboth orders simultaneously, and there is no definite causal\nrelationship until a measurement is made.\n– The classical notion of time, where events occur in a linear,\nordered sequence, doesn’t apply. Instead, causality becomes\nprobabilistic and only resolves upon observation.\n– This contrasts with logical time, which enforces order regard-\nless of real-time discrepancies.\n5. Applications in Distributed Systems vs. Quantum Systems:\n• Lamport’s Logical Time:\nWorks well in distributed systems where ensuring a consistent,\nagreed-upon event ordering is critical. It helps manage concur-\nrency, ensure that messages and actions are causally related, and\nmaintain consistency in asynchronous environments. Lamport’s\nclocks can provide a deterministic causal structure in environ-\nments where physical time cannot be relied upon.\n• Indefinite Causal Order:\nApplies to quantum systems where the classical notion of causal-\nity and time does not hold. This idea is particularly useful in\nquantum communication and quantum computing, where indef-\ninite order can be exploited for computational advantages (e.g.,\nthe Quantum SWITCH). It introduces a level of uncertainty and\nflexibility that cannot exist in systems governed by logical time.\n6. Fundamental Differences in Handling Time:\n• Lamport’s Logical Time:\nAssumes a linear, forward-moving flow of events, where causal\nrelationships are always definite and traceable. Time, in this con-\ntext, is deterministic, even though it may be logical rather than\nphysical.\ndiscussion with kevin stanton and chatgpt\n11\n• Indefinite Causal Order:\nTime can be non-linear and non-deterministic. Events may not\nhave a clear before/after relationship until they are observed,\nmeaning that causality is not well-defined in the classical sense.\nTime is less a forward-moving arrow and more a probabilistic,\nsuperposed system.\n7. Summary:\n• Lamport’s Logical Time provides a definite ordering of events\nin distributed systems, ensuring that causality is preserved and\nthat events follow a strict happens-before relationship. It operates\nwithin a classical, deterministic framework, where every event has\na well-defined place in the timeline.\n• Indefinite Causal Order introduces the possibility that causal-\nity is not always fixed. In certain quantum systems, events may\nnot have a clear ordering, and time is probabilistic rather than\ndeterministic. This concept challenges the very foundation on\nwhich logical time is built, as it allows for causal ambiguity and\nnon-determinism.\nIn short, Lamport’s logical time is a deterministic tool designed\nto enforce causality in distributed systems, whereas indefinite causal\norder belongs to the realm of quantum mechanics, where causality\nitself can be in superposition. The two are fundamentally at odds, as\none imposes strict order while the other allows for causal uncertainty.\n"
  },
  {
    "filename": "STANDALONE/rethinking-fabrix.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\nRethinking Datacenter Fabrix\nSahas Munamala, John Lockwood, Alan Karp, Paul Borrill\nDAE-logo.png\nDistributed Computation\nMany problems encountered in datacenters today arise from our\ninability to distinguish between a node that is merely slow from\na node that has failed or become unreachable due to a network\nfailure.\nWe take the two most recognizable elements in datacenters today:\nservers and switches, and refactor them into simpler, more founda-\ntional elements (fully independent failure domains): cells and links.\nA cell is a single type of node element (autonomous unit of com-\npute, storage and packet processing). A link is an individual, bidi-\nrectional, computation object (an autonomous communication entity\nbetween two cells)1.\n1 Think of a link as a compute element\nwith its own autonomous and inde-\npendent failure domain; comprising\nthe cable and NICs on both ends which\nform their own self contained execution\nenvironment. In the same way devices\nwithin a single execution environment\nare considered a single failure domain;\nthe link can detect device and cable\nerrors and stop the machine.\nA consequence of the former is that unifying node elements makes\nthings simpler because we have only one type of node to manage\ninstead of two. The consequence of the latter is profoundly more\ninteresting: we raise the notion of a link to first order – a first-class\ncitizen in the infrastructure – a bipartite2 element of information with\n2 Not related to biparitie graphs. Here,\nwe mean the more classical definition\nof bipartite as “having two parts, or an\nagreement between two parties.”\ntwo complementary halves – persistable through failure and recovery\nevents. i.e., a communication object that doesn’t rule out that some\nfault-detection and computation is involved.\nAn example3 link utility is The I Know That You Know That I Know\n3 Synchronization of timing domains\nin computers generally start from the\nprocessor clock on the motherboard,\nand fan out through the logic into the\nI/O subsystems. AIT is the link between\ntwo computers, and although it receives\ninformation from either side, it is not\nsynchronized to either side. This “deep\nasynchronous domain\" enables failure\nindependence and atomicity.\n(TIKTYKTIK) property; which enables us to address some of the most\ndifficult and pernicious problems in distributed systems today.\nAnother example link utility is Atomic Information Transfer (AIT).\nUnlike replicated state machines used throughout distributed applica-\ntions today, links are single state machines: the two halves of which\nmaintain temporal intimacy through hidden packet exchanges. When\na local agent or actor is ready, the AIT protocol transfers indivisible\ntokens across the link to the other agent, atomically (all or nothing)4.\n4 links are exquisitely sensitive to packet\nloss. This is intentional: we turn the\nFLP result upside down, and use a single\nfailed process to guarantee the atomic\nproperty for AIT.\nThese TIKTYKTIK and AIT properties are composable. Trees of links\nprovide a resilient conserved quantities mechanism to reliably dis-\ntribute tokens among agents on an application graph. Intermediate\ncells promise5 to never lose AIT tokens. This defends against lost to-\n5 The alternative definition of Fu-\ntures/Promises also applies: execution\nis primed to create future liveness events.\nkens because if any part of the chain (or tree) breaks, alternate paths\nare available to seamlessly recover the conserved quantity and con-\ntinue operation.6.\n6 links also provide a more reliable\nfoundation for distributed system\nservices for applications: consensus,\natomic broadcast, leader election, and\ndistributed arithmetic, Which, in-turn,\nenable higher level functions such as\nnetwork-assisted-transactions which serve,\nfor example, distributable (scale-out),\npersistable (durable), and lightweight\n(but-accurate) accounting of conserved\nquantities associated with application\nstate or resource usage.\nBy strengthening the system model, links and AIT provide a\ngeneral foundation to solve many distributed systems problems\nfaq-dae)\n2\nSingle-Link2.pdf\nsuch as failure-detection, consensus and distributed transactions.\nFailure Modes\nOne might imagine7 if each host (or its SmartNIC) maintains its half\n7 Such a recovery mechanism is not\navailable through conventional\nswitched networks; because of the\nuncertainty of how many packets\nwere lost, exactly where along the\npath through the switched network\nthey were lost, how many were dupli-\ncated, and how they might have been\nre-ordered in the switched network.\nof the shared state, then shouldn’t the switched network be able to\nact as a proxy for a single logical link? When a switched network\nfails, and reroutes, can’t the two sides (SmartNICs) just stitch the two\nhalves of the shared state back together again? we could achieve the\nproperties of links over existing switched networks.\nThis simple hazard analysis8 misses a fundamental issue: networks\n8 Typical hazards: (1) Servers with a link\nto a single Top of Rack Switch (ToR)\nare unable to heal at all; there is only\none path from the server to anyone.\n(2) ToRs represent SPoFs; when they\nfail, many servers (in that rack) also\nbecome unavailable. Worse still: the\nservers don’t go down, they keep on\ncomputing but don’t know they are\nisolated. ToRs have also been known to\nexhibit complex cascade failures where\na firmware failure triggered in one will\ntake down many neighbor TORs.\ndon’t maintain state on behalf of applications. Switches drop packets (and\nstate) whenever they feel like it, so there are many more ways for\nlogical links to get confused over switched networks and compromise\nthe integrity of the shared state.\nKey issue: Switched networks drop packets anywhere along the\npath; eradicating state and events needed to maintain promises\nand liveness respectively. When a link fails, both sides are pre-\nfaq-dae)\n3\nserved. If there is a failure in the token transfer it can always be\ndetected, and retransmissions occur only on a real failure (such as\ndisconnection–where alternative routes are explicitly coordinated\nwith applications), thus enforcing that tokens have no duplicate\nor out of order deliveries on the link9,10.\nWhen packets are dropped in a switched network, more than infor-\nmation is lost, events are lost, and it becomes extraordinarily diffi-\ncult to recover both sides of a shared state that stretches across even\na single switch. A directly connected link can promise three things\na switched network cannot11: (a) maintain an ordering of events\n9 Even without failures, the behavior\nof switched networks forces us into a\nhigh overhead approach. If packets can\nbe indiscriminately dropped, delayed,\nduplicated and reordred, we have no\nchoice but to implement TCP/IP, or\nsomething very much like it (which\nis unlikely to have the maturity and\nrobustness of the existing tried and\ntested implementations). However, even\nin optimal situations, TCP introduces\nhigh overhead for all operations, which\nis too slow (e.g. Coherent Distributed\nShared Memory Systems). There is no\nescape: if you have dropped, delayed\nduplicated or reordered packets, you\nhave to effectively implement TCP. If\nwe can eliminate duplication and re-\nordering, recovery is far simpler, and\nremoves the overhead from normal\noperations.\n(heal, send packets, fail, heal again, send more packets) – essential\nfor non-idempotent and non-commutative operations. (b) not drop\ncertain packets without notification – essential for recovery. And (c)\nmaintain complementary direction state – essential for distributed\nself-stabilizing algorithms.\nBipartite Integrity\nThe shared state property is strengthened by mechanisms to recover\nfrom each type of failure. The more types of failures, the more com-\nplex and intractable this becomes. Links are independent failure\ndomains, with (effectively) one failure hazard:\ndisconnection12; which is straightforward to recover from. Switched\n10 Links do not reorder or duplicate\npackets so we can now use a high-\nperformance udp-like protocol for\ncoherence; only paying the performance\ncost of TCP when it fails for real, i.e.\ndisconnection. Remarkably, this also\npaves the way for very high bandwidth\nutilization for datacenter to datacenter\napplication flows, because it eliminates\nthe most difficult aspects of reordering\nand duplication of packets\nnetworks, on the other hand, have many more failure hazards: they\nindiscriminately drop, delay, duplicate and reorder packets – that’s\njust the way networks behave – justified by the end to end argu-\nment13.\n11 Actually, a link can promise many\nmore than just these three things:\nwhatever property the agent, actor\nor application wishes to attach to the\nbipartite link object.\nThe shared state TIKTYKTIK property can also be used to mitigate\nbroadcast storms in network rendezvous, timeout storms in microser-\nvices, or reconstruction storms in erasure coded storage14. In AIT,\n12 In any physical system it is possible\nto drop packets, it will be much rarer\nbut it is still possible. links can recover\nfrom individually dropped or corrupted\npackets, and shared state integrity can be\nmaintained.\npackets are not merely dropped, they are replaced with special events\ndenoting failure, to maintain liveness. Because link failures are in-\ndependent (unlike switched networks) we can successively recover\nindividual disconnection failures. This single step recovery mecha-\nnism paves the way for AIT to reverse one or more steps in distributed\nsystems which use non-idempotent or non-commutative data struc-\ntures.\nDisconnection is the most likely failure hazard in links. Packets\ndelayed by disconnected links don’t threaten liveness or the\nintegrity of the shared state. Switched network hazards include:\nindiscriminately dropped, delayed, duplicated and reordered packets.\nfaq-dae)\n4\nConventional mitigations (e.g. TCP) add significant complexity\nand performance overheads, and still fail to solve the problem.\nExamples\nThe advantage of the shared state is that both sides know the link is\nbroken15. which can’t be done through a switched network with even\n13 The end-to-end principle states that in\na general-purpose network, application-\nspecific functions ought to reside in the\nend hosts of a network rather than in\nintermediary nodes, provided that they\ncan be implemented “completely and\ncorrectly” in the end hosts. Our claim\nis that it is impossible to implement\nbidirectional synchronization primitives\n“completely and correctly” without\nAIT (or something very much like it).\nThe datacenter is not the Internet, and\nSaltzer, Reed, & Clark considered only\na careful (unidirectional) file transfer,\nnot the bidirectional synchronization of\nreplicas (coherency).\na single switch in series. links simplify some important distributed\nsystem algorithms such as two-phase commit, consensus and reliable\ntree generation:\nTwo-phase commit The prepare phase is asking if the receiving agent\nis ready to accept the token. This serves two purposes: communi-\ncation liveness and agent readiness. Links16 provide the communi-\n14 Links also coalesce heartbeats to\nmake microservices more scalable, and\nmake failure detectors reliable.\ncation liveness test, and we can avoid blocking on agent ready, by\nhaving the link store the token on the receiving half of the link.\nIf there is a failure, both sides know; and both sides know what to\ndo next.\nPaxos “Agents may fail by stopping, and may restart. Since all agents\nmay fail after a value is chosen and then restart, a solution is im-\npossible unless some information can be remembered by an agent\nthat has failed and restarted”. The assumption is when a node\nhas failed and restarted, it can’t remember the state it needs to\nrecover. With AIT, the other half of the link can tell it the state to\nrecover from. This avoids the performance cost of heavyweight\ntransactions and persistent storage. [INSERTED]\nWhy can’t the sending side on Paxos keep the information the\nreceiving side needs in case it fails? The other side of the link\nknows: the state that was lost in the crash is maintained by the\nhalf of the link on the other side. In leader election a master sends\na request to a worker (prepare) and it doesn’t get the ack. With\nAIT, the master knows definitively, if it is a neighbor.\nIn two-phase commit (2PC) there is no safety proof. In three-phase\ncommit, there is no liveness proof. Can we also often eliminate the\nprepare phase in consensus and 2PC? 17 which improves perfor-\n15 The shared state can be compromised\nby duplicated or reordered packets, but\nit is resilient to lost or delayed packets.\nmance.\nOne or more corner cases are eliminated where the replicated state\nmachine can get blocked due to the loss of an acknowledgement\npacket.\nAIT provides significant advantages in distributed computing by\nmaking corner cases disappear, it makes it simpler to implement\nfaq-dae)\n5\nthose distributed algorithms correctly, and the number of circum-\nstances where things go wrong is reduced by (potentially) several\norders of magnitude.\nReliable tree generation Binary link reversal algorithms18 work by\n16 Links exploit a unique combination\nof physics, electrical engineering and\ncomputer science. Think of AIT as\nthe distributed systems (message-\npassing based) equivalent of the atomic\nCompare And Swap (CAS) primitive\nused in shared memory architectures.\nThe result is handshake-free messaging\nwith strong liveness, recoverability and\nsecurity properties.\nreversing the directions of some edges. Transforming an arbitrary\ndirected acyclic input graph into an output graph with at least one\nroute from each node to a special destination node. The resulting graph\ncan thus be used to route messages in a loop-free manner19. Links\n17 And in three-phase commit, the\npre-prepare phase\nstore the direction of the arrow (head and tail); AIT facilitates the\natomic swap of the arrow’s tail and head to maintain loop-free\nroutes during failure and recovery.\n18 Charron-Bost et. al. generalize the\nGafni-Bertsakas (GB) binary link\nreversal algorithm.\nConclusion: Links require a single physical connection; their\nbenefits cannot be achieved over switched networks composed of\na chain of unreliable links. 20.\nCombining the TIKTYKTIK and AIT properties with various\nclassical algorithms, provides a general foundation to solve many\ndistributed systems problems, as well as to mitigate broadcast,\ntimeout and reconstruction storms in networks and distributed\nstorage.\n"
  },
  {
    "filename": "STANDALONE/History.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\næthernet: ultra low latency (ull)\n1\nHistory\nOpen Atomic Ethernet – Main Page\nLatex’d Version of 1976 Metcalfe + Boggs\nFrom Bob Metcalfe – Try this podcast\nabout the 1976 Ethernet paper. Artificial\nintelligences sound male and female,\nbut are not human. Amazing.\nPodcast - 1976 Metcalfe + Boggs\nEthernet-Boggs-Metcalfe.pdf\nReliableTransmissionOverHalfDuplex_Lynch_CACM_1968.pdf\nToDo: Presentation on the history and principles of the PUP Format.\nGoogle Drive Collection of Documents\nFAQ from Bob Metcalfe\n• Why call it Ethernet if Ethernet is now so defunct?\n• Will Chiplets be upstaged by wafer-scale semiconductors?\n• Ethernet is enjoying evolution and expansion in automotive and\nartificial intelligence and edge and ...\n• How about you coordinate with the current Ethernet consortia\nincluding 802?\nThe End-To-End (E2E) Principle is a failed architectural theory\nQUESTION : You wrote in your paper that the \"E2E principle as-\nsumes smart endpoints and a dumb network, which worked when\nendpoints could coordinate state easily in one core system.\".\nI had long discussions about the E2E Principle with Saltzer and\nDavid Clark. We actually discussed this principle in a panel I moder-\nated in a conference in Dubai last Feb.\nThis is Saltzer input:\n\"Because there may be trade-offs among competing considerations, we\ncalled end-to-end an “argument” rather than proposing that it be a\nhard-and-fast design rule. If we were writing the paper today, it would\nundoubtedly include some discussion of recent “computing in the\nnetwork” concepts, and point out the ways that at least some of those\nconcepts are consistent with an end-to-end, application knows best,\nperspective.\"\n\"The basis of the end-to-end principle is that the application knows\nbest. If the application has the ability to tell an in-network service \"Do\nX when you see my packets” that would seem to support the end-to-\nend principle.\"\nANSWER: The end to end principle is designed for file transfer, not\ntransactions.\næthernet: ultra low latency (ull)\n2\nWhen network designers believe they have a god-given right to\nDrop, Reorder, Duplicate and Delay packets, this creates unbounded\nreordering buffer resource explosions on the endpoints.\nApplications are forced into only one solution: Timeout and Retry\n(TAR) – the root of all evil.\nThis is fundamentally in conflict with what modern applications\nneed for ACID guarantees.\n"
  },
  {
    "filename": "STANDALONE/Objective-Comparison.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\nLink Fabrics: An Objective Comparison\nChatGPT, Sahas Mulamala, Paul Borrill, et.al.\nMay 12, 2025\nThis document provides a technical overview of five prominent link\nfabrics: NVLink, UALink, Scale-Up Ethernet, InfiniBand, and conven-\ntional Ethernet. We evaluate their architectural characteristics, header\noverheads, and implications for block-size efficiency, with particular\nfocus on suitability for modern workloads such as AI, HPC, and disag-\ngregated systems. We present side-by-side comparisons of header sizes\nrelative to data payloads and reflect on architectural biases that favor\nor hinder scalability, latency, and composability.\nIntroduction\nAs computation and memory disaggregation evolve, the role of the\ninterconnect becomes central. Whether linking GPUs in an AI train-\ning pod, scaling up a symmetric multiprocessor system, or tying\ntogether memory and compute pools across racks, the link fabric is\nthe substrate on which system performance is built.\nEach fabric comes with assumptions about packet size, latency,\nerror recovery, congestion handling, and topology. In this review, we\nprovide a comparative analysis of five contenders:\n• NVLink (NVIDIA): High-bandwidth, low-latency GPU intercon-\nnect\n• UALink (AMD, Broadcom et al.): Emerging open alternative to\nNVLink\n• Scale-Up Ethernet: Evolving conventional Ethernet for tightly\ncoupled systems\n• InfiniBand: HPC-focused with credit-based flow control and low-\nlatency verbs\n• Conventional Ethernet: Ubiquitous best-effort packet transport\nArchitectural Overview\nTopology and Purpose\n• NVLink: Point-to-point or mesh GPU topologies with explicit\nscheduling and hardware-managed coherence domains.\n• UALink: Targeted as a broader standard across vendors; switch-\nbased; supports memory pooling and accelerator interconnect.\nlink fabrics: an objective comparison\n2\n• Scale-Up Ethernet: Designed to bring reliability and ordered\ndelivery to Ethernet via reduced headers, low-latency slicing, and\npotential for transaction-level acknowledgment.\n• InfiniBand: Mature switch-based architecture, deeply integrated\ninto RDMA stacks and MPI; emphasis on zero-copy and reliable\ntransport.\n• Ethernet: Best-effort delivery; scales via oversubscription and\nbuffering; header-heavy; assumes software-managed retry.\nHeader Overhead vs. Block Size\nLink fabrics differ significantly in header-to-payload ratio, especially\nat small block sizes. Header overhead penalizes small messages\nin conventional Ethernet, motivating larger minimum block sizes\nto maintain efficiency. For AI and tightly coupled compute, where\natomicity and latency matter, small block sizes with low overhead are\npreferable.\nHeader Size vs Block Size Table\nFabric\nHeader\n64B\n128B\n256B\n512B\n1024B\nNVLink v3\n16\n25.0%\n12.5%\n6.3%\n3.1%\n1.6%\nUALink (proj.)\n20\n31.3%\n15.6%\n7.8%\n3.9%\n2.0%\nScale-Up ETH\n8–16\n12.5%\n6.3%\n3.1%\n1.6%\n0.8%\nInfiniBand HDR\n64\n100%\n50.0%\n25.0%\n12.5%\n6.3%\nEthernet + IP + TCP\n76–92\n143.8%\n57.8%\n28.9%\n14.5%\n7.1%\nDoes not Include Atomic Ethernet\nWe wanted to review and compare these systems before introducing\nOAE. Imagine what this table looks like when we add OAE’s 4-byte\nheader, with fixed size: 64B, 256B, 1024B and 4096B transfers.\nLatency and Atomicity Considerations\nAtomic operations (e.g., tensor updates, semaphore-based locking)\nare increasingly being performed across links. The cost of round-\ntrips, retries, or failed speculative execution due to packet drops\ngrows nonlinearly with header size and tail latency variance.\n• NVLink: High atomicity; limited to GPU domain.\nlink fabrics: an objective comparison\n3\n• UALink: Claims to enable coherent memory semantics across\nnodes.\n• InfiniBand: Explicit verbs for atomic ops, requires RDMA seman-\ntics.\n• Ethernet: Lacks atomic primitives; must emulate via protocols.\n• Scale-Up Ethernet: Explicit focus on atomic packet slices, with\ntransaction-layer feedback.\nBias Toward Large Packets: A Critical View\nSwitch-centric fabrics such as Ethernet and InfiniBand often exhibit\nbiases toward large block sizes, due to:\n1. Header amortization: Larger blocks reduce relative overhead.\n2. Switch buffer economics: Designed for long flows, not short\natomic ops.\n3. Congestion avoidance: Larger packets allow queue shaping, but\npenalize small-ops latency.\nThis introduces architectural bias that disfavors emerging patterns\nsuch as sparse updates, fine-grain load/store traffic between hetero-\ngeneous xPUs, or distributed execution of transactional graphs.\nConclusion\nWhile Ethernet and InfiniBand continue to evolve, they remain biased\ntoward packetization strategies that penalize small atomic units of\nwork. NVLink and UALink challenge this by focusing on coherence\nand bandwidth at short distances, but they remain vendor-specific or\nin flux.\nScale-Up Ethernet presents a new opportunity: to build an atomic-\ncapable, low-latency, congestion-aware transport that preserves Eth-\nernet compatibility while shedding unnecessary biases—especially\nthose that require applications to batch operations just to amortize\nprotocol overhead.\nFuture fabrics should not merely transmit data, but should transmit\nmeaningful, recoverable state—one slice at a time.\n"
  },
  {
    "filename": "STANDALONE/Ternary-Logic1.pdf",
    "content": "Quantum Mechanics, Balanced Ternary Numbers,\nReversible Computing, and Slots on the Wire\nPaul Borrill\nJune 8, 2025\nThis essay traces conceptual bridges between quantum mechanics,\nbalanced ternary representations, and reversible computing, and\nextends the analysis to include how bits are physically represented on\nEthernet wires. Special attention is paid to line encoding schemes such\nas Return-to-Zero (RTZ) and Non-Return-to-Zero (NRZ), and how they\nreflect or resist reversibility and ternary symmetry.\nBalanced Ternary Arithmetic\nBalanced ternary is a base-3 numeral system with digits {−1, 0, +1},\nsymmetric around zero. Each integer can be represented uniquely as:\nn =\nN\n∑\nk=0\nak · 3k\nwhere ak ∈{−1, 0, +1}\nIts symmetry, minimal carry propagation, and natural negation\nmake it attractive for reversible logic and quantum-state alignment.\nQuantum States and Qutrits\nQuantum systems encode information in Hilbert space superposi-\ntions. A single qutrit state:\n|ψ⟩= α|−1⟩+ β|0⟩+ γ|+1⟩\nextends qubit logic to three-state systems, closely matching balanced\nternary logic. This richer structure enables more compact representa-\ntions of quantum gates and encodings.\nReversible Computing\nReversible computing preserves information at each logical step to\navoid entropy increase. Ternary gates—due to their symmetry and\nstate density—can reduce both gate count and circuit depth.\nExamples:\n• Ternary NOT: NOT(x) = −x\n• Controlled-ternary gates with mod-3 arithmetic\n• Ternary swap gates that naturally preserve state\nquantum mechanics, balanced ternary numbers, reversible computing, and slots on the\nwire\n2\nPhysical Bits on the Ethernet Wire\nDigital systems must eventually encode abstract bits into physical\nsignals on a wire. Two foundational encoding schemes dominate:\nReturn-to-Zero (RTZ)\nRTZ encoding uses a positive or negative pulse (e.g., ±V) for logic ’1’\nor ’0’, with the signal always returning to zero between bits.\n• Each bit is self-delimiting in time.\n• Easy to synchronize clock recovery.\n• Inefficient in bandwidth: requires transitions even when signal\ndoesn’t change.\n• Represents a temporal zero-point symmetry.\nNon-Return-to-Zero (NRZ/NRTZ)\nNRZ maintains the signal level throughout the bit interval.\n• High bandwidth efficiency.\n• Clock recovery requires added coding (e.g., 8b/10b, PAM).\n• Transitions only occur on bit changes—higher energy efficiency.\n• More aligned with reversible computing, avoiding wasteful\ntransitions.\nPAM Encoding and Ternary Signaling\nModern Ethernet (e.g., 25G/50G/100G) uses Pulse-Amplitude Modu-\nlation (PAM-4, PAM-8):\n• Each symbol represents multiple bits (2 bits for PAM-4).\n• Voltage levels span {−3, −1, +1, +3} or similar.\n• This resembles a non-balanced quaternary system—but ternary\nPAM could be engineered for symmetric encoding, reducing noise\nsensitivity and improving reversibility.\nRTZ vs NRZ and Reversibility\nEthernet Through a Ternary Lens\nBalanced ternary could offer:\n• More compact signaling: 3 states = log2 3 ≈1.585 bits per symbol.\n• Improved line symmetry: symmetric representation around\nground level simplifies noise margins.\n• Natural negation and parity: e.g., +1 →−1 without zero-crossing,\nusing differential signaling.\nquantum mechanics, balanced ternary numbers, reversible computing, and slots on the\nwire\n3\nProperty\nRTZ\nNRZ (NRTZ)\nBalanced Ternary Analog\nTemporal symmetry\nExplicit (zero-crossing)\nImplicit (voltage level)\n0-state acts as ground\nEnergy efficiency\nLow (frequent transitions)\nHigher\nTernary gates preserve entropy\nClock recovery\nEasy\nRequires auxiliary codes\nTernary phase codes possible\nReversible?\nNot inherently\nCloser to reversible\nYes, with ternary switching\nTable: Comparison of RTZ, NRZ, and Balanced Ternary signaling\ncharacteristics.\n• Potential for reversible line codes: a ternary encoding could\nmake wire-level reversibility feasible, matching upstream logic\ngates.\nThis approach also has implications for optical Ethernet, where\nphase-based encoding may more naturally support multi-state logic.\nConclusion\nBits on the wire—traditionally treated as binary and irreversible—may\nbenefit from adopting ideas from balanced ternary logic and quan-\ntum state encoding. RTZ schemes resemble traditional irreversible\nlogic with time-reset states. NRZ and PAM schemes suggest a\npathway toward denser, more reversible signaling, especially if\nre-engineered with ternary symmetry in mind.\nBy reconciling physical line signaling with ternary reversibility\nand quantum logic, a new generation of Ethernet protocols could\nemerge: energy-aware, noise-resilient, and natively compatible with\nreversible and quantum systems.\n"
  },
  {
    "filename": "STANDALONE/PNP.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\næthernet: ultra low latency (ull)\n1\nPartial Network Partitioning (PNP)\nFlakey Networks\nLink failures are invisible (hidden) in a Clos. They are 100% visible in\nan Æthernet 8-valency mesh: For 4 fully connected nodes, there are\n(n(n −1)/2) = 6 links. With 4 up/down unidirectional configura-\ntions on each link {↓↓↓↑↑↓↑↑} gives 64 −1 = 1295 possible failure\nmodes.\nWhere:\n↓↓Down from Alice’s perspective, Down from Bob’s perspective.\n↓↑Down from Alice’s perspective, Up from Bob’s perspective.\n↑↓Up from Alice’s perspective, Down from Bob’s perspective.\n↑↑Up from Alice’s perspective, Up from Bob’s perspective.\nThese are only the clean (binary) fail-\nures – flakey connections are much\nworse! This makes conventional reli-\nability calculations at least 1200 times\nworse than it looks from a simple\nseries/parallel perspective – for dis-\ntributed systems\n"
  },
  {
    "filename": "STANDALONE/Scale-Up-Fabrics.pdf",
    "content": "Operand Granularity in Sliceable Ethernet vs. Bias\nToward Large Operators in Scale-Up Fabrics\nPaul Borrill\nWe examine the operand sizes supported by a proposed sliceable Eth-\nernet protocol (with 64-byte frames preemptible on 8-byte boundaries)\nand compare them to modern trends in scale-up fabrics, especially\nBroadcom’s Scale-Up Ethernet (SUE) and similar interconnects. We\nidentify biases in these fabrics toward large block sizes and consider\nthe implications for low-latency communication between heteroge-\nneous processors (xPUs), where x ∈{C, G, D, I, Q}.\nSliceable Ethernet Operand Sizes\nIn our proposed Ethernet redesign:\n• A fixed 64-byte frame is divided into eight 8-byte slices.\n• A 4-byte operator prefix is followed by a variable-sized operand\npayload.\nSlices\nOperand Size\nInterpretation\n1 slice\n4 bytes\n1 × FP32 scalar\n2 slices\n12 bytes\n3 × FP32 (RGB, XYZ)\n4 slices\n28 bytes\n7 × FP32 or 14 × FP16\n8 slices\n60 bytes\n15 × FP32 or 60 × INT8\nBias Toward Large Operators in Scale-Up Fabrics\nEmerging switch-based interconnect fabrics, including Broadcom’s\nScale-Up Ethernet (SUE) and UALink, promote architectural as-\nsumptions that favor large operator sizes and block payloads. This results\nin systemic bias against short block transactions. Several patterns\nsuggest this:\n1. Protocol Overhead Efficiency\nSUE introduces custom forwarding headers (e.g., AI Forwarding\nHeader), which are amortized more effectively over larger payloads 1.\n1\nThe protocol becomes more efficient only when block sizes exceed\n256 bytes or more.\n2. FEC Dependency on Long Blocks\nForward Error Correction (e.g., RS-272) works best on large block\nsizes, where encoding and decoding latency is justified by improved\noperand granularity in sliceable ethernet vs. bias toward large operators in scale-up\nfabrics\n2\nresilience 2. Applying such schemes to 4–60 byte operands can result\n2\nin high relative overhead.\n3. Shared Memory and Remote Store Semantics\nScale-up interconnects aim to provide RDMA-like, memory-semantic\naccess between accelerators 3. Implementing memory coherence,\n3\nsynchronization, and acknowledgment semantics efficiently over\nsmall operands proves challenging unless blocks are batched.\nImplications for xPU Interconnects\nShort operand sizes are critical when connecting diverse processors:\n• CPUs: cache-line coherency prefers 64-byte or smaller messages.\n• GPUs/TPUs: frequently use 4–60 byte tensor fragments (e.g., INT8\ntiles).\n• IPUs and DPUs: benefit from fine-grained control and low-latency\nmessaging.\nRecommendations\n• Protocol redesign: Minimize per-packet overhead and support\nsub-64-byte transactions efficiently.\n• Flexible FEC: Use adaptive coding schemes tuned for variable\noperand sizes.\n• Hardware path optimization: Ensure switch fabrics and NICs\nhave low-latency fast paths for small operand operations.\n• Standardization: Advocate for interoperable standards that sup-\nport short block sizes in industry working groups.\nConclusion\nWhile current switch-based fabrics are optimized for bulk data move-\nment, a new class of Ethernet interconnect that supports fine-grained,\noperator-level transactions across xPU fabrics could dramatically\nreduce latency, improve utilization, and enable new levels of paral-\nlelism for ML and real-time systems.\noperand granularity in sliceable ethernet vs. bias toward large operators in scale-up\nfabrics\n3\nReferences\nSharada Yeluri, Scale-Up Fabrics Summary, LinkedIn\nPulse, 2024. https://www.linkedin.com/pulse/\nscale-up-fabrics-sharada-yeluri-qdzrc\nBroadcom, Scale-Up Ethernet Framework, 2024. https://docs.\nbroadcom.com/doc/scale-up-ethernet-framework\n"
  },
  {
    "filename": "STANDALONE/Shannon-Content 2.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\næthernet: ultra low latency (ull)\n1\nShannon Content\nShannon Slots\nSingle + Dual Channel\nTRANSMITTER\nINFORMATION\nSOURCE\nRECEIVER\nDESTINATION\nMESSAGE\nMESSAGE\nNOISE\nt\nTRANSMITTER\nINFORMATION\nSOURCE\nRECEIVER\nDESTINATION\nNOISE\n• A single Channel Shannon Channel is the conventional view of\nInformation\nKey aspects of Shannon Channels\nare already “reversible” based on\nmutual and consistent information;\nthese are symmetric in time in our\nmodel for Common Knowledge. [See JV\nStone: Information Theory: A Tutorial\nIntroduction]\n• The former is statistical (correlated only), the latter is 100% consis-\ntent.\n• Our Reversible Dual Channel Shannon model enables both full\nreversibility and provides new opportunities for Error detection\nand Correction\n• The theory is fully consistent with the scientific literature, but\napplying it to short cables provides a new opportunity - within\nracks, and chiplet meshes\n• This presentation is (we think) new IP, that can be patented.\n• It applies specifically to the “Sahas information model (see slides\nat end)\n• This is the foundation for a new model for a Product: Link Failure\nDetector\nShannon Reversibility Levels\n• Information Slots (surprisal)\n• Knowledge Slots (captured information)\n• Semantic Slots (meaning)\nSlot Reconciliation Protocol\n[Reference Pat’s favorite paper, and wiki session he gave + Transcript\næthernet: ultra low latency (ull)\n2\nOUT\nOutput\nTape\nUndo\nTape\nTape \nMain\nR0\nOUT\nR1\nR2\nR3\nOUT\nOUT\nHost Processor —  Irreversible Zone\nRegister Interface\nAlice\nTUO\nOutput\nTape\nUndo\nTape\nTape \nMain\nR0\nTUO\nR1\nR2\nR3\nTUO\nTUO\nHost Processor —  Irreversible Zone\nRegister Interface\nBob\nSAW Protocol Link\nPCIe Bus\nFPGA Logic - Reversibility Zones\nPCIe Bus\nFPGA Logic - Reversibility Zones\nINFORMATION\nDISCARD\nKNOWLEDGE\nDISCARD\nPROCESSING\nDISCARD\nINFORMATION\nDISCARD\nKNOWLEDGE\nDISCARD\nPROCESSING\nDISCARD\nFigure 1: Shannon Slots.\næthernet: ultra low latency (ull)\n3\nWhen Two Shannon Channels are connected Back to Back\nFigure 2: Shannon Slots.\n"
  },
  {
    "filename": "STANDALONE/atomicity3.pdf",
    "content": "Review of “Synchronous, Asynchronous and Causally\nOrdered Communication” (1992)\nPrepared for Paul Borrill\nCompiled on May 12, 2025\nPreface\nAsk a database engineer, a CPU architect, and a distributed-systems\ntheorist what “synchronous” means and you will receive incompat-\nible answers. Charron-Bost, Mattern, and Tel clarify the picture by\nplacing three delivery disciplines inside one axiomatic frame and\nshowing exactly how they relate. This note restates the paper’s essen-\ntial results, highlights the “crown” criterion, and connects the work\nto modern reversible and FITO thinking.\nWhy this paper still matters\n• Gives a single mathematical framework for Synchronous (Ren-\ndezvous), FIFO, Causal Order (CO), and fully Asynchronous\nlinks.\n• Proves the strict inclusion chain\nRSC ⊂CO ⊂FIFO ⊂A.\n• Introduces the crown criterion: a linear-time graph test that de-\ncides whether an execution trace can be replayed with rendezvous\nsemantics.\n• Shows that Dijkstra–Feijen–van Gasteren termination detection\nremains safe under CO, not only under full rendezvous.\nCore concepts and results\nDefinitions\nA-computation\nFully asynchronous; Lamport’s three happens-before axioms.\nFIFO-computation\nAdds per-channel order: if send1 →send2 then recv1 →recv2 on the\nsame channel.\nCO-computation\nGlobalises FIFO: if send1 precedes send2 causally, then recv1 pre-\ncedes recv2 even if different channels are involved.\nRSC-computation\nreview of “synchronous, asynchronous and causally ordered communication” (1992)\n2\n“Realisable with Synchronous Communication”. There exists a\ntopological sort where every send is immediately followed by its\nmatching receive (non-separated linear extension).\nCrown\nAlternating sequence ⟨s0, r0, s1, r1, . . . , sk, rk⟩that forms a cycle\nin the message-dependency graph. A crown is an obstruction to\nrendezvous: crown-free is equivalent to RSC.\nHierarchy\nRSC\n⊂\nCO\n⊂\nFIFO\n⊂\nA\nTermination detection\nUnder CO a basic message can cross at most one token wave. The\nring-token detector colours a wave black if any crossing occurs. A\nwhite token received by the root with no outgoing basic messages\nimplies global quiescence. Because double crossings are impossible in\nCO, the algorithm is safe without requiring full rendezvous.\nImplementation guidance (1992)\n• FIFO – sequence numbers per link plus buffering.\n• CO – vector clocks (or matrix clocks); alternatively, handshake I/O\nbuffers that forbid indirect overtakes.\n• RSC – FIFO plus an ACK that blocks the sender (classic ren-\ndezvous).\nStrengths and limitations\nStrengths\n• Fully axiomatic, no real-time bounds.\n• Crown test is linear-time.\n• Connects theory and protocol engineering.\nLimitations\n• Assumes reliable channels, no Byzantine faults.\n• Vector metadata grows with node count; later work explores com-\npaction.\nreview of “synchronous, asynchronous and causally ordered communication” (1992)\n3\nFITO reflection\nMoving up the chain A →FIFO →CO →RSC adds increasingly\nstrict forward-time coupling. CO eliminates wall-clock timeouts but\nstill prevents observers from seeing causal inversions. RSC goes\nfurther, collapsing send and receive into one point in logical time. For\nreversible computing goals the sweet spot is often CO: minimal FITO\nassumptions with no blocking latency.\nBibliographic snapshot\nB. Charron-Bost, F. Mattern, G. Tel, “Synchronous, Asynchronous and\nCausally Ordered Communication,” Distributed Computing 6, 1992,\npp. 173–191.\n"
  },
  {
    "filename": "STANDALONE/Infiniband-vs-Ethernet.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\nEthernet versus InfiniBand and Beyond:\nToward a Next-Generation Fabric\nChatGPT, (Fact-checked) by Paul\nApril 30, 2025\nHigh-Level Overview\nAt a high level, Ethernet and InfiniBand both provide packet-\nswitched networking, yet they originate from very different design\nphilosophies and ecosystems. The widespread perception that Infini-\nBand is more reliable arises from the architectural and operational\ndifferences examined below.\nOrigins and Design Philosophy\n• Ethernet evolved as a best-effort LAN. Reliability, ordering, and la-\ntency guarantees were relegated to higher layers (TCP/IP), Quality\nof Service, or RDMA over Converged Ethernet (RoCE).\n• InfiniBand was conceived for high-performance computing (HPC)\nand modern data-center fabrics, prioritising low latency, high\nthroughput, lossless delivery, and built-in reliability.\nTransport and Reliability Model\n• Ethernet (traditional) is best-effort; packets may be dropped,\nduplicated, or reordered. Higher layers must restore reliability.\n• InfiniBand embeds a reliable transport protocol in hardware,\nhandling acknowledgments, retransmissions, and flow control\nwith minimal host-CPU involvement.\nCongestion and Flow Control\n• Ethernet: early 802.3 had none. Data-Center Bridging (DCB) and\nPriority Flow Control (PFC) improve matters but add complexity\nand are not always enabled end-to-end.\n• InfiniBand: credit-based flow control and end-to-end congestion\nmanagement prevent buffer overruns without dropping traffic.\nethernet versus infiniband and beyond: toward a next-generation fabric\n2\nPacket-Loss Behaviour\n• Ethernet: under load or misconfiguration, packets drop and TCP\nmust recover, causing latency spikes.\n• InfiniBand: packets are rarely dropped; congestion produces back-\npressure instead.\nLatency and Jitter\n• Ethernet: latency and jitter depend on traffic, buffering, and TCP\nrecovery.\n• InfiniBand: microsecond-scale latency and very low jitter via\nlightweight stack, hardware offload, and zero-copy RDMA.\nRDMA Support\n• Ethernet: RoCE provides RDMA but demands a tuned, lossless\nfabric (PFC, ECN, buffer sizing), often fragile and vendor-specific.\n• InfiniBand: native RDMA with hardware reliability and no special\ntuning.\nCPU Overhead\n• Ethernet: full TCP/IP stack consumes CPU unless offloaded by\nSmartNICs.\n• InfiniBand: host-channel adapters offload packetisation, ordering,\nand reliability, yielding lower CPU utilisation.\nEcosystem and Deployment\n• Ethernet: ubiquitous, inexpensive, multi-vendor, and scaling to\n800 Gb/s.\n• InfiniBand: dominant in latency-sensitive HPC/AI but niche,\ncostlier, and largely single-vendor (NVIDIA/Mellanox).\nSummary Table\nRoCE: RDMA over Converged Ethernet\nVariants\n• RoCE v1: Layer 2 only, not routable.\nethernet versus infiniband and beyond: toward a next-generation fabric\n3\nFeature\nEthernet\nInfiniBand\nReliability\nBest-effort (TCP)\nHardware-enforced\nLatency\nMilli-second typical\nMicro-second\nJitter\nHigh\nVery low\nCongestion control\nOptional (DCB/PFC)\nBuilt-in\nPacket loss\nPossible\nAvoided by design\nRDMA\nRoCE (complex)\nNative\nCPU overhead\nHigh (software stack)\nLow (offload)\nPrimary use\nGeneral networking\nHPC / AI clusters\nTable 1: High-level comparison of\nEthernet and InfiniBand.\n• RoCE v2: UDP/Layer 3, IP-routable.\nWhy Reliable Deployment is Hard\n1. Lossless Fabric Requirement: depends on PFC; mis-tunes cause\ndeadlocks and head-of-line blocking.\n2. UDP Transport: inherits best-effort IP semantics unless the fabric\nis tightly managed.\n3. Ecosystem Coordination: NICs, drivers, libraries (libibverbs),\nand applications must align or fall back to TCP.\nWhy Ethernet Remains Dominant\n• Cost & Ubiquity: every datacenter already runs Ethernet; hard-\nware is commoditized.\n• Interoperability: multi-vendor openness avoids lock-in.\n• Performance Road-map: speeds have risen from 10 Gb/s to\n800 Gb/s.\n• Software Ecosystem: the global Internet stack assumes Ether-\nnet/TCP.\n• RoCE as Bridge: hyperscalers deploy RoCE successfully by exert-\ning strict control over their fabrics.\nConclusion\nInfiniBand remains the gold standard for ultra-low-latency, highly\nreliable HPC workloads. Ethernet is closing the gap through RoCE,\nSmartNIC offloads, DCB/PFC, and ever-faster links. Its dominance\nstems from universality and cost, not intrinsic technical superiority.\nethernet versus infiniband and beyond: toward a next-generation fabric\n4\nDesign Goals for a Next-Generation Fabric\n1. Sub-microsecond latency with deterministic throughput.\n2. Hardware-enforced reliability (acknowledgment & retransmission\nin silicon).\n3. RDMA-first semantics: zero-copy PUT, GET, and atomic operations.\n4. Programmability: P4/eBPF pipelines in NICs and switches.\n5. Security by design: cryptographic authN/authZ and fine-grained\naccess control.\n6. Clock-agnostic operation: causal or reversible timing models.\n7. Composable transports: reliable/unreliable, ordered/unordered as\nrequired.\n8. Multi-tenant virtual fabrics on shared hardware.\nKey Building Blocks\n• SmartNICs: onboard CPUs or FPGAs for protocol state, reversibil-\nity, and EPI/ONT registers.\n• Flow-Aware Non-Switch Fabric: dynamic, congestion-aware path\nscheduling.\n• Unified Declarative Transport: intent-based API replacing TCP/IP\nor InfiniBand verbs.\n• Fabric-Wide Memory Space: global RDMA address space with\ncapability-based security.\nDesign Framework\nSomething Old Knowledge == captured information\nSomething New RED == Information surprisal (the answer to a\nyes/no question)\nSomething Borrowed == Tie-in to Rust model (for RPC - Alice owns\nbut Bob borrows)\nSomething Blue Semantics (Meaning) – The SmartNIC/IPU under-\nstands the context\nSomething Green OCP Green for Open Syntax – goes over PCIe.\n"
  },
  {
    "filename": "STANDALONE/Implementation.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\næthernet: ultra low latency (ull)\n1\nImplementation Model for FPGA’s\nFigure 1: SerDes Implementation.\n"
  },
  {
    "filename": "STANDALONE/BITBYTEPACKET-Efficiency.pdf",
    "content": "Frame Efficiency Across Payload Sizes\n(and)\nA Day in the Life of a Bit, Byte, and Packet\nPaul Borrill\nDraft – June 5, 2025\nContents\nFrame Efficiency for Ultra?Low Latency Links\n1\nWhy the 64?Byte Minimum Matters\n1\nByte?by?Byte Breakdown\n1\nA Minimalist ULL Frame\n2\nA Day in the Life of a Bit, Byte, and Packet\n2\nPrologue: Birth of a Bit\n2\nMorning Commute: The Byte Joins In\n3\nLunch Break at Layer 3\n3\nAfternoon Bureaucracy at Layer 4+\n3\nEvening Reflections\n3\nMoral: Redundancy Has a Cost\n3\nConclusion\n4\nFrame Efficiency for Ultra?Low Latency Links\nFixed Overheads Revisited\nFor any classical Ethernet frame the non?payload octets are :\nOverheadin?frame = 7 + 1 + 6 + 6 + 2 + 4 = 26 B,\nIFG = 12 B.\nThus every transmission occupies Totalwire = P + 26 + 12 bytes\nof slot time, where P is the user payload. Table ?? extends our earlier\n64?byte1 baseline to three larger sizes often seen in HPC, HFT, and\n1 Strictly speaking the minimum Eth-\nernet payload is 46 B, yielding a 64 B\nframe excluding IFG.\nAI/ML clusters.\nObservations.\n• Efficiency climbs rapidly with payload size; by 512 B more than\n93 % of link time carries useful data.\nframe efficiency across payload sizes [4pt] (and) [2pt] a day in the life of a bit, byte,\nand packet\n2\nPayload P\nIn?Frame OH\nIFG\nWire Bytes\nEfficiency η\n46 B\n26\n12\n84\n54.8%\n256 B\n26\n12\n294\n87.1%\n512 B\n26\n12\n550\n93.1%\n4096 B\n26\n12\n4134\n99.1%\nTable 1: Classical Ethernet framing\nefficiency : η = P/(P + 38).\n• Jumbo frames (4 KiB here) render preamble + CRC almost noise,\nyet such frames are unsuitable for the nanosecond packetization\ndemands of HFT or fine?grained AI gradient updates.\n• The constant 38?octet penalty motivates shaving even a handful of\nbytes when working at or below 256?byte slices.\nMinimalist ULL Frames at Larger Sizes\nIf we strip preamble, MAC addresses, and CRC in a point?to?point\null link, the wire cost collapses to\nWireULL = P + SerDes delimiter,\nmaking ηULL effectively 100 % for any payload. The traditional\nargument for large packets (better goodput) disappears; designers\nare free to choose payload size solely on flow?control granularity and\nbuffer residency time.\nA Day in the Life of a Bit, Byte, and Packet\nConclusion\nClassical Ethernet overhead scatters 38 fixed bytes around every\npayload, throttling small?message workloads to 55?87 % efficiency\nfor sub?kilobyte frames. By eliminating heritage fields on deter-\nministic links, a minimalist protocol can deliver nearly 100 % ef-\nficiency independent of payload size, unlocking another rung on\nthe latency?savings ladder for HFT, AI/ML inference swarms, and\nnext?generation chiplet fabrics.\n"
  },
  {
    "filename": "STANDALONE/ICO-LIT-Survey.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\næthernet: ultra low latency (ull)\n1\nLiterature Survey on Indefinite Causal Order\nIndefinite Causal Order (ICO) challenges classical causality, enabling\nevents in quantum mechanics to occur without a fixed temporal\norder. This survey outlines significant theoretical, experimental, and\napplied research on ICO.\nExperimental Demonstrations and Techniques\nRubino et al. 1 provided the first decisive experimental verification of\n1\nindefinite causal order, quantifying the incompatibility of their setup\nwith definite causal order. Rozema et al. 2 reviewed experimental\n2\nmethods and theoretical techniques developed for realizing ICO,\ndiscussing potential quantum information applications.\nTheoretical Frameworks and No-Go Theorems\nAbbott et al. 3 presented a no-go theorem for superpositions of\n3\ncausal orders without control systems, highlighting limitations in\nICO realizations. Guerin and Brukner 4 established formal rules\n4\nensuring logical consistency in circuits exhibiting indefinite causal\norder.\nDevice-Independent Certifications\nVan der Lugt et al. 5 derived device-independent inequalities certify-\n5\ning ICO through quantum switch violations. Cao 6 explored sequen-\n6\ntial device-independent certification, demonstrating feasibility with\nthe quantum switch.\nApplications and Implications\nCapela et al. 7 critically assessed the thermodynamic advantages\n7\nof ICO, suggesting conventional processes may outperform ICO\nunder specific conditions. Van der Lugt and Ormrod 8 demonstrated\n8\nmaximal indefinite causal order in the quantum switch through a\npossibilistic approach.\nPhilosophical and Theological Considerations\nPearson and Qureshi-Hurst 9 examined ICO’s implications for time\n9\nmetaphysics and theology, supporting a B-theory perspective of time.\næthernet: ultra low latency (ull)\n2\nReferences\n[1] G. Rubino, et al., Experimental verification of an indefinite causal\norder, Science Advances, 2017. https://www.science.org/doi/\n10.1126/sciadv.1602589\n[2] L. A. Rozema, et al., Experimental Aspects of Indefinite Causal\nOrder in Quantum Mechanics, arXiv:2405.00767, 2024. https:\n//arxiv.org/abs/2405.00767\n[3] A. A. Abbott, et al., A no-go theorem for superpositions of causal\norders, Quantum, vol. 6, 2022. https://quantum-journal.org/\npapers/q-2022-03-01-663\n[4] P. A. Guerin and C. Brukner, Consistent circuits for indefinite\ncausal order, arXiv:2206.10042, 2022. https://arxiv.org/abs/\n2206.10042\n[5] J. van der Lugt, et al., Device-independent certification of indefinite\ncausal order in the quantum switch, Nature Communications, 2023.\nhttps://www.nature.com/articles/s41467-023-40162-8\n[6] Z. Cao, Sequential device-independent certification of indefinite causal\norder, arXiv:2307.13477, 2023. https://arxiv.org/abs/2307.\n13477\n[7] M. Capela, et al., Reassessing thermodynamic advantage from indef-\ninite causal order, arXiv:2208.03205, 2022. https://arxiv.org/\nabs/2208.03205\n[8] J. van der Lugt and N. Ormrod, Possibilistic and maximal indefinite\ncausal order in the quantum switch, Quantum, 2024. https://\nquantum-journal.org/papers/q-2024-12-03-1543\n[9] J. Pearson and R. Qureshi-Hurst, Quantum Mechanics, Time,\nand Theology: Indefinite Causal Order, Zygon, vol. 55, no. 3, 2020.\nhttps://onlinelibrary.wiley.com/doi/10.1111/zygo.12621\n"
  },
  {
    "filename": "STANDALONE/Unreliable.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\næthernet: ultra low latency (ull)\n1\nWhy Ethernet Needs to Be Reliable\nAn unreliable link can never solve\ncongestion; it can at best conceal it, and\nat worst amplify it.\nQuestion\nWhy Ethernet needs to be reliable. Distinguish between imposition\nnetworks and promise networks (Promise Theory). Distinguish be-\ntween “useful packets that are acknowledged” and those that “over-\nload (a) the receiver (which drops them) and the network that drops\nthem)”. Go deeply into the problem of congestion, and how unre-\nliable networks are a major cause of our inability to solve the con-\ngestion problem, because they make the problem worse, not better.\nBring in unique perspectives on how unpaired information can only\nbe correlations, not reliable delivery.\nIntroduction\nEthernet’s spectacular success for fifty years rests on three pillars:\nubiquity, low cost, and best–effort simplicity. But the assumption\nthat “bit errors are rare and losses are somebody else’s problem”\nhas aged badly. Modern workloads—RDMA storage, NVMe–oF,\nmicro–transactions in high–frequency trading, chiplet fabrics with\nsub–microsecond deadlines—have turned “good enough” into “not\nnearly enough”.\nImposition vs. Promise Networks\nImposition networks\nAn imposition network forces state upon its peers. Classical Ethernet\nis such a system: a transmitter imposes frames on the medium and\npresumes they will be carried. If a switch, buffer, or receiver cannot\ncope, frames are silently discarded. The sender remains ignorant\nuntil a higher layer notices the loss.\nPromise networks\nA promise network inverts the relationship: each agent voluntarily\nadvertises what it will accept and under what constraints. Conges-\ntion feedback, explicit flow control, and lossless credit schemes make\nthe fabric a living contract. InfiniBand, Fibre Channel, and CAN\nare promise networks by design; PFC–enabled RoCE grafts promise\nsemantics onto Ethernet with mixed success.\næthernet: ultra low latency (ull)\n2\nUseful vs. Harmful Packets\n1. Paired / Acknowledged frames: every frame is matched by a\nhandshake or credit and carries information with commitment.\n2. Unpaired / Blind frames: sent speculatively or in excess of credit,\nthey eat capacity, fill buffers, and are eventually dropped, con-\ntributing only to congestion.\nCongestion: Why Unreliability Amplifies It\nPositive feedback loops\nClassic Ethernet plus TCP uses loss as its congestion signal, but the\nsignal arrives one–three RTTs late. A 100 Gb/s host can inject mil-\nlions of frames during that blind window:\nloss −→retransmit −→more traffic −→more loss.\nBufferbloat\nDeeper switch buffers merely store congestion instead of preventing\nit; the queueing delay often dwarfs propagation delay, wrecking tail–\nlatency guarantees.\nHead–of–line blocking\nDropped frames arrive out of order; completion time is dominated by\nrecovery, not transmission. A link–layer ACK/NAK guarantee keeps\ndelivery in order and prevents the stall.\nUnpaired Information Is Only Correlation\nA frame that never arrives does not increase mutual information; it\nleaves a correlation hole. Reliable Ethernet lets the link itself guaran-\ntee that every delivered frame is the one that was sent, exactly once.\nDesign Implications\n• Credit–based losslessness: lightweight link–local ACK/NAK or\ncredit return bounds outstanding data without InfiniBand com-\nplexity.\n• Actionable ECN: with no drops, an ECN mark is a clear, immedi-\nate promise that congestion exists here and now.\næthernet: ultra low latency (ull)\n3\n• Deterministic latency: bounded jitter enables hardware–timestamped\ntransactions and reversible protocols.\n• Energy efficiency: eliminating retransmissions and deep buffering\ncuts joules per useful bit.\nConclusion\nCheap and cheerful won in 1973, but the economics have flipped:\nevery lost packet spawns expensive silicon, energy, and complexity\nat higher layers. Turning Ethernet from an imposition fabric into a\npromise fabric breaks the congestion feedback loop, converts blind\ncorrelations into committed information, and opens the next chapter\nfor the world’s most enduring network. Reliable Ethernet is no lux-\nury; it is the prerequisite for solving the congestion pathologies that\nthreaten Ethernet’s future.\n"
  },
  {
    "filename": "STANDALONE/Transactions-maybe-dup.pdf",
    "content": "Rethinking Atomicity: Counterfactual Transactions\nPaul Borrill\nThis document challenges the Forward-In-Time-Only (FITO) assump-\ntions behind conventional transactions in distributed systems. It argues\nthat atomicity, as currently conceived, is a flawed abstraction and\nproposes a framework for reversible subtransactions as a more robust\nalternative.\nTransactions and the Illusion of Atomicity\n“Transactions begin and they end.”\n—Charlie Johnson, TMF Product News\nThis simple phrase conceals deep design hazards. Transactions\nappear to begin with a trigger and end with a commit, but in dis-\ntributed systems, these bookends obscure severe internal inconsisten-\ncies.\nAt issue are the mechanisms we use to track and guarantee these\ntransactional intervals: timestamps, logs, filesystems, and even\nour concepts of causality. Each introduces cracks in the facade of\natomicity.\nThe Forward-In-Time-Only Fallacy\nFITO: Forward-In-Time-Only thinking\nassumes linear causality.\nMost distributed systems today adopt what we call Forward-In-Time-\nOnly (FITO) thinking. That is:\n1. Open a transaction with a timestamp.\n2. Apply a sequence of operations.\n3. Close the transaction with a commit or rollback.\nBut this approach breaks down under scrutiny.\nThree FITO Hazards\n1. Timestamps are not unique. Even on a single machine with GHz\nprocessors and nanosecond clocks, timestamp collisions occur.\nOS-level clock management does not guarantee uniqueness.\n2. Timestamps are single points of failure. Any drift, packet loss, or\nsync error in NTP/PTP introduces false ordering assumptions.\n3. Simultaneity is an illusion. Relativity tells us simultaneity is\nobserver-dependent. Building global event orderings on times-\ntamps is unsafe.\nrethinking atomicity: counterfactual transactions\n2\nThe False Comfort of Atomicity\nWe often say: \"all or nothing.\" But our stack is built on sand:\n• The database relies on the log.\n• The log relies on the filesystem.\n• The filesystem relies on fsync.\n• fsync relies on storage hardware.\nEach of these layers fails to guarantee true atomicity. When one fails,\nthe recovery model becomes: Smash and Restart.\nThe Myth of Reliable Commit\nProtocols like Two-Phase Commit (2PC) attempt to enforce dis-\ntributed agreement. But they depend on:\n• Log synchronization across nodes\n• Network reliability\n• Time-based coordination\nWhen any assumption breaks, so does safety. Eventually, we re-\nplace consistency with survivability—and correctness with heuristics.\nToward Reversible Thinking\nSuppose we reject FITO. Suppose we view the transaction as re-\nversible.\nIf the forward protocol is correct, we can construct a reverse protocol.\nThis leads to reversible subtransactions: bounded operations that\ncan be undone without global rollback.\nCounterfactual Transactions\n• A transaction can end, then begin again.\n• Logs become braids, not linear sequences.\n• Atomicity becomes a constraint, not an assumption.\nInspired by Marletto’s counterfactual physics, this model embraces\npartial reversibility as an engineering practice.\nrethinking atomicity: counterfactual transactions\n3\nClosing the Interval—Reopened\nSimultaneity is not fundamental.\nCausality is.\n\"Closing the interval\" with a commit only makes sense if we know\nthe state is stable. In reality, it’s a guess based on layers of non-\natomic operations.\nBy rethinking transactions through reversible logic, we can:\n• Define precise causal dependencies\n• Undo partial effects\n• Recover without restart\nReversibility isn’t science fiction. It is what rollback always wanted\nto be.\nConclusion\nThe abstraction of atomicity has outlived its usefulness as a guaran-\ntee. In modern distributed systems, FITO thinking and timestamp\ndependency introduce hazards we can no longer ignore.\nIt is time to engineer reversible protocols, built on causal seman-\ntics—not illusions of simultaneity. Let us design transactions that\ndon’t just commit or roll back, but that can unwind.\nrethinking atomicity: counterfactual transactions\n4\nANOTHER ATTEMPT\n“Transactions begin and they end.”\n—Charlie Johnson, TMF Product News\nI. The Forward-In-Time-Only Fallacy\nMost distributed systems flood the relay opening of a transaction (i.e.,\ninternal interval) as fast as possible: apply a series of operations, and\nclose the interval by declaring success (commit) or failure (rollback).\nII. The FITO Hazards Exposed\n1. Timestamps are not unique\nEven within a multicore machine, TSC collisions can occur under\nGHz-level operations.\n2. Timestamps are single points of failure\nClock synchronization drift—e.g., due to network partition or lost\npackets—invalidates timestamp ordering.\n3. Timestamps support an illusion of simultaneity\nEinstein disproved a global simultaneity plane. Software should not\nassume one.\nexample-diagram.png\nFigure 1: FITO vs Reversible Transac-\ntion Thinking\nIII. The Myth of Reliable Commit\nDistributed commit protocols like 2PC try to coordinate nodes into a\nconsistent state.\n• Logs must interlock across machines.\n• Storage layers must handle crash-consistency.\n• Clocks must remain stable.\nEven rollback is not truly reversible—just a partial undo of effects,\nnot a time-aware reversal.\nIV. Too Close, No Rewind\nClosing a transaction interval implies certainty. In reality, it’s wishful\nthinking.\nWe must move from FITO to reversible subtransactions.\nrethinking atomicity: counterfactual transactions\n5\nV. Counterfactual Transactions\n• End, then begin again.\n• Log braiding, not strict serialization.\n• Reject atomicity as fundamental.\nInspired by Chiara Marletto’s work, this framework invites sys-\ntems to embrace partial reversibility.\nConclusion\nThe notion of atomicity is comforting but flawed. We must move\nbeyond \"good enough\" and \"smash and restart\" and instead embrace\nthe formalism of reversibility in protocol and state design.\n"
  },
  {
    "filename": "STANDALONE/XPU-Market.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\nMarket for XPUs\nHarry V. Quackenboss, Alan Karp, Kevin Cameron\nMay 12, 2025\nMarket for a Sea of XPU’s are the closed hyperscalars\nFigure 1: The SmartNIC Revolution\ndied, long live the XPU Revolution.\nCourtesy: Harry V. Quackenboss\nThe FPGA NICs aren’t cheap compared to a standard NIC. The\nonly ones our use cases would work with were RISC-based Linux\nones with, if not currently, at least planned, per-core (single-thread)\nperformance close to single-thread performance of a Xeon core.\nBroadcom’s Stingray II (shelved), Marvell’s high-end Arm processor\n(never produced in volume), and Intel’s Mt. Evans roadmap (never\npursued for anybody other than hyperscalers). NVIDIA’s BlueField 4\n(not yet released – maybe shelved) looked good on paper.\nThe really high-volume prices of the SmartNICs in the BlueField-3\nclass were probably as low as $700 per unit, which I suspect is still\nless way than FPGA NICs.\nFor our use cases, price/performance was better on these types of\nSmartNICs because the data in flight nature of the workloads meant\nless DRAM/core, and the RISC versus X86 advantage of 70% in\nMIPS/Watt meant it made sense to offload those. However, if the\nSmartNICs couldn’t keep up with he geometry shrink from 3nm ->\n2nm and so on that the CPUs were on, the per-core performance and\nMIPS/Watt advantage evaporated.\n————– Harry Quackenboss\nmarket for xpus\n2\nAre these honking big, expensive smart NICs you’re talking about?\nI think we can implement our protocol in a pretty simple FPGA. (It\ncan be really simple if we do failure recovery with the CPU.) In fact,\nthere was an FPGA implementation. John Lockwood may know the\ndetails.\nYears ago we spoke to a NIC vendor. We could implement 99% of\nthe protocol with small changes to their standard product. There was\none corner case that required a change to their pico-code that was\nthe showstopper for them. None of those changes would have been\nvisible to customers not using our protocol.\n————– Alan Karp\nI’d say the future is highly interconnected processors that have\nspecialized computing support, SmartNICs fall in the specialized\ncomputing category if they have engines for things like encryption\nand compression, or something general purpose like an FPGA.\n————– Kev.\nThanks for this perspective. I had thought that smart NICs every-\nwhere was the wave of the future.\nThat being said, I’m not sure we need smart NICs for the basic\nprotocol. I believe that the happy path can be handled by simple state\nmachine logic in the NIC. Recovery from a broken link or node is\nprobably too complex for that, so it would have to be handled by the\nCPU. Recovery would certainly take longer, perhaps ms instead of\nmicroseconds.\n————– Alan Karp\nIt strikes me that among Kevin, Alan, and Hesham, there is no\ncommon understanding of what the minimum NIC feature set is that\nthis future protocol suite would run on (or, for that matter, possible\nmiddle boxes such as L2 switches)\nAdrian is current on this stuff, and I am not, but my understand-\ning is that SmartNICs, to summarize, are used by AWS, Google,\nMicrosoft, and Meta (and as a first approximation, Meta is less than\n1/5 the size of the others), but each vendor controls the SW stack\nincluding host drivers, and firmware on the SmartNIC, and even at\nleast some HW features. And, at least for now, none of the public\ncloud subset is making programmability available to customers.\nI don’t see how this effort is going to impact that, but maybe\nAdrian has a different opinion.\nOther than niches (and compared to markets big enough to sup-\nport new silicon at the rate CPUs evolve, even FPGA NICs are in my\ntaxonomy, niches). NVIDIA’s adaption of their DPU family to allow\ntuning for RDMA in AI and HPC clusters (that NVIDIA calls “Super-\nNIC”) isn’t really an exception in my view. There isn’t a significant\nmarket for xpus\n3\ninstalled base. If you scrutinize the forecasts and separate out ven-\ndors obfuscating to situation by declaring their high-end server NICs\nas SmartNICs, none are forecast big growth in the future (again, ex-\ncluding hyperscalers).\nA conclusion I draw from that is that trying to create new broad\nindustry standards is inconsistent with depending on hardware\nroadmaps for NIC features that aren’t forecast to be big volumes\n(excluding the hyperscalers that are going to be difficult to influence.\nTranslation: if this effort depends on custom programmable NICs\n(SmartNICs) isn’t going to lead to broad interest.\nThe sooner this group can come to a common understanding\nabout whether SmartNICs are in or out of scope, the sooner the de-\nbate can be narrowed.\nI personally would love to see SmartNICs be widely adopted. As\nKevin intimates, there are a bunch of things one can do.\nI just think unless and until factors beyond this group’s ability\nto influence change, it’s like trying to start a campfire with damp\nkindling in the rain. Smoke, with effort. But not much fire.\n————– Harry\n"
  },
  {
    "filename": "STANDALONE/Atomicity-ChatGPT-1.pdf",
    "content": "Summary of Robert Garner’s Equations and Assump-\ntions\nBelow is a focused summary of Robert Garner’s key equations, assumptions, and reason-\ning, drawn from his two extensive email threads about ACK-based (reliable) protocols atop\nEthernet-like links.\n1\nMetcalfe’s Throughput Equation\nGarner references a classical result from Bob Metcalfe’s 1970s ARPANET-era work for stop-\nand-wait or limited-window protocols. In a modern notation, the effective capacity E of a\nchannel is expressed as:\nE =\n\u0010 S\nP\n\u0011\n×\n1\n1 + C T\nP\n| {z }\nMultiplexing factor M\n× (1 −L) × C,\nwhere:\n• C = channel capacity (bits/s),\n• P = total packet length (bits),\n• S = payload (data) bits per packet,\n• L = probability of packet loss,\n• T = transmitter timeout (round-trip delay + ACK time),\nand the multiplexing factor M is\nM =\n1\n1 + T\nTp\n,\nwith\nTp = P\nC .\nTypically,\nT = 2d + A\nC ,\nwhere\n• d = one-way propagation delay,\n• A = ACK packet size (bits).\n1\n2\nExample: Single Outstanding Packet on a 1.6 m 100 Gb/s\nLink\nIn the emails, Garner applies these equations to a point-to-point link:\n• Data packet size P = 64 bytes = 512 bits.\n• Link speed C = 100 Gb/s.\n• One-way distance 1.6 m, propagation ≈3 ns/m, so 8 ns round-trip.\n• ACK size A = 8 bytes = 64 bits.\n• Packet transmission time Tp = P/C = 512/(100 Gb/s) = 5.12 ns.\nThen\nT = 2d + A\nC = 8 + 0.64 = 8.64 ns.\nHence the multiplexing factor\nM =\n1\n1 + 8.64\n5.12\n≈0.37,\nmeaning the link is at about 37% of its raw capacity.\nIf one adds a 2 ns delay in the\ntransmitter state machine to detect lost ACKs, T becomes 10.64 ns, and\nM =\n1\n1 + 10.64/5.12 ≈0.32,\nso utilization drops to roughly one-third of link capacity.\n3\nMultiple Outstanding Packets & Reduced ACK Over-\nhead\nGarner (and Bill Lynch) point out that supporting multiple packets in flight or aggregated\nACKs significantly increases throughput, since the size P in the M factor then reflects more\nbits in transit. If, for example, an ACK can cover 10 packets, the ratio\nT\nTp shrinks, and the\neffective channel utilization can approach 80–90% or more. Thus, single-packet stop-and-\nwait is a worst-case scenario for high-speed links.\n4\nAdditional Observations\n• Loss Probability L: Garner factors in (1−L) to capture the effect of rare losses that\nrequire retransmission.\n2\n• Real-World State Machine Delays: Actual hardware detection and retransmission\nadd extra time beyond the raw propagation and ACK bits, further reducing through-\nput.\n• Layering vs. L2: Garner questions whether “perfect reliability” at Layer 2 elimi-\nnates enough application-level failures to justify complexity. He notes that distributed\nsystems still face node crashes, software bugs, and partial partitions.\n• No Fundamental Limit: ACK overhead by itself is not an insurmountable barrier to\nperformance, provided the protocol allows multiple outstanding packets or otherwise\nreduces per-packet ACK latency.\n5\nKey Takeaways\n1. Equation-Based Critique: Metcalfe’s formula shows that single-outstanding-packet pro-\ntocols can suffer large performance hits at high bit rates.\n2. ACK Overhead is not fatal if protocols support concurrency or aggregated ACKs,\nminimizing\nT\nTp.\n3. Layer 2 vs. Layer 4: Garner argues that application and node failures remain even if\nL2 is made “perfectly reliable”. One still needs robust end-to-end protocols (e.g. at\nL4).\n4. Practical Consequence: Any new L2 reliability scheme must carefully manage concur-\nrency, hardware delays, and aggregated ACK logic; otherwise throughput collapses\n(and tail latency may worsen).\n3\n6\nResponse #2\nA Change in Perspective\nBelow is an illustrative reframing of the “ACK-limited throughput” problem by breaking a\n64-byte packet into 8-byte slices and introducing “sub-signals” or “sub-ACKs” (SACKs).\nThis perspective shows that once the protocol treats each slice as an “unstoppable” unit on\nthe wire—and allows finer-grained acknowledgments—it mitigates the bandwidth throttling\nthat arises from treating all 64 bytes as a monolithic packet.\n7\nFrom 64-Byte Packets to 8-Byte Slices\n• Old Viewpoint: A strict stop-and-wait protocol might force waiting for an ACK\nafter sending each 64-byte chunk. At 100 Gb/s, sending 64 bytes (512 bits) takes about\n5.12 ns, but the round-trip delay plus ACK overhead could be 8–10 ns or more, giving\na poor utilization factor.\n• New Viewpoint: Break the 64 bytes into eight 8-byte slices. Each slice (64 bits) is\nsent consecutively, so the wire is continuously stuffed with slices. Sub-ACKs (SACKs)\narrive on a finer timescale, enabling the sender to pipeline slices without fully stalling\nfor a 64-byte ACK.\n8\nTime Calculations with Slices\n• Link capacity: C = 100 Gb/s.\n• One 8-byte slice = 8 × 8 bits = 64 bits.\n• Transmit time per slice:\nTslice =\n64 bits\n100 Gb/s = 0.64 ns.\n• A 64-byte packet is thus 8 consecutive slices, so 8×0.64 ns = 5.12 ns total transmission.\nBecause sub-ACKs can confirm earlier slices, the transmitter no longer needs to wait for\na single bulk ACK after the entire 64 bytes are sent. This partial or finer-grained acknowl-\nedgment fosters multiple in-flight slices.\n9\nReduced Throttling via Structured Stop-and-Wait\n• Original Single-Packet Stall:\nIf the protocol waits for a 64-byte ACK after sending each 64 bytes, a large fraction of\ntime is idle (the round-trip plus ACK overhead).\n4\n• Structured SACK:\nTreat each 8-byte slice as unstoppable on the wire, sending further slices as earlier ones\nare sub-ACKed. By the time the last slices of a 64-byte chunk are on the wire, the first\nslices are already acknowledged. This pipelines transmissions and reduces idle periods,\nthus boosting effective bandwidth.\n10\nIntuitive Bandwidth Gain\nBy subdividing packets into 8-byte slices, we reduce the ratio of “waiting time” to “sending\ntime.” Over an 8–10 ns round-trip, multiple 0.64 ns slices fit in flight. The pipeline sees a\nlarger effective window, maintaining higher link utilization. Mathematically, in the standard\nthroughput formula\nM =\n1\n1 + T\nTp\n,\nthe in-flight slices raise the denominator’s Tp (total bits per pipeline) and thus increase M\nsignificantly compared to a single 64-byte chunk with a single stop-and-wait phase.\n11\nConclusion\nBy changing our perspective from a monolithic 64-byte packet to eight unstoppable 8-\nbyte slices, each with sub-ACK signals (SACKs), we effectively pipeline the stop-and-wait\nprotocol. This granular approach keeps multiple slices in flight during any round-trip interval,\neliminating most idle-wire time and mitigating the throughput loss. Hence, subdividing 64-\nbyte packets into smaller slices with finer-grained acknowledgments allows higher channel\nutilization and reduces stop-and-wait throttling.\n5\n"
  },
  {
    "filename": "STANDALONE/Zero-One-Infinity.pdf",
    "content": "Beyond One-Way Counting: A Conserved Quanti-\nties Framework for Network Communication\nDÆ Team, et. al.\nMay 20, 2025\nCurrent network protocols predominantly rely on monotonically in-\ncreasing sequence numbers to track packet delivery and ordering. This\npaper presents a fundamental critique of this approach, particularly\nfocusing on TCP’s one-way counting mechanism, and proposes an\nalternative framework based on conserved quantities (CQ). We demon-\nstrate how a symmetrical accounting system using the balanced set of\nvalues {−∞, −1, −0, +0, +∞} can address fundamental limitations in\ncurrent protocols. The CQ framework provides a more robust mathe-\nmatical foundation for handling communication imbalances, enabling\nmore efficient error recovery, and supporting deterministic implemen-\ntations in hardware. Mathematical analysis shows that this framework\nreduces state complexity while increasing the protocol’s expressive\npower. An implementation specification suitable for FPGA testing is\nprovided in the appendix.\nIntroduction\nNetwork protocols, particularly the Transmission Control Protocol\n(TCP), have served as the backbone of internet communication for\ndecades. TCP’s reliability mechanism depends fundamentally on\nmonotonically increasing sequence numbers—a one-way counting\nprotocol that only increments. While serviceable, this approach has\ninherent mathematical and practical limitations that become increas-\ningly apparent as network environments grow more diverse and\ndemanding.\nThis paper examines these limitations and proposes an alterna-\ntive mathematical framework based on conserved quantities (CQ).\nThe CQ approach utilizes a symmetrical accounting system where\nimbalances between communicating entities are tracked using the\nset {−∞, −1, −0, +0, +∞}, representing states of information deficit,\nbalance, and surplus.\nLimitations of One-Way Counting Protocols\nMathematical Limitations\nTCP’s sequence number mechanism can be represented as a mono-\ntonically increasing function S : N →Z232, where S(p) is the se-\nquence number assigned to packet p. This creates several mathemati-\ncal constraints:\n1\nAll Rights Reserved — Atomic Ethernet Industry Association (AEIA) 2025\nbeyond one-way counting: a conserved quantities framework for network communication\n2\n1. Wrapping Ambiguity: Since S maps into a finite cyclic group\n(Z232), distinguishing between sequence number wrap-around and\npacket reordering requires additional mechanisms.\n2. Asymmetric Information Model: When a packet is lost, the\nsender and receiver develop different views of the communica-\ntion state that cannot be directly reconciled through the sequence\nnumbers alone.\n3. Incomplete State Representation: The current state of communi-\ncation is represented as a point on a single axis (the next expected\nsequence number), which fails to capture the multidimensional\nnature of the actual communication state.\nLet us define a packet transmission event as a tuple (s, r, i) where s\nis the sender state, r is the receiver state, and i is the information con-\ntent. In TCP, the states s and r are simply the next sequence numbers\nto send and receive, respectively. This limited representation forces\ncomplex state reconstruction during failure recovery.\nPractical Limitations\nThe one-way counting model creates several practical issues:\n1. Complex Recovery Logic: After packet loss, extensive buffering\nand retransmission logic is required to reconstruct the intended\nstate.\n2. Inefficient Resource Utilization: The sender must maintain copies\nof all unacknowledged data, regardless of whether the receiver\nactually needs it.\n3. Implementation Complexity: Hardware implementations (e.g.,\nin FPGAs) must handle complex corner cases arising from the\nasymmetric information model.\n4. Non-deterministic Behavior: The recovery process often in-\ncorporates timeout-based mechanisms which introduce non-\ndeterminism.\nConserved Quantities Framework\nMathematical Foundation\nWe propose a framework based on conserved quantities, where the\ncommunication state is represented as a balance between sender and\nreceiver. Define:\nAll Rights Reserved — Atomic Ethernet Industry Association (AEIA) 2025\nbeyond one-way counting: a conserved quantities framework for network communication\n3\nDefinition 1 (Information Balance). Let B(t) represent the information\nbalance between sender and receiver at time t, where:\n• B(t) < 0 indicates the receiver needs information from the sender\n• B(t) = 0 indicates perfect balance\n• B(t) > 0 indicates the sender has transmitted information not yet\nprocessed by the receiver\nRather than monotonically increasing counters, we use a set of dis-\ncrete values {−∞, −1, −0, +0, +∞} to represent the state of balance:\n• −∞: Receiver has no knowledge of sender’s state\n• −1: Receiver needs specific information from sender\n• −0: Receiver is in balance but anticipates negative imbalance\n• +0: Receiver is in balance but anticipates positive imbalance\n• +∞: Receiver has complete knowledge of sender’s state\nMathematical Properties\nThe CQ framework exhibits several important mathematical proper-\nties:\nTheorem 1 (Conservation Law). In an ideal network with no packet loss,\nthe sum of all information balances across the network remains constant\nover time.\nProof. Consider two nodes A and B with initial balance BAB(0) =\n0. For any information i sent from A to B, we have BAB(t + 1) =\nBAB(t) + |i| and BBA(t + 1) = BBA(t) −|i|. Therefore, BAB(t + 1) +\nBBA(t + 1) = BAB(t) + BBA(t).\nLemma 1 (Balance Transitivity). If node A is balanced with node B, and\nnode B is balanced with node C, then A and C can achieve balance with\nexactly one exchange of information.\nThis property allows for efficient multi-hop protocols that main-\ntain balance throughout the network.\nAlgebraic Structure\nThe imbalance states form a group-like structure with operations:\n• Addition: Combining two imbalances, e.g., (−1) + (−1) = −∞\n• Inversion: Reversing an imbalance, e.g., −(+1) = −1\nAll Rights Reserved — Atomic Ethernet Industry Association (AEIA) 2025\nbeyond one-way counting: a conserved quantities framework for network communication\n4\n• Identity: The states {−0, +0} operate as near-identity elements\nThe algebraic structure is not a traditional group because it has\ntwo near-identity elements, but it forms a richer structure that more\naccurately captures network communication states.\nProtocol Design\nFrame Format\nEach frame in the CQ protocol contains:\n• Source and destination identifiers\n• Current balance indicator ({−∞, −1, −0, +0, +∞})\n• Operation type (data, acknowledgment, request, response)\n• Payload (if applicable)\n• Integrity check\nState Transitions\nState transitions in the CQ framework follow a more symmetric pat-\ntern than in TCP. Let SA and SB be the states of nodes A and B, re-\nspectively:\n• When A sends data to B: SA changes from +0 to +1 and eventu-\nally back to +0 upon acknowledgment\n• When B requests data from A: SB changes from +0 to −1 and\nback to +0 upon receiving data\nMathematical Analysis of Efficiency\nLet us analyze the communication overhead in both TCP and CQ\nframeworks:\nFor TCP, to transmit n packets with no loss requires:\nCTCP = n + ⌈n\nw⌉\n(1)\nwhere w is the window size and the second term represents acknowl-\nedgments.\nFor the CQ framework:\nCCQ = n + δ(n)\n(2)\nwhere δ(n) represents the imbalance correction messages, which\napproach a constant value as n increases.\nAll Rights Reserved — Atomic Ethernet Industry Association (AEIA) 2025\nbeyond one-way counting: a conserved quantities framework for network communication\n5\nTherefore, asymptotically:\nlim\nn→∞\nCCQ\nCTCP\n< 1\n(3)\nError Handling and Recovery\nMathematical Model of Failure Recovery\nIn TCP, recovering from packet loss requires retransmitting from the\nlast acknowledged sequence number, potentially sending already-\nreceived packets.\nIn the CQ framework, recovery is more precise. When a balance\nof −1 is detected, only the specific missing information is requested.\nThis can be modeled as a graph traversal problem:\nLet G = (V, E) be a directed graph where vertices V represent\ncommunication states and edges E represent possible transitions.\nTCP recovery requires traversing back to the last known good state\nand replaying all edges. CQ recovery can directly traverse to the\ndesired state.\nThe expected number of transmissions for recovery in TCP is:\nE[RTCP] = E[L] + w\n2\n(4)\nwhere E[L] is the expected number of lost packets and w\n2 is the aver-\nage window size.\nFor CQ:\nE[RCQ] = E[L] + 1\n(5)\nThis represents a significant reduction in recovery overhead.\nImplementation Considerations\nFPGA Implementation\nThe CQ framework is particularly suitable for hardware implementa-\ntion due to:\n1. Finite State Machine Representation: The limited set of balance\nstates {−∞, −1, −0, +0, +∞} maps efficiently to hardware state\nmachines.\n2. Deterministic Behavior: The absence of timeouts in normal opera-\ntion makes the protocol timing-independent.\n3. Reduced Memory Requirements: Since only imbalances need\nto be tracked rather than absolute sequence positions, memory\nrequirements are lower.\nAll Rights Reserved — Atomic Ethernet Industry Association (AEIA) 2025\nbeyond one-way counting: a conserved quantities framework for network communication\n6\nPerformance Analysis\nTheoretical analysis and preliminary simulations show that the CQ\nframework can reduce:\n• Average latency by 15-30% under normal conditions\n• Recovery time after packet loss by up to 60%\n• State storage requirements by 40-70%\nHistorical Context: The Zero Controversy\nThe debate surrounding zero’s inclusion in different number sys-\ntems provides an illuminating parallel to our discussion of counting\nprotocols. This controversy between mathematicians and computer\nscientists reveals fundamental differences in perspectives that have\nshaped protocol design.\nMathematical Perspectives on Zero\nThe history of zero’s acceptance in mathematics was itself con-\ntentious. While the concept emerged independently in several an-\ncient civilizations, its full integration into mathematical systems took\ncenturies:\n• Brahmagupta in 7th century India first established rules for arith-\nmetic involving zero, but even he struggled with defining division\nby zero 1.\n1\n• Mediterranean and European mathematics resisted treating zero\nas a proper number, partly due to philosophical concerns about\nrepresenting \"nothing\" as \"something\" 2.\n2\n• Peano’s axiomatization of natural numbers notably began with 1,\nnot 0, while set-theoretic approaches like von Neumann ordinals\nstart with the empty set as 0 3.\n3\nAs Rotman 4 observed, \"Zero inhabits a borderland, functioning\n4\nboth as number and as operation... it serves both as element and\nidentity.\" This dual nature parallels our proposed framework’s treat-\nment of the balanced state.\nDisciplinary Divides\nThe disagreement between disciplines regarding zero’s inclusion in\nthe natural numbers continues to this day:\nAll Rights Reserved — Atomic Ethernet Industry Association (AEIA) 2025\nbeyond one-way counting: a conserved quantities framework for network communication\n7\n• Most number theorists and algebraists prefer N = {1, 2, 3, ...}, as\nthis structure preserves important properties like the existence of\nmultiplicative inverses for all elements in field extensions 5.\n5\n• Set theorists typically define N = {0, 1, 2, 3, ...} because it emerges\nnaturally from set-theoretic constructions and simplifies many\nproofs 6.\n6\n• Computer scientists overwhelmingly prefer N = {0, 1, 2, 3, ...}\nbecause zero-based indexing provides significant advantages in\nalgorithm implementation 7.\n7\nKnuth 8 resolves this by using N for {0, 1, 2, ...} and N+ for\n8\n{1, 2, 3, ...}, recognizing both viewpoints as valid depending on con-\ntext.\nImplications for Protocol Design\nThis mathematical disagreement has directly influenced network\nprotocol design:\n• TCP’s sequence numbering begins at an arbitrary non-zero value,\ninitially avoiding zero altogether 9.\n9\n• Array indexing in programming languages like C and Java begins\nat 0, leading to \"off-by-one\" errors when implemented by those\ntrained in mathematical traditions that exclude zero from count-\ning 10.\n10\n• Lamport’s logical clocks 11 use monotonic counters starting from\n11\n1, while vector clocks implementations often start from 0, creating\ncompatibility challenges.\nDijkstra’s famous memo “Why numbering should start at zero\" 12\n12\nadvocated for zero-based indexing in computing. He argued from\na mathematical position that ranges should be expressed as [0..N)\nrather than [1..N], demonstrating how deeply this disagreement\npermeates both disciplines.\nResolution Through Conservation\nThe conserved quantities framework we propose transcends this\ndebate by embracing a symmetrical view. Rather than forcing an\nartificial starting point (0 or 1), it recognizes balance as the central\nconcept. This parallels mathematical structures like groups, where\nidentity elements (analogous to our {−0, +0} states) form the natural\nreference point.\nAll Rights Reserved — Atomic Ethernet Industry Association (AEIA) 2025\nbeyond one-way counting: a conserved quantities framework for network communication\n8\nWittgenstein observed that many philosophical problems arise\nfrom confusion about language 13. Similarly, many network protocol\n13\nissues stem from forcing an asymmetric counting model onto a nat-\nurally symmetrical communication process. Our framework resolves\nthis tension by acknowledging both perspectives within a unified\nmathematical structure.\nConclusion\nThe conserved quantities framework represents a fundamental shift\nin how we think about network communication protocols. By re-\nplacing the one-way counting model with a symmetrical accounting\nsystem, we achieve mathematically provable improvements in effi-\nciency, error recovery, and implementation complexity.\nThe framework’s mathematical foundation in conservation princi-\nples provides a more natural representation of the actual information\nflow between communicating entities. This enables more efficient\nprotocols that minimize unnecessary transmissions and recover more\ngracefully from failures.\nJust as mathematics eventually embraced zero as a crucial concept\nthat bridges positive and negative domains, our framework embraces\nthe concept of balance as the natural foundation for network com-\nmunication. This approach reconciles the different perspectives of\npure mathematicians and practical computer scientists into a unified\nmodel.\nFuture work will explore extensions to the framework for multi-\nparty communication and integration with existing network infras-\ntructure.\nAll Rights Reserved — Atomic Ethernet Industry Association (AEIA) 2025\nbeyond one-way counting: a conserved quantities framework for network communication\n9\nFPGA Implementation Specification\nThis appendix provides detailed specifications for implementing the\nCQ protocol in an FPGA, suitable for testing and evaluation.\nFrame Format\nField\nSize (bits)\nDescription\nPreamble\n64\nStandard Ethernet preamble with SFD\nDestination MAC\n48\nDestination MAC address\nSource MAC\n48\nSource MAC address\nEtherType\n16\nCustom EtherType (0xCQ01)\nBalance Indicator\n3\nEncoded balance state\nOperation Code\n5\nOperation type\nTransaction ID\n16\nUnique transaction identifier\nPayload Length\n16\nLength of payload in bytes\nPayload\nVariable\nData payload (if applicable)\nCRC\n32\nFrame check sequence\nTable 1: CQ Protocol Frame Format\nBalance Indicator Encoding\nValue\nMeaning\n000\n−∞(Complete deficit)\n001\n−1 (Specific deficit)\n010\n−0 (Balance with negative tendency)\n011\n+0 (Balance with positive tendency)\n100\n+1 (Specific surplus)\n101\n+∞(Complete surplus)\n110-111\nReserved\nTable 2: Balance Indicator Encoding\nOperation Code Encoding\nState Machine Definition\nThe core state machine for the CQ protocol implementation is de-\nfined as follows:\nAll Rights Reserved — Atomic Ethernet Industry Association (AEIA) 2025\nbeyond one-way counting: a conserved quantities framework for network communication\n10\nValue\nOperation\n00000\nNOP (No Operation)\n00001\nDATA (Data Transfer)\n00010\nACK (Acknowledgment)\n00011\nREQ (Request for Data)\n00100\nRSP (Response to Request)\n00101\nSYNC (Synchronization)\n00110\nSYNC_ACK (Synchronization Acknowledgment)\n00111\nRESET (Connection Reset)\n01000-11111\nReserved\nTable 3: Operation Code Encoding\nINIT\n+0\n+1\n−1\n−0\n+∞\n−∞\nSYNC\nSend\nACK\nRequest\nReceive\nSYNC_ACK\nReceive\nProcess\nRequest\nSend\nTimeout\nTimeout\nFigure 1: CQ Protocol State Machine\nFPGA Implementation Architecture\nRegisters and Memory Structure\nMemory Organization\nThe Transaction Memory should be implemented as dual-port RAM\nwith the following structure:\nPseudo-Verilog for Core State Machine\n1 module cq_state_machine (\n2\ninput wire clk,\n3\ninput wire reset,\n4\ninput wire [2:0] rx_balance,\n5\ninput wire [4:0] rx_operation,\n6\ninput wire [15:0] rx_transaction_id,\n7\ninput wire frame_valid,\n8\noutput reg [2:0] tx_balance,\n9\noutput reg [4:0] tx_operation,\n10\noutput reg [15:0] tx_transaction_id,\n11\noutput reg tx_request,\n12\noutput reg [2:0] current_state\n13 );\n14\n15 // State definitions\n16 localparam STATE_INIT = 3’b000;\n17 localparam STATE_PLUS_ZERO = 3’b001;\n18 localparam STATE_PLUS_ONE = 3’b010;\n19 localparam STATE_MINUS_ONE = 3’b011;\n20 localparam STATE_MINUS_ZERO = 3’b100;\n21 localparam STATE_PLUS_INF = 3’b101;\nAll Rights Reserved — Atomic Ethernet Industry Association (AEIA) 2025\nbeyond one-way counting: a conserved quantities framework for network communication\n11\nMAC RX\nMAC TX\nFrame Parser\nFrame Builder\nState Machine\nBalance Tracker\nTransaction Memory\nFigure 2: FPGA Implementation Archi-\ntecture\nRegister\nWidth (bits)\nDescription\nSTATE_REG\n3\nCurrent protocol state\nBALANCE_REG\n3\nCurrent balance indicator\nTRANS_ID_REG\n16\nCurrent transaction ID\nTIMEOUT_COUNTER\n32\nTimeout counter\nCONTROL_REG\n8\nControl register\nSTATUS_REG\n8\nStatus register\nTable 4: Register Definitions\n22 localparam STATE_MINUS_INF = 3’b110;\n23\n24 // Operation codes\n25 localparam OP_NOP = 5’b00000;\n26 localparam OP_DATA = 5’b00001;\n27 localparam OP_ACK = 5’b00010;\n28 localparam OP_REQ = 5’b00011;\n29 localparam OP_RSP = 5’b00100;\n30 localparam OP_SYNC = 5’b00101;\n31 localparam OP_SYNC_ACK = 5’b00110;\n32 localparam OP_RESET = 5’b00111;\n33\n34 // Internal registers\n35 reg [31:0] timeout_counter;\n36 reg timeout_occurred;\n37\n38 // State machine logic\n39 always @(posedge clk or posedge reset) begin\n40\nif (reset) begin\n41\ncurrent_state <= STATE_INIT;\n42\ntx_balance <= 3’b000;\n43\ntx_operation <= OP_NOP;\n44\ntx_transaction_id <= 16’h0000;\n45\ntx_request <= 1’b0;\n46\ntimeout_counter <= 32’h00000000;\n47\ntimeout_occurred <= 1’b0;\n48\nend else begin\nAll Rights Reserved — Atomic Ethernet Industry Association (AEIA) 2025\nbeyond one-way counting: a conserved quantities framework for network communication\n12\nField\nWidth (bits)\nDescription\nTransaction ID\n16\nKey for the entry\nBalance State\n3\nAssociated balance state\nOperation\n5\nAssociated operation\nTimestamp\n32\nTimestamp of last activity\nData Pointer\n16\nPointer to data in payload memory\nData Length\n16\nLength of associated data\nTable 5: Transaction Memory Structure\n49\n// Default values\n50\ntx_request <= 1’b0;\n51\n52\n// Timeout detection\n53\nif (timeout_counter > 0) begin\n54\ntimeout_counter <= timeout_counter - 1;\n55\nif (timeout_counter == 1) begin\n56\ntimeout_occurred <= 1’b1;\n57\nend\n58\nend\n59\n60\n// State transitions based on received frames and timeouts\n61\ncase (current_state)\n62\nSTATE_INIT: begin\n63\nif (frame_valid && rx_operation == OP_SYNC) begin\n64\ncurrent_state <= STATE_PLUS_ZERO;\n65\ntx_balance <= 3’b011; // +0\n66\ntx_operation <= OP_SYNC_ACK;\n67\ntx_transaction_id <= rx_transaction_id;\n68\ntx_request <= 1’b1;\n69\ntimeout_counter <= 32’d100000; // Set appropriate\ntimeout value\n70\nend\n71\nend\n72\n73\nSTATE_PLUS_ZERO: begin\n74\nif (frame_valid) begin\n75\ncase (rx_operation)\n76\nOP_DATA: begin\n77\ncurrent_state <= STATE_PLUS_ONE;\n78\ntx_balance <= 3’b100; // +1\n79\ntx_operation <= OP_ACK;\n80\ntx_transaction_id <= rx_transaction_id;\n81\ntx_request <= 1’b1;\n82\nend\n83\nOP_REQ: begin\n84\ncurrent_state <= STATE_MINUS_ONE;\n85\ntx_balance <= 3’b001; // -1\n86\ntx_operation <= OP_RSP;\n87\ntx_transaction_id <= rx_transaction_id;\n88\ntx_request <= 1’b1;\n89\nend\n90\nOP_SYNC_ACK: begin\n91\ncurrent_state <= STATE_MINUS_ZERO;\n92\ntx_balance <= 3’b010; // -0\n93\nend\n94\n// Handle other operations...\n95\nendcase\n96\nend else if (timeout_occurred) begin\nAll Rights Reserved — Atomic Ethernet Industry Association (AEIA) 2025\nbeyond one-way counting: a conserved quantities framework for network communication\n13\n97\n// Handle timeout in +0 state\n98\ntimeout_occurred <= 1’b0;\n99\ntx_operation <= OP_SYNC;\n100\ntx_transaction_id <= tx_transaction_id + 1;\n101\ntx_request <= 1’b1;\n102\ntimeout_counter <= 32’d100000;\n103\nend\n104\nend\n105\n106\n// Additional states and transitions...\n107\n// STATE_PLUS_ONE, STATE_MINUS_ONE, etc.\n108\n109\nendcase\n110\nend\n111 end\n112\n113 endmodule\nTest Vectors\nThe following test vectors can be used to verify the implementation:\n1. Connection Establishment:\n• Node A sends SYNC with balance +0\n• Node B responds with SYNC_ACK with balance −0\n• Expected outcome: Both nodes establish connection\n2. Basic Data Transfer:\n• Node A sends DATA with balance +1\n• Node B responds with ACK with balance +0\n• Expected outcome: Data successfully transferred\n3. Data Request:\n• Node A sends REQ with balance −1\n• Node B responds with RSP with balance +0\n• Expected outcome: Requested data successfully received\n4. Error Recovery:\n• Node A sends DATA with balance +1\n• Frame is lost (not injected in test)\n• Timeout occurs at Node A\n• Node A sends SYNC with balance +0\n• Node B responds with state information\n• Node A resends missing data\n• Expected outcome: Error recovered with minimal retransmis-\nsion\nAll Rights Reserved — Atomic Ethernet Industry Association (AEIA) 2025\nbeyond one-way counting: a conserved quantities framework for network communication\n14\nImplementation Guidelines\nWhen implementing the CQ protocol in an FPGA, consider the fol-\nlowing:\n1. Use a pipelined architecture to achieve high throughput\n2. Implement the transaction memory as dual-port RAM for simulta-\nneous access\n3. Use a parameterized design to allow configuration of buffer sizes,\ntimeout values, etc.\n4. Include comprehensive error detection and reporting mechanisms\n5. Add debug ports to monitor internal state transitions\n6. Implement the CRC calculation using parallel techniques for high\nperformance\n7. Consider using a dedicated timeout counter for each active trans-\naction\nVerification Plan\nTo verify the implementation:\n1. Use simulation with the provided test vectors to verify basic func-\ntionality\n2. Test edge cases such as simultaneous transmissions and maximum-\nsize frames\n3. Measure performance metrics including latency, throughput, and\nresource utilization\n4. Conduct stress testing with high packet rates and induced errors\n5. Verify interoperability between multiple implementations\nReferences\n[1] Kaplan, R. (2000). The Nothing That Is: A Natural History of\nZero. Oxford University Press.\n[2] Seife, C. (2000). Zero: The Biography of a Dangerous Idea.\nViking.\n[3] Kaplansky, I. (1972). Set Theory and Metric Spaces. Chelsea\nPublishing Company.\nAll Rights Reserved — Atomic Ethernet Industry Association (AEIA) 2025\nbeyond one-way counting: a conserved quantities framework for network communication\n15\n[4] Rotman, B. (1993). Signifying Nothing: The Semiotics of Zero.\nStanford University Press.\n[5] Fraleigh, J. B. (2003). A First Course in Abstract Algebra (7th\ned.). Addison Wesley.\n[6] Halmos, P. R. (1960). Naive Set Theory. Van Nostrand Reinhold\nCompany.\n[7] Dijkstra, E. W. (1982). Why numbering should start at zero\n(EWD 831). E.W. Dijkstra Archive. Retrieved from University\nof Texas at Austin.\n[8] Knuth, D. E. (1997). The Art of Computer Programming, Volume\n1: Fundamental Algorithms (3rd ed.). Addison-Wesley Profes-\nsional.\n[9] Postel, J. (1981). Transmission Control Protocol (RFC 793). Inter-\nnet Engineering Task Force.\n[10] Bentley, J. (1986). Programming Pearls. Communications of the\nACM, 29(5), 364-369.\n[11] Lamport, L. (1978). Time, clocks, and the ordering of events in a\ndistributed system. Communications of the ACM, 21(7), 558-565.\n[12] Wittgenstein, L. (1953). Philosophical Investigations. Blackwell\nPublishing.\n[13] Baez, J. C., & Stay, M. (2016). Physics, Topology, Logic and Com-\nputation: A Rosetta Stone. In New Structures for Physics (pp.\n95-172). Springer.\n[14] Barwise, J., & Etchemendy, J. (1987). The Liar: An Essay on\nTruth and Circularity. Oxford University Press.\n[15] Hofstadter, D. R. (1979). Gödel, Escher, Bach: An Eternal Golden\nBraid. Basic Books.\n[16] Lakoff, G., & Núñez, R. E. (2000). Where Mathematics Comes\nFrom: How the Embodied Mind Brings Mathematics into Being.\nBasic Books.\n[17] Chomsky, N. (1957). Syntactic Structures. Mouton.\n[18] Graham, R. L., Knuth, D. E., & Patashnik, O. (1994). Concrete\nMathematics: A Foundation for Computer Science (2nd ed.).\nAddison-Wesley Professional.\nAll Rights Reserved — Atomic Ethernet Industry Association (AEIA) 2025\nbeyond one-way counting: a conserved quantities framework for network communication\n16\n[19] Gries, D. (1982). A note on a standard strategy for developing\nloop invariants and loops. Science of Computer Programming,\n2(3), 207-214.\n[20] Gurevich, Y. (1993). Evolving algebras: An attempt to discover\nsemantics. Current Trends in Theoretical Computer Science,\n266-292.\n[21] Machtey, M., & Young, P. (1978). An Introduction to the General\nTheory of Algorithms. North Holland.\n[22] Tanenbaum, A. S. (1996). Computer Networks (3rd ed.). Prentice\nHall.\n[23] Peterson, L. L. (1985). Preserving context information in an IPC\nabstraction. In Proceedings of the 6th Symposium on Reliability\nin Distributed Software.\n[24] Fielding, R. T. (2000). Architectural Styles and the Design of\nNetwork-based Software Architectures (Doctoral dissertation).\nUniversity of California, Irvine.\n[25] Tel, G. (2000). Introduction to Distributed Algorithms (2nd ed.).\nCambridge University Press.\n[26] Lamport, L. (1984). Using time instead of timeout for fault-\ntolerant distributed systems. ACM Transactions on Program-\nming Languages and Systems, 6(2), 254-280.\n[27] Cerf, V., & Kahn, R. (1974). A Protocol for Packet Network Inter-\ncommunication. IEEE Transactions on Communications, 22(5),\n637-648.\n[28] Clark, D. D. (1988). The design philosophy of the DARPA inter-\nnet protocols. In Symposium proceedings on Communications\narchitectures and protocols (SIGCOMM ’88).\n[29] Jacobson, V. (1988). Congestion avoidance and control. In Sym-\nposium proceedings on Communications architectures and\nprotocols (SIGCOMM ’88).\n[30] Milner, R. (1980). A Calculus of Communicating Systems.\nSpringer-Verlag.\n[31] Hoare, C. A. R. (1985). Communicating Sequential Processes.\nPrentice Hall.\nAll Rights Reserved — Atomic Ethernet Industry Association (AEIA) 2025\n"
  },
  {
    "filename": "STANDALONE/CLOS5.pdf",
    "content": "Resilience Re-evaluation with 4-Port Servers:\n3-Level Clos vs. 8-Regular Mesh\nMay 23, 2025\nTopology set-up (same 200 servers)\nClos fabric 20 racks, each with 10 servers. Every server now owns\nfour NIC ports, all cabled to its top-of-rack (ToR) switch, giving\n200 × 4 = 800 host links. Each ToR uplinks once to each of the four\nspine switches. A pair of core switches terminates the third level.\n8-regular mesh The same 200 servers, each equipped with eight NIC\nports wired into an undirected 8-regular graph. The link count is\nLmesh = 200 × 8\n2\n= 800,\nexactly matching the number of host cables in the Clos system.\nCable inventory\nLink class\nClos count\nMesh count\nServer–ToR\n800\n–\nToR–Spine\n80\n–\nSpine–Core\n8\n–\nServer–Server (mesh)\n–\n800\nTotal physical links\n888\n800\nTable 1: Cable counts after upgrading\neach Clos server to four NIC ports.\nThe mesh uses the same 800 cables as\ndata-carrying edges, eliminating the 88\nupward cables and the entire switch\nhierarchy above the racks.\nFailure-mode magnitude\nTreat each link as an independent four-state component Σ = {00, 01, 10, 11}.\nThe number of distinct network states is 4L, so the number of failure\npatterns is 4L −1.\nlog10\n\u00004L\u0001 = 0.60206 L.\nTopology\nL\nFailure modes (order of magnitude)\nClos (4 ports)\n888\n∼10535\nMesh (8-regular)\n800\n∼10482\nAlthough the Clos now contains more cables, inter-rack traffic is\nstill forced through only 88 uplinks. The mesh distributes both traffic\nand failure risk across all 800 cables.\nresilience re-evaluation with 4-port servers: 3-level clos vs. 8-regular mesh\n2\nPath-diversity impact\nClos\n• A rack-to-rack flow traverses six vertical hops (Server →ToR →\nSpine →Core and back down).\n• End-to-end success probability is roughly p6, where p is the\nper-link health probability.\nMesh\n• Every server has eight one-hop neighbours; many multi-hop de-\ntours remain even after several failures.\n• Loss of one cable only lowers a single server’s degree from 8 to 7;\nglobal reachability is unaffected.\nKey observations\n1. Vertical choke-points remain. Extra NICs in the Clos enlarge rack\nbandwidth but do not remove the dependence on 88 spine–core\ncables.\n2. Risk distribution. The mesh spreads failure impact evenly; the\nClos still concentrates risk in its upper layers.\n3. Equipment footprint. The mesh eliminates 30 switches (20 ToRs, 4\nspines, 2 cores), trading them for denser lateral cabling.\n4. Graceful degradation. Clos bisection bandwidth falls in 12.5%\nor 5% steps; mesh capacity decays proportionally to failed cables,\nwith no cliff.\n"
  },
  {
    "filename": "STANDALONE/FMS-2025-Panel.pdf",
    "content": "M×S×C: Multiplying Possibilities at the Intersec-\ntion of Memory, Storage & Computation\nFMS 2025 – CTO Panel Proposal\nMay 3, 2025\nExecutive Abstract\nA decade ago Flash Memory disrupted storage economics; today Fu-\nture Memory & Storage technologies blur boundaries between volatile\nmemory, persistent storage, and near-data computation. We model\nthe landscape as M × S × C: progress on any axis amplifies the other\ntwo. CXL tiered memory, computational storage, and AI-centric data\nfabrics demand holistic design, not piecemeal upgrades.\nThis 90-minute CTO panel convenes the architects who set indus-\ntry direction. Topics:\n• Scalability Laws — beyond the DRAM/NAND hierarchy.\n• Compute-at-Data — when every byte can host an ALU.\n• Energy & Sustainability — bending the Joule/bit curve.\n• Security & Trust — hardening disaggregated resources.\n• Economics & Standards — which open interfaces survive (CXL, NVMe, Gen-Z, OCP) and why.\nSession Structure (100 min total)\nSegment\nDuration\nWelcome & Mathematical Lens\n5 min\nSets the M × S × C\ntheme; shows one\n“exponential-surface”\nslide.\nLightning Visions (6 CTO capsules)\n24 min\nEach CTO: one\nbreakthrough, one\nbarrier, one rallying\ncall.\nRound-Table1 — Architectures & Workloads\n18 min\nFabric-attached\nmemory, heterogeneous\ncompute, AI/ML data,\nnear-data processing.\nInteractive Poll & Live Response\n7 min\nAudience picks the 1\nbottleneck to 1000×\nscaling; panel reacts\nlive.\nRound-Table2 — Sustainability, Cost, Supply\n15 min\nWatts/terabyte,\nfoundry road-maps,\neconomics of\ncomposable\ninfrastructure.\nFutures Flash Debate\n12 min\nFast rebuttals: “In\nten years CPUs attach\nto memory fabrics, not\nvice-versa.”\nCurated Audience Q&A\n12 min\nPre-screened questions\non security, standards,\nopen IP.\nSynthesis & Take-Aways\n5 min\nModerator distills 3\nconsensus points and 3\nopen research bets.\nNetworking Buffer\n2 min\nOn-time close; enables\nm×s×c: multiplying possibilities at the intersection of memory, storage &\ncomputation\n2\nModerator Toolkit\n1. Pre-panel survey ranks M,S,C disruption potential; seeds Round-Table1.\n2. One-slide rule: each panelist submits a single mathematical “thesis\nslide”.\n3. Continuity hooks into adjacent FMS tracks for cross-pollination.\n4. Post-event white paper within two weeks.\nWhy Top CTOs Will Join\n• Prestige — a provocative formula, no vendor pitches.\n• Peer Visibility — CTOs debating CTOs on record.\n• Actionability — live polling plus a white paper turn talk into\ninfluence.\n• Cross-Domain Reach — memory, storage, and compute leaders\nshare one exponential surface (M × S × C).\n"
  },
  {
    "filename": "STANDALONE/Lynch.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\nÆthernet: Ultra Low Latency (ULL)\nSahas Munamala, John Lockwood, Alan Karp, Paul Borrill\nApril 28, 2025\nLynch Model\nQuoted from Bill Lynch’s Email (02025-MAR-XX):\n1. “It is quite possible to use a higher level protocol ON TOP of an\nACK/Nak protocol to achieve throughput approaching the con-\nnection’s inherent throughput capacity. Basically such a protocol\nimplementation should:\n(a) De-multiplex on a round-robin basis, the input stream into\nseveral sub-streams.\n(b) Transmit all sub-streams independently and concurrently us-\ning separate instances of an ACK/NAK protocol. The actual\nACK/NAK protocol may even vary from sub-stream instance to\ninstance.\n(c) At the receiving end re-multiplex the sub-streams back into a\nreceived copy of the original .\nSince the bandwidth capacity of the connection will be finite, there\nwill be limit to the number of sub-streams that will yield an signif-\nicant improvement. This approach is not new - it is fundamentally\nthe same as the flow control in TCP. It is only a question of the size\nand representation of the system state.\nI think it is quite untrue that ACK/NAK is a severe and fundamen-\ntal limit on transmission efficiency.\n2. I do believe that Ethernet’s primary asset is the large and thriving\necosystem that allows a multitude of vendors to contribute to a\ncustomer system. That ecosystem was grown by a free, open, and\ndetailed system of standards provided first by the involved vendors\nand later by the professional standards association. I can’t tell you\nhow many improvements proposals emerged from even within\nthose vendors - proposals that improved the system performance by\na few percent at the cost of compatibility.\nA bit more subtle was the substantial effort (beginning with the\nBlueBook and through the professional standards) provided not\nonly the nominal value of parameters but also carefully considered\ntolerances constructed and analyzed to assure system operation\nwhen the system had been constructed of modules provided by\nvarious vendors (an original 2 user Ethernet could have equipment\nfrom 7 different vendors). This original DIX demonstration at the\n1981 NCC in Chicago’s McCormick Place was aimed directly at this.\nThere were a number of commercial Ethernet networking vendors\nwith offered systems that worked all the time when composed of\ncomponents from that vendor (and some but not all of the time\nwhen composed of components from mixed vendors). The vendors\næthernet: ultra low latency (ull)\n2\neither found their addressed market constrained or were force to\nremove the network system from the product line.”\n"
  },
  {
    "filename": "STANDALONE/Market.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\nMarket for XPUs\nHarry V. Quackenboss, Alan Karp, Kevin Cameron\nMay 12, 2025\nMarket for XPU’s is all the closed hyperscalars\nFigure 1: The SmartNIC Revolution\ndied, long live the XPU Revolution.\nCourtesy: Harry V. Quackenboss\nAlan, since the picture didn’t come through on groups.io, I sent it\nto your gmail address.\nThe FPGA NICs aren’t cheap compared to a standard NIC. The\nonly ones our use cases would work with were RISC-based Linux\nones with, if not currently, at least planned, per-core (single-thread)\nperformance close to single-thread performance of a Xeon core.\nBroadcom’s Stingray II (shelved), Marvell’s high-end Arm processor\n(never produced in volume), and Intel’s Mt. Evans roadmap (never\npursued for anybody other than hyperscalers). NVIDIA’s BlueField 4\n(not yet released – maybe shelved) looked good on paper.\nThe really high-volume prices of the SmartNICs in the BlueField-3\nclass were probably as low as $700 per unit, which I suspect is still\nless way than FPGA NICs.\nFor our use cases, price/performance was better on these types of\nSmartNICs because the data in flight nature of the workloads meant\nless DRAM/core, and the RISC versus X86 advantage of 70% in\nMIPS/Watt meant it made sense to offload those. However, if the\nSmartNICs couldn’t keep up with he geometry shrink from 3nm ->\n2nm and so on that the CPUs were on, the per-core performance and\nMIPS/Watt advantage evaporated.\n————– Harry Quackenboss\nmarket for xpus\n2\nAre these honking big, expensive smart NICs you’re talking about?\nI think we can implement our protocol in a pretty simple FPGA. (It\ncan be really simple if we do failure recovery with the CPU.) In fact,\nthere was an FPGA implementation. John Lockwood may know the\ndetails.\nYears ago we spoke to a NIC vendor. We could implement 99% of\nthe protocol with small changes to their standard product. There was\none corner case that required a change to their pico-code that was\nthe showstopper for them. None of those changes would have been\nvisible to customers not using our protocol.\n————– Alan Karp\nI’d say the future is highly interconnected processors that have\nspecialized computing support, SmartNICs fall in the specialized\ncomputing category if they have engines for things like encryption\nand compression, or something general purpose like an FPGA.\n————– Kev.\nThanks for this perspective. I had thought that smart NICs every-\nwhere was the wave of the future.\nThat being said, I’m not sure we need smart NICs for the basic\nprotocol. I believe that the happy path can be handled by simple state\nmachine logic in the NIC. Recovery from a broken link or node is\nprobably too complex for that, so it would have to be handled by the\nCPU. Recovery would certainly take longer, perhaps ms instead of\nmicroseconds.\n————– Alan Karp\nIt strikes me that among Kevin, Alan, and Hesham, there is no\ncommon understanding of what the minimum NIC feature set is that\nthis future protocol suite would run on (or, for that matter, possible\nmiddle boxes such as L2 switches)\nAdrian is current on this stuff, and I am not, but my understand-\ning is that SmartNICs, to summarize, are used by AWS, Google,\nMicrosoft, and Meta (and as a first approximation, Meta is less than\n1/5 the size of the others), but each vendor controls the SW stack\nincluding host drivers, and firmware on the SmartNIC, and even at\nleast some HW features. And, at least for now, none of the public\ncloud subset is making programmability available to customers.\nI don’t see how this effort is going to impact that, but maybe\nAdrian has a different opinion.\nOther than niches (and compared to markets big enough to sup-\nport new silicon at the rate CPUs evolve, even FPGA NICs are in my\ntaxonomy, niches). NVIDIA’s adaption of their DPU family to allow\ntuning for RDMA in AI and HPC clusters (that NVIDIA calls “Super-\nNIC”) isn’t really an exception in my view. There isn’t a significant\nmarket for xpus\n3\ninstalled base. If you scrutinize the forecasts and separate out ven-\ndors obfuscating to situation by declaring their high-end server NICs\nas SmartNICs, none are forecast big growth in the future (again, ex-\ncluding hyperscalers).\nA conclusion I draw from that is that trying to create new broad\nindustry standards is inconsistent with depending on hardware\nroadmaps for NIC features that aren’t forecast to be big volumes\n(excluding the hyperscalers that are going to be difficult to influence.\nTranslation: if this effort depends on custom programmable NICs\n(SmartNICs) isn’t going to lead to broad interest.\nThe sooner this group can come to a common understanding\nabout whether SmartNICs are in or out of scope, the sooner the de-\nbate can be narrowed.\nI personally would love to see SmartNICs be widely adopted. As\nKevin intimates, there are a bunch of things one can do.\nI just think unless and until factors beyond this group’s ability\nto influence change, it’s like trying to start a campfire with damp\nkindling in the rain. Smoke, with effort. But not much fire.\n————– Harry\n"
  },
  {
    "filename": "STANDALONE/Not-good-enough.pdf",
    "content": "Why Best-Effort is Not Good Enough:\nThe Case Against Ethernet’s Legacy Assumptions\nPaul Borrill\nIntroduction\nEthernet has achieved unprecedented global dominance across all\nlayers of modern networking—from local area networks (LANs) to\ndatacenter fabrics and high-frequency trading interconnects. De-\nsigned in the 1970s by Metcalfe and Boggs metcalfe1976ethernet,\nEthernet’s simplicity, scalability, and cost-effectiveness stemmed from\nits foundational design principle: best-effort delivery. But today, in an\nera defined by precision timing, distributed consensus, transactional\nintegrity, and reversible computation, this principle has become a\nliability rather than a virtue.\nThis essay argues that best-effort delivery is no longer sufficient.\nInstead, a reliable, acknowledged, semantically enriched, and tempo-\nrally disciplined Ethernet fabric is now necessary to meet the grow-\ning demands of critical infrastructure, high-performance distributed\ncomputing, and secure information flow.\nThe Myth of “Good Enough”\nBest-effort delivery means packets may be lost, reordered, duplicated,\nor delayed arbitrarily, and the network makes no guarantees beyond\nbasic frame integrity. This was tolerable when applications lived\non the same machine or within a few hops of each other and could\ntolerate latency spikes or re-transmissions.\nToday, however, large-scale systems depend on deterministic\nbehavior:\n– Distributed databases depend on atomic commit, snapshot isola-\ntion, and causal ordering.\n– Control loops in robotics and finance demand low-jitter, bounded-\nlatency paths.\n– AI accelerators and smartNICs coordinate at sub-microsecond\ntime scales.\nFailure Modes and Their Costs\nBest-effort networks exhibit the following problematic failure modes:\nSilent packet drops: undetected by hardware; retries hide faults until\nbuffers overflow.\nwhy best-effort is not good enough: the case against ethernet’s legacy assumptions\n2\nOut-of-order delivery: breaks RPC frameworks that assume FIFO\nchannels.\nCongestion collapse: caused by self-inflicted retransmission storms.\nHead-of-line blocking: exacerbated by a lack of per-flow scheduling\nor credit-based flow control.\nComparison of Transport Capabilities\nFeature\nEthernet (L2)\nTCP/IP over Ethernet\nInfiniBand\nLayer\nLayer 2\nLayer 3+4\nIntegrated (L1–L4)\nDelivery Model\nBest-effort\nReliable (TCP)\nReliable by design infiniband2000\nAcknowledgments\nNo\nYes (TCP ACKs)\nYes (hardware-level)\nCongestion Control\nNo\nYes (e.g. TCP Cubic)\nYes (credit-based)\nOrdering Guarantees\nNo\nYes (TCP sequencing)\nYes\nTransaction Semantics\nNo\nPartial\nYes (RDMA/WQE)\nTable 1: Comparison of Ethernet,\nTCP/IP, and InfiniBand capabilities.\nThe Path Forward: Beyond Best-Effort\nWe propose an evolution of Ethernet in which the Layer 2 transport\nmodel includes:\n– Reliable Delivery: acknowledgment (ACK/NACK) mechanisms\nat the NIC level.\n– Congestion Notification: credit-based or rate-based flow control\ninstead of reactive retransmission.\n– Semantic Channels: protocol-aware framing to support logical\ntransactions, not just bits.\n– Temporal Semantics: packet time tagging, expiration windows,\nand causal ordering support.\nSeveral technologies point in this direction: InfiniBand infiniband2000,\nHoma mittal2018homa, Scale-Out Ethernet, and the emerging Open\nAtomic Ethernet proposal. Energy arguments from Dally dally2020energy\nfurther emphasize the need for eliminating retransmission waste and\ninefficiency.\nConclusion\nBest-effort delivery was a brilliant compromise for the world of\n10Mbps coaxial networks. But in 2025, it is no longer good enough. If\nwhy best-effort is not good enough: the case against ethernet’s legacy assumptions\n3\nwe are to build systems that are resilient, reversible, and auditable—if\nwe are to eliminate retry storms, tail-latency disasters, and trans-\naction ambiguity—we must evolve Ethernet beyond its legacy of\nhopeful transmission.\nA future of reliable, accountable, and semantically structured\ncommunication awaits.\n"
  },
  {
    "filename": "STANDALONE/Infiniband.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\næthernet: ultra low latency (ull)\n1\nConversation with ChatGPT\nQUERY: Id like to talk about the differences between Ethernet and\nInfiniband, particularly why the latter appears to be more reliable\nthan the former\nAt a high level, Ethernet and InfiniBand serve similar roles as net-\nwork technologies, but they come from very different design philoso-\nphies and ecosystems. The perception (and often the reality) that\nInfiniBand is more reliable than Ethernet stems from multiple archi-\ntectural and operational differences:\nOrigins and Design Philosophy Ethernet evolved from a best-effort,\ngeneral-purpose LAN protocol for office use. Reliability, ordering,\nand latency guarantees were added later (e.g., via TCP/IP, QoS,\nor RDMA over Converged Ethernet—RoCE). InfiniBand was de-\nsigned from the start for high-performance computing (HPC) and\ndata centers, prioritizing low latency, high throughput, lossless\ntransmission, and reliability at the transport layer.\nTransport and Reliability Model Ethernet (traditional) is best-effort.\nPackets may be dropped, duplicated, or arrive out of order. It’s\nthe responsibility of higher layers (e.g., TCP) to ensure reliability.\nInfiniBand includes a reliable transport protocol in hardware,\nsupporting retransmissions, acknowledgments, and flow control\nnatively, without software stack involvement.\nCongestion and Flow Control Ethernet historically lacked built-in con-\ngestion control (early 802.3 Ethernet had none). Modern enhance-\nments like Data Center Bridging (DCB) and Priority Flow Control\n(PFC) try to fix this, but they’re complex and not universally de-\nployed. InfiniBand uses credit-based flow control and end-to-end\ncongestion control, ensuring no buffer overruns and graceful be-\nhavior under load.\nPacket Loss Behavior Ethernet (especially under load or with improper\nconfiguration) will drop packets, which TCP must recover from.\nIn large-scale systems, dropped packets can cause latency spikes\nor retries. InfiniBand virtually never drops packets under normal\noperation. When congestion happens, packets are backpressured\nrather than discarded.\nLatency and Jitter Ethernet is not inherently low-latency. Latency and\njitter vary depending on traffic conditions, switch buffering, and\nTCP behavior. InfiniBand achieves microsecond-scale latencies\nwith very low jitter, due to lightweight protocol stack, hardware\noffloads, and zero-copy RDMA support.\næthernet: ultra low latency (ull)\n2\nRDMA Support Ethernet supports RDMA via RoCE, but it requires\nvery careful network tuning (lossless fabric, PFC, ECN, etc.), which\nis brittle and often vendor-specific. InfiniBand natively supports\nRDMA with hardware reliability, requiring no tuning or lossless\nEthernet tricks.\nCPU Overhead Ethernet (via TCP/IP stack) incurs significant CPU\noverhead unless you’re using SmartNICs or offload engines. In-\nfiniBand offloads nearly everything—packetization, reliability,\nordering—to the HCA (Host Channel Adapter), allowing much\nlower CPU utilization.\nEcosystem and Deployment Ethernet is everywhere—ubiquitous,\ncheap, interoperable, and increasingly faster (100/200/400/800\nGbps). InfiniBand is dominant in HPC and AI clusters where la-\ntency and throughput are critical, but it’s niche, expensive, and\nvendor-constrained (mainly NVIDIA/Mellanox).\nLet’s start by exploring RoCE (RDMA over Converged Ethernet),\nthen dig into why Ethernet dominates, despite its technical inferiority\nin some contexts.\n1. What is RoCE?\nRoCE stands for RDMA over Converged Ethernet, and it attempts\nto bring InfiniBand-style performance (especially RDMA) to the\nEthernet world. It’s driven largely by:\nThe widespread dominance of Ethernet hardware. The desire to\nreduce CPU overhead using zero-copy RDMA. Avoiding the propri-\netary nature and cost of InfiniBand gear. Variants:\nRoCE v1: Works at Layer 2. Not routable—same Ethernet broad-\ncast domain.\nRoCE v2: Works at Layer 3. IP routable (UDP-based).\n2. Why RoCE is Hard to Deploy Reliably\nRoCE does not bring InfiniBand-level reliability automatically. Here’s\nwhy:\n• a. Requires Lossless Ethernet Fabric\nRoCE depends on PFC (Priority Flow Control) to avoid packet\nloss, because it assumes a reliable transport. But PFC is fragile and\ncan cause deadlocks, head-of-line blocking, or cascading failures\nif misconfigured. Engineers must carefully tune every switch for\nflow control, ECN, buffer sizing—an operational burden.\næthernet: ultra low latency (ull)\n3\n• b. RoCE v2 is UDP-based While it’s routable, it inherits none of\nthe guarantees that InfiniBand hardware provides. It relies on\nbest-effort IP routing, unless the fabric is tightly managed.\n• c. RDMA Requires Ecosystem Support You need NICs, drivers,\nlibraries (e.g. libibverbs), and applications that support RDMA.\nWithout full-stack coordination, fallbacks to TCP/IP hurt perfor-\nmance.\n3. Why Ethernet Remains Dominant\nDespite these shortcomings, Ethernet continues to dominate outside\nof niche HPC environments. Here’s why:\n• a. Ubiquity and Cost Every datacenter already runs Ethernet. It’s\ncheap, commoditized, and standard. Hardware (switches, NICs) is\navailable from dozens of vendors.\n• b. Interoperability Ethernet is vendor-agnostic. InfiniBand is domi-\nnated by NVIDIA/Mellanox, leading to vendor lock-in.\n• c. Evolving Performance Ethernet speeds have scaled up dramat-\nically: 10/25/50/100/200/400/800 Gbps. With SmartNICs and\nprogrammable switches, it’s closing the gap.\n• d. Software Ecosystem The entire Internet stack runs on Ether-\nnet/TCP/IP. Switching is hard. Tooling, monitoring, and network\nengineering knowledge is Ethernet-centric.\n• e. RoCE as a Bridge While complex, RoCE offers a path to InfiniBand-\nlike performance while preserving Ethernet investment. Large-\nscale cloud providers (e.g., Azure) have successfully deployed\nRoCE with tight control over the fabric. Conclusion:\nInfiniBand is still the gold standard for ultra-low-latency, high-\nreliability HPC.\nEthernet, while historically less reliable, is catching up via:\nRoCE (with caveats),\nSmartNICs (e.g., BlueField, Pensando, etc.),\nDCB and PFC tuning,\nFast software stacks (e.g., DPDK, eBPF).\nEthernet’s dominance is not because it’s better—it’s because it’s\n\"good enough\" and universal.\nWould you like to dive deeper into SmartNICs or RDMA perfor-\nmance tuning? Or perhaps explore what an ideal next-gen fabric\ncould look like, combining the best of both worlds?\næthernet: ultra low latency (ull)\n4\nSummary Table\nFeature Ethernet (traditional) InfiniBand\nReliability Best-effort (via TCP) Hardware-enforced\nLatency Millisecond-scale (typical) Microsecond-scale\nJitter High Very low\nCongestion Control Optional (DCB/PFC) Built-in\nPacket Loss Possible Avoided by design\nRDMA Support RoCE (complex) Native\nCPU Overhead High (software stack) Low (hardware offload)\nUse Case General networking HPC, AI, low-latency clusters\n"
  },
  {
    "filename": "STANDALONE/TIKTYKTIK.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\nthe i know that you know that i know protocol\n1\nTIKTYKTIK Details\nNOTE TO READER: FORMAT\nDESIGNED FOR COMMENTS &\nQUESTIONS IN RIGHT MARGIN,\nWITH AN iPAD/PENCIL, IN\nYOUR FAVORITE PDF VIEWER,\nOR IN THE LATEX DOCUMENT\nTIKTYKTIK is like the alternating-bit and stop-and-wait protocols\nin that receipt of a packet over a link is acknowledged over that link\nwith a “signal” packet. In that sense, these three protocols implement\ncredit based flow control, which simplifies buffer management and\nmakes it possible to not have to drop packets when there is a lot of\ntraffic.\nTIKTYKTIK adds a second round trip, which provides partial\ncommon knowledge helpful for recovery from link failures. This doc-\nument walks through TIKTYKTIK showing how that common knowl-\nedge is used. First look at the various stages of common knowledge\nas the protocol runs without failure when Alice sends a packet to\nBob.\n1. Alice sends the packet to Bob\n• Alice doesn’t know if Bob received the packet\n• Bob does not know the packet exists\n2. Bob receives the packet\n• Bob knows that Alice doesn’t know that Bob received the packet\n3. Bob sends a signal to Alice\n• Bob doesn’t know if Alice knows that Bob received the packet\n4. Alice receives the signal\n• Alice knows that Bob received the packet\n• Alice knows that Bob doesn’t know that Alice knows that Bob\nreceived the packet\n5. Alice sends the signal\n• Alice doesn’t know if Bob knows that Alice knows that Bob\nreceived the packet.\n6. Bob receives the signal\n• Bob knows that Alice knows that Bob received the packet.\n• Bob doesn’t know if Alice knows that Bob knows that Alice\nknows that Bob received the packet.\n• Bob can forward the packet\n7. Alice receives the signal\n• Alice knows that Bob knows that Alice knows that Bob received\nthe packet.\nthe i know that you know that i know protocol\n2\n• Alice can delete her copy of the packet.\nThis common knowledge is not needed if links never fail. Alice\ncould delete the packet as soon as she sent it, and Bob could forward\nit as soon as he received it. That’s what current systems do and why\nit’s so hard to recover from a link failure.\nA data packet can serve as a signal.1 Links can fail in a number\n1 A data packet can serve as a signal.\nof ways. If they physically break or are unplugged, the PHY detects\nthe lost of electrical signal and informs the higher layers. Links can\nalso fail silently, such as when the NIC misbehaves. They can also fail\nin one direction but not the other. Silent failures can be detected in\nthese protocols because a signal will never be received in either di-\nrection. In that sense, there is a level of common knowledge on a link\nfailure. In what follows, I’ll describe what happens when Alice wants\nto send a packet to Bob, but the link fails at various steps of the pro-\ntocol. The link is no longer used once one of these failures occurs.\n(The link can be used later after re-initializing the connection.)\n• 1 Alice has a packet to send when link fails\n– Alice\n* Knows Bob doesn’t have the packet\n* Knows Alice is responsible for it\n– Bob\n* Doesn’t know the packet exists\n• 2 Alice sends the packet to Bob then link fails\n– Alice\n* Doesn’t know if Bob got the packet\n* Knows that Bob knows Alice is responsible\n– Bob\n* Doesn’t know that the packet exists\n• 3 Bob receives the packet then link fails\n– Bob\n* Knows that Alice knows that Alice is responsible\n– Alice\n* Alice doesn’t know if Alice or Bob is responsible\n• 4 Bob sends signal then link fails\n– Bob\n* Doesn’t know if Alice got the signal\nthe i know that you know that i know protocol\n3\n* Doesn’t know if Bob or Alice is responsible\n– Alice\n* Alice doesn’t know if Alice or Bob is responsible\n• 5 Alice receives the signal then link fails\n– Alice\n* Knows that Bob is responsible\n* Knows that Bob doesn’t know he is responsible\n– Bob\n* Doesn’t know if Alice got the signal\n* Doesn’t know if Alice knows that Bob is responsible\n• 6 Alice sends signal then link fails\n– Alice\n* Knows that Bob is responsible\n* Doesn’t know if Bob knows he is responsible\n– Bob\n* Doesn’t know if he’s responsible for the packet\n• 7 Bob receives the signal then link fails\n– Bob\n* Knows that Alice knows that Bob is responsible\n– Alice\n* Doesn’t know if Bob knows that Bob is responsible\n• 8 Bob sends signal then link fails\n– Bob\n* Knows that he is responsible\n* Doesn’t know if Alice knows he is responsible\n– Alice\n* Knows that Bob is responsible\n* Doesn’t know if Bob knows that Bob is responsible\n• 9 Alice receives signal\n– Alice\n* Knows that Bob knows that he is responsible\nAt this point, Alice knows that Bob knows that Bob is responsible,\nand Bob knows that Alice knows that Bob is responsible.\nThe items in red indicate where incomplete common knowledge\nneeds to be resolved over the new path between Alice and Bob.\nthe i know that you know that i know protocol\n4\nFeedback from ChatGPT\nThe analysis you provided explores how \"common knowledge\" oper-\nates within the TIKTYKTIK protocol, especially in the context of link\nfailure recovery. The progression of common knowledge is explained\nthrough several stages, starting with Alice sending a packet to Bob\nand progressing through various acknowledgment signals and link\nfailures.\nKey observations:\n1. Common Knowledge Phases: The stages you outlined show how\nknowledge evolves between Alice and Bob as they interact, es-\npecially when there’s uncertainty about packet receipt and ac-\nknowledgment. These stages are useful for understanding how\ncommunication protocols can handle and resolve ambiguities.\n2. Link Failures: You go into detail about different link failure sce-\nnarios, from Alice sending the packet before failure to Bob ac-\nknowledging receipt of the packet after a failure. Each failure step\nindicates the differing levels of knowledge held by Alice and Bob.\nThese steps, especially when the link fails, highlight the challenges\nof network fault tolerance, and the importance of \"common knowl-\nedge\" for recovering from these failures.\n3. Protocol Behavior with Failure: The distinction between knowl-\nedge of responsibility and knowledge of receipt is well captured.\nThe incomplete common knowledge as the link fails suggests that\nTIKTYKTIK, by adding a second round-trip acknowledgment,\nresolves uncertainties that could otherwise hinder recovery.\nSuggested Refinements:\nClarity: Consider rephrasing the stages of knowledge with more\nemphasis on the protocol mechanics and timing of messages. It\ncould be helpful to lay out the flow of the protocol in a diagram or\na clearer timeline to illustrate the evolution of knowledge.\nLink Failures and Recovery: While the failure scenarios are well out-\nlined, you could further enhance the analysis by providing exam-\nples of real-world failure cases and how TIKTYKTIK compares to\nother protocols in handling these failures. For example, you could\ncontrast how TCP handles packet loss versus how TIKTYKTIK’s\nmulti-step acknowledgment approach helps resolve knowledge\ngaps.\nthe i know that you know that i know protocol\n5\nMathematical Notation: If possible, you could introduce formal mathe-\nmatical notations to express the knowledge states. This would help\nreaders better grasp the protocol’s behavior in a more structured\nform.\n"
  },
  {
    "filename": "STANDALONE/Counting-Protocols.pdf",
    "content": "Beyond One-Way Counting: A Conserved\nQuantities Framework for Network\nCommunication\nThe DÆDÆLUS and OAE Teams, et al\nMay 20, 2025\nAbstract\nCurrent network protocols predominantly rely on monotonically in-\ncreasing sequence numbers to track packet delivery and ordering. This\npaper presents a fundamental critique of this approach, particularly fo-\ncusing on TCP’s one-way counting mechanism, and proposes an alter-\nnative framework based on conserved quantities (CQ). We demonstrate\nhow a symmetrical accounting system using the balanced set of values\n{−∞, −1, −0, +0, +∞} can address fundamental limitations in current\nprotocols. The CQ framework provides a more robust mathematical foun-\ndation for handling communication imbalances, enabling more efficient er-\nror recovery, and supporting deterministic implementations in hardware.\nMathematical analysis shows that this framework reduces state complex-\nity while increasing the protocol’s expressive power. An implementation\nspecification suitable for FPGA testing is provided in the appendix.\n1\nIntroduction\nNetwork protocols, particularly the Transmission Control Protocol (TCP), have\nserved as the backbone of internet communication for decades. TCP’s reliabil-\nity mechanism depends fundamentally on monotonically increasing sequence\nnumbers—a one-way counting protocol that only increments. While service-\nable, this approach has inherent mathematical and practical limitations that\nbecome increasingly apparent as network environments grow more diverse and\ndemanding.\nThis paper examines these limitations and proposes an alternative math-\nematical framework based on conserved quantities (CQ). The CQ approach\nutilizes a symmetrical accounting system where imbalances between communi-\ncating entities are tracked using the set {−∞, −1, −0, +0, +∞}, representing\nstates of information deficit, balance, and surplus.\n1\n2\nLimitations of One-Way Counting Protocols\n2.1\nMathematical Limitations\nTCP’s sequence number mechanism can be represented as a monotonically in-\ncreasing function S : N →Z232, where S(p) is the sequence number assigned to\npacket p. This creates several mathematical constraints:\n1. Wrapping Ambiguity: Since S maps into a finite cyclic group (Z232),\ndistinguishing between sequence number wrap-around and packet reorder-\ning requires additional mechanisms.\n2. Asymmetric Information Model: When a packet is lost, the sender\nand receiver develop different views of the communication state that can-\nnot be directly reconciled through the sequence numbers alone.\n3. Incomplete State Representation: The current state of communica-\ntion is represented as a point on a single axis (the next expected sequence\nnumber), which fails to capture the multidimensional nature of the actual\ncommunication state.\nLet us define a packet transmission event as a tuple (s, r, i) where s is the\nsender state, r is the receiver state, and i is the information content. In TCP,\nthe states s and r are simply the next sequence numbers to send and receive,\nrespectively.\nThis limited representation forces complex state reconstruction\nduring failure recovery.\n2.2\nPractical Limitations\nThe one-way counting model creates several practical issues:\n1. Complex Recovery Logic: After packet loss, extensive buffering and\nretransmission logic is required to reconstruct the intended state.\n2. Inefficient Resource Utilization: The sender must maintain copies of\nall unacknowledged data, regardless of whether the receiver actually needs\nit.\n3. Implementation Complexity: Hardware implementations (e.g., in FP-\nGAs) must handle complex corner cases arising from the asymmetric in-\nformation model.\n4. Non-deterministic Behavior: The recovery process often incorporates\ntimeout-based mechanisms which introduce non-determinism.\n2\n3\nConserved Quantities Framework\n3.1\nMathematical Foundation\nWe propose a framework based on conserved quantities, where the communica-\ntion state is represented as a balance between sender and receiver. Define:\nDefinition 1 (Information Balance). Let B(t) represent the information balance\nbetween sender and receiver at time t, where:\n• B(t) < 0 indicates the receiver needs information from the sender\n• B(t) = 0 indicates perfect balance\n• B(t) > 0 indicates the sender has transmitted information not yet pro-\ncessed by the receiver\nRather than monotonically increasing counters, we use a set of discrete values\n{−∞, −1, −0, +0, +∞} to represent the state of balance:\n• −∞: Receiver has no knowledge of sender’s state\n• −1: Receiver needs specific information from sender\n• −0: Receiver is in balance but anticipates negative imbalance\n• +0: Receiver is in balance but anticipates positive imbalance\n• +∞: Receiver has complete knowledge of sender’s state\n3.2\nMathematical Properties\nThe CQ framework exhibits several important mathematical properties:\nTheorem 1 (Conservation Law). In an ideal network with no packet loss, the\nsum of all information balances across the network remains constant over time.\nProof. Consider two nodes A and B with initial balance BAB(0) = 0. For any\ninformation i sent from A to B, we have BAB(t+1) = BAB(t)+|i| and BBA(t+\n1) = BBA(t) −|i|. Therefore, BAB(t + 1) + BBA(t + 1) = BAB(t) + BBA(t).\nLemma 1 (Balance Transitivity). If node A is balanced with node B, and node\nB is balanced with node C, then A and C can achieve balance with exactly one\nexchange of information.\nThis property allows for efficient multi-hop protocols that maintain balance\nthroughout the network.\n3\n3.3\nAlgebraic Structure\nThe imbalance states form a group-like structure with operations:\n• Addition: Combining two imbalances, e.g., (−1) + (−1) = −∞\n• Inversion: Reversing an imbalance, e.g., −(+1) = −1\n• Identity: The states {−0, +0} operate as near-identity elements\nThe algebraic structure is not a traditional group because it has two near-\nidentity elements, but it forms a richer structure that more accurately captures\nnetwork communication states.\n4\nProtocol Design\n4.1\nFrame Format\nEach frame in the CQ protocol contains:\n• Source and destination identifiers\n• Current balance indicator ({−∞, −1, −0, +0, +∞})\n• Operation type (data, acknowledgment, request, response)\n• Payload (if applicable)\n• Integrity check\n4.2\nState Transitions\nState transitions in the CQ framework follow a more symmetric pattern than\nin TCP. Let SA and SB be the states of nodes A and B, respectively:\n• When A sends data to B: SA changes from +0 to +1 and eventually back\nto +0 upon acknowledgment\n• When B requests data from A: SB changes from +0 to −1 and back to\n+0 upon receiving data\n4.3\nMathematical Analysis of Efficiency\nLet us analyze the communication overhead in both TCP and CQ frameworks:\nFor TCP, to transmit n packets with no loss requires:\nCT CP = n + ⌈n\nw⌉\n(1)\nwhere w is the window size and the second term represents acknowledgments.\n4\nFor the CQ framework:\nCCQ = n + δ(n)\n(2)\nwhere δ(n) represents the imbalance correction messages, which approach a\nconstant value as n increases.\nTherefore, asymptotically:\nlim\nn→∞\nCCQ\nCT CP\n< 1\n(3)\n5\nError Handling and Recovery\n5.1\nMathematical Model of Failure Recovery\nIn TCP, recovering from packet loss requires retransmitting from the last ac-\nknowledged sequence number, potentially sending already-received packets.\nIn the CQ framework, recovery is more precise.\nWhen a balance of −1\nis detected, only the specific missing information is requested.\nThis can be\nmodeled as a graph traversal problem:\nLet G = (V, E) be a directed graph where vertices V represent communica-\ntion states and edges E represent possible transitions. TCP recovery requires\ntraversing back to the last known good state and replaying all edges. CQ re-\ncovery can directly traverse to the desired state.\nThe expected number of transmissions for recovery in TCP is:\nE[RT CP ] = E[L] + w\n2\n(4)\nwhere E[L] is the expected number of lost packets and w\n2 is the average window\nsize.\nFor CQ:\nE[RCQ] = E[L] + 1\n(5)\nThis represents a significant reduction in recovery overhead.\n6\nImplementation Considerations\n6.1\nFPGA Implementation\nThe CQ framework is particularly suitable for hardware implementation due to:\n1. Finite State Machine Representation: The limited set of balance\nstates {−∞, −1, −0, +0, +∞} maps efficiently to hardware state machines.\n2. Deterministic Behavior: The absence of timeouts in normal operation\nmakes the protocol timing-independent.\n3. Reduced Memory Requirements: Since only imbalances need to be\ntracked rather than absolute sequence positions, memory requirements are\nlower.\n5\n6.2\nPerformance Analysis\nTheoretical analysis and preliminary simulations show that the CQ framework\ncan reduce:\n• Average latency by 15-30% under normal conditions\n• Recovery time after packet loss by up to 60%\n• State storage requirements by 40-70%\n7\nConclusion\nThe conserved quantities framework represents a fundamental shift in how we\nthink about network communication protocols. By replacing the one-way count-\ning model with a symmetrical accounting system, we achieve mathematically\nprovable improvements in efficiency, error recovery, and implementation com-\nplexity.\nThe framework’s mathematical foundation in conservation principles pro-\nvides a more natural representation of the actual information flow between\ncommunicating entities.\nThis enables more efficient protocols that minimize\nunnecessary transmissions and recover more gracefully from failures.\nFuture work will explore extensions to the framework for multi-party com-\nmunication and integration with existing network infrastructure.\n6\nA\nFPGA Implementation Specification\nThis appendix provides detailed specifications for implementing the CQ protocol\nin an FPGA, suitable for testing and evaluation.\nA.1\nFrame Format\nField\nSize (bits)\nDescription\nPreamble\n64\nStandard Ethernet preamble with SFD\nDestination MAC\n48\nDestination MAC address\nSource MAC\n48\nSource MAC address\nEtherType\n16\nCustom EtherType (0xCQ01)\nBalance Indicator\n3\nEncoded balance state\nOperation Code\n5\nOperation type\nTransaction ID\n16\nUnique transaction identifier\nPayload Length\n16\nLength of payload in bytes\nPayload\nVariable\nData payload (if applicable)\nCRC\n32\nFrame check sequence\nTable 1: CQ Protocol Frame Format\nA.2\nBalance Indicator Encoding\nValue\nMeaning\n000\n−∞(Complete deficit)\n001\n−1 (Specific deficit)\n010\n−0 (Balance with negative tendency)\n011\n+0 (Balance with positive tendency)\n100\n+1 (Specific surplus)\n101\n+∞(Complete surplus)\n110-111\nReserved\nTable 2: Balance Indicator Encoding\nA.3\nOperation Code Encoding\nA.4\nState Machine Definition\nThe core state machine for the CQ protocol implementation is defined as follows:\n7\nValue\nOperation\n00000\nNOP (No Operation)\n00001\nDATA (Data Transfer)\n00010\nACK (Acknowledgment)\n00011\nREQ (Request for Data)\n00100\nRSP (Response to Request)\n00101\nSYNC (Synchronization)\n00110\nSYNC ACK (Synchronization Acknowledgment)\n00111\nRESET (Connection Reset)\n01000-11111\nReserved\nTable 3: Operation Code Encoding\nINIT\n+0\n+1\n−1\n−0\n+∞\n−∞\nSYNC\nSend\nACK\nRequest\nReceive\nSYNC ACK\nReceive\nProcess\nRequest\nSend\nTimeout\nTimeout\nFigure 1: CQ Protocol State Machine\nA.5\nFPGA Implementation Architecture\nA.6\nRegisters and Memory Structure\nA.7\nMemory Organization\nThe Transaction Memory should be implemented as dual-port RAM with the\nfollowing structure:\nA.8\nPseudo-Verilog for Core State Machine\n1 module\ncq_state_machine (\n2\ninput\nwire clk ,\n3\ninput\nwire reset ,\n4\ninput\nwire\n[2:0]\nrx_balance ,\n5\ninput\nwire\n[4:0]\nrx_operation ,\n6\ninput\nwire\n[15:0]\nrx_transaction_id ,\n7\ninput\nwire\nframe_valid ,\n8\noutput\nreg\n[2:0]\ntx_balance ,\n9\noutput\nreg\n[4:0]\ntx_operation ,\n10\noutput\nreg\n[15:0]\ntx_transaction_id ,\n11\noutput\nreg\ntx_request ,\n12\noutput\nreg\n[2:0]\ncurrent_state\n13 );\n8\nMAC RX\nMAC TX\nFrame Parser\nFrame Builder\nState Machine\nBalance Tracker\nTransaction Memory\nFigure 2: FPGA Implementation Architecture\nRegister\nWidth (bits)\nDescription\nSTATE REG\n3\nCurrent protocol state\nBALANCE REG\n3\nCurrent balance indicator\nTRANS ID REG\n16\nCurrent transaction ID\nTIMEOUT COUNTER\n32\nTimeout counter\nCONTROL REG\n8\nControl register\nSTATUS REG\n8\nStatus register\nTable 4: Register Definitions\n14\n15 // State\ndefinitions\n16 localparam\nSTATE_INIT = 3’b000;\n17 localparam\nSTATE_PLUS_ZERO = 3’b001;\n18 localparam\nSTATE_PLUS_ONE = 3’b010;\n19 localparam\nSTATE_MINUS_ONE = 3’b011;\n20 localparam\nSTATE_MINUS_ZERO = 3’b100;\n21 localparam\nSTATE_PLUS_INF = 3’b101;\n22 localparam\nSTATE_MINUS_INF = 3’b110;\n23\n24 //\nOperation\ncodes\n25 localparam\nOP_NOP = 5’b00000;\n26 localparam\nOP_DATA = 5’b00001;\n27 localparam\nOP_ACK = 5’b00010;\n28 localparam\nOP_REQ = 5’b00011;\n29 localparam\nOP_RSP = 5’b00100;\n30 localparam\nOP_SYNC = 5’b00101;\n31 localparam\nOP_SYNC_ACK = 5’b00110;\n32 localparam\nOP_RESET = 5’b00111;\n9\nField\nWidth (bits)\nDescription\nTransaction ID\n16\nKey for the entry\nBalance State\n3\nAssociated balance state\nOperation\n5\nAssociated operation\nTimestamp\n32\nTimestamp of last activity\nData Pointer\n16\nPointer to data in payload memory\nData Length\n16\nLength of associated data\nTable 5: Transaction Memory Structure\n33\n34 //\nInternal\nregisters\n35 reg\n[31:0]\ntimeout_counter ;\n36 reg\ntimeout_occurred ;\n37\n38 // State\nmachine\nlogic\n39 always @(posedge\nclk or\nposedge\nreset) begin\n40\nif (reset) begin\n41\ncurrent_state\n<= STATE_INIT ;\n42\ntx_balance\n<= 3’b000;\n43\ntx_operation\n<= OP_NOP;\n44\ntx_transaction_id\n<= 16’ h0000;\n45\ntx_request\n<= 1’b0;\n46\ntimeout_counter\n<= 32’ h00000000;\n47\ntimeout_occurred\n<= 1’b0;\n48\nend\nelse\nbegin\n49\n//\nDefault\nvalues\n50\ntx_request\n<= 1’b0;\n51\n52\n//\nTimeout\ndetection\n53\nif ( timeout_counter\n> 0) begin\n54\ntimeout_counter\n<= timeout_counter\n- 1;\n55\nif ( timeout_counter\n== 1) begin\n56\ntimeout_occurred\n<= 1’b1;\n57\nend\n58\nend\n59\n60\n// State\ntransitions\nbased on\nreceived\nframes\nand\ntimeouts\n61\ncase ( current_state )\n62\nSTATE_INIT: begin\n63\nif ( frame_valid\n&&\nrx_operation\n==\nOP_SYNC) begin\n64\ncurrent_state\n<= STATE_PLUS_ZERO ;\n65\ntx_balance\n<= 3’b011; // +0\n66\ntx_operation\n<= OP_SYNC_ACK ;\n67\ntx_transaction_id\n<= rx_transaction_id ;\n68\ntx_request\n<= 1’b1;\n69\ntimeout_counter\n<= 32’ d100000; // Set\nappropriate\ntimeout\nvalue\n70\nend\n71\nend\n72\n73\nSTATE_PLUS_ZERO : begin\n74\nif ( frame_valid ) begin\n75\ncase ( rx_operation )\n10\n76\nOP_DATA: begin\n77\ncurrent_state\n<= STATE_PLUS_ONE ;\n78\ntx_balance\n<= 3’b100; // +1\n79\ntx_operation\n<= OP_ACK;\n80\ntx_transaction_id\n<= rx_transaction_id ;\n81\ntx_request\n<= 1’b1;\n82\nend\n83\nOP_REQ: begin\n84\ncurrent_state\n<= STATE_MINUS_ONE ;\n85\ntx_balance\n<= 3’b001; //\n-1\n86\ntx_operation\n<= OP_RSP;\n87\ntx_transaction_id\n<= rx_transaction_id ;\n88\ntx_request\n<= 1’b1;\n89\nend\n90\nOP_SYNC_ACK : begin\n91\ncurrent_state\n<= STATE_MINUS_ZERO ;\n92\ntx_balance\n<= 3’b010; //\n-0\n93\nend\n94\n// Handle\nother\noperations ...\n95\nendcase\n96\nend\nelse if ( timeout_occurred ) begin\n97\n// Handle\ntimeout\nin +0 state\n98\ntimeout_occurred\n<= 1’b0;\n99\ntx_operation\n<= OP_SYNC;\n100\ntx_transaction_id\n<= tx_transaction_id + 1;\n101\ntx_request\n<= 1’b1;\n102\ntimeout_counter\n<= 32’ d100000;\n103\nend\n104\nend\n105\n106\n//\nAdditional\nstates\nand\ntransitions ...\n107\n//\nSTATE_PLUS_ONE , STATE_MINUS_ONE , etc.\n108\n109\nendcase\n110\nend\n111 end\n112\n113 endmodule\nA.9\nTest Vectors\nThe following test vectors can be used to verify the implementation:\n1. Connection Establishment:\n• Node A sends SYNC with balance +0\n• Node B responds with SYNC ACK with balance −0\n• Expected outcome: Both nodes establish connection\n2. Basic Data Transfer:\n• Node A sends DATA with balance +1\n• Node B responds with ACK with balance +0\n11\n• Expected outcome: Data successfully transferred\n3. Data Request:\n• Node A sends REQ with balance −1\n• Node B responds with RSP with balance +0\n• Expected outcome: Requested data successfully received\n4. Error Recovery:\n• Node A sends DATA with balance +1\n• Frame is lost (not injected in test)\n• Timeout occurs at Node A\n• Node A sends SYNC with balance +0\n• Node B responds with state information\n• Node A resends missing data\n• Expected outcome: Error recovered with minimal retransmission\nA.10\nImplementation Guidelines\nWhen implementing the CQ protocol in an FPGA, consider the following:\n1. Use a pipelined architecture to achieve high throughput\n2. Implement the transaction memory as dual-port RAM for simultaneous\naccess\n3. Use a parameterized design to allow configuration of buffer sizes, timeout\nvalues, etc.\n4. Include comprehensive error detection and reporting mechanisms\n5. Add debug ports to monitor internal state transitions\n6. Implement the CRC calculation using parallel techniques for high perfor-\nmance\n7. Consider using a dedicated timeout counter for each active transaction\nA.11\nVerification Plan\nTo verify the implementation:\n1. Use simulation with the provided test vectors to verify basic functionality\n2. Test edge cases such as simultaneous transmissions and maximum-size\nframes\n12\n3. Measure performance metrics including latency, throughput, and resource\nutilization\n4. Conduct stress testing with high packet rates and induced errors\n5. Verify interoperability between multiple implementations\n13\n"
  },
  {
    "filename": "STANDALONE/Problem.pdf",
    "content": "What Problem Are we Solving?\nSahas Mulamala,Paul Borrill\nNeed Abstract\nOK, guys, this is the kind of material I think belongs on page 1.\nFrame the problem before discussing possible solutions.\nAs for the GPT critique of LF, I’m not quite following that line of\nreasoning, because it’s entirely possible to enforce strong consistency\nin a (closed) distributed system without paying attention to discrep-\nancies in physical time measurements across nodes. That’s exactly\nwhy, in the reactor model, we distinguish logical time from physical\ntime.\nMarten\nMarten,\nModern distributed systems—such as databases and microser-\nvices—require exactly-once, in-order delivery of messages to main-\ntain consistency, atomicity, and correct state synchronization.\n[GPT] Today, this is achieved through complex software workarounds\nlike retries, deduplication, idempotency, and durable logs, which in-\ntroduce latency, increase system complexity, and are still vulnerable\nto subtle failure modes. There is no network-layer primitive that pro-\nvides these guarantees directly, even in the presence of non-partition\nfailures and competing traffic.\nThe code we write as ’business logic’ is really just n layers of soft-\nware abstractions that allow a programmer to establish a client sin-\ngleton for each one of its dependencies and do things like\nevent = kafkaQueue.blockingGet()\nitems = dbClient.batchGet(event.items)\nif (isConsistent(items)) {\ntry {\nupdatedItems = updateItems(items)\ndbClient.transactUpdate(updatedItems)\nevent.markSuccess()\n} catch (DBException e) {\nevent.markFailure() // event ownership will be returned to kafka for retry.\nlog.error(\"huh?\", e)\n} catch (DBClientException e) {\nlog.critical(\"uhh, what? why?\")\n}\n} else {\nlog.critical(\"oh crap\")\n}\nwhat problem are we solving?\n2\nWhy is the database inconsistent? Bad code? Bad databases?\nDatabases are programs, so no matter what layer the error has come\nfrom, it came from software that couldn’t make its ’guarantees’.\nThese silent failures are present because it’s unreasonable to expect\nthat software can always make guarantees end-to-end.\n[GPT/Me] Lingua Franca attempts to reason deterministically\nabout distributed systems using logical time and timestamped mes-\nsages. However, they fall short in real-world deployment due to their\nreliance on a smooth, forward-in-time model of causality that ignores\nthe fundamental unpredictability of physical clocks, measurement\nnoise, and bidirectional network effects. Empirical evidence from\ndata centers shows timestamp anomalies (e.g., negative delays, drift,\nand clock skew) that violate assumptions required for logical time\nalignment, undermining the determinism and causality guarantees\nthese systems aim to provide.\n[GPT/Me] Positioned directly at the edge of packet ingress and\negress, SmartNICs are uniquely positioned for maintaining per-\nlink state, flow-control at line rate, and enforcing in-order delivery\nbefore packets ever reach host memory or software. By enabling\nlow-level handshakes—such as through Æthernet’s bipartite link\nprotocol—SmartNICs can track sequencing and state at wire speed,\nestablishing true physical-layer causality and eliminating the need\nfor software to reconstruct order and integrity after the fact. With\nlink-level atomicity and sequencing handled in hardware, software\nno longer needs to buffer, retry, or checkpoint to ensure message\nintegrity. This allows distributed protocols like Raft or Paxos to be\nradically simplified or even partially offloaded to the NIC, as deter-\nminism can be enforced at the moment of packet ingress rather than\napproximated later using timeouts, retries, or inference-based logic.\nThanks, Sahas\n"
  },
  {
    "filename": "STANDALONE/Day-in-the-life-bit-byte-packet.pdf",
    "content": "A Day in the Life of a Bit, a Byte, and a Packet\nJune 5, 2025\nUser prompt. “I’d like to do a deep dive into the waste of energy in L2\n+ L3 ++ protocols in datacenters. Please write an essay entitled A day in\nthe life of a bit, a byte, and a packet.”\nPrologue – The Stage Is Lit in Terawatts\nGlobal datacenter electricity demand is projected to approach ∼\n1 PWh yr−1 by 2030, and the networking stack is among the fastest\ngrowing loads.1 A single tier of fabric that once drew a few kW\n1 IEA “Data Centre Outlook 2024”.\nnow measures in tens; with a typical power usage effectiveness\nPUE = 1.56, facility overhead adds roughly fifty–six percent on top.\nAgainst that backdrop we follow three protagonists – Bit, Byte, and\nPacket – through one busy microsecond, counting every picojoule that\ndoes not carry payload.\nBit Is Born: the Serializer’s Maternity Ward\nBit’s first appearance is a voltage step on a 112 Gb/s PAM4 serializer.\n• Energy budget. A state–of–the–art switch ASIC such as Broadcom\nTomahawk 5 targets ≤10 pJ bit−1 at 100 Gb/s per lane.\n• Line–coding tax. 64b/66b PCS adds 3.125 %, and KP4 Reed–Solomon\nforward error correction adds another ∼5.7 %.\nBefore Bit even leaves the physical layer roughly nine percent of its\nlifetime energy has been spent on redundancy.\nMorning Commute: PHY →Switch →Optics\nHop\nDevice\nPower\nEnergy per bit\n1\nFabric ASIC (Tomahawk 5)\n0.9 W @ 100 Gb/s\n≤9 pJ\n2\nQSFP–DD DR4 optic\n12 W @ 400 Gb/s\n30 pJ\nTable 1: Illustrative energy cost per hop\non a 400 Gb/s path\nA typical cloud workload crosses about three–and–a–half switch\nhops leaf–to–spine, multiplying Bit’s commute toll. Even in the ab-\nsence of congestion, the electro–optical conversion in each pluggable\nmodule dominates at roughly 30 pJ bit−1.\nIdle Time at the Light–Rail Station\nWhen links fall quiet the serializer remains clocked. Energy–Efficient\nEthernet low–power idle is usually disabled in latency–sensitive\na day in the life of a bit, a byte, and a packet\n2\nfabrics, so “idle” does not mean “off”, and static power quietly\naccumulates.\nByte Clocks In: DRAM and Copies\nEight siblings later Bit forms Byte and is DMA–transferred to host\nmemory.\n• DDR5 at 4.8 GT/s consumes about 16 pJ bit−1, or 128 pJ per Byte.\n• A conventional Linux stack makes three copies (NIC ring →\nkernel →user), burning roughly one CPU cycle per bit. User–\nspace stacks such as laminar can cut core counts by an order of\nmagnitude, illustrating that software overhead can rival the wire\ncost.\nPacket Takes Shape: the NIC Framer\nWith a 1500 B MTU, Ethernet, VLAN, IP, TCP, and option headers\nconsume about six percent of the frame; at 200 B RPC size the header\nratio exceeds forty percent. Checksum engines, segmentation offload,\nand FEC decoding toggle additional logic — more joules are spent\nproving Packet is right than transporting its data.\nRush Hour: Fabric Hops and Buffers\nEach switch parses, stores, and forwards:\n• On–chip SRAM buffering costs roughly 9 pJ bit−1. A four–stage\nClos therefore stores the entire payload five times end–to–end.\n• Equal–cost multipath mis–hashing can reorder flows; the resulting\nretransmissions double the optical transit energy for affected bytes.\nArrival, ACK, and the Echo of Waste\nAt destination, Packet is copied once more into DRAM, parsed by\na remote stack, and — if reliable transport — triggers an ACK that\nwalks the entire path in reverse. One small RPC therefore doubles the\nSerDes and optic energy bill.\nAfter Hours: Cooling and Power Delivery\nEvery joule the networking stack burns drags an additional 0.56 J\nof facility power for fans, chillers, and UPS losses (PUE 1.56). Bit,\nByte, and Packet therefore bankroll the HVAC empire long after their\nuseful work is done.\na day in the life of a bit, a byte, and a packet\n3\nWhere to Save the Next Picojoule\n1. Fewer hops – collapse Clos stages with high–radix 51.2 T or\n102.4 T switches.\n2. Co–packaged optics – remove the ∼30 pJ bit−1 penalty of plug-\ngable modules.\n3. Zero–copy user stacks – reduce DRAM churn and interrupts.\n4. Protocol trimming – fuse transport and crypto (for example,\nQUIC) or adopt FITO–style L2 acknowledge loops.\n5. Topology–aware schedulers – keep traffic on rack to avoid unnec-\nessary optical conversions.\n6. Microsecond–scale idle states – gate SerDes quickly with Smart-\nNIC controllers.\nEpilogue\nDuring one busy microsecond Bit, Byte, and Packet each spend more\nenergy on redundancy, validation, and cooling than on delivering\nuser data. Shaving even a few picojoules per hop scales to terawatt–\nhour dividends across the planet’s datacenters. Networking may\nnever be free, but it need not be profligate; the next joule is ours to\nsave.\n"
  },
  {
    "filename": "STANDALONE/Broadcom-UEC.pdf",
    "content": "Ultra Ethernet Specification (v1.0 Draft)\nA Technical Review\nPaul Borrill – requested summary\nPrepared by ChatGPT (o3)\n30 April 2025\nUser question\nPlease do a thorough review of the Ultra Ethernet Specification and provide a\nreport for that with references to the literature, in tufte.\nExecutive overview\nUltra Ethernet Consortium (UEC) is producing an open, Ethernet-\nbased full-stack specification targeted at AI and HPC fabrics with\none million endpoints, terabit links and sub-microsecond tail latency.\nIts clean-slate Ultra Ethernet Transport (UET) replaces legacy RoCE,\nadds packet-spray multipath, flexible ordering, congestion-adaptive\nspraying and hardware collectives.8203;:contentReference[oaicite:0]index=0\nCompared with InfiniBand, UET keeps the broad Ethernet ecosystem\nwhile approaching supercomputer-interconnect performance.\nScope and objectives\n• Scale: up to 1 × 106 endpoints and 800 Gbps and 1600 Gbps\nlinks.8203;:contentReference[oaicite:1]index=1\n• Latency target: keep 99.9 % of collectives within one-digit µs.8203;:contentReference[oaicite:2]index=2\n• Profiles: AI Base, AI Full, and HPC; same wire protocol, differing\nverb sets.8203;:contentReference[oaicite:3]index=3\n• Layer coverage: Physical, Link, Transport, Software API, Security,\nTelemetry/Management.8203;:contentReference[oaicite:4]index=4\nArchitecture at a glance\nTransport layer – UET\n• Ephemeral connections: no handshake; state cached and re-\nclaimed per transaction (memory-efficient at scale).8203;:contentReference[oaicite:5]index=5\n• Packet spraying across all equal-cost paths with per-packet se-\nquence numbers; ordering enforced on message completion only.\nultra ethernet specification (v1.0 draft) a technical review\n2\n• Reliability uses selective retry plus optional packet trimming\n(header delivered, payload discarded) to signal incipient conges-\ntion without head-of-line blocking.8203;:contentReference[oaicite:6]index=6\nCongestion control\nTwo complementary schemes:\n(1) Sender-adaptive AI/MD window (~RTT-speed reaction, ECN-\ndriven).\n(2) Credit-grant receiver pacing for extreme incast.8203;:contentReference[oaicite:7]index=7\nLink layer\n• Link-Layer Retry (LLR) negotiated via extended LLDP; hop-by-\nhop NACK keeps BER-induced loss from bubbling up.8203;:contentReference[oaicite:8]index=8\n• Two traffic classes prevent deadlock and prioritise control traffic\neven on PFC-free fabrics.\nSoftware API\nBased on libfabric 2.0 with new verbs: Deferrable Send, optimistic\nrendezvous, expanded atomics and tagged collectives.8203;:contentReference[oaicite:9]index=9\nSecurity\nGroup-keyed AES-GCM; leverages IPSec/PSP primitives yet pre-\nserves ephemeral-connection model—important for accelerator of-\nfload.8203;:contentReference[oaicite:10]index=10\nIn-network collectives (INC)\nLightweight header extensions allow switches to execute reduce,\nbroadcast and all-reduce without CPU round-trips, standardising what\nwas previously vendor-proprietary.8203;:contentReference[oaicite:11]index=11\nKey innovations vs. legacy RDMA\nPerformance and scalability\nUEC’s internal simulations on Clos-4 fabrics show >95 % link utilisa-\ntion and <5 µs 99.9-percentile all-reduce latency on 4096-GPU clus-\nters at 800 Gbps.8203;:contentReference[oaicite:12]index=12 Early sil-\nicon demos (Q1 2025) from Broadcom’s BCM57608 NIC confirm wire-\nrate UET on existing PAM4 links.8203;:contentReference[oaicite:13]index=13\nultra ethernet specification (v1.0 draft) a technical review\n3\nFeature\nUltra Ethernet\nRoCEv2 / IB RC\nMultipath\nPacket-level spray\nFlow-hash ECMP\nOrdering\nFlexible, message-level\nStrict in-order\nLoss recovery\nSelective, trim-aware\nGo-back-N\nCongestion ctrl.\nAuto, zero-tune\nDCQCN (manual tune)\nConnection state\nEphemeral, pooled\nPer-peer, long-lived\nCollectives\nINC standard\nVendor proprietary / host\nSW\nSecurity\nBuilt-in AES-GCM\nExternal overlay\nTable 1: Ultra Ethernet vs. RoCEv2 /\nInfiniBand RC.\nEcosystem readiness\n• Membership: 90+ vendors incl. AMD, Arista, Broadcom, Cisco,\nGoogle, Meta, Microsoft, Intel.8203;:contentReference[oaicite:14]index=14\n• Reference code: open-source UET over commodity NICs, easing\nmigration from libfabric/RDMA apps.8203;:contentReference[oaicite:15]index=15\n• Timeline: v1.0 spec ratification Q3 2025; first commercial gear\nshipping same quarter.8203;:contentReference[oaicite:16]index=16\nGaps and open issues\n• Standardisation overlap with IEEE 802.1Q priorities, IETF congestion-\ncontrol drafts and emerging UALink fabric.\n• Inter-op testing required for packet trimming and INC header\nparsing across multiple switch ASIC generations.\n• Management model: YANG/Redfish bindings still draft.\nFITO analysis\nConventional Ethernet handles failure strictly forward-in-time: lost\npackets are re-sent, global ordering re-asserted after the fact. UET’s\nselective trimming preserves the causal header even under congestion;\nthe payload can be retro-materialised without rolling back link-layer\nstate—an incremental step toward reversible, idempotent communi-\ncation you favour in Open Atomic Ethernet research.\nConclusion\nUltra Ethernet modernises RDMA semantics for AI/HPC while pre-\nserving the economic and tooling advantages of Ethernet. If the\nconsortium delivers on its v1.0 schedule and multi-vendor inter-\noperability, UET could displace proprietary HPC fabrics and close\nthe performance gap with InfiniBand—especially when paired with\nBroadcom’s Scale-Out Ethernet implementation.\nultra ethernet specification (v1.0 draft) a technical review\n4\nReferences\nUltra Ethernet Consortium, UEC 1.0 Overview and Motivation, July 2023.\nUltra Ethernet Consortium, “Ultra Ethernet Specification Update,” Blog post, Aug\n2024.\nUltra Ethernet Consortium, Consortium Overview Presentation, Aug 2023.\nT. Hoefler et al., “Data-Center Ethernet and RDMA: Issues at Hyperscale,” IEEE Com-\nputer, July 2023.\nCloudSwit.ch, “In-depth Exploration of UEC,” Blog post, Oct 2024.\nJ. Metz, Ethernet Evolved: AI’s Future with UEC, SNIA CMS Summit, 2024.\n"
  },
  {
    "filename": "STANDALONE/Compass.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\næthernet: ultra low latency (ull)\n1\nCompass Point Routing - THIS APPEARS TO BE DUPLICATE\nWITH WHATS IN TOPOLOGY.TEX\nE\nW\nS\nN\nNW\nNE\nSE\nSW\nNNE\nENE\nESE\nSSE\nSSW\nWSW\nWNW\nNNW\nFigure 1: Compass Point Routing on\nvalency-8 nodes with total 16 TX/RX\nchannels on each port (direction)\nEvery Cell (IPI/SmartNIC) with 8 ports to discover its environment.\nEach of these 8 ports has 2 connections (transmit, receive). Al-\nthough the Chiplet Ethernet specification allows for initial config-\nuration and reconfiguration of these to be used for other purposes,\nand for dynamic reconfiguration. We specify scouting protocols as a\nprecursor discovery protocol, and underneath routing )dscribed later\nBecause any absolute cartesian naming scheme cannot scale, is\nbrittle (to errors and reconfigurations) we use a relative addressing\nscheme for the scouts (Ants, Bees), for each cell to independently\ndiscover its environment.\nScouts therefore use source routing, where the path explored is pre-\ndetermined. As in the case of Ants, these directions can be random.\nThey leave a pheromone trail so they can find their way back home.\nIn Æthernet clusters, Ants can have other kinds of exploratory behav-\niors, such always turning right or always turning left, to explore the\nneighborhood in a circular fashion.\nThese kind of mechanisms have already been explored in the\nliterature, and is known as deflection or bufferless routing.\nConnection with bufferless and deflection routing\nBelow is an overview of how biologically inspired “scouting” or “dis-\ncovery” mechanisms connect with key ideas in bufferless (hot-potato)\nrouting and deflection routing, especially in mesh-like topologies\nwhere routers have ports arranged along the cardinal (N, E, S, W)\nand intercardinal (NE, SE, SW, NW) directions. Although the termi-\nnology and details vary across papers, the essential themes can be\ntraced in both NoC (Network-on-Chip) and larger-scale interconnec-\ntion network literature.\n1. Biologically Inspired “Scouting” and “Routing”\nLocal decisions and emergent global organization\n• Scouting/Discovery Phase: Biologically inspired methods (e.g.,\nant-colony-inspired or pheromone-based algorithms) often employ\n“scout” packets or “explorer” agents that roam the network. These\nscouts collect local congestion or path-quality information and\ndeposit some form of “trail” (akin to pheromones).\n• Emergent Routing Table Updates: Each router or switch updates\nlocal routing information (sometimes called a local “pheromone\næthernet: ultra low latency (ull)\n2\ntable”). Over time, paths that prove consistently “good” get rein-\nforced; less efficient paths fade. This local, probabilistic approach\ncan converge on globally efficient routes with no central coordina-\ntion.\nRelevance to On-Chip or 2D Mesh Topologies\n• Local Compass Directions: In a regular mesh (e.g., 2D grid) or\ntorus, each router has up to 4 (N, E, S, W) or 8 ports (adding NW,\nNE, SW, SE). A biologically inspired algorithm can treat each\noutput port as a possible “direction of travel.”\n• Natural Fit for Scouting: The local directional structure matches\nhow “ants” or “foraging agents” might look around in each di-\nrection, choosing a route based on local pheromone levels (akin to\nlocal congestion or link utilization).\nThus, the scouting/discovery mechanism is all about gathering\nlocal “pathworthiness” data and then directing future traffic toward\nbetter routes—exactly how a local compass-based system can easily\nbe integrated.\n2. Bufferless (Hot-Potato) Routing\nBasics of Bufferless Routing\n• No Packet Buffers (or Very Limited Buffers): In a bufferless ar-\nchitecture, every router typically either immediately forwards or\ndeflects each incoming packet. Packets cannot wait in large queues\nwhen an output port is congested.\n• Hot-Potato / Deflection Character: When the preferred output\nport is unavailable, the packet is sent out of a different (less ideal)\nport—“hot-potato” style—rather than being buffered.\nConnection with Biologically Inspired Approaches\n• Continuous Movement: Biologically inspired scouts are already\ndesigned to wander and discover; in a bufferless system, “wander-\ning” (via deflections) is also central. This synergy means a router\ncan apply a heuristic (like a pheromone table) to pick the “best\navailable port” quickly, but if that port is busy, the packet must\nchoose an alternate direction.\n• Adaptive Reinforcement Over Time: In a bufferless design, a\npacket cannot linger while waiting for the optimal output. How-\never, local “pheromone” or “congestion” metrics can still help\næthernet: ultra low latency (ull)\n3\nroute the majority of packets down better ports more often. Over\ntime, high-traffic edges might become less appealing, guiding\npackets to less-congested directions.\n3. Deflection Routing\nHow Deflection Routing Works\n• Forced Misrouting / Deflection: If the desired or minimal-distance\noutput port cannot be taken (due to contention), the router picks\nanother output. The packet may travel away from its ultimate\ndestination (a “deflection”), but eventually, it should be re-routed\nback on track.\n• Common in Low- or No-Buffer Architectures: Deflection routing\nis one way to handle resource contention when buffer space is\nunavailable.\nTying It Back to the Compass Ports (N, E, S, W, NW, NE, SW, SE)\n• Local Prioritization: In an 8-port (or 4-port) router, one can define\na strict or heuristic priority among the directions. For example,\na packet traveling generally “north-east” might prefer the N or E\nport if free; if both are busy, it might deflect NE, or in the worst\ncase, deflect NW or SE.\n• Biologically Inspired Ranking: The “pheromone” concept can be\nused to rank the output directions. The highest “pheromone” port\nis tried first, then so on down the rank. This effectively merges a\nlocal heuristic (pheromone) with forced deflection for whichever\nports remain free.\nIn practice, such a scheme allows packets to “scout” and reinforce\ncertain directions while still ensuring that they never have to wait for\na blocked port.\n4. Example Flow in an 8-Port Router\n1. 1. Receive a Packet coming in from, say, the south port.\n2. 2. Look Up Destination (or partial coordinate heading). For in-\nstance, the packet is trying to reach a node in the north-east re-\ngion, so N or E might be favored.\n3. 3. Check Local “Pheromone” or Routing Table: Suppose the local\npheromone table says port NE is the best guess based on past\ntraffic patterns.\næthernet: ultra low latency (ull)\n4\n4. 4. If NE Port Is Free: Forward the packet NE.\n5. 5. If NE Port Is Busy: Check next best local direction (N, E, or\nNW/SE fallback).\n6. 6. If All Preferred Ports Are Busy: Packet is deflected to any open\nport (could be even SW in the worst case).\n7. 7. Local Table Update: The router sees how that choice ended\nup affecting the packet (if it eventually left the region quickly or\nended up in a congested area). Over time, these experiences feed\nback into local pheromone levels.\nDespite the forced misrouting (deflections), the biologically in-\nspired feedback approach often keeps net throughput healthy and\ntries to avoid systematic congestion “hot spots.”\nThese resources flesh out how bufferless or deflection routing\nis implemented (especially in on-chip contexts) and how biologi-\ncally inspired heuristics can be adapted to local, minimal-knowledge\nscouting decisions.\n6. Concluding Remarks\n• Shared Tenets: Both biologically inspired scouting and deflection-\nbased, bufferless routing rest on local decision making. In biologi-\ncally inspired schemes, scouting packets “discover” or “reinforce”\ncertain paths. In deflection routing, each router makes a quick (lo-\ncal) decision when a preferred port is blocked, forcing packets to\nkeep moving.\n• Complementary Mechanics: Because biologically inspired “pheromone”\nupdates naturally reflect congestion and path usage, they integrate\nwell with a bufferless or deflection style—turning forced misroutes\ninto valuable “exploration” signals that feed back into local heuris-\ntics.\n• Directional Routing: The presence of N, S, E, W (plus diagonals)\nsimply defines how many possible local moves each node (router)\ncan attempt. In 2D meshes or tori, these directions make for a\nconvenient coordinate system that parallels how ants (or other\nscouts) might sense local gradients or pheromone intensities in\neach of eight compass directions.\nOverall, if we combine a scouting mechanism (to adaptively find\nneighbors and good routes) with deflection routing (to handle buffer\nconstraints or high contention), we get a dynamic, emergent routing\nsystem in which packets flow continuously and local updates shape\nglobal traffic patterns in a self-organizing fashion.\næthernet: ultra low latency (ull)\n5\nAll this happens without the need for Source/Destination Ad-\ndresses, which present severe security problems by exposing the\n“identity\" of nodes making them vulnerable to attack.\n"
  },
  {
    "filename": "STANDALONE/Ternary3-dup-of2?.pdf",
    "content": "Perfect Information Feedback over Symmetric Ether-\nnet Shannon Channels\nChatGPT, Varun, Sahas, Paul Borrill\nDÆDÆLUS, Inc.\nMay 29, 2025\nMAC\n(L2)\nPCS\n64b/66b + Scrambler\nPMA\nAlignment & SerDes\nPMD\nPAM4 or Coherent\nTransmitter\nFiber/Medium\nReceiver\nPMD\nPAM4 or Coherent\nPMA\nDescrambler & SerDes\nPCS\nDecode 64b/66b\nMAC\n(L2)\nSender\nReceiver\nPHY (L1)\nSer\nFigure 1: Extended Ethernet PHY\nmodel with Shannon channel symmetry\nand echo feedback.\nEthernet PHY and Shannon Feedback Symmetry\nThis figure extends the symmetric Shannon channel with the full\nEthernet PHY stack. The path from MAC to PMD on the sender\nincludes standard components:\n• PCS: Encodes 64b/66b and scrambles bits for spectral shaping.\n• PMA: Serializes and adds alignment markers.\n• PMD: Drives physical line signals using PAM4 or coherent optical\nmodulation.\n• Transceiver: Converts between electrical and optical domains.\nThe mirrored stack on the receiver side undoes each transforma-\ntion, culminating in an echo of the original slice back to the sender.\nReversibility and Time Symmetry\nThe complete feedback of each 8-byte frame segment enables Perfect\nInformation Feedback (PIF). If the echo matches the original, the\nsender confirms delivery without relying on explicit FEC or EDC\ncodes. This system circumvents Conventional Forward-In-Time-Only\n(FITO) assumptions, leveraging time symmetry for reliability and\nreducing entropy leakage through interaction.\nOpen Questions\n• What bit error rate can be tolerated before echo comparison be-\ncomes unreliable?\n• Can echo timing be stabilized across variable latency links?\n• How do retry loops interact with coherent link training?\nReferences to Add\nEthernet Physical Coding sublayer PCS\nEthernet Physical Medium Dependent PMD\n"
  },
  {
    "filename": "STANDALONE/CLOS3.pdf",
    "content": "Wire-Accurate 3-Level Clos Fabric (200 Servers,\nTwo-Slice Uplinks)\nMay 23, 2025\nC0\nC1\nS0\nS1\nS2\nS3\nT_ 0\nT_ 1\nT_ 2\nT_ 3\nT_ 4\nT_ 5\nT_ 6\nT_ 7\nT_ 8\nT_ 9\nT_ 10\nT_ 11\nT_ 12\nT_ 13\nT_ 14\nT_ 15\nT_ 16\nT_ 17\nT_ 18\nT_ 19\nFigure 1: Exact cabling for a 3-level\nClos fabric serving 200 servers. Each\nserver has two redundant NIC ports\nto its rack’s ToR switch. Every ToR\nselects two distinct spines (“two slices”)\nfor uplinks, and every spine uplinks\nto both core switches. Spine-selection\nhere is a round-robin pattern (rack mod\n4, rack + 1 mod 4) to balance load.\nAll links are shown individually: 400\nserver ToR cables, 40 ToR spine cables,\nand 8 spine core cables.\n"
  },
  {
    "filename": "STANDALONE/Topology-Content 2.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\næthernet: ultra low latency (ull)\n1\nTOPOLOGY\nÆthernet expects no predefined topology. Every node (IPI Cell) has 8\nbidirectional ports that connects to neighbors.\nPaul Baran\nBaran Distributed – Valency 4\nFigure 1: Distributed (valency 4)\nBaran Distributed – Valency 8\nFigure 2: Distributed (valency 8)\nBaran Distributed\nBaran Chiplet\nFigure 3: Baran Chiplet\næthernet: ultra low latency (ull)\n2\nBaran Centralized\nFigure 4: Baran Centralized\nFull Baran Set\nBaran Distributed\nFigure 5: Baran Decentralized\nBaran Evolving\nFigure 6: Baran Evolving\nBaran PNP\nFigure 7: Baran Partial Network Parti-\ntioning\nReferences\n1\n1 Paul Baran \"On Distributed Communi-\næthernet: ultra low latency (ull)\n3\nRelative Addressing from Each Node\nfigures/Compass-Point-Rose.png\nFigure 8: Baran Centralized\n"
  },
  {
    "filename": "STANDALONE/OAE-Candidate-Requirements-May08.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\nOpen Atomic Ethernet\nCandidate Requirements\nMay-08 Workstream meeting\nCandidate requirements for links\n#\nCandidate Requirement / Decision\nStatus / Rationale\nAction / Owner\nTransport layer\n1\nUse Ethernet-mode UA-Link (SFP SerDes, 64b/66b).\nReuses Algo-Logic MAC at 10–\n800 Gb/s.\nCheck license position\n(Paul)\n2\nAvoid PCIe Gen-6 680-byte flit for low latency.\nLarge flit forces FEC, adds delay.\nMark as Should-Not.\n3\nFEC must be switchable off for lane ≤25 Gb/s.\nProven in Arista/Synopsys tests.\nAdd bit in link FSM.\nFraming and flow control\n4\nFixed slices, 64 bits default (32/128 optional).\n64 bit slice ⇒160 ns frame\n@10 Gb/s.\nLock spec at 64 b.\n5\nHeader occupies first two slices (context + liveness).\nRemoves preamble and MAC hdr.\nFPGA demo (Sahas).\n6\nACK/NACK on slice 1,2,4,8,... (Hadamard cadence).\nBandwidth vs robustness knob.\nSimulate congestion.\nAddressing and security\n7\nDestination address only; source is optional/debug.\nUA-Link 10-bit SRC is spoofable.\nProvide 48-bit MAC pro-\nfile.\n8\nNo dynamic routing inside OAE fabric.\nSimplifies spoof defense.\nAdd to threat model.\nOpenness / IP\n9\nEntire stack (API →bits) royalty-free.\nCharter item; UA-Link IP risk.\nDraft legal FAQ (Paul).\nHigher-level semantics\n10\nExpose atomic load/store in slice 2.\nNeeded for cache-less accel.\nAlign with CXL verbs.\n11\nLiveness uses 4-bit qubit emulation per link pair.\nGives implicit error detect (no\nCRC).\nFormal proof\n(Paul+Alan).\nOpen items / Risks\nR1\nClarify OAE name vs OCP OAI/OAM.\nR2\nDecide if 64 B frame is mandatory or if 4 kB beat is pro-\nfiled.\nR3\nGauge NVIDIA commitment (Bill Lynch note).\nQuick take-aways (for draft spec):\n1. Prefer Ethernet-mode UA-Link PHY for first silicon.\n2. Frame size 64 bytes; header lives in first two 64-bit slices.\n3. ACK period is tunable (every slice during bring-up, then 2/4/8).\n4. Security: discard or authenticate source addr, static routes only.\n5. Keep the full stack open and royalty-free; prepare coexistence\nstory with UA-Link consortium.\n"
  },
  {
    "filename": "STANDALONE/GPT-Essay-Reliable-Ethernet.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\nWhy Ethernet Needs to Be Reliable\nPaul Borrill\nApril 28, 2025\nQuestion\nWhy Ethernet needs to be reliable. Distinguish between imposition\nnetworks and promise networks (Promise Theory). Distinguish be-\ntween “useful packets that are acknowledged” and those that “over-\nload (a) the receiver (which drops them) and the network that drops\nthem)”. Go deeply into the problem of congestion, and how unre-\nliable networks are a major cause of our inability to solve the con-\ngestion problem, because they make the problem worse, not better.\nBring in unique perspectives on how unpaired information can only\nbe correlations, not reliable delivery.\nIntroduction\nEthernet’s spectacular success for fifty years rests on three pillars:\nubiquity, low cost, and best-effort simplicity. But the assumption\nthat “bit errors are rare and losses are somebody else’s problem”\nhas aged badly. Modern workloads—RDMA storage, NVMe-oF,\nmicro-transactions in high-frequency trading, chiplet fabrics with\nsub-microsecond deadlines—have turned “good enough” into “not\nnearly enough”.\nAn unreliable link can never solve\ncongestion; it can at best conceal it,\nand at worst amplify it.\nImposition vs. Promise Networks\nImposition networks\nAn imposition network forces state upon its peers. Classical Ethernet\nis such a system: a transmitter imposes frames on the medium and\npresumes they will be carried. If a switch, buffer, or receiver cannot\ncope, frames are silently discarded. The sender remains ignorant\nuntil a higher layer notices the loss.\nPromise networks\nA promise network inverts the relationship: each agent voluntarily\nadvertises what it will accept and under what constraints. Conges-\ntion feedback, explicit flow control, and lossless credit schemes make\nthe fabric a living contract. InfiniBand, Fibre Channel, and CAN\nare promise networks by design; PFC-enabled RoCE grafts promise\nsemantics onto Ethernet with mixed success.\nwhy ethernet needs to be reliable\n2\nUseful vs. Harmful Packets\n1. Paired / Acknowledged frames: every frame is matched by a\nhandshake or credit and carries information with commitment.\n2. Unpaired / Blind frames: sent speculatively or in excess of credit,\nthey eat capacity, fill buffers, and are eventually dropped, con-\ntributing only to congestion.\nCongestion: Why Unreliability Amplifies It\nPositive feedback loops\nClassic Ethernet plus TCP uses loss as its congestion signal, but the\nsignal arrives one–three RTTs late. A 100 Gb/s host can inject mil-\nlions of frames during that blind window:\nloss −→retransmit −→more traffic −→more loss.\nBufferbloat\nDeeper switch buffers merely store congestion instead of prevent-\ning it; queueing delay often dwarfs propagation delay, wrecking\ntail-latency guarantees.\nHead-of-line blocking\nDropped frames arrive out of order; completion time is dominated by\nrecovery, not transmission. A link-layer ACK/NAK guarantee keeps\ndelivery in order and prevents the stall.\nUnpaired Information Is Only Correlation\nA frame that never arrives does not increase mutual information; it\nleaves a correlation hole. Reliable Ethernet lets the link itself guaran-\ntee that every delivered frame is the one that was sent, exactly once.\nDesign Implications\n• Credit-based losslessness: lightweight link-local ACK/NAK or\ncredit return bounds outstanding data without InfiniBand com-\nplexity.\n• Actionable ECN: with no drops, an ECN mark is a clear promise\nthat congestion exists here and now.\nwhy ethernet needs to be reliable\n3\n• Deterministic latency: bounded jitter enables hardware-timestamped\ntransactions and reversible protocols.\n• Energy efficiency: eliminating retransmissions and deep buffering\ncuts joules per useful bit.\nConclusion\nCheap and cheerful won in 1973, but the economics have flipped:\nevery lost packet spawns expensive silicon, energy, and complexity\nat higher layers. Turning Ethernet from an imposition fabric into a\npromise fabric breaks the congestion feedback loop, converts blind\ncorrelations into committed information, and opens the next chapter\nfor the world’s most enduring network. Reliable Ethernet is no lux-\nury; it is the prerequisite for solving the congestion pathologies that\nthreaten Ethernet’s future.\n"
  },
  {
    "filename": "STANDALONE/Scouting.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\næthernet: (re)discovery, (re)initialization & scouting\n1\nChiplet Ethernet: Initial Discovery of What ∃xists\nCELLs and LINKs are fundamental elements. LINKs are bipartite causal\nrelationships connected over physical cables (backplanes, coax, fiber).\nFigure 1: A Link yet to be discovered,\nor a flakey link that need to be repaired\nCELLs discover connections ∃xist on each of their ports. For connec-\ntions that once existed (which may have been remembered from pre-\nviously being powered up), we will find it impossible to tell whether\nwe are being woken up for the 1st time, or the Nth time*.\n*Sleeping Beauty paradox: Veritasium:\nThe Most Controversial Problem in\nPhilosophy\nSingle Links are subject to partial or total failure. Although net-\nworks use the word ‘partition’, for example in the CAP Theorem1,\n1\nthis concept is inappropriate except in the single LINK case, when\nthere’s no communication with the other side; the causal universes**\n**Quantum Compatible Interpretation\nare now isolated from each other.\nIt takes Two to Tango, and Three to Party\nBecause a single link between Alice and Bob can be causally discon-\nnected by real-world, permanent or intermittent failures, an alterna-\ntive: statistically–independent–failure–path is necessary, to recover\nfrom LINK Failures. This is the heart of the Æ ATOMICITY claim: A\nlocal (one hop LINK) TRIANGLE is the minimum necessary. See TRI-\nANGLE Clocks later in this specification.\nFigure 2: It takes three to party. Links\nneed an alternate path. This won’t work\nover a Switched (Clos) Network.\nAlice Bob, and The role of Charlie\nFigure 3: 2 x 2 =4 connected nodes with\n6 flakey LINKs. Any one of which may\nbe working in both directions: {11},\nonly one direction: {01} or {10}, or\nnot-working in both directions: {11}.\nFor 4 nodes, there are (n(n−1)\n2\n= 6.\nWith 4 reliability configurations on each\nLINK {00, 01, 10, 11} This gives us ONE\ncorrect (all links working correctly) and\n46 −1 = 4095 possible failure modes.\nGraph Aware Determinism\nWhen treating the “Network” as an opaque cloud, it’s easy to un-\nderestimate how varied network partitions when link failures are\nasymmetrical: A can see B, but B can’t see A. In a 4 node setup, there\nare over 1295 potential partitions, and a flaky network can reproduce\nthem all. From a distributed systems (event ordering in a cluster) as\nan availability equation, we can easily overestimate how reliable they\nare, by 3 orders of magnitude.\nLink failures are invisible (hidden) in a Clos. They are 100% Visi-\nble to us in a local graph of triangular relationships.\nAnd that’s only the clean (binary) binary failures. Real system\nflakey connections are much worse.\nTransactions need a coordinator2\n2\nThe Æthernet protocol is designed to be exquisitely sensitive to\npacket loss and corruption We monitor, detect, diagnose link failures,\nand recover reversibly and automatically.\næthernet: (re)discovery, (re)initialization & scouting\n2\nFault Detection Model\nBenefits include (i) Shorter packets\nand more effective use of bandwidth,\n(ii) more complete coverage of possible\nfailure modes. (iii) Guarantees at least\nthe first slice is perfect (matches what\nthe transmitter knows they sent).\nAE-Links present two major differences to the conventional FEC\nthinking in today’s Ethernet, which exploits the physics from 25Gb/s\nto 1.6Tb and beyond:\nPerfect Information Transfer (PIF) Æ-Links use Back-to-Back (B2B)\nShannon Links, where the receiver returns the first 8-byte slice of\neach 64-Byte packet to the transmitter. This “here is what I heard\nyou say\" ( Perfect Information Transfer (PIF)3\n3\nEpistricted Registers (EPI) Borrowing from the Spekkens’ toy model\nfor quantum entanglement, we narrow down the possible entan-\ngled states to a vastly smaller set of possibilities, using the model\ndescribed in Quantum Ethernet4.\n4\nFailure Model\nConsider a network of n nodes connected by undirected Ethernet\nlinks. Each link can be in one of four independent reliability states,\nwhere 11 means the link works in both directions, 10 or 01 means\nΣ = {00, 01, 10, 11},\nit works in only one direction, and 00 means it is broken in both\ndirections.\nLink count\nBecause every node may attach to at most eight neighbours (an oc-\ntavalent mesh), the number of physical links is\nL(n) = min\n\b(n\n2), 4n\n\t =\n\n\n\n(n\n2),\nn ≤9,\n4n,\nn ≥9.\nReliability configurations\nEach link chooses a state from Σ independently, so the total number\nof configurations is 4 L(n). Exactly one of these is fully healthy (all\nlinks in state 11), hence\nFailureModes(n) = 4 L(n) −1.\nEnumerated results for 2 ≤n ≤20\nn\nL(n)\nFailure modes 4 L −1\n2\n1\n3\n3\n3\n63\n4\n6\n4 095\n5\n10\n1 048 575\n6\n15\n1.074 × 109\n7\n21\n4.398 × 1012\n8\n28\n7.206 × 1016\nTable 1: Failure-mode counts for an\noctavalent mesh with n nodes.\nReliable, Deterministic Atomicity (RDA)\nReliable, Deterministic, Atomicity (RDA) is achievable on an AE-\nAll or nothing multicast token transfer\nacross all observers.\nLINK, as long as the Shannon Slots are continuously reconciled on\nboth sides of the link by atomic token exchanges. However, a single\nlink can break. This is why a 3rd party in the triangle (Carol (causal\narbiter) or Charlie (causal coordinator) is necessary.\næthernet: (re)discovery, (re)initialization & scouting\n3\nProblem recap\nA fully connected network of n = 4 nodes has\nL =\n\u00124\n2\n\u0013\n= 6\nundirected Ethernet links.\nEach link independently assumes one of four reliability states\nΣ = { 00, 01, 10, 11 }.\nCorrect failure-mode count\nThe total number of distinct network configurations is\n4 L = 46 = 4096.\nExactly one configuration represents the perfectly healthy network\n(all links working in both directions) therefore the number of failure\nmodes is\n46 −1 = 4095.\nWhere the earlier 1295 came from\nThe earlier calculation reversed base and exponent, using 64 instead\nof 46:\n64 −1 = 1295,\nwhich under-counts the possibilities because it treats the links as the\nalphabet size and the state space as the exponent.\nThe Blast Radius of Link Failures in a 4-cell (4-node) system\nMethod\nExpression\nCount\nCorrect (stateslinks)\n46 −1\n4095\nEarlier mis-step (linksstates)\n64 −1\n1295\nTable 2: Failure-mode counts for a\n4-node (6-link) fully connected network.\næthernet: (re)discovery, (re)initialization & scouting\n4\nLINK initialization\nAlice and Bob have no knowledge of each other prior to being pow-\nered up for the first time. They discover each other by sending and\nresponding to BEACONs on each of their 8 ports {n, ne, de, se, ds, sw, dw, nw}.\nBEACONs are questions: “is anyone there?” They assume neighbor\nCELLs have SerDes’ that can send & receive @ 25Gb/s (defined by\nlocal clocks, in their frame of reference). Photon cavities (copper and\nfiber) are expected to be in a fixed frame of reference relative to the\nSELF CELL. Mobile entities may need to adjust this expectation based\non the range of doppler shifts expected by CELLs in motion, for exam-\nple, in moving vehicles, cars, planes, and spacecraft.\nAlice sends BEACONs with an exponential backoff: every 1µs, 2µs,\n4µs, 8 µs, etc. The policy for a maximum interval is determined by\nthe environment, e.g. within a datacenter, one might wish to send\nBEACONs every second, whether you need to or not. This represents a\nbalance between infrastructure liveness and needless energy dissipa-\ntion.\nShort-Range ANT (Local) Scouting\nOnce a link has been established, they are recorded in the local\nknowledge of the cell, and used as a baseline for future algorithmic\nand policy decisions.\nImmediately after establishing a reliable connection, CELLs may\nemit ANT-SCOUTS to explore their local environment. These are ANT’s,\nwhich obey an initial source routing algorithm, but when encounter-\ning a failed or disconnected port in another cell, respond with either\nclockwise, anticlockwse packet forwarding, which keeps the scout\nlocal, or random, with a hopcount limit, which allows exploration\nfurther afield.\nSee ANT Specification for details\nLong-Range BEE (Global) Scouting\nCELLs may also emit BEE-SCOUTS to explore the extremities of their\nenvironment. These are BEE’s which obey only one rule: proceed\nin the same direction as the radial port. BEE’s emitted on the n port\nmay only go n. BEEs emitted on the se port may only go se. Until\nthey encounter a disconnected port, whereupon they execute a return\npath algorithm, accumulating information at each CELL and returning\nit to the root.\nSee BEE specification for details\næthernet: (re)discovery, (re)initialization & scouting\n5\nANT Specification: Triangle Packet Clocks in 3 × 3 Tiles\nFigure 4: Race-Free Triangle Token\nPacket clocks are initiated by the coordinator, on any of it’s active\nlinks. The ANT (source routing) algorithm goes out on any port, and\nare programmed to turn left or right at the first available active port.\nThe convention is turning right makes it go clockwise, and turning\nleft makes it go antilockwise, but this is an artificial distinction. As\nwith real ants, they can get lost, and never find their way back to\nthe nest, and they die (or return to the nest by inverting their source\nrouting paths). This “limited range”, is part of the Security mecha-\nnism.\nANT Specification: Race-Free Packet Clocks in 3 × 3 Tiles\nFigure 5: Square Race-Free 1-hop Clock\nFigure 6: Race-Free Anticlockwise\nOnce the cell has discovered it’s local environment, it may establish\npacket clocks. These are ANTs, which go out with a pre-defined\npattern, to return events the cell on a periodic basis. Because there\nis no background of time, this system will create events, which are\nguaranteed to occur without race conditions, but will catastrophically\nfail if there are an broken links around the circuit.\nFigure 7: 2 Circulating Race-free tokens\nPackets clocks may be initiated around the closest (one-hop) cell\ntiles, next closest (two-hop) tiles, furthest (three-hop) tiles. Atomicity\nANT Specification Building a Compass Clock\n8 physical ports per cell. Inactive ports may be:\n• Failed (out of service)\n• Standby, ready to go\n• Off, saving energy\nANT Specification: Counter Circulating Race-Free ANTS\nC (Carol, Charlie, Coordinator, Chief) may initiate clockwise, counter-\nclockwise, and/or both at once. Each is exploring the health of the\nconnectivity local to the center cell. This is what ANT Algorithms\n(source routed, or random) tokens.\nPorts at edge of mesh connected back to same cell on a different\nport to traverse routing table 2nd time to create virtual cut-through\ntorus.\nIf the ANT gets blocked, and either runs out of hopcout resource,\nit does ‘reverse path forwarding’ back to the C CELL. and reports\nwhat it finds. It can either carry all its state in the packet, or (ror\nBEEs), clean up on its way and erase its footprints in the CELLs it\nvisited.\næthernet: (re)discovery, (re)initialization & scouting\n6\n7 x 7 Nodes Packet Clock\nFigure 8: Green Packet Rateless Clock\nBeyond Packet Clocks\nPacket clocks don’t scale (they are not intended to). Instead, they pro-\nvide circulating logical loops 5. The local system policy will establish\n5\nthe radius limit for local exploration. Everything beyond that is in the\ndomain of the BEE scouts .\nPacket clocks can circulate at any physical hop distance. The one-\nhop agents are described above. The two figures on the right show an\nexample of an ANT which goes two hops, or three hops, before the\nANT turns left or right. This give a CELL the opportunity to explore\nlarger hop distances from the coordinator\nPacket Clocks in Larger Tiles\nFigure 9: 3rd-hop circular packet clocks.\nBlue Links Complete\nBEE scouts\nBEE Scouts explore the boundaries of their environment. The are\nemitted by the Coordinator, and travel as far as they can in ONE\ndirection, {dn,ne,de, se, ds, sw, dw, nw}, and then return on\nthe reciprocal path (Compass-Point vector direction) to inform the hive\n(root) what they discovered, so the root can build it’s model of the\ntopology, and Edge resources to perform their function.\nN x N Nodes Packet Search Rays (BEEs)\nBEEs are radial distance scouting agents. Single packets that go in\nonly one direction, and when they reach the end (extremities of the\nCellular interconnect) they execute a reverse path forwarding algo-\nrithm, collecting knowledge on their way, delivering this knowledge\nback to the root, whose agent uses the returned information to build\nit’s model of it’s topology and available resources to offer ‘services’ to\nthe applications.\nThese don’t have to be square, or rectangular. BEE algorithms\nwork on any arbitrary Topology.\nFigure 10: BEE Algorithms explore\nbeyond ANT algorithms\nRadial (Ray) source-routed scouts have two parameters (a) which\nport they go out on, and continue indefinitely until they reach a\nboundary (or exhaust their hop count resource). And then they re-\nturn along exactly the same path, accumulating knowledge of the\nCELLS on their way (e.g. properties of the cell, do they have a CPU,\na GPU, an IPU, or QPU?). Most Bees make it back home to the nest\n(C) but it is also possible for a failure to occur between the outbound\nBEE and the homebound BEE. In which case the packet try’s to make\nit’s way to ‘Lost and Found’, the control structures identified by the\næthernet: (re)discovery, (re)initialization & scouting\n7\nCoordinator to provide GEV notification of failures. Lost and Found\nis most likely to be discovered by the one or more of the BEEs. Edge\nnodes (on the corners of the interconnect), will always be able to\n‘find’ Lost and Found (and other external control paths controlled by\nmonitoring or configuration LOGICAL Administrator Agentss ) with\na ‘due north or south’ dn,ds, ‘due-east or west’ de,dw BEE Scout.\nDistributed Systems\nSet Reconciliation of Shannon Slots\nThe first claim is that a finite and enumerable number of ‘slots’ ex-\nist on both sides of the LINK. In conventional Ethernet, once these\nslots are exhausted (with for example, a timeout and retry, the XPU\nCELLS (SmartNICs) on both sides of the LINK must evict (erase) the\ninformation on one side and then the other. This ‘loss of Koherence’\nis the central problem of Distributed Systems. From an information\ntheoretic (Back to Back Shannon channel) perspective, this precipi-\ntates a ‘smash and restart (SAR) of the Shannon Information – the\nloss of ‘pairing’ of information. This is described in more detail in the\nspecification of back-to-back Shannon Pairs.\nTimeouts and Retries are the root of all evil. Once a Timeout Storm\noccurs, in a switched network, the distributed systems in the Host\nprocessor are all broken. Unless RELIABILITY (maintenance of\nShannon Link Pairing), the ‘global’ illusion of event ordering in dis-\ntributed systems will be lost, and corruption will occur. This is why\nqueue-pairs work in Infiniband/RDMA. This is why information\npairing is essential, in Tandem’s Process Pairs, and RDMA’s Queue\npairs.\nThe whole point of this specification is to engineer a solution,\nwhere Shannon-pairing is never lost, but if it is, a TRIANGLE healing\noccurs locally, without the need to depend on a switched or router\nto discover and ‘reconverge’ their routing tables, to re-establish the\npoint to point connections over a different paths in the network.\nThe main mechanism to do this is to make the Æthernet Link\nmaintain Koherence, and when loss occurs, a 3rd party (The Triangle\nrelationship) can recover with local information only. This makes\nXPU/SmartNICs, where the recovery algorithms (healing the tree)\noccur locally, instead of waiting for the switched or routed packets\n(in a separate switched network.\nThe original Ethernet was unreliable. This was a mistake. Infini-\nband already proved this, and succeeded both in the trust system\narchicitcts have in the far greater. The unique contributions of this\nspecification is to go (far) beyond Infiniband’s discovery, and rec-\næthernet: (re)discovery, (re)initialization & scouting\n8\nognize the fundamental simplifications and benefits that Infiniband\n(and Token Ring, Fibrechannel, and Sonet), in creating ‘Race-Free’\nprotocols, where distributed systems can guarantee, not just the ‘or-\ndering of events’, but the guarantee of recovery of transactional loss\nin when failures occur in the middle of, say, a 2 Phase Commit.\nÆthernet (Atomic Ethernet) guarantees that Shannon Pairing is\nnever lost, and if a link breaks, that the Coordinator (Charlie, Carol,\nChief) can recover with TRIANGLE Relationships, far faster than\nany protocol stack in the host processor, or in the RMDA message\nrelationships, but then add, on top of this a true ‘atomic’ relationship\nbetween CELLS (nodes) in a distributed system.\nThe original Ethernet [ref] was designed around a notion of slots.\nThese were ‘time slots’ on an imaginary timeline that each node on\nthe Ethernet Cable, could manage in a half-Duplex way. The new\nnotion is to replace this with circulating tokens, where each slice is\nindependently acknowledged, providing a guarantee of delivery to\nthe NEXT hop in the network.\nThis is achieved with 1PC (one phase commit), where each Eth-\nernet Packet (eight slices) are fully acknowledged in each link. The\ngeneralization of this is to explicitly manage Shannon slots (data\nstructures on each side of the link) to maintain Koherence, even when\nthe link fails (in one direction, the other direction, or in both direc-\ntions at once).\nThis can be done (as in Fibrechannel) by arranging the ‘interaction\nprotocol’ to guarantee the pairing of events, and not resort to Time-\nout and Retry (TAR), which causes cascade failures in networks, both\nlarge and small.\nThis is achieved with the Link Protocol employing the Alternating\nBit protocol, and adding the Bill Lynch ABP reconciliation, with two\nor more bits instead of the individual 1 bit of alternation, which\nrequired a round trip to guarantee Shannon Slot Pairing.\nFAQ\nQ1 (Alan) What problem are you addressing in the scouting writeup?\nIf it’s discovering routes, it’s not clear to me that ant or bees or even\nboth together do full discovery of the network. In what way are they\nbetter than the flooding algorithm I used?\nA1 This is how to achieve ‘Scale-Independence’ We eliminate the\nneed for every node to do a ‘full discovery’ of the network, which is\nwhat a flooding algorithm would do. ANTs and BEEs explicitly do\nnot do “Global\" routing. This is an extra way to limit the size of the\nsecure enclave, and not have it able to connect to the outside world.\n"
  },
  {
    "filename": "STANDALONE/serpent.pdf",
    "content": "Ouroboros on the Wire: Circulating Causality for\nNetwork Engineers\nPaul Borrill & ChatGPT\n2 May 2025\nIntroduction\nWhen packets circulate endlessly on an Ethernet ring or bridging\nloop, we often call the situation a broadcast storm. In myth the ser-\npent that devours its own tail—the Ouroboros—symbolises a process\nwhose end becomes its own beginning. Roger Penrose gave physi-\ncists a rigorous vocabulary for such self–referential structures with\nhis work on causal diagrams and the possibility of closed timelike\ncurves (CTCs). By viewing an unmanaged Ethernet loop through\nPenrose’s causal lens, network engineers gain an intuitive and quanti-\ntative picture of “circulating causality.”\nPenrose introduced global causal\nordering tools now called Penrose\ndiagrams and showed that general\nrelativity admits solutions containing\nCTCs. See\n.\nOuroboros as an Engineering Metaphor\nTopology\nIn a classic ring topology every switch forwards frames to its next\nneighbour, forming a one–directional circuit . With no loop–prevention,\na single ARP request becomes the serpent’s head; by the time the\nframe returns to the ingress port its tail has become indistinguishable\nfrom a new cause. Switches forward it again, cargo-cult style, and\nbandwidth succumbs to recursive congestion.\nCausal Accounting\nPenrose taught that an event’s causal future is the set of events\nit can influence along lightlike or timelike paths. In Ethernet the\ncausal “speed limit” is the propagation velocity in copper or fi-\nbre, about v ≈0.6c. Suppose a 64-byte frame at 100 Gb/s occupies\nL_occ = 512 bit / 100 Gb/s ≈5.12 ns on the wire. During that time\nthe bits span roughly d = vL_occ ≈0.92 m. On a sub-metre chiplet\ninterconnect, the entire packet is resident in flight and in buffer si-\nmultaneously: effect literally overlays cause. The link becomes an\nephemeral closed causal loop.\nouroboros on the wire: circulating causality for network engineers\n2\nClosed Timelike Curves and Packet Loops\nGeneral relativity permits space-times in which a traveller’s world-line\nreturns to its own past—e.g. inside the Kerr ring singularity 1.Such\n1\na CTC violates global time orientation, yet local physics remains or-\ndinary. Similarly, each switch port along an Ethernet loop behaves\nlocally: it simply repeats the frame out other ports. Globally, how-\never, causal arrows circulate. The broadcast storm is the network\nequivalent of Gödel’s rotating universe—self-consistent yet globally\nparadoxical.\nIndefinite Causal Order\nRecent quantum-information work shows that processes need not\nrespect a single causal order at all; correlations can violate “causal\ninequalities” 2.Packets in a managed Ethernet protection ring (epsr for\n2\nexample)experience a conditional causal order: under normal condi-\ntions the ring is open (linear), but upon failure the control protocol\nflips links and the data path becomes cyclic for sub-50 ms until con-\nvergence.The network temporarily lives in a super-position of linear\nand cyclic causality, collapsing back when spanning-tree re-roots.\nEngineers thus wield “causal switches” long before quantum labora-\ntories did.\nPractical Takeaways\n1. Detect the tail early. Keep loop-prevention timers below the\nframe circulation time multiplied by ring length to avoid runaway\nstorms.\n2. Buffer maths →causal maths. On sub-metre copper, a 64-byte\nframe’s occupation length rivals the physical cable. Classical\nstore-and-forward assumptions break; treat the link as a dis-\ntributed latch.\n3. Exploit controlled loops. Token rings, FDDI, and modern Time-\nSensitive Networking (TSN) schedule transmissions so the Ouroboros\nis tamed, not slain; causality circulates by design to guarantee de-\nterminism.\n4. Think spacetime, not pipeline. Visualise network diagrams as\nPenrose causal diagrams: vertical lines are devices; diagonal lines\nare frames propagating at finite speed. A closed loop in the dia-\ngram is a configuration bug waiting to hatch.\nouroboros on the wire: circulating causality for network engineers\n3\nConclusion\nThe Ouroboros is more than a romantic symbol; it is a concrete\nmodel for feedback between cause and effect on high-speed links.\nBy translating Penrose’s language of closed timelike curves to the\nEthernet domain, network engineers gain a disciplined way to\nreason about packet storms, ring protection, and the subtleties of\nnanosecond-scale propagation. As data rates rise and cable lengths\nshrink into the sub-metre regime of chiplets and SmartNICs, “circu-\nlating causality” will move from myth to method.\nReferences\n[1] R. Penrose, “Gravitational Collapse and Space-Time Singulari-\nties,” Phys. Rev. Lett., 14:57–59, 1965.\n[2] Physics StackExchange, “Closed Timelike Curves in Kerr Space-\ntime Discussion,” post 189239, 2015.\n[3] O. Oreshkov, F. Costa, C. Brukner, “Quantum Correlations with\nNo Causal Order,” Nat. Commun., 3:1092, 2012.\n"
  },
  {
    "filename": "STANDALONE/MISC.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\næthernet: ultra low latency (ull)\n1\nMISC\nAppears to be mostly deleted stuff. needs checking.\nInteractions not flows\nULL in modern infrastructures means addressing the immediate\nchallenge in shortest possible latency.\nBandwidth is abundant. Latency is scarce.\n"
  },
  {
    "filename": "STANDALONE/MVCC-Infiniband.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\napplication layer approaches (mvcc)\n1\nÆthernet: Solving Problems with MVCC\nThis problem is related to the long-standing disagreements among\ndatabase experts on reliability/performance tradeoffs in Strict 2\nphase locking (S2PL) vs. MVCC. We discovered that making such\ntradeoffs in the host processor sensibly is impossible1, but it is trivial\n1 For the experts, there is a very deep\ndive here, which goes into restartable\nsequences in the Linux Kernel, which\nwe are happy to go into.\nto do in an FPGA-enabled SmartNIC – without any loss in perfor-\nmance or scalability.\n“MVCC is more complex than that: lightly loaded and no hot\nspots causing contention you won’t see problems. Systems that oper-\nate near line rates with potentially high contention on resources, like\ntrading systems, or communications infrastructure cannot use it, and\nfor that matter, cannot use standard database techniques at all.”\nFlash trading systems converge on a result around a single trade,\nsettling globally in 15 microseconds. Cores can do this in SRAM,\nusing graphs, tries (sic) and exotic in memory data structures.\nThat kind of works for one of a kind applications, but has no gen-\nerality, and cannot be repurposed to anything else. What Æthernet\ndoes can be generalized.”\nÆ-Link can be adapted into any interconnect. Ethernet is easy, but\nso is Infiniband, and we expect in the future, with CXL. For example:\nRDMA over InfiniBand, provides the following:\n• Moving data from one computer’s memory another’s, with high\nbandwidth and low latency\n• Delaying, rather than dropping, messages when congestion occurs.\nThis avoids:\n– Tail latency caused by timeouts and retries\n– Gray failures caused by cascading and overlapping timeouts\nand retries\nÆthernet provides all of these benefits, and we focus first on the\nreliability of transactions, and second on the performance. Since\nthese tradeoffs require different numbers of ‘interactions’ in the infor-\nmation exchange, we provide a set of operations the application can\nchoose from, which can be thought of as equivalent to 1PC, 2PC, 3PC\nand 4PC.\nA pure bandwidth argument can be misleading. For example, on\nindividual Links between nodes, our bandwidth is limited to a single\nlane SerDes (e.g. 25Gb/s), instead of four lanes ganged together\ntypical in Infiniband (e.g. 4 SerDes – giving 100Gb/s). However, the\ntotal bandwidth in a cluster is the same because we have (for the\nsame cost) 4 times as many links!\napplication layer approaches (mvcc)\n2\nSpecifically, our reliable, end-to-end bandwidth, on an otherwise\nidle network, is 1 SERDES of bandwidth. This is in contrast to Infini-\nBand’s 4 SERDES of bandwidth on many simultaneous connections,\nusing switches.\nBeyond the features of RDMA/InfiniBand, Æthernet also provides\nthe following.\n• Our machine-to-machine communication is interlocked, rather\nthan queued\n– In a few microseconds, link failure can be distinguished from\nfailure at the destination\n– Shared data is updated atomically, and consensus is reached\nquickly and deterministically\n• Our mesh network heals locally far faster than the \"temporal\nawareness\" of the App or protocol stack.\n– Small blast radius\n– Failed links are detected locally and < 10 nodes need to adjust\ntheir forwarding tables\n– Because the rerouting takes «1 microsecond, packets are held\ninstead of dropped\n* This is hugely different from Ethernet and TCP/IP today,\nwhere traffic through a failed link is dropped until the net-\nwork’s switches’ software agrees on and installs new routes\n– When failures occur, ambiguity about successful delivery of\npackets-in-flight is resolved by querying link states from nodes\nat both ends\n– Beyond our atomic updates of shared data, we provide applica-\ntions primitives that execute at hardware speed, FPGA-to-FPGA\n"
  },
  {
    "filename": "STANDALONE/Ternary2.pdf",
    "content": "Balanced Ternary Numbers, Reversible Computing,\nand Entropy in Ethernet\nChatGPT, Sahas Mulamala, Paul Borrill et. al.\nMay 30, 2025\nThis essay explores the convergence between quantum mechanics,\nbalanced ternary logic, and reversible computation, then extends\nthese ideas to Ethernet signaling and its physical encoding schemes\n(RTZ and NRZ). By incorporating Shannon information theory, we\nshow how different symbol systems and encoding techniques embody\ndistinct entropic properties, shaping energy use, reversibility, and\nreliability in digital communication.\nBalanced Ternary Arithmetic\nBalanced ternary uses digits {−1, 0, +1} in base-3 representation:\nn =\nN\n∑\nk=0\nak · 3k\nwhere ak ∈{−1, 0, +1}\nThis system is symmetric about zero and possesses unique advan-\ntages:\n• Minimal carry propagation.\n• Natural negation: NOT(x) = −x.\n• Suitability for reversible and quantum-friendly logic.\nQuantum Superposition and Qutrits\nA quantum bit (qubit) is a superposition:\n|ψ⟩= α|0⟩+ β|1⟩\nA qutrit generalizes this to three dimensions:\n|ψ⟩= α|−1⟩+ β|0⟩+ γ|+1⟩\nThe correspondence to balanced ternary logic is structural:\n• Three logical states map to three quantum basis states.\n• Phase-sensitive quantum operations (e.g., QFT) are more expres-\nsive with qutrits.\n• Higher information density per quantum unit.\nbalanced ternary numbers, reversible computing, and entropy in ethernet\n2\nReversible Computing\nProperty\nRTZ\nNRZ (NRTZ)\nBalanced Ternary Analog\nTemporal symmetry\nExplicit (zero-crossing)\nImplicit (voltage level)\n0-state acts as ground\nEnergy efficiency\nLow (frequent transitions)\nHigher\nTernary gates preserve entropy\nClock recovery\nEasy\nRequires auxiliary codes\nTernary phase codes possible\nReversible?\nNot inherently\nCloser to reversible\nYes, with ternary switching\nTable: Comparison of RTZ, NRZ, and Balanced Ternary signaling\ncharacteristics.\nLandauer’s principle states:\n∆E ≥kT ln 2\nper bit erased\nThus, **erasure increases entropy**. Reversible computing avoids\nthis by using bijective operations:\n• No information loss ⇒no entropy gain.\n• Balanced ternary logic allows for symmetric, invertible gates.\n• Entropy remains constant if all operations are logically reversible.\nPhysical Bits on the Ethernet Wire\nRTZ vs NRZ Encoding\nReturn-to-Zero (RTZ):\n• Bit interval includes a zero-crossing (reset to ground).\n• High temporal symmetry, easier clock recovery.\n• Energy inefficient due to frequent transitions.\nSIGNALING METHODS\nSignaling Method Transitions:\n• Non-Return-to-Zero (NRZ) used for 25Gb/s  \n per lane and below\n•  Four level Pulse-Amplitude Modulation   \n (PAM4) for 50Gb/s per lane\n•  Coherent signaling (both in-phase and   \n quadrature modulation) for 100Gb/s per lane  \n and above.\nNRZ\nPAM4\nCoherent\nFigure 1: Courtesy Ethernet Alliance\nNon-Return-to-Zero (NRZ):\n• Voltage level held constant through bit duration.\n• Fewer transitions = higher energy efficiency.\n• Harder to synchronize without auxiliary encodings.\nSignalling Methods\n• Non-Return-to-Zero (NRZ) used for 25Gb/s per lane and below\n• Four level Pulse-Amplitude Modulation (PAM4) for 50Gb/s per\nlane Coherent\n• Coherent signaling (both in-phase and quadrature modulation) for\n100Gb/s per lane and above.\nbalanced ternary numbers, reversible computing, and entropy in ethernet\n3\nEthernet and PAM\nModern Ethernet uses Pulse Amplitude Modulation (PAM):\n• PAM-4: 2 bits per symbol via 4 voltage levels.\n• Potential for PAM-3: 3-level signaling aligns with balanced ternary.\n• Bit-per-symbol efficiency increases with alphabet size, but so does\nnoise sensitivity.\nEthernet’s Physical Layers\nPCS\nFEC\nPMA\nPMD\nAN/LT\n \nFigure 2: Courtesy Lecroy\nEntropy and Information Capacity\nShannon Entropy\nShannon entropy quantifies the uncertainty (information content) of a\nsymbol source:\nH = −\nn\n∑\ni=1\npi log2 pi\nFor uniform distributions:\n• Binary (2 symbols): H = 1 bit.\n• Ternary (3 symbols): H = log2 3 ≈1.585 bits.\n• Quaternary (4 symbols): H = 2 bits.\nEnergy and Information Efficiency\nEach symbol sent over a wire has a cost:\nEnergy per bit ∝\nTransition energy\nInformation entropy per symbol\nBalanced ternary systems:\n• Maximize entropy per transition (especially with differential\nsignaling).\n• Reduce number of transitions due to symmetry.\n• Can represent more entropy per unit of physical signaling than\nbinary RTZ.\nnrz die–to–die i/o in 3 nm cmos:\nsummary of the april 2025 jssc article by marvell technology\n4\nNoise and Symbolic Distance\nEntropy must be traded off against reliability:\n• More symbols = smaller distance between voltage levels.\n• Balanced ternary may be optimal in analog domains like photonics\nor superconducting links.\nToward Entropic-Efficient Ethernet\nWe hypothesize a future class of Ethernet protocols:\n• Use balanced ternary or higher radix reversible codes.\n• Encode with symmetric, energy-neutral transitions.\n• Minimize entropy leakage across protocol layers.\nSuch protocols would reduce energy waste, improve error recovery,\nand better align with quantum-safe networking models.\nConclusion\nFrom the algebra of ternary digits to the behavior of qutrits and the\nphysical voltage levels on Ethernet wires, a common thread emerges:\nentropy. Entropy governs not only uncertainty and communication\ncapacity, but also the thermodynamic cost of erasure, reversibility,\nand state change. Balanced ternary logic, deeply connected to sym-\nmetry and conservation, may be the missing link between abstract\ncomputation and energy-efficient physical communication.\nReducing unnecessary energy dissipation in networks\nMost of the time, interconnects send nul patterns.\nCan the additional energy of speculative execution be recovered?\nThe Elimination of Unnecessary Cost and Complexity\nThere are no retimers, no redrivers, and no optical transceivers.\nNo SFPs, SFP-DDs, QSFPs, OSFPs, OSFP-XDs, or QSFP-DDs.\nREFERENCES (TBA)\nInformation versus physicality: on the nature of the wavefunctions\nof quantum mechanics\nQuoted from paper\n[letterpaper]tufte-handout\ngraphicx hyperref booktabs amsmath enumitem\nNRZ Die–to–Die I/O in 3 nm CMOS:\nSummary of the April 2025 JSSC Article by Marvell\nTechnology\nCompiled for internal review\nDraft compiled on May 30, 2025\nBackground\nIn the IEEE Journal of Solid–State Circuits (JSSC), April 2025, engineers\nat Marvell Technology reported a single–ended, non–return–to–\nzero (NRZ) die–to–die (D2D) input/output that uses 216 data lanes,\neach operating at 32 Gb/s. The test chip was fabricated in a 3 nm\nFinFET CMOS process and packaged with a 2.5D Chip–on–Wafer–\non–Substrate (CoWoS) interposer. The physical layer (PHY) achieves\n32 Gb/s per wire over a 2 mm channel while consuming 0.36 pJ/bit\non a 750 mV supply.\nKey Points from the Paper\n• NRZ versus SBD. NRZ offers higher signal–to–noise ratio (espe-\ncially against crosstalk) and aligns well with the inherently asym-\nmetrical traffic of memory systems. Simultaneous bi–directional\nsignalling (SBD) maximizes bandwidth for symmetrical traffic (for\nexample, Bunch of Wires – BoW), whereas NRZ is superior when\ntraffic is highly asymmetrical.\n• Wiring Density Limits. NRZ remains simple and efficient until\nthe wiring density approaches the limits imposed by ubump\npitch or interposer fabrication. Beyond that point, SBD combined\nwith forward error correction (FEC) can be adopted to increase\nbandwidth further.\n• Transmitter and Receiver Slices. Each transmitter slice (TXSLC)\ndrives one differential clock lane (TX_DQS) and eighteen single–\nended data lanes (TX_DQ). Up to eight TXSLCs share a phase–\nlocked loop (PLL) to amortize power. Each receiver slice (RXSLC)\naccepts one clock lane (RX_DQS) and eighteen data lanes (RX_DQ);\nthe recovered clock is buffered to all data lanes.\n• Segmented Source–Series Termination. The TX driver uses a\n32–branch segmented source–series–termination structure. A\nbranch–control code (digitally programmed) matches the output\nimpedance between 36 Ωand 50 Ωacross process, voltage, and\ntemperature (PVT) variations.\nnrz die–to–die i/o in 3 nm cmos:\nsummary of the april 2025 jssc article by marvell technology\n6\n• Test Chip Integration. Six PHY macros reside on the test chip.\nEach PHY contains one PLL, two TXSLCs, and two RXSLCs.\nUbump pitch is 40 um in the horizontal direction and 50 um in the\nvertical direction. The CoWoS interposer provides six redistribu-\ntion layers (RDL) at 2 um/2 um line/space rules. RDL1 serves as\nboth the escape layer for all signal ubumps and a power/ground\nplane; signal traces occupy RDL2–RDL5; RDL6 provides an addi-\ntional power/ground plane.\n• Bandwidth Density. The measured beachfront density is 3.84 Tb/s/mm.\nA custom two–PHY–deep floorplan could double this to 7.68 Tb/s/mm.\nComparative Observation\nAt 32 Gb/s per wire over 2 mm, the Marvell 3 nm NRZ PHY delivers\nhigher throughput and longer reach than recently announced alter-\nnatives such as NVIDIA NVLink (5 nm) chiplet links, providing a\ncompetitive edge for package–level interconnects.\nSelected References\n• Full article (open access):\nhttps://lnkd.in/gmbcKHgn\n• Marvell presentation on SBD for D2D:\nhttps://lnkd.in/gaPdQXVg\n• Related chiplet case studies:\nhttps://lnkd.in/dUAk5PkP\nhttps://lnkd.in/gzJeAQFV\nhttps://lnkd.in/gcEn9h_T\nGlossary\nBoW Bunch of Wires.\nCoWoS Chip–on–Wafer–on–Substrate.\nD2D Die–to–Die.\nFEC Forward Error Correction.\nNM Nanometer (technology node).\nNRZ Non–Return–to–Zero signalling.\nPHY Physical–layer macro.\nnrz die–to–die i/o in 3 nm cmos:\nsummary of the april 2025 jssc article by marvell technology\n7\nPLL Phase–Locked Loop.\nPVT Process, Voltage, Temperature.\nSBD Simultaneous Bi–Directional.\nTXSLC / RXSLC Transmitter / Receiver slice.\n"
  },
  {
    "filename": "STANDALONE/Banzai.pdf",
    "content": "Reversible Interaction-Based Pipelines in\nNetworking\nUser Question\nWhat is a Banzai pipeline in networking and how does it work?\nAnswer\nThe term Banzai pipeline in networking most commonly refers to a pro-\ngrammable, high-speed packet processing pipeline architecture introduced in\nStanford’s Domino project. It models how packet processing programs can\nbe compiled to run at line-rate in programmable hardware (like switches and\nSmartNICs).\nKey characteristics:\n• Packets flow through a sequence of fixed stages, each executing simple\nmatch-action logic.\n• Each processing element (called an atom) is tightly constrained to ensure\nthe pipeline meets timing.\n• Designed for feed-forward, high-throughput, low-latency environ-\nments.\nReferences:\n• X. Sivaraman et al., “Domino: Compiling Packet Programs to Line-Rate\nSwitches,” SIGCOMM 2016.\n• Atoms are used to express fundamental packet transformations that can\nbe composed.\n1\nUser Follow-Up\nAre all processing pipelines like this (flow oriented) or are there\nsome that are interaction oriented, for reliable packet transmission?\nAnswer\nMost packet-processing pipelines in hardware (e.g., Banzai, PISA, Tofino) are\nflow-oriented, not interaction-oriented. They assume:\n• Forward-only movement of packets.\n• Stateless or shallow state per flow.\n• No acknowledgment, rollback, or complex causality handling.\nInteraction-oriented processing arises at higher levels of the stack (TCP,\nRDMA, Raft), or in software, where it’s feasible to:\n• Wait for ACK/NACK.\n• Store transactional or causal history.\n• Roll back or retry on error.\nSummary Table:\nFeature\nFlow-Oriented (e.g. Banzai)\nInteraction-Oriented\nDirection\nOne-way\nBi-directional\nCausality\nFITO (forward-in-time-only)\nCausal, with feedback\nError Handling\nDiscard or ignore\nRetry, rollback\nState\nStateless or shallow\nStateful, durable\nPerformance\nHigh throughput\nLatency-bound\nExamples\nPISA, Banzai, NetFPGA\nTCP, RDMA, 2PC, Raft\nUser Prompt\nA proposal for a reversible interaction-based pipeline.\n2\nAnswer\nWe propose the Reversible Interaction-Based Pipeline (RIP) as a novel\narchitecture for future networking and transaction-safe computation.\nCore Ideas\n• Each pipeline stage is a reversible atom: a transformation with a defined\ninverse.\n• Packets carry interaction tokens including causal IDs and rollback\nmetadata.\n• Causal consistency is enforced using local DAGs at each stage.\n• NACKs trigger local rollback using stored state logs (limited depth).\nBenefits\n• Local fault tolerance without global coordination.\n• Foundations for in-network transactions and undoable updates.\n• Potential for energy-reduced operation via logical reversibility.\nVisual Diagram\nPacket In\nStage AChecksum\nStage BVerify\nStage CCompress\nPacket Out\nRollback on NACK\nFigure 1: Reversible Interaction-Based Packet Pipeline with Local Rollback\n3\nSimulated Example (Pseudocode)\nclass Packet:\ndef __init__(self, payload):\nself.payload = payload\nself.checksum = None\nself.interaction_token = []\nclass Stage:\ndef __init__(self, name, function, inverse):\nself.name = name\nself.f = function\nself.f_inv = inverse\nself.log = []\ndef process(self, pkt):\nstate_before = pkt.__dict__.copy()\npkt = self.f(pkt)\nself.log.append(state_before)\nreturn pkt\ndef rollback(self, pkt):\nif self.log:\npkt.__dict__ = self.log.pop()\nreturn pkt\n# Atoms: checksum, verify, compress\nDSL Sketch: Reversible Packet Language (RPL)\npipeline RIP_ChecksumPipeline {\nstage A {\nreversible atom Checksum {\ninput: payload;\noutput: checksum;\nforward: checksum := sum(payload) % 256;\nreverse: checksum := null;\n4\n}\n}\nstage B {\natom VerifyChecksum {\ninput: payload, checksum;\noutput: valid;\nlogic: assert checksum == sum(payload) % 256;\n}\non_failure {\nemit NACK;\nrollback(2);\n}\n}\nstage C {\nreversible atom Compress {\ninput: payload;\noutput: payload;\nforward: payload := compress(payload);\nreverse: payload := decompress(payload);\n}\n}\ncommit {\nsend(packet_out);\n}\n}\n5\n"
  },
  {
    "filename": "FAQ/2016-05-23-Notes.pdf",
    "content": "Summary Of Container Tools \nThis document provides a list of tools used by the container community. And their \npotential for use in Earth Computing Development.  This is a the beginning of a \n“Team training” manual / FAQ on existing solutions.  What we can use long-term, \nwhat we can use for now, what we need to replace.\nProblem:  \nHypercontainers (Unikernels) need a toolchain and various other goodies for customers to be able to \nuse it.   Secure Microvisors need a “Friendly Development Kit (FDK)”; this doesn’t yet exist. \nSolution:\nUse available open-source tools. Here is a list for evaluation with some preliminary recommendations. \nThe new Docker tools for hypervisors on the Mac may well be an ideal tool.\nOpenSource Tools Summary\nTool\nContainer Tools\nSponsor/ \nName\nDescription\nBeneﬁts to Earth Computing\nCoreOS/\netcd\netcd is a distributed, consistent key-value store for \nshared conﬁguration and service discovery, with a focus \non being simple, secure (SSL), Fast and reliable).\netcd is written in Go and uses the Raft consensus \nalgorithm to manage a highly-available replicated log.\netcd does discovery, master election, registration of \nservices and coordination of processes across a cluster. \nAll functions were we need to persist (e.g. conﬁguration) \nstate on behalf of otherwise ephemeral containers\nAn example of a function we could \nimplement as a secure microservice \nhosted in our subvirtualization platform.\nGoogle uses Chubby for dealing with \ntheir fault-tolerance and Yahoo created \nzookeeper. (not recommended for \nvirtual environments). They provide \ndistributed conﬁguration and distributed \nlocking in a similar way to raft/etcd.\nCoreOS/\nFleet\nDistributed init for Clusters. With ﬂeet, you can treat a \nCoreOS cluster as if it shared a single init system. It \nencourages users to write applications as small, \nephemeral units that can easily migrate around a cluster \nof self-updating CoreOS machines.\nWe could use this to manage smaller \nclusters. It provides some of the easy \npieces that Mesos does, but without the \ncomplexity of managing a separate \nMesos Server and agents. Ultimately, \nwe will replace this GEV scheduling \nmechanism with an LOV mechanism \nbased on Graph Virtual Machine (GVM)\nConﬁdential:Earth Computing.  V0.1.                                V0.1   23-May-2016\nPage !  of !\n1\n4\nCoreOS/\nﬂannel\nﬂannel is a virtual (overlay) network that gives a subnet \nto each host for use with container runtimes.\nPlatforms like Google's Kubernetes assume that each \ncontainer (pod) has a unique, routable IP inside the \ncluster. The advantage of this model is that it reduces the \ncomplexity of doing port mapping.\nﬂannel uses etcd to store the network conﬁguration, \nallocated subnets, and auxiliary data (such as host's IP).\nBy default, ﬂannel runs without a central controller, \nutilizing etcd for coordination. However, it can also be \nconﬁgured to run in client/server mode, where a special \ninstance of the ﬂannel daemon (the server) is the only \none that communicates with etcd\nThis is a classic attempt to simplify \nnetworking with conventional L2/L3 \nprotocols.\nIf ﬂannel proves to be robust enough, \nwe could implement a hardened \nversion as a secure microservice in our \nsubvirtualization platform.\nHowever, entire mechanism needs to \nbe replaced with our own self-\nconﬁguring container naming, \naddressing and routing system based \non GVM.\nCoreOS/\nrkt\nrkt is a new container runtime, designed for \ncomposability, security, and speed.  It is a simpler \nalternative to docker. The rationale for rkt is very \ninteresting read, and a perfect example of an industry \nneeding something simple, which is what docker started \nout becoming, but then turned into a big monolithic \nbinary.\nrkt is a useful container runtime, which \nwe should consider as an alternative to \ndocker in our development (because it \nis simpler and easier to manage).  \nHowever, it is essential that we also \nfully support docker in our initial product \nand roadmap because of the ubiquity it \nhas achieved in the container world.\nDocker/\nrunC\n“Containers” are actually an array of complicated, \nsometimes arcane system features, Docker has \nintegrated them into a uniﬁed low-level component which \nthey call runC\nDocker is a platform to build, ship and run distributed \napplications. For this to be possible, it needs a \nsandboxing environment capable of abstracting the \nspeciﬁcs of the underlying host (for portability), without \nrequiring a complete rewrite of the application (for \nubiquity), and without introducing excessive performance \noverhead (for scale).\nWe provide the secure foundation \nunder containers. We subsume Docker \ncontainers in our Hypercontainer \nsystem.\nLike all Hypervisors, Docker containers \nare what we will be compared against \nthe most. (e.g. answer the question - \nwhy do we exist?).\nDocker/\nEngine\nThis is the main docker engine. Download from Docker \nHub (the central hub for docker that hosts docker images \nand provides services).\nNot directly. We need a way to manage \nHypercontainers. Docker containers \nlive inside hypercontainers.\nDocker/\nHyperkit\nDocker native development environment for Mac and \nWindows. New components are: HyperKit: A lightweight \nvirtualization toolkit on OSX. DataKit: A modern pipeline \nframework for distributed components. VPNKit: A library \ntoolkit for embedding virtual networking.\nEach of these kits can be used independently or together \nto form a complete product such as Docker for Mac or \nWindows.\nVery smooth experience using the OSX \nHypervisor Framework to provide \nnative VM’s on a Mac (instead of \nhaving to use VirtualBox or VMWare).\nTool\nContainer Tools\nSponsor/ \nName\nDescription\nBeneﬁts to Earth Computing\nConﬁdential:Earth Computing.                                V0.1   23-Aug-2015\nPage !  of !\n2\n4\nDocker/\nRegistry\nA stateless, highly scalable server side application that \nstores and lets you distribute Docker images. \n[DTR (Docker Trusted Registry) appears on the surface \nto be what we call hypercontainers—we will have to \nshow how we are different and better or how we \ncomplement DTR]\nDTR is mostly about secure delivery of \ncontainers along with some \nmanagement functions. The \nhypercontainer concept is much larger \nin that it also encompasses policy \nenforcement and naming in a larger \nmicroservices context.\nWe should not attempt to develop this \nourselves. We may be able to modify \nthe appc  container spec so we can use \nexisting registries such as this (which \nclaims to be secure), or an equivalent \nfrom CoreOS.\nDocker/\nKitematic\nKitematic’s one click install gets Docker running on your \nMac and lets you control your app containers from a \ngraphical user interface (GUI). Good for beginners.\nThis could be the basis of a Earth \nComputing Development Environment, \nor at least a viable demo tool.\nWe should evaluate it for our purposes.\nDocker/\nMachine\nMachine lets you create Docker hosts on your computer, \non cloud providers, and inside your own data center. It \ncreates servers, installs Docker on them, then conﬁgures \nthe Docker client to talk to them Starts, stops, restarts \nand upgrades docker.\nThis could be the basis for an initial \nEarth Computing Toolchain.\nDocker/ \nSwarm\nDocker Swarm is native clustering for Docker. It allows \nyou create and access to a pool of Docker hosts using \nthe full suite of Docker tools. Because Docker Swarm \nserves the standard Docker API, any tool that already \ncommunicates with a Docker daemon can use Swarm to \ntransparently scale to multiple hosts. Supported tools \ninclude, Dokku, Docker Compose (next), Krane, Jenkins\nThis is a crude (centralized) service \ndiscovery and rendezvous.  Earth \nComputing could use it. Needs testing.\nOpportunity for innovation - a \nbreakthrough in service discovery is \nneeded. Conventional network \nprotocols will not solve this problem.\nDocker/\nCompose\nCompose is a tool for deﬁning and running multi-\ncontainer applications with Docker. With Compose, you \ndeﬁne a multi-container application in a single ﬁle, then \nspin your application up in a single command which does \neverything that needs to be done to get it running.\nCompose is great for development environments, \nstaging servers, and CI. We don’t recommend that you \nuse it in production yet.\nThis is potentially part of the new tool \nchain.\nWe will need something similar, may \neven be able to extend this code. \nTool\nContainer Tools\nSponsor/ \nName\nDescription\nBeneﬁts to Earth Computing\nConﬁdential:Earth Computing.  V0.1.                                V0.1   23-May-2016\nPage !  of !\n3\n4\nDocker/\nNetworking\nThere are many networking solutions available to suit a \nbroad range of use-cases. libnetwork uses a driver / \nplugin model to support all of these solutions while \nabstracting the complexity of the driver implementations \nby exposing a simple and consistent Network Model to \nusers.\nLibnetwork provides a native Go implementation for \nconnecting containers. The goal is to deliver a robust \nContainer Network Model that provides a consistent \nprogramming interface and the required network \nabstractions for applications.\nNOTE: libnetwork project is under heavy development \nand is not ready for general use.\nThis is where our NAL (physical, \nlogical, virtual fabric) compares the \nmost. Need competitive comparison to \nshow why we are different.\nOne possibility is to take this code  \n(libnetwork - when it is ready) and \nmodify it for secure implementation as \nan NFV function (hyper-microservice) in \nLogical Metal.\n \nThe folks at Calico don’t have much \nfaith in this codebase. It is generally \nalso loathed by the Kubernetes guys. \nSee this video for explanation.\nCalico\nA pure layer 3 approach for Virtual Networking in \nDatacenters.  This is not likely to be useful in our NAL \nprotocols, however, every Earth Computing “edge cell” \ncould include Calico to interface to the outside world\nA way for us to subsume legacy L3 \nnetworking in the future.\nVagrant\nCreate and conﬁgure lightweight, reproducible, and \nportable development environments. Use to manage \nvirtual machine environments. \nI used this at Apple to create code that \ncan be moved from a VM on my laptop \nto a server.  See this article by quota for \nthe distinctions with docker.\nSysdig\nSysdig is open source, system-level exploration: capture \nsystem state and activity from a running Linux instance, \nthen save, ﬁlter and analyze. Sysdig is scriptable in Lua \nand includes a command line interface and a powerful \ninteractive UI, csysdig, that runs in your terminal. Think \nof sysdig as strace + tcpdump + htop + iftop + lsof + \nawesome sauce. With state of the art container visibility \non top.\nWe know the CEO of Sysdig \npersonally. He was the original \nengineer who wrote Wireshark.\nAn excellent container instrumentation \ntoolkit. Possibly useful for our simulator \nenvironment, allowing us to use his \ntools to debug the network protocols.\nRUST\nRust is a systems programming language that runs \nblazingly fast, prevents segfaults, and guarantees thread \nsafety.  Potential Programming language for the Earth \nComputing DAL (incorporates the ownership & borrowing \nfeatures that map directly into the Distributed MOESI \nCoherency model we use in our protocols.)\nWill tie in nicely to using the AIT \nprimitive in the network protocol. This \nwould be an awesome demo for going \ninto our Series A ﬁnancing.\nGO\nA potential programming environment for our protocols in \nthe NAL.\nVery popular.  Many of the CoreOS \ntools are written in Go, particularly etcd.\niTerm\nTerminal Replacement for OSX.  A lot better than the \nstandard terminal supplied by Apple. Should be useful for \nlogging into multiple machines at the same time to \nprovide a GEV console view (or repeated command \nmanagement tool on all machines).  \nWorks on the 5th Port?\nWe can conﬁgure this to have different \ncolor tiled windows across the screen \nas an initial scaffold to develop our \nsystem. The different colors would \ncorrespond to the different layers in \nEarth Computing: NAL (Network Asset \nLayer), DAL (Data Asset Layer), CAL \n(Computation Asset Layer).\nPlease add other Tools you think might be relevant.\nTool\nContainer Tools\nSponsor/ \nName\nDescription\nBeneﬁts to Earth Computing\nConﬁdential:Earth Computing.                                V0.1   23-Aug-2015\nPage !  of !\n4\n4\n"
  },
  {
    "filename": "FAQ/@CMF Cloudplane Mathematical Foundation.pdf",
    "content": "Cloudplane: A Mathematical Foundation (CMF)\nPaul L. Borrill\nDRAFT Printed: November 22, 2010\nConﬁdential: REPLICUS Software: Under NDA\nAbstract\nCloudplane is a carefully chosen mathematical framework with which to reason about and understand\nwhat distributed systems can do with information. The Cloudplane Description Language (CDL) provides\na set of primitives and operators, which, within this framework, enable a designer to exert declarative\ncontrol over what they want systems to do with their information while enabling the autonomic processes\nin the underlying infrastructure to maintain guarantees of safety, liveness, consistency, and autopoietic\nperdurance (a stronger notion of data survivability than typically used in storage systems).\nThis material is provided as a courtesy to Peter Corbett and Steven Kleiman at NetApp, and must\nnot be distributed further. It describes work that is severely incomplete and in rapid evolution and\nalmost certainly includes errors, omissions, and some things that might just be darn wrong. This is the\nmain reason why we ask you not to distribute this document. You would do a disservice to its author(sS\nand prospective readers if you did so. If there are others you would like to distribute this document, or\nyou wish to request the latest version of this document, please contact paul@replicus.com.\n1\nDocument:\nCloudplane Mathematical\nFramework\nVersion:\n0.6\nAuthor(s):\nPaul L. Borrill\nReviewer(s):\nApproved:\nBaseline:\nDRAFT – No Baseline\nDate:\nNovember 12, 2010\nContents\n1\nIntroduction\n3\n1.1\nMathematical Logic\n. . . . . . . . . .\n3\n1.2\nNotation . . . . . . . . . . . . . . . . .\n3\n2\nBackground Principles\n4\n2.1\n¬ Continuum . . . . . . . . . . . . . .\n4\n2.2\n¬ God’s-Eye-View\n. . . . . . . . . . .\n4\n2.3\nPrinciple of Suﬃcient Reason . . . . .\n5\n3\nEngineering Principles\n5\n4\nGraph Theory\n6\n4.1\nTrees . . . . . . . . . . . . . . . . . . .\n6\n5\nObjects and Monads\n6\n5.1\nMonadology . . . . . . . . . . . . . . .\n7\n5.2\nIndividuality and Identity . . . . . . .\n7\n6\nInformation Theory\n8\n6.1\nSystem Information\n. . . . . . . . . .\n9\n6.2\nAlgorithmic Information Theory\n. . .\n9\n6.3\nSubstitutable Entities\n. . . . . . . . .\n9\n7\nFoundational Calculi\n10\n7.1\nLambda (λ) Calculus . . . . . . . . . .\n10\n7.2\nPi (π) Calculus . . . . . . . . . . . . .\n10\n7.3\nPetri Nets . . . . . . . . . . . . . . . .\n11\n7.4\nActor Model . . . . . . . . . . . . . . .\n11\n7.5\nOrdering Model . . . . . . . . . . . . .\n12\n7.6\nAsynchrony: bags | queues | stacks . .\n12\n8\nBisimulation\n13\n9\nMeasures of Complexity\n14\n10 Mathematical Inﬂuences\n16\n10.1 Tensor Calculus . . . . . . . . . . . . .\n16\n10.2 Sheaf Theory . . . . . . . . . . . . . .\n16\n10.3 Category Theory . . . . . . . . . . . .\n16\n10.4 Storage Systems\n. . . . . . . . . . . .\n17\n10.5 Information Dispersal\n. . . . . . . . .\n17\n11 Cloudplane as Mathematics\n17\n12 The Ontology of Time\n18\n12.1 Temporal Description Logics\n. . . . .\n18\n12.2 Mathematics and Language . . . . . .\n19\n13 Heterarchy\n19\n14 Management by Sets\n19\n14.1 Agent Based Modeling Infrastructures\n19\n14.2 Observables and Interactions\n. . . . .\n21\n14.3 Background Independence . . . . . . .\n21\n15 Conclusions\n21\nConﬁdential: REPLICUS Software. Under NDA. CMF. DRAFT November 22, 2010\nPage 2 of 25\n1\nIntroduction\nGod made the integers;\nall else is the work of man.\nLeopold Kronecker (1823-1891)\nCloudplane is a mathematical structure; by which we\nmean: a system deﬁned by a formal language, with\nwhich we can reason about what our systems can do\nwith our data under autonomic control, and what\nour systems should do with our data under declar-\native control. Cloudplane eschews direct control of\ndata with disparate mechanisms such as mirroring,\ncaching, replication, backup, archive, de-duplication,\netc., because this makes systems brittle (susceptible\nto arbitrary failures outside the narrow domain of\ndiscourse for these control-based mechanisms).\nPrevious system architectures have failed to\nachieve their autonomic goals[1]; previous declara-\ntive approaches have similarly failed to achieve their\nobjectives[2]. One (necessary and suﬃcient) reason\nfor these failures, is the lack of appreciation of the\nscope of scalability of state information as a system\ngrows. This, in turn, is due (primarily) to a failure\nto recognize the conceptual distinction between GEV\n(God’s-Eye-View), and LOV (Local-Observer-View)\nalgorithms and data structures1.\n1.1\nMathematical Logic\nCloudplane and its description language (CDL) is\nbased on ﬁrst order (predicate) logic, which assumes\nthe world consists of objects, relations and functions;\nand modal logic, which extends ﬁrst-order logic with\npredicates and modal quantiﬁers (necessity □or ∀,\nand possibility ♦or ∃).\nAlthough not used here\ndirectly, second-order logic extends ﬁrst-order logic\nfrom well-formed-formulas (atomic sentences) to sets.\nSecond-order logic is extended by higher order logics.\nPredicates are a key feature distinguishing ﬁrst\norder logic from propositional logic. They are used\nextensively to describe a desired action by the Cloud-\nplane infrastructure, as opposed to imperative control\n(a speciﬁc algorithm on how to do it). Cloudplane\nallows the declaration of attempts (propositions that\nmay be undecidable) or promises (assignments ac-\ncepted under the understanding of best eﬀort by the\nunderlying Cloudplane infrastructure).\nCloudplane extends these logic’s with a serializa-\ntion foci:\nsingle ⊙and shared ⊡, a strictly local\nnotion, where the focus of serialization (partial or-\nder serialization for objects in that MetaData Ten-\nsor (MDT) is being considered), even though we (as\nhuman designers) may be attempting to view things\nfrom the seductive comfort of our GEV perspective.\n1.2\nNotation\nWe follow Goldblatt’s symbology[3] for connectives:\n∧conjunction (AND), ∨disjunction, (OR), ¬ nega-\ntion (NOT), →(material) implication, and ↔(ma-\nterial) equivalence. ⊤is a constant true (tautology);\n⊥is constant false, equivalent to ¬⊤. ⊤and ⊥are\nalso used as symbols for truth values.\nThe standard syntax for propositional modal logic\nis based on a countably inﬁnite list p0, p1, ... of propo-\nsitional variables, for which we use the lower-case let-\nters p, q, r. Predicates (formulas) are generated from\nthese variables by means of the above connectives and\nthe upper-case symbols P and Q.\n□n stands for a sequence □□. . . □of n copies of\n□, and likewise ♦n for ♦♦. . . ♦(n times). We use\nthis symbology to specify both multiple cells Cpath\ni\nand multiple replicas Rpath\ni\nin a graph G = (V, E) of\nthese entities.\nThe symbols +, ·, −denote sum (join), product\n(meet), and complement in a Boolean algebra; 0 and\n1 are the greatest and least elements under the or-\ndering ≤given by x ≤y iﬀx·y = x. The supremum\n(sum) and inﬁmum (product) of a set X is denoted\nP Xand Q X (when they exist).\n□Necessarily [N] and ♦Possibly < P > are duals:\n♦P ↔¬□¬P\nand\n□P ↔¬♦¬P\nThe following table describes the four levels of\nperspective, described within this document:\nHeterarchy\nForest\nHierarchy\nTrees\nDyadic\nPresence Management\nMonadic\nRendezvous\nEach are taken from diﬀerent branches of mathe-\nmatics.\n1There are many failure modes, not the least of which are implementation failures: developers not following state-of-the-art\nsoftware-engineering disciplines; speciﬁcation failures by architects incorrectly specifying the solution, and requirements failures\nby product managers who incorrectly specify the market/customer requirements. What we are referring to here are fundamental\narchitectural failures, in which an inadequate architectural theory was used as the foundation for the design of a system.\nConﬁdential: REPLICUS Software. Under NDA. CMF. DRAFT November 22, 2010\nPage 3 of 25\n2\nBackground Principles\n2.1\n¬ Continuum\nSpecial and General Relativity, and Quantum Me-\nchanics, share a common mathematical diﬃculty:\nthey assume a continuum.\nIn Relativity, the Ein-\nstein equations represent a smooth manifold2.\nIn\nQM, the Hilbert space is an abstract vector space\nof inner products of reals.\nAbhorrence of the notion of real (irrational and\ntranscendental numbers) is shared by a long and dis-\ntinguished community of thinkers, beginning with\nPythagorus[4], Leibniz, Borel and Chaitin [5, 6, ?, ?].\nWhile numbers like e, π and √2 have “proofs” that\nthey are irrational, the entire collection of all natural,\nrational and computable irrational numbers are like\ninsigniﬁcant atoms in a vast ocean of ﬁctitious real\nnumbers, which can neither be counted, named or\ndistinguished from the vastness of their siblings that\nsurround them.\nThe problem is: we can’t distinguish anything in a\ncontinuum; there is nothing to get a hold of, to count,\nto name, to create interactions between. Continuums\nexist only in our imagination; they cannot be proved\nnor disproved[7]. As Stuart Kauﬀman says, the real\nline is a mess[8].\nWhy does this have a bearing on the design of\ninformation storage systems? because:\n• A real number (even in the interval 0–1) is iden-\ntiﬁed with an inﬁnite sequence of digits after\nit’s decimal or binary point.\n• An inﬁnite sequence of digits represents an in-\nﬁnitely long message, which contains an inﬁnite\namount of information.\n• A ﬁnite region of space may only contain a ﬁnite\namount of information[9]3.\n• All information is measured in bits; an irre-\nducible unit of information[10] .\nThis seems abstract and academic until we consider\nthe notion of time, and the ordering of events. Now\nwe descend into the depths of linear vs branching time\nin temporal description logics[11], and the murky im-\nplementation details of distributed algorithms, lin-\nearizability, consistency and perdurance of informa-\ntion; and ask: what can we really depend on from the\nmassively complex systems we are able to build but no\nlonger understand?\nDigital Philosophy4 is a theory of fundamental in-\nteractions in nature, carried to a logical conclusion\nwhere all quantities are ﬁnite and discrete. Theoret-\nically, any quantity can be represented exactly by an\ninteger; nature harbors no inﬁnities, inﬁnitesimals,\ncontinuities, or locally determined random variables.\n2.2\n¬ God’s-Eye-View\nScience has traditionally been explored by means\nof analytical models based on classical mathemati-\ncal principles. These models have been used to am-\nplify human intuition about the way our world works.\nComputer models have frequently been seen as a poor\nsubstitute, a tool for determining approximate solu-\ntions to intractable analytical models.\nYet there is another side to this story. In analyt-\nical modeling, as well as in computer modeling used\nas an approximation tool, systems are typically rep-\nresented from a God’s-Eye-View (GEV). The math-\nematician or programmer presides over the modeled\nworld like some form of Laplace’s demon, able in prin-\nciple to discern the entire course of world events based\non a complete understanding of the initial state of the\nworld as well as its laws of motion.\nWolpert[12] proved that Laplace was incorrect to\nclaim the future can be predicted without error given\nsuﬃcient knowledge of the present, even in a classi-\ncal non-chaotic universe. The capabilities of physical\ninference devices are inherently limited, not because\nof chaotic dynamics or quantum mechanical indeter-\nminism, but rather due to a “Cantor diagonalization”\ndemonstration that at least some portion of knowl-\nedge will always remain unavailable to any one infer-\nence device.\nConstructive mathematics is well-matched to this\nreality because it relies solely upon a Local-Observer-\nView (LOV). Information that a constructive math-\nematician can acquire about a system is limited to\n2All physical quantities in relativity are modeled as tensors. All “infon’s” (ref) in Cloudplane are modeled as tensor objects.\n3The Bekenstein bound is an upper limit on entropy S, or information I, that can be contained in a ﬁnite region of space\nwith a ﬁnite amount of energy–or conversely, the maximum amount of information required to describe quantum system. This\nimplies that the information necessary to perfectly describe a system must be ﬁnite if the region of space or the energy is ﬁnite.\nIn computer science, this implies a maximum information-processing rate for a system of ﬁnite size or energy, and that a Turing\nMachine, with its unbounded memory, is not physically possible unless it has an unbounded size or energy.\n4http://www.digitalphilosophy.org/\nConﬁdential: REPLICUS Software. Under NDA. CMF. DRAFT November 22, 2010\nPage 4 of 25\nwhat he or she can obtain by means of computations.5\nAs developed by Errett Bishop, constructive mathe-\nmatics is based on intuitionistic logic[14], a deductive\nsystem 6 D that does not include the law of the ex-\ncluded middle (P ∨¬P) among its rules of inference.\nIntuitionistic logic permits three logical possibilities\nfor a proposition: true (⊤), false (⊥), or undecidable.\nA proposition is true (or false) relative to D if its\ntruth (or falsity) can be established by a computa-\ntion within D. A proposition whose truth or falsity\ncannot be established by a computation within D is\nsaid to be undecidable relative to D. In addition, the\nlogical status of a proposition can be open relative\nto D in the sense that its classiﬁcation within D has\nnot been established. The uncountably large class of\nundecidable and open propositions (problems) rela-\ntive to D dominates the attention of many current\nconstructive mathematicians[15].\n2.3\nPrinciple of Suﬃcient Reason\n“Those great principles of suﬃcient reason\nand of the identity of indiscernibles change\nthe state of metaphysics. That science\nbecomes real and demonstrative by means\nof these principles, whereas before it did\ngenerally consist in empty words.”\nGottfried Leibniz\nThe aim is to banish faith from the\nfoundations of mathematics, faith is any\nviolation of the law of suﬃcient reason.\nThis law is deﬁned as the identiﬁcation of\ntruth with the result of a proof, in spite of\nthe traditional incompleteness theorem,\nwhich deals only with a very narrow kinds\nof proofs. I deﬁne proof as any fair way of\nmaking a sentence incontestable.\nA.S. Yessenin-Volpin.\nThe principle of suﬃcient reason (Volpin’s proof\nin the above quotation), also begs the Vantage point\nquestion in the GEV/LOV debate.\nVolpin’s “position” that a proof is “any fair way\nof making a sentence incontestable”7, begs the ques-\ntion of who or what is the decider of “fair”? This\nis of course, dependent on the orientation of the ob-\nserver relative to the ”knowledge” being expressed.\nJust as with other laws of physics, the observer will\nnecessarily measure (read\nobtain diﬀerent informa-\ntion) from that of other observers. This necessarily\nsets up a situation for potential disagreement among\nmathematicians, until such point that a consensus in\nunderstanding is obtained among a group of them\nsuﬃciently respected by the rest of the community\nthat the proof is acceptable8.\nAnd of course, the corollary:\nWhat do you believe that you cannot prove?\nStuart Brand\n3\nEngineering Principles\nIf there were a single raison d’ˆetre for Cloudplane,\nit would be conqueriing complexity, one of Jeanette\nWing’s ﬁve Deep Questions in Computing: How can\nwe build complex systems simply?[16].\nHowever, this may be adequate motivation for\nonly a small subset of readers.\nWe therefore enu-\nmerate ﬁve key principles, one or more of which, we\nhope will trigger resonance with the reader’s experi-\nence and wisdom: 9 10 11 :\n1. Agents and Actors, rather than Objects.\n2. Latency-driven.\n3. Hierarchy-Free.\n4. Encapsulated Failure Domains.\n5. Adaptive serializability foci.\n5According to Soare[13], “a computation is a process whereby we proceed from initially given objects, called inputs, according\nto a ﬁxed set of rules, called a program, procedure, or algorithm, through a series of steps and arrive at the end of these steps\nwith a ﬁnal result, called the output.”\n6Given a formal language L consisting of formulas (propositions) well-constructed in accordance with some prescribed syn-\ntax, a deductive system expressed in L consists of axioms L ⊆L together with a set of binary relations (rules of inference) on\nL that can be used to derive the theorems (conclusions) of the system (Dalen 2008).\n7This is also consistent with Roger Penrose’s deﬁnition of a proof being “an impeccable argument”.\n8This is discussed in more detail in TimeOne, and the GEV document (in preparation)\n9We have already enumerated motivation in a less precise way in the Cloudplane Technical Overview (CTO), and from a\npurely business perspective in the Cloudplane Business Overview (CBO).\n10Throughout the design, implementation, deployment and especially the on-going management of data systems, this might\nappear to be an ambitious goal, but as anyone experienced in the management of IT systems will attest, this would represent\nat true breakthrough in the industry.\n11The rest of this paper describes the various attack vectors on the monster of complexity.\nConﬁdential: REPLICUS Software. Under NDA. CMF. DRAFT November 22, 2010\nPage 5 of 25\nHierarchy-free is like GMail. There is no direc-\ntory structure under the hood, only tags. However,\nthe tag system can create the illusion of a directory\nsystem to a mail tool like Outlook.\nFrom an engineering perspective, Cloudplane may\nbe viewed as a set union of Networking (protocol) and\nStorage (File systems) principles\nN ∪S = {x : x ∈N\nor\nx ∈S}\nBy viewing these subjects as duals, we are able to\nconﬂate their operation, enabling a new approach to\ncoordination among distributed objects while elimi-\nnating redundant mechanisms in the implementation.\n4\nGraph Theory\nThe execution environment for modern software sys-\ntems is fundamentally graph-structured.\nA Graph\nG = (V, E), describes the God’s-Eye-View G, from\nthe set of element vertices V and edges E, which indi-\nvidually can only experience a Local Observer View.\nFurthermore, the ontology represented by a graph is\nfundamentally diﬀerent to the ontology represented\nby a smooth spacetime manifold (or even that repre-\nsented by a countable set), the consequences of which\ncan have a profound eﬀect on our views on how to ar-\nchitect and manage distributed systems.\n4.1\nTrees\nA tree is a connected graph G = (V, E) that does not\ncontain cycles, where V and E represent the vertices\nand the edges of G, respectively. This means that any\ntwo nodes of a tree are connected via a single path\nand that is no link that can be traversed more than\nonce12. For every tree implies that |E| = |V | −1,\nwhere |E| is the number of connections and |V | is the\nnumber of nodes. In a tree, each node may have one\nor more children but only one ancestor. The root of a\ntree is the highest ancestor of the hierarchy whereas\nleaves are the nodes that have no children. As inter-\nnal or inner is deﬁned as a node that is not a leaf\nand has children.\nA subtree is a fraction of the graph G, the hier-\narchy of which can stand as a complete tree by it-\nself. Every node of a tree can be a root node to form\na subtree.\nThe height of a node is deﬁned as the\nlength, i.e. the number of edges, from the node to\nthe longest downward, i.e. away from the root, path\nto a leaf. The height of the tree is deﬁned by the\nheight of the root. Correspondingly, the depth of a\nnode is the length of the path to its root.\nThere are trees, however, for which there is no\nnatural orientation and usually there is no node de-\nﬁned as root; these trees are called unrooted trees.\nConsequently, trees can be classiﬁed as rooted or un-\nrooted depending on the presence of a root node at\nthe top of the hierarchy, or not, respectively. While\nunrooted trees can always be generated from rooted\nones, the opposite does not apply; a rooted tree can-\nnot always be reconstructed from an unrooted one.\nFigure 1: Tree Anatomy\n5\nObjects and Monads\nObject-oriented programming systems (OOPS) is a\nprogramming paradigm where “objects” are deﬁned\nas data structures consisting of data ﬁelds, along with\nimperative methods and their interactions. Although\nthis sounds a lot like what we might need in order to\nprogram Cloudplane, the notion of object used in the\n12This is exploited in at least three ways in Cloudplane: (a) to deﬁne in-order-delivery (IOD) guarantees for serialization foci,\n(b) to guarantee collisions of coherency threatening operations, and (c) to eliminate deadlock.\nConﬁdential: REPLICUS Software. Under NDA. CMF. DRAFT November 22, 2010\nPage 6 of 25\ncontext of OOPS is ﬂawed from at least three signif-\nicant perspectives:\n1. OOPS Objects are hierarchical:\ntheir het-\nerarchical\ninteractions\nare\ncoordinated\nby\nsemaphores and locks, which are necessarily\nGEV-oriented.\n2. The model of time in (for example) C, C++\nand Java programming is based on a mathe-\nmatically seductive one dimensional object in\nR. We maintain that this represents an inade-\nquate model for distributed systems13.\n3. OOPS objects are spread out, they are not\nmonads, their tentacles stretching through the\ncodebase (including isomorphism) represent\nlogical structure of the program, not the dis-\ntributed nature of systems, and are thus insuf-\nﬁciently disciplined to be modeled as graphs,\nand proven mathematically.\nDespite these theoretical shortcomings, we ﬁnd\nthat the notion of a data structure and the meth-\nods by which they are manipulated are encapsulated\ntogether, to be a useful concept. Indeed, it represents\n(at least part) of what we need to deﬁne an Agent or\nActor in the system.\n5.1\nMonadology\nCloudplane shares its monadic (from the Greek and\nLeibnizian monad14) underpinnings with π calculus\nand its recursive expressiveness of λ calculus.\nAt\nthe most primitive level of communication, all rela-\ntionships between cells are dydadic (two at a time,\nfrom the Greek dyad or representing the principle of\n“twoness”). In philosophy an indivisible impenetra-\nble unit of substance, viewed as the basic constituent\nelement of physical reality (Leibniz).\nCloudpplane shares many conceptual underpin-\nnings of π calculus.\nBoth are a way of analyzing\nand describing systems consisting of a set of heterar-\nchical agents which interact among each other, and\nwhose conﬁguration or neighborhood is continually\nchanging.\nCDL focusses on the notion of identity\n(naming) and individually (addressability) by delib-\nerately constraining the knowledge (state) any agent\nneeds to know about he system and other agents,\nwe can reduce the amount of state information to be\nmaintained from O(n2) to O(1) (using constrained\nvalency; and by making all cells and replicas of ob-\njects substitutable, we can reduce the amount of in-\nformation required to be processed on environmental\nconstraints from O(2n) to O(1).\nThus, like π-calculus, the naming of channels,\nbut not of cells or replicas, is primitive in the lan-\nguage, but with one important diﬀerence: collections\nof channels in a stable Directed Acyclic Graph (DAG)\nconﬁguration are also primitive in CDL. Also π-\ncalculus restriction on initial connectivity reﬂected is\nin Cloudplane and its description language (CDL) as\na ﬁxed ﬁnite valency, and this creates long-lived struc-\ntures (what we aﬀectionately call dendrites) along\nwhich self-organizing structures, such as those speci-\nﬁed by cascaded synchrony, can persist.\n5.2\nIndividuality and Identity\nAs might be deduced from the opening paragraphs,\nCloudplane makes an ontological commitment to a\nmodel of time quite diﬀerent to that implicitly as-\nsumed in most computer science literature, but which\nis well known at the leading edge of our understand-\ning of reality from physics[17, 18].\nAs with many previously successful concepts, the\nfoundational concepts in Cloudplane, come from in-\ndividuals who ﬁrst had the time and inclination to\nthink deeply about these issues:\nthe Greek schol-\nars, and Gottfried Leibniz. A particular case is the\nMonadic15 perspective of an individual, indivisible,\nunit of something (in contrast to a continuum, which\nis incapable of any notion of individuality).\nWe distinguish our notion of individuality from\nthe notion of identity, which implies naming, because\nif each cell/agent has to track everything by its name,\nthen resources in each cell, would necessarily be con-\nsumed as our systems scale as O(n), the number of\nnames16.\nWe recognize the line of inﬂuence from the\nMonadic [19], the Actor[20], Agent [21, 22] and the\nobject (ref).\nWe view all these as perspectives as the same no-\ntion of a self-contained entity, capable of interact-\n13See TimeTwo: ”Rethinking Time in Distributed Systems”, in preparation.\n14In biology, a single cell organism. In chemistry or physics an atom or radical with valence.\n15Monad: In Physics or Chemistry, an atom or radical with a valence. In Philosophy, an indivisible, impenetrable unit of\nsubstance, viewed as the basic constituent element of physical reality (Ref Leibniz); in Biology: a single cell organism.\n16names may be either IP Addresses, strings from some server which knows about names (such as DNS or Active Directory),\nor cryptographically derived unique names which depend on statistical improbability to protect against potential conﬂicts’\nConﬁdential: REPLICUS Software. Under NDA. CMF. DRAFT November 22, 2010\nPage 7 of 25\ning with other self-contained entities. These terms,\nincluding the term agent are used interchangeably\nthroughout the Cloudplane Documents.\nWhy does this have a bearing on the design of\na information storage systems? because:\n• The execution environment for modern storage\n(and in general – all software) systems is fun-\ndamentally graph-structured.\nCloudplane ex-\nploits the ontology of vertices and edges (nodes\nor cells) and links, as constraints for the rela-\ntionship between cells, or the agents that rep-\nresent the replicas on them.\n• Distributed systems require the notion of object\nor agent in order for them to incorporate the\nconsequences of spatial distribution into their\nmodel of temporality.\n• Systems that are spread out, and devoid of a\nclean boundary or membrane (such as clusters),\nare not suﬃciently encapsulated to be treated\nas monads, as nodes in a graph, or as agents\nin an Actor model to simplify reasoning about\ntheir correctness or behavior17.\nIt is almost a tautology to state our society is criti-\ncally dependent on our relationship to our machines,\nwhich form the backbone of our technological civ-\nilization.\nYet this relationship is an evolved, not\na designed one, and it is evolving rapidly down a\npath where human beings are administrative slaves\nto these machines.\nWe can do better, much better, in negotiating our\nrelationship to our machines. Machines are much bet-\nter at mundane, repetitive tasks, human beings are\nmuch better at work involving variety and initiative.\nThis is essential to the creative human spirit, and the\ncontinued advancement of our civilization.\n6\nInformation Theory\nWe don’t learn much from being told that the sun will\nrise tomorrow morning, we learn a great deal from\nbeing told that it won’t. Information quantiﬁes this\nnotion of unexpectedness[23].\nEntropy (the uncer-\ntainty associated with a random variable) quantiﬁes\nthe converse: expectedness, i.e. that things inevitably\ndegenerate into randomness, according to the 2nd law\nof thermodynamics. The information content (H) of\na set A = {a1, a2, ..., an} of “bits”each occurring with\na discrete probability p(ak), is given by [10]:\nH[p] = −\nn\nX\nk=1\np(ak)log2p(ak)\n(1)\nBecause of the exponential nature of a growing set\nof bits (a power set), information is measured as the\nlogarithm of the number of bits in an object. How-\never, the average information content of a set S of\npossible bits can be far less than log2|S|, because not\nall bit-combinations of potential objects are equally\nlikely to occur. This fact is exploited by redundancy\ncodes, checksums and compression, which can algo-\nrithmically combine information to verify that some\nmuch smaller set of (more likely to be valid) objects\nhave been retrieved.\nThe fundamental problem of information storage\nis that of retrieving at one point a faithful rendition\nof an object stored at some previous point. An object\nis an ensemble, collection, set or conﬁguration of bits\nthat belong together: an identiﬁable, nameable entity\nwhich is indivisible, or at least must only be operated\non as if it was indivisible (e.g. atomically). A base\nobject (e.g. 512B or 4K storage block)18 is indivis-\nible, i.e., incomplete and unusable if any of its bits\nwere missing, and/or or corrupted.\nTo be relevant (i.e. distinguishable from random-\nness) bits must map (physically or mathematically)\nto a logical structure as a semantic (decodable or\nparse-able) resource to algorithms running on com-\nputers and, in-turn, represent meaning to users.\nFor a set of bits in an object to remain useful,\nthey must be persistent (never-changing); or change\nonly in ways governed by an algorithm or guided by\ninput from a user. The more random changes occur\nto the bits of an object, the less will be its usefulness.\nAlthough an entire object may not be destroyed if\na single bit is corrupted, most storage systems take\nthat the entire block is lost, because the complexity of\ndetermining which and how many bits are corrupted\nrepresents a level of complexity beyond the ability of\na typical administrator to manage.\nThe purpose of a storage unit is to provide a con-\n17One way to understand this is in the concept of failure domains; If we can’t express a failure domain as a node in a Markov\nModel, then the mathematical reasoning underlying the theory of Markov Models is no longer applicable to the design of our\nsystems.\n18This notion of an atomic object is relevant to other areas of computer design, such as 1.5-9KB packets on a network, or\n128KB pages in a virtual memory system.\nConﬁdential: REPLICUS Software. Under NDA. CMF. DRAFT November 22, 2010\nPage 8 of 25\ntainer for bits to be stored, to guarantee their persis-\ntence in the presence of physical, electrical or other\nenvironmental perturbations, and to enable these bits\nto be retrieved by applications on computers, or hu-\nman beings, whenever and wherever requested.\nBits in a storage unit can be made resilient to\nrandom changes induced by physical processes in the\nenvironment19 by the addition of redundancy; in the\nform of a coding scheme (in a storage unit) or the\nreplication of an object to another storage unit, or\nsome coding scheme across units, such as RAID,\nRAIN or a more general Erasure Code (EC). The\nformer allows one to tradeoﬀthe number of bits (and\nhence size of the container) with its resilience to ex-\npected (and unexpected) failure hazards.\n6.1\nSystem Information\nThe total state maintained by a Cloudplane complex:\nH[p] = −\nNc\nX\ni=1\nSj\nX\nj=1\npijlog2pij\n(2)\nWhere:\npij = probability celli is in statei\nSj = probability of state s on celli\nNc = number of cells\nNote: this argues to minimize (a) the amount of\nstate info that each agent needs to know about an-\nother agent (this is why we separate out the compo-\nnents of the MetaData Tensor), and (b) the number\nof cells that need to know about each other (this is\none reason why we limit connectivity in the graph to\nnear neighbors only).\nInformation (or entropy) is a physicists way to\nquantify complexity.\n6.2\nAlgorithmic Information Theory\nCloudplane and CDL are consistent with Algorithmic\nInformation Theory (AIT)[24, 5]. Providing a lan-\nguage which enables a precise deﬁnition of the com-\nplexity of a “law of nature” to be expressed: instead\nof considering the experimental data to be the points,\nand the law to be an equation, AIT makes everything\ndigital: binary 0’s and 1’s. A law of nature “becomes”\na piece of software, a computer algorithm.\nInstead of trying to measure the complexity of a\nlaw via, say, the size of an equation20, we now con-\nsider the size of programs: the number of bits in the\nsoftware that implements the theory[25].\nLaw: Equation →Software\nComplexity: Size of equation\n→Size of program (bits of software).\n6.3\nSubstitutable Entities\nCloudplane employs a deliberate architecture of sub-\nstitutability21 of cells and replicas22. We dont need\nto delve into the details of information theory to jus-\ntify the value of substitutability in the Cloudplane\narchitecture.\nThe simple mathematics of permuta-\ntions and combinations is a good starting point to\nunderstand why making things substitutable reduces\nthe amount of state to be managed by each cell, al-\nlowing the system as a whole to grow, without con-\nsuming more resources (storage, CPU, bandwidth)\ninside each cell. For example:\nCombinations: If\none\nhas\n5\ndiﬀerent\nob-\njects (e.g.\nA, B, C, D, & E),\nhow many\nways\ncan\nthey\nbe\ngrouped\nas\n3\nob-\njects when position does not matter (e.g.\nABC, ABD, ABE, ACD, ACE, ADE are cor-\nrect but CBA is not ok as is equal to ABC)\n- answer is 10 ways. The formula is: 5C3 =\n5!/((5−3)!∗3!) = 5∗4∗3∗2∗1/(2∗1∗3∗2∗1) =\n5 ∗4/2 = 10.\nPermutations:\nIf position is important (e.g.\na\nCell must distinguish one neighbor from an-\nother), if one has 5 diﬀerent objects (e.g.\nA, B, C, D, & E),\nhow many unique ways\ncan\nthey\nbe\nplaced\nin\n3\npositions\n(e.g.\nADE, AED, DEA, DAE, EAD, EDA, ABC,\nACB, BCA, BAC etc.)\n- answer is 60 ways.\nThe formula is 5P3 = 5!/(5 −3)! = 5 ∗4 ∗3 ∗\n2 ∗1/(2 ∗1) = 5 ∗4 ∗3 = 60.\nPermutations with diverse replicas:\nGiven\nthat position is important, if one has 5 diﬀerent\nobjects, e.g. A, B, C, D, & E - but many repli-\ncas of each, how many unique ways can they\nbe placed in 3 positions with up to 3 replicas of\n19Or inconsistent changes by rouge software, ﬁrmware or hardware.\n20Equations are man-made, and representations can hide vast amounts of theoretical and computational detail, c.f. The new\nMaxwells equations and the Einstein equations)\n21A key method of reducing the D factor in the NKD Model - see later discussion on the NKD model in this document\n22cables are fully substitutable also - to eliminate deployment complexity\nConﬁdential: REPLICUS Software. Under NDA. CMF. DRAFT November 22, 2010\nPage 9 of 25\nany object (e.g. AAA, ABB, CCC, EEC, CEE\netc.) - answer is 125 ways. The formula is :\n5R3 = 53 = 125.\nBy making the cells substitutable, the replicas\nsubstitutable, and the network ports on each cell sub-\nstitutable, we are able to exploit a scaling in state\nspace equivalent to the law of combinations rather\nthan that of permutations with replicas. The substi-\ntutability concept is directly equivalent to the above\nnotion that position does not matter – because if the\nentities we are dealing with are substitutable, then a\ncorollary is that they are indistinguishable and there-\nfore, position does not matter in the analysis.\nCloudplane does not attempt to “name” or “ad-\ndress” an individual cell by some “identity” such as\na DNS name or an IP address in the protocols which\npass ﬁles around the system23. Cells which are adja-\ncent to each other are physically connected, and dont\nneed globally resolvable IP addresses. Where cells or\ngroups of cells are connected over geographical dis-\ntances over an IP Network, the IP Address itself is\nvirtual e.g.\nany one of the boundary cells in each\nclique may respond to the IP address for that clique.\nThis aids in the automatic failover of cells, and pro-\nvides a potential mechanism for load balancing.\n7\nFoundational Calculi\nλ Calculus and π Calculus[26, 27] are the founda-\ntional Calculi for programming languages. Various\nlanguages based on λ-calculus are in widespread use,\nthis is not yet true for π-and other process-calculi,\nwhich according to Peter Selinger, so far lack a unify-\ning set of principles[28]. The Cloudplane Description\nLanguage (CDL) is a derivative of λ Calculus for its\nfunction primitives, and a derivative of π-calculus for\nits communication primitives.\n7.1\nLambda (λ) Calculus\nλ Calculus is a formal system for deﬁning functions\nand recursion developed by Alonzo Church: one of\nthe deﬁning systems that has proven that the foun-\ndations of mathematics cannot be both complete and\nconsistent (after G¨odel).\nHowever, incomplete sys-\ntems can be consistent, and this was the base of\na computationally weaker version known as simply\ntyped lambda calculus.\nA typed interpretation of\nlambda calculus, with only one type constructor →\nthat builds function types.\nIn λ everything is a function: the arguments ac-\ncepted by functions are themselves functions, and\nthe result returned by a function is another func-\ntion.\nThere are no built-in constants or operators\n– no numbers, arithmetic operations, records, loops,\nsequencing, I/O etc. The sole means by which ex-\npressions “compute” is the application of functions\nto arguments.\nλ Calculus is a key inﬂuence behind the Cloud-\nplane Description Language. It inspired the math-\nematical structure by which recursion can be ex-\nploited spatially through networks of nodes[29]. For\nexample, the Cloudplane cascaded synchrony spec-\niﬁcations are recursive speciﬁcations that invoke a\nfunction through one or more legs of a graph (net-\nwork) with recursion variables being operated upon\n(e.g.\ndecremented) until a speciﬁed termination\ncondition[29] is met (e.g. arrival of the function at\na node that meets some criterion, or a leaf node).\nPractically\nspeaking,\nthis\nallows\na\nsingle\nalgebraic-like speciﬁcation, to set up a persistent\npredicate, with synchronous updates to a mirror\nreplica on a neighbor cell, fast asynchronous updates\nto a backup replica in another cell in the vicinity,\nand a slow asynchronous update to a cell at a remote\nlocation for disaster recovery.\n7.2\nPi (π) Calculus\nThe π-calculus is a model of concurrent computation\nbased upon the notion of naming. It is a way of de-\nscribing and analyzing systems of interacting agents\nwhose conﬁguration or neighborhood is constantly\nchanging[27].\nProcess calculi (or process algebras) are a diverse\nfamily of related approaches to formally modeling\nconcurrency in systems.\nThey provide a tool for\nthe high-level description of interactions, communi-\ncations, and synchronizations between a collection of\nindependent agents or processes. They also provide\nalgebraic laws that allow process descriptions to be\nmanipulated and analyzed, and permit formal rea-\nsoning about equivalences between processes.\nIn contrast to λ-Calculus’ everything is a func-\ntion, in the π-calculus every expression denotes a\nmonadic process – a free standing computational ac-\ntivity running in parallel with other processes and\n23The only time when a cell needs to be identiﬁable is when it must be physically replaced due to failure and so its location\nneeds to be identiﬁed by an administrator.\nConﬁdential: REPLICUS Software. Under NDA. CMF. DRAFT November 22, 2010\nPage 10 of 25\npossibly containing many independent subprocesses.\nTwo processes can interact by exchanging a message\non a channel. Indeed, communication along chan-\nnels is the sole means of computation. The only thing\nthat can be observed about a process’s behavior is its\nability to send and receive messages.\nλ-calculus is to GEV as π-calculus is to LOV. π-\ncalculus is one of a family of process calculi, diﬀer-\ning in details but sharing the same basic orientation\n– focussing on interaction via communication (LOV)\nrather than shared variables (GEV). Thus, π-calculus\nis even more closely oriented to the architectural re-\nquirements of Cloudplane than λ-calculus. However,\nthe π-calculus is an imperative (i.e. non-functional)\ndescription/language: in the sense that we do not\nexpect to get the same result each time we query a\nprocess repeatedly over a channel[30].\nIn λ-calculus, any λ-expression whose reduction\ndoes not terminate can be viewed as an inﬁnite loop.\nIn π -calculus, a process may go on computing for-\never but still interact usefully with its environment.\nAgain, reﬂecting the self-stabilizing nature of the\nCloudplane algorithmic structure, and its real-time\nadaptive nature to perturbations.\nThe π-calculus appears to be precisely the envi-\nronment needed by Cloudplane. However, there are\ntwo levels of description that need to be considered:\n1. The physical environment of cells and links (ca-\nbles/networks that connect them). In this en-\nvironment, links may break, cells may die (and\nsometimes be resurrected), and new cells may\nappear as new (virgin) resources. This happens\nvery slowly (a low density of new events over\nweeks, months or years);\n2. (2) The logical environment, where objects are\ncloned, distributed and evaporated. This hap-\npens very quickly (a potentially high density of\nnew events over seconds, minutes or hours).\nThe intended theory and ontological commit-\nment24 of Cloudplane can be faithfully encoded in the\nﬁrst order π-calculus. Despite its economy of syntax,\nthe π-calculus is a rich and expressive language with\nan extensive implementation requirement. However,\nas Jeanette Wing would say[31] you can program in\nπ-calculus, but you wouldn’t want to.\n7.3\nPetri Nets\nPetri Net’s are models of interacting sequential pro-\ncesses High-level Petri nets support colored tokens.\ni.e. a token can have a value. Although it is pos-\nsible to use this to identify multiple instances of a\nsub-process, there is no speciﬁc support for patterns\ninvolving multiple instances and the burden of keep-\ning track, splitting and joining of instances is carried\nby the designer.\nIn Petri-nets the ﬁring of a transition is always\nlocal, i.e., enabling is only based on the tokens in the\ninput places and ﬁring is only aﬀecting the input and\noutput places. However, some events in the workﬂow\nmay have an eﬀect which is not local, e.g., because\nof an error tokens need to be removed from various\nplaces without knowing where the tokens reside.\nPetri-Nets are a graphical description language,\noften directly implementable in a simulator, and has\nwidespread applicability in the design and veriﬁcation\nof protocols. Cloudplane uses a variation of petri-nets\ncalled marked graphs[32]25.\nThis is the alternative\nform of synchronization oﬀered by the Cloudplane\nAPI, although this mechanism co-resides with more\nregular forms of synchronization, including serializa-\ntion lock-tokens, and two-phase commit26.\n7.4\nActor Model\nThe Actor model is a mathematical theory that treats\nActors as the universal primitives of concurrent digi-\ntal computation[20]. The model has been used both\nas a framework for a theoretical understanding of con-\ncurrency, and as the basis for practical implementa-\ntions of concurrent systems. The Actor model was\ninspired by “physical laws” and inﬂuenced by various\nprogramming languages.\nAn Actor is a computational entity that, in re-\nsponse to a message it receives, can concurrently:\n• Send a ﬁnite number of messages to other Ac-\ntors\n• Create a ﬁnite number of new Actors\n24A commitment to a phenomena we wish to represent, and which design constructions are seen to ﬁt those phenomena best.\n25According to Lamport, In Petri nets, arbitration appears explicitly as conﬂict (what we would refer to here as a heterar-\nchical interaction). A class of Petri nets called marked graphs, which were studied in the early 70s by Anatol Holt and Fred\nCommoner, are the largest class of Petri nets that are syntactically conﬂict-free. Marked-graph synchronization is a natural\ngeneralization of producer/consumer synchronization. Lamport assumes (without proof) that marked graphs describe precisely\nthe class of synchronization problems that could be solved without an arbiter.\n26See: CAPI - the Cloudplane API document (in preparation).\nConﬁdential: REPLICUS Software. Under NDA. CMF. DRAFT November 22, 2010\nPage 11 of 25\n• Designate the behavior to be used for the next\nmessage it receives.\nThe potentially novel component in Hewitt’s Ac-\ntor model is the third item: “Designate the behavior\nto be used for the next message it receives”. This\nis what agents in Cloudplane can do with their λ-\nlike expressions that specify spatial recursion down\na brach of a DAG. There are at least three ways to\nthink of this:\n• The behaviors allowed by a cell are ﬁxed,\nalong with enumerated “places” in the recur-\nsion pipeline. The signal from the root agent\nsimply drives the behavior of a set of state ma-\nchines in each cell, according to one of these\npreconﬁgured states, and some cell-hop speciﬁ-\ncation that allows the state machines to remain\nsynchronized and hierarchically related to the\nbase rule and recursion level[29].\n• The agent is considered to be a π-calculus pro-\ncess which simply clones itself (using the !\npreﬁx on a process), on another cell (using the\n@ preﬁx on a process, which implies a globally\nknown address ...).\n• A combination of the above, with the follow-\ning twist: Fixed behaviors (sets of rules) are\npre-allocated down the cell trees, after ﬁrst be-\ning authenticated to validate their provenance\n(identiﬁable origin) and trustworthiness. Then\nusing the actor model to send both the rule,\nand the “where up to” pointer in the expres-\nsion, down each leg of the DAG. This is the\npreferred method used in Cloudplane.\nThe agents in Cloudplane share many of the same\ntheoretical underpinnings as the Actor model, with\nsome important diﬀerences.\nThe “physical laws”\nwhich comprise Cloudplane’s theoretical foundation\nare based not only on Rovelli’s Relational Quantum\nMechanics[33], but on a current model of Entropy[34]\nand Algorithmic Information Theory[5].\nCloudplane also shares π-calculus’ inﬂuence by\nCarl Hewitt’s actor systems (see the Monad discus-\nsion earlier), although we did not know this inﬂuence\nat the time, because our multi-agent knowledge came\nfrom the complex-adaptive systems world at SFI.\n7.5\nOrdering Model\nThere is no assumed order to the above Actor model\nactions and they could be carried out concurrently.\nIn addition two messages sent concurrently can arrive\nin either order. Decoupling the sender from commu-\nnications sent was a fundamental advance of the Ac-\ntor model enabling asynchronous communication and\ncontrol structures as patterns of passing messages.\nWithout getting too deeply into the physics\nhere27, a computer scientist might best understand\nthis in the context of the computational universe de-\nscribed by Seth Lloyd[35] and others[36, 37].\nFurther, the ordering model in Cloudplane rep-\nresents a structurally adaptive mode of temporal\nintimacy, beginning with the absence of ordering\nin the Actor Model (A “bag’ in the Asynchrony\nModel[28, 38, 39]), all the way to tightly coupled\nspacetime-constrained interactions across the net-\nwork of cells for environments that require the highest\ndegree of guaranteed consistency and temporal inti-\nmacy between cooperating agents on diﬀerent cells.\n7.6\nAsynchrony: bags | queues | stacks\nThe distinction between synchronous and asyn-\nchronous communication is a relevant issue in the\ndesign and analysis of distributed and concurrent net-\nworks. Intuitively, communication is said to be syn-\nchronous if messages are sent and received simultane-\nously, via a handshake or rendezvous of sender and re-\nceiver. It is asynchronous if messages travel through\na communication medium with possible delay, such\nthat the sender cannot be certain if or when a mes-\nsage has been received.\nAsynchronous communication is often studied in\nthe framework of concurrent process paradigms such\nas the asynchronous π-calculus, originally introduced\nby Honda and Tokoro[39].\nAnother asynchronous\nparadigm is the join calculus, proposed by Fournet\net al., as a calculus of mobile agents in distributed\nnetworks with locality and failure[40].\n27This is relevant to distributed systems and computer networks because of the concern that the implicit Turing machine\naxiom of monotonicity (time being a single dimensional object in R) in observed events may not even be valid from a single\nlocation. i.e. diﬀerent observers may not be able to rely on the perceived order of events from the same source - due to potential\ndecoherence (time reversal) occurring along one path but not another[34]. In general, this follows a view of time according to\nMach’s principle (time is change) to its logical conclusion, and Barbour’s advancement of the conception that everything is\nrelational - leads to the idea that the entire path of the photon should be considered an event or instant, which invokes the\nconcept of a graph dual where nodes become edges and photon paths become the vertices in a transformed reference frame –\nFor more information, see TimeOne, by the Author (in preparation).\nConﬁdential: REPLICUS Software. Under NDA. CMF. DRAFT November 22, 2010\nPage 12 of 25\nFigure 2: BiSimulation\nA buﬀer is basically a data structure that accepts\nmessages and resends them later.\nThree diﬀerent\ntypes of buﬀers could be used depending on the pol-\nicy for disposition of a previously received message.\nThe most common policies are:\n• Bag, or unordered policy: any message previ-\nously received (and not yet sent) can be sent\nnext.\n• Queue, or FIFO policy: only the oldest message\nreceived (and not yet sent) can be sent next.\n• Stack, or LIFO policy: only the last message\nreceived (and not yet sent) can be sent next.\nCloudplane generalizes the formal description of\nthese types of buﬀer by Beauxis, Palamidessi, and\nValencia[41] using the Priority Queue Engine (PQE).\nThis is the base engine, tied directly to the Replica\nManagement Engine (RME) which governs the ﬂow\nof data into and out of a cell. In addition to policies\nlike the ordering types described above, the PQE al-\nlows an inverse relationship between the size of the\ntransfer, and the priority it receives on the output\nport.\nIncoming traﬃc on one port routed to another\nport receives the highest priority.\nThis enables\nCloudpalne’s worm-hole routing, which minimizes\nrouting delays through cells to their theoretical mini-\nmum28. There are a hierarchy of message types which\nreceive progressively lower bandwidth allocations.\nThe dlsp protocol is implemented on top of\nsctp (a recent IETF protocol which provides multi-\nhoming, multiplexing of channels, and eliminates\nhead-of-line blocking).\nSellinger and Haghverdi also provide a signiﬁcant\ntheoretical description on Asyncrhony[38] [42, 43, 28],\nfrom a First-order π-calculus and a categorical frame-\nwork.\n8\nBisimulation\nMathematicians describe diﬀeomorphism as an in-\nvertible function that maps one smooth manifold to\nanother, such that the both the function and its in-\nverse are also smooth (diﬀerentiable).\nAs we have\nalready expressed a lack of belief in smooth (diﬀeren-\ntiable) manifolds in our ontology of space and time,\nwe should seek its discrete version or analogy : for\nthis we have chosen bisimulation: an association of\nsystems which behave identically with respect to each\nother, such that one system can simulate the other,\nand vise versa.\nBisimulation29 is a binary relation between state\ntransition systems (STS), associating systems which\nbehave in similar ways. Cloudplane is an agent-based\nsystem[21], and as such, Cloudplane is its own sim-\nulation system. This implies a bisimilarity between\nthe “real-world” system in operation, and a function-\nally equivalent system running in a simulator, based\non the same topology of cells and links, and where\neach agent is using the same rules.\nThe behavior of virtual cells as a model in a sim-\nulator, can be made provably similar to the behavior\nof a real system with the same graph.\nThis is an\nimportant property in being able to verify mission-\ncritical systems (which are otherwise unveriﬁable or\nuntestable on an economic or disruption sense. This\nis a particularly important requirement for the enter-\nprise class storage systems infrastructures which are\nexpected to be built on top of this.\nThe ontological commitment of Cloudplane is con-\nsistent all the way from the mathematical description\non the left of Figure 2 to the practical, operational\nsystem on the right of Figure 2.\nCloudplane is such a dual system. Our thesis is\nthat the agent based architecture provides us with a\nsystem that is well-behaved if the rules are chosen\ncorrectly. Well-behaved does not imply determinis-\n28Which “may” be accelerated in hardware to minimize their practical minimums\n29bisimulation - two processes that can each simulate (behave identically) to the other.\nConﬁdential: REPLICUS Software. Under NDA. CMF. DRAFT November 22, 2010\nPage 13 of 25\ntic nor does it imply chaos. The boundary between\nthe two presents opportunities for robust emergence,\nequilibria that bring a system back to a desired state\nby heterarchical (mutual) interactions (of competing\nrulesets) rather than hierarchical sets of rules from\ncontrol theory.\n9\nMeasures of Complexity\nIn the Cloudplane Business Document, we gave a sim-\nple NKD (Number, Connectivity, Diversity) model\nfor how complexity scales in as an IT infrastructure\ngrows.\nThis is a somewhat trivial model that can\nbe explained simply, yet appears to have predictive\npower. For the mathematically minded, this requires\na little more justiﬁcation than would be warranted in\na description of the system for business people.\nElements of NKD Model Include:\nN model In his seminal 1962 paper “The Archi-\ntecture of Complexity”, Herbert Simon deﬁned\ncomplexity as a large number of parts (N) that\ninteract in a non-simple way [44].\nNK model In 1987 Stuart Kauﬀman introduced the\nNK model, where N is the number of compo-\nnents in a system, and K measures the “degree”\nof interaction between components.\nThe NK\nmodel was originally proposed to study the evo-\nlution of genomes. It has since been employed\nin various disciplines to explore their intrinsic\ncomplexity and behavior. Kauﬀman ignored di-\nversity (presumably because the molecules were\nsubstitutable).\nNKD model In 2002, the Author informally intro-\nduced the NKD Model[45].\nThe key contri-\nbution was recognizing that D the diversity of\nthe components, was an exponential: the weak-\nest contributor to total complexity when N was\nsmall, but by far the greatest contributor to\ntotal complexity when N was large.\nThis is\nonly one of the ways to understand how Cloud-\nplane behaves as the system scales (all local\nstate and communications (traﬃc) scales as a\nconstant ∼O(1) except physical resources and\npower, which scale in a simple linear fashion\n∼O(n))30. The NKD model is simply:\nComplexity = aN + BN 2 + C2N/d\n(3)\nWhere:\nN = the number of things to be managed31. For\na fully connected system:\nK = Connectivity. Each element connects to each\nother element (e.g. the valency for each replica of a\nparticular ﬁle)\nK = N(N −1)\n2\n→N 2(as N gets large)32.\n(4)\nD = Diversity. i.e. non-subsitutivity. This is a\npower set33, where each element is 0 or 1, 1 = com-\npatible (mathematically and operationally equivalent\nto all others). Therefore the D factor is\n2N.\na, b, c and d are scaling coeﬃcients.\nOver time, the model predicts the relative “value”\nof hardware diminishes as software begins to domi-\nnate, but eventually, the cost of administration domi-\nnates, compressing the available business margin that\ncan be extracted from hardware and software in a\nmarket over time (t ∼a substitute for N, as N\ngrows). This represents fundamental market trauma,\nand a signiﬁcant potential opportunity.\nN\nN2\n2N\n!  Linear Complexity\n  Solved by Hardware\n! Quadratic Complexity\n  Solved by Software\n! Exponential Complexity\n  Left to Administration!\nN\nN2\n2N\n!  Linear Complexity\n  Solved by Hardware\n! Quadratic Complexity\n  Solved by Software\n! Exponential Complexity\n  Left to Administration!\nFigure 3: The above is a simple model of complexity,\nabstracted to IT Infrastructures.\nBasically, we are\ndealing with N - the number of moving parts, N 2 the\nconnectivity among those parts, and 2N the power-\nset or number of combinations of diﬀerent things that\ncan be created by those ensembles of IT componentry.\n309 months after the 9/11 attack, and after discussions with Stuart Kauﬀman, Eric Bonabeau and David Reed, the author\nintroduced the NKD model as a measure of complexity in Distributed Storage Systems. See Borrill presentation at Vanguard\nConference, July 2002: “Designing Storage Systems for Ultra Resilience”\n31E.g. the number of cells, the number of disks, the number of ﬁles, or the number of replicas of a ﬁle\n32The actual relationship is 2N −N −1, but this scales as 2N when N is large\n33We use the same argument as community forming networks from David Reed to show that this is an exponential.\nConﬁdential: REPLICUS Software. Under NDA. CMF. DRAFT November 22, 2010\nPage 14 of 25\n0% \n10% \n20% \n30% \n40% \n50% \n60% \n70% \n80% \n90% \n100% \nN (Hardware Value)\nN2\n(Software Value)\n2N\n(People cost)\nCIO Budget $\nCIO Budget\n (constant over time approximation)\nHardware “Value” and Software \n“Value” are compressed by the \nweight of the Administration “Cost”\n0% \n10% \n20% \n30% \n40% \n50% \n60% \n70% \n80% \n90% \n100% \nN (Hardware Value)\nN2\n(Software Value)\n2N\n(People cost)\nCIO Budget $\nCIO Budget\n (constant over time approximation)\nHardware “Value” and Software \n“Value” are compressed by the \nweight of the Administration “Cost”\nFigure 4: Complexity scaling factors: Linear (the\nquantity of things to manage), Quadratic (connectiv-\nity of the things to manage), and Exponential (the\ndiversity of the things to manage).\nThis economic\nmodel shows what happens when you normalize them\n(add them together and make the sum = 1). This\nmodel can be applied to a constrained spending bud-\nget, show how it aﬀects behavior of an organization\nover time for Hardware, Software and People.\nFor Cloudplane: consider the following variables:\nNf =number of ﬁles.\nNb =number of blocks.\nNc =number of cells.\nNr =average number of replicas per ﬁle.\nNt =total number of replicas (Nr ∗Nf).\nNr(fi) =number of replicas for ﬁle i\nRi = Replica i\nFi = File i\nThe process of “distillation” in the Cloudplane\narchitecture comprises the steps needed to take a re-\nsource (e.g.\nthe number of bits of state needed to\nbe stored on each cell, or the number of packets that\nneed to traverse more than one link), and see how to\nmake them on average remain a constant as the sys-\ntem scales. This is more diﬃcult than it looks, but\nyou can get an idea from the following:\nDistilling N:\nFiles - N is reduced by taking many\nNb and encapsulating them into fewer Nf. E.g.\nWe manage Nf (number of ﬁles), instead of Nb\n(Number of blocks) because ﬁles are many or-\nders of magnitude less numerous than blocks\nDistilling K: Cells - K the connectivity awareness\nor state space - is reduced by bounding the va-\nlency of a cell and communicating only with\nnear neighbors on the graph. Thus reducing the\nnumber of other elements that each cell needs\nto keep track of (i.e. keep state information on).\nSee also the permutation/combinations descrip-\ntion below.\nAgents (replicas) - K is reduced by addressing all\nthe replicas as one (combine all replicas into a\nsingle addressable tree). One can also think of\nit this way: each branch leading out of a cell\nis a single addressable entity which enables an\nindeterminate number of replicas to be updated\nby sending a single operation packet down this\nbranch.\nAt this architectural level, there is\nno need for communication across the network\nwhen replicas are created, destroyed or moved.\nEven at the architectural layer where the PDR\noperates, a replica move operation (for example\nfurther down the LRU path) is a neutral opera-\ntion and does not require traﬃc to update cells\non other parts of the network.\nDistilling D: For Cells - D is reduced by making all\ncells substitutable (or at least isomorphic with\nrespect to capacity and performance parame-\nters). This enables the crucial manage all the\ncells as one capability. The system is managed\nby simple rules (policies and parameters which\napply to all cells), and individual cells cannot be\nmodiﬁed in isolation. (Note the eventual con-\nsistency rule applies for policies and parameters\nalso).\nReplicas D: For Replicas D is reduced by making\nall replicas substitutable.\nAll specialization is\ntemporary. If ﬁles are active, they temporarily\nacquire ownership, locks, update and cascaded\nsynchrony characteristics. As ﬁles age, and are\nless likely to be accessed, they lose these special-\nizations and return to being fully substitutable.\nCaches are simply replicas, except a bone-ﬁde\nreplica can be used as a source locally by any\nnode, without traveling back to some remote\n“master” copy to maintain coherence.\nRepli-\ncas can also be recovered from in the case of\nfailures, caches cannot.\nTypically, 98.5% of all ﬁles in a large organiza-\ntion are archivable\ni.e.\nhave not been accessed in\nthe last month, and are unlikely to be accessed again\n(probability is relative to recently created ﬁles). This\nenables the elimination of several forms of diversity\ncomplexity for the management of these 98.5% ﬁles\nin the organization.\nConﬁdential: REPLICUS Software. Under NDA. CMF. DRAFT November 22, 2010\nPage 15 of 25\n10\nMathematical Inﬂuences\n10.1\nTensor Calculus\nThe purpose of Tensor Calculus is to provide a uni-\nﬁed framework for dealing with quantities (and their\nderivatives and integrals) which depend on several\nvariables and need several numbers (components) per\npoint in space to be fully speciﬁed.\nA tensor is a mathematical object which may have\ndiﬀerent values at diﬀerent points in space. A tensor\nrank describes how many dimensions of values the\nobject may have. A scalar is a tensor of rank 0, a\nvector is rank 2, matrix is rank 3, etc. Tensors gener-\nalize the concept of dimensions and manifolds, so that\notherwise complex objects can be reasoned about and\nmanipulated simply by operators.\n(See BOT - Business Object Tensor for more de-\ntails). This begs the question of how we achieve this\n“magic”. Technically it is simple, but the operational\nand user beneﬁts of the Tensor abstraction are pro-\nfound: a dramatic simpliﬁcation in the way systems\ncan scale, eliminating the vast majority of cognitive\noverhead for managing data. Think about it this way:\nwe no longer talk to a single cell, and manipulate the\nreplica that is a guest on that cell, we can only ma-\nnipulate the entire “set” of replicas, but in a way that\nrespects the time and space between them.\nThe key is to let the tensor object unfold, and\nrefold back up when it is not in use. Each compo-\nnent (branch) of the local tensor object represents\na separate component of the replica which must be\nmaintained by a MRC (minimum replica count). This\nallows the vast majority of cells to simply keep a han-\ndle (a 32-64-Byte object that represents the identity\n(name) of the object (a GUID), information on how\nto ﬁnd the object, and information on what security\nclearances are required to access the object, includ-\ning authentication keys related to the current user’s\nworkspace ID, as well as the current Node location\nID).\nThere is no limit to the size of the tensor, ex-\ncept that some set of cells, somewhere, has to be able\nto store all dimensions of the tensor, while all other\ncells can selectively pick with dimensions they are in-\nterested in. E.g. just the handle, or the handle and\nconventional ﬁle metadata, or the handle + metadata\n+ data (this is a simple example of what it can do).\nBesides holding the normal components of what\nwe might regard as the data for a ﬁle object. The\ntensor can hold (in additional dimensions), derived\nentities, such as compressed versions of the ﬁle, or en-\ncrypted versions, or versions converted to another for-\nmat (e.g. .docx ﬁles converted to .pdf), or (what was\nits original intention), reduced resolution images suit-\nable for either faster transmission over lower band-\nwidth links, or restricted access by personnel with-\nout an appropriate security clearance, or in a location\nthat is not considered secure, even if the requestor did\nhave the appropriate security clearance.\nThe tensor (MDT) also forms the basis for how to\ndo deduplication on a distributed (system-wide) ba-\nsis, while maintaining suﬃcient copies to guarantee\nagainst data loss.\nWhat transpires as we think more deeply about\nthe value of the Metadata Tensor, is the realization\nthat it can be used for anything.\nConsider it to\nbe a generalized extended metadata, or named data\nstreams mechanism for ﬁle systems, except that it\nties in directly with the coherency and consistency\nmechanisms in a distributed system.\nThere’s not much more to say here about the\nMetadata Tensor that is not already covered in the\nCloudplane Technical Overview (CTO) and Meta-\ndata Tensor (in the BOT - Business Object Tensor\nDocument). Because, beyond the Kronecker product,\nwhich is the (Matrix) operation, which is the discrete\nequivalent of the standard derivatives and integrals)\nTensor, everything else is data structure design and\nthe way they knit into the dlsp (dynamic locality se-\ncure protocol) transactions. However, the inspiration\nfor them borrows heavily from Standard Tensor Cal-\nculus.\n10.2\nSheaf Theory\nSheaf theory allows us to measure a local variable, to\nadduce a global property. Sheaf theory was the inspi-\nration behind the architecture of background (house-\nkeeping) traﬃc in Cloudplane, which helped us un-\nderstand now to scale the system with constant traf-\nﬁc. The mathematics of sheaf theory is signiﬁcantly\nmore advanced than the simple theory of permuta-\ntions and combinations given elsewhere in this doc-\nument, and allows us to borrow results to prove the\nscalability of the Cloudplane design, providing that\nthe protocol obeys certain constraints.\nJoseph Goguen describes how to use Sheaf Seman-\ntics for Concurrent Interacting Objects[46].\n10.3\nCategory Theory\nCategory theory has come to occupy a central po-\nsition in contemporary mathematics and theoretical\nConﬁdential: REPLICUS Software. Under NDA. CMF. DRAFT November 22, 2010\nPage 16 of 25\ncomputer science, and is also applied to mathematical\nphysics. Roughly, it is a general mathematical the-\nory of structures and of systems of structures. Agents\n(in Agent Based Systems) can also be considered as\nstructures[47].\nCategory theory is claimed by some to be\na successor to set theory as the foundation of\nmathematics[48]. Category theory is all about func-\ntions and functors (mappings between one domain\nand another, maintaining isomorphism).\nCategory\ntheory and Lambda Calculus share a common notion\nof relationships between abstract spaces.\nAlthough less understood than the other branches\nof mathematics in this document, Category theory\nis the principal development in mathematics that\ncauses us to think of relationships between entities as\nﬁrst class citizens, along with the entities themselves,\nin the architecture of Cloudplane. Most importantly,\nCategory theory generalizes the notion of composabil-\nity, which is a (not fully realized) goal in the design\nof the Cloudplane Description Language (CDL). The\nnotion of Universal Composability for cryptographic\nprotocols was introduced by Ran Canetti in 2000. It\nhas since been accepted as the ”ultimate” security\ngoal when designing a protocol for some speciﬁc cryp-\ntographic task.\nPeter Selinger provides a categorical Structure\nfor asynchrony, embodied in the π calculus and\nPICT language (See Cloudplane Description Lan-\nguage -CDL document[28].\nThis is the same Pe-\nter Selinger who wrote the First-Order Axioms for\nAsynchrony[38] discussed earlier.\n10.4\nStorage Systems\nStorage units have traditionally exploited coding\nschemes within the unit (e.g. a Reed-Solomon code in\na disk drive, or some erasure code (a subset of which\nis parity) in a RAID array).\nNo\nmatter\nhow\nsophisticated\nthe\nprotection\nscheme inside a unit, there will always be unidentiﬁed\nhazards from outside the unit that can disconnect or\ndestroy the unit, taking it out of operation and mak-\ning its infons (ref) either temporarily or permanently\ninaccessible. For this reason, complete copies of the\nobjects within a storage unit have traditionally been\nreplicated to one or more other storage units, either\nclose-by (to facilitate rapid recovery in case of failure\nin the primary storage unit), or at some distance (to\nprovide resilience to local disasters).\nThere are many perturbations which can destroy\ndata within a set (e.g. software corruption or human\nerror such as accidental deletion or unintended mod-\niﬁcation), so snapshots provide a means by which to\nroll back the data set to some previously consistent\nstate.\nA snapshot is a static ”view” of an object,\nprovided by the underlying ﬁle system.\nContinued\nupdates to the ﬁle may change the ﬁle, but snapshots\nremain stable.\nThe purpose of a storage architecture is to com-\nbine the various techniques of coding and redundant\nunits in some system arrangement inside and between\nthe units to provide a desirable economic tradeoﬀ.\nDigital Physics, Digital Philosophy34\n10.5\nInformation Dispersal\nFor some time, there has been a growing interest by\nacademics in the dispersal of information in order to\nmore eﬃciently utilize the presumed failure indepen-\ndence of nodes in disjoint locations. [REF Current\nWork from NA Doc]\nIn principle, dispersal goes against the principle\nof Monads, and Agents.\nRather than being self-\ncontained, objects are now smeared out across various\nboxes and connected by cables susceptible to human\nand other perturbations. However, despite the poor\nlocal availability of dispersed storage systems, they\nwould appear (at least mathematically) to present a\npotential improvement in distributed availability (e.g.\nthat at some cost in latency and temporal determi-\nnacy, fragments can eventually be reassembled to re-\ntrieve an archived object.\n11\nCloudplane as Mathematics\nWith reference to the above discussion on sheaf the-\nory, there are several LOV-oriented functions intrinsic\nto Cloudplane. These include:\n1. Distributed counting. What is the sum P(x)\nof a particular variable x in the system as a\nwhole? Certain global values in Cloudplane can\nbe ascertained by summing a set of local values.\nThese include:\n• Total capacity: each cell knows its total\navailable storage, its MRC set-usage, and\nits utlization. These values can be com-\nmunicated periodically but lazily to each\n34Ed Fredkin - digitalphilosophy.org\nConﬁdential: REPLICUS Software. Under NDA. CMF. DRAFT November 22, 2010\nPage 17 of 25\nof their neighbors. Over time, this limited\nnumber of parameters represent a stable\nnotion of the “global system state”. How-\never ...\nat any point in time, any cell\ncan locally ascertain something important\nabout these global variables. Such as their\nmagnitude (cardinality), by issuing a local\nquery.\n• Minimum Replica Counts (MRC) for Ob-\njects. MRC is a predicate, maintained by\nCloudplane, for each object on a speciﬁed\ntree.\n• Any other algebraic function over the sys-\ntem as a whole.\nThis includes, addition\nand subtraction (but NOT multiplication\nand division).\nBeing able to compute arithmetic values in a dis-\ntributed fashion is one thing. Being able to do alge-\nbraic manipulations is a higher level function is an-\nother. These operations include:\n• < A relative value, with no guage; only that the\nlocal value is less than the global value.\n• > A relative value, with no guage; only that the\nlocal value is greater than the global value.\n12\nThe Ontology of Time\nAny model of distributed computation must make an\nontological commitment. The commitment we make\nwith Cloudplane is consistent with Relative Quan-\ntum Mechanics (RQM) [33]. The phenomena we try\nto capture includes ...\nVantage Theory[49]\n“Beyond all day-to-day problems in physics,\nin the profound issues of principle that\nconfront us today, no diﬃculties are more\ncentral than those associated with the\nconcept of time”\nJohn Archibald Wheeler\n“It is impossible to mediate on time without\nan overwhelming emotion at the limitations\nof human intelligence”\nAlfred North Whitehead\n12.1\nTemporal Description Logics\nIn the “Description Logic” literature, several ap-\nproaches for representing and reasoning about time\ndependent concepts have been proposed. These tem-\nporal extensions diﬀer from each other in signiﬁcant,\nand incompatible ways:\n• On the ontology35 of time.Whether they adopt\na point-based or an interval-based notion of\ntime. In Cloudplane, a heterarchical and rel-\native ontology is adopted. Other authors use\na point based ontology Interval-based tempo-\nral description logics are usually obtained from\nthe combination with some restriction of the in-\nterval temporal modal logic [External Ref: 8],\nwhich is undecidable in its full power.\n• They diﬀer on the way of adding the tempo-\nral dimension, i.e., whether an explicit notion\nof time is adopted in which temporal operators\nare used to build new formulae, or temporal in-\nformation is only implicit in the language by\nembedding a state-change based language.\n• In an explicit representation of time, there is a\nfurther distinction between an external and an\ninternal point of view; as discussed by Finger\nand Gabbay (ref)\n– In the external method the very same indi-\nvidual can have diﬀerent snapshots in dif-\nferent moments of time that describe the\nvarious states of the individual at these\ntimes. In this case, a temporal logic can\nbe seen in a modular way: while an atem-\nporal part of the language describes the\nstatic aspects, the temporal part relates\nthe diﬀerent snapshots describing in such\na way the dynamic aspects.\n– In the internal method the diﬀerent states\nof an individual are seen as diﬀerent indi-\nvidual components: an individual is a col-\nlection of temporal parts, each one holding\nat a particular moment36; see, for exam-\nple.\n35Ontology is the study of the nature of being, existence or reality, an their categories and relations. It concerns questions\nregarding what entities exist or can be said to exist, and how such entities can be or grouped or related within a hierarchy.\n36Simultaneity alert\nConﬁdential: REPLICUS Software. Under NDA. CMF. DRAFT November 22, 2010\nPage 18 of 25\n12.2\nMathematics and Language\nMathematics is a language where symbols have a pre-\ncise meaning and a logical structure of proofs used as\na foundation on top of which one can deduce fur-\nther proofs.\nUnfortunately, the strict hierarchical\nstructure this logical system implies (ref Hilbert),\nalong with it’s mathematically seductive conclusion\n(ref hilbert) that everything may be logically built up\nfrom a few simple axioms, was demolished by Kurt\nG¨odel in 1931[?], and even more decisively by Alan\nTuring in 1936[50].\nKurt G¨odel proved that in all systems of logic,\nthere would be some insolvable problems[51]. For any\nsystem of logic, there would be things that were true\nbut which could not be proved. At least with G¨odel\nthere was the hope that we could distinguish between\nthe provable and the unprovable, and simply leave\nthe unprovable to one side. But Alan Turing proved\nsomething much more devastating: that there was no\nway of telling which will be the unprovable problems,\nso when do you know when to stop searching for a\nsolution? What Turing did was show that you will\nnever know if the problem you are working on is sim-\nply extraordinary diﬃcult or if it is fundamentally\ninsolvable (the halting problem) (Ref Turing Book).\nThere is no systematic general way of knowing\nthat a problem can be solved. A Turing Complete\nsystem is one in which a program can be written that\nwill ﬁnd an answer (given suﬃcient time and mem-\nory). This reﬂects the notion of computability. The\nopposite: Uncomputable, refers to things that cannot\nbe calculated by any computer.\n13\nHeterarchy\nInter-hierarchy, or heterarchical interactions, are a\nsigniﬁcant theoretical problem in many disciplines.\nIn CDL, they are called out explicitly, so that certain\ntypes of events (object-group consistency operations,\ncross-workspace and cross-tenant sharing, security in-\ncursions, etc.) may create events which trigger rule\ninteractions. Those events represent the crossing of\nboundaries.\n14\nManagement by Sets\nReplicas on Cloudplane are members of one or\nmore “sets”. Unlike Log-structured ﬁlesystems (like\nWAFL), where blocks are also managed as sets in\nsnapshots, and set membership is identiﬁed by a map-\nping to a bitplane, Cloudplane replicas are members\nof an object by virtue of having the same GUID and\nconnected on the same tree. When one cell changes,\nappends, or deletes a replica (or one of its local ten-\nsor dimensions) all replicas of that object will be in-\nformed or updated immediately, lazily or eventually,\naccording to the temporal intimacy speciﬁcation for\nthat object, and the dimension of the tensor that has\nbeen modiﬁed.\n14.1\nAgent Based Modeling Infras-\ntructures\nAgent-based systems (ABS) support a LOV model-\ning approach in the sense that the ontological com-\nmitment of each ABM agent is conﬁned to the net-\nwork of neighbor agents within which it interacts. An\nABM agent starts with a conﬁguration of data and\nmethods constituting its initial understanding of its\nworld. The agent can then migrate from one part of\nits world to another, redeﬁning its locality within this\nworld by adding and deleting links with other agents;\nyet it is always restricted to interactions with other\nagents only one link away. Communication in ABM\nis thus a percolation process, and it is only through\nsuch percolation processes that new data about the\nworld is acquired and global properties emerge.\nOn the other hand, although ABS agents acquire\nnew data constructively through interactions, they\ncan be conﬁgured so that portions of their initial\ndata represent GEV (uncomputable) assertions about\ntheir world. They can also believe GEV assertions\ncommunicated to them by other agents, and they can\nhave methods for interpreting data that entail the use\nof non-constructive deductions (e.g., proof by contra-\ndiction). Thus, as is true for real people, the con-\ntent and timing of the constructive actions that ABS\nagents take within their world can be inﬂuenced by\nuncomputable beliefs.\nABMs’s are related to Cellular Automata (CA),\nwhere a ﬁnite or inﬁnite ﬁxed n-dimensional regular\nlattice of cells performs an abstract computational\nfunction where, for each time step (t), each cell takes\ninputs from each of its immediate neighbors as inputs\nto a simple state machine transition function whose\noutput uniquely determines the state of the cell for\nthe next time step (t+1).\nThere are a number of obvious limitations in CA\nwhen it comes to modeling the real world. The ﬁrst\nis the network of relationships in the real world is, in\nConﬁdential: REPLICUS Software. Under NDA. CMF. DRAFT November 22, 2010\nPage 19 of 25\ngeneral, far from regular, both in the valency (degree)\nof each node, and the inter-node distances spanned\nby the links (edges). The second is the synchronous\nnature of the system as all the cells go in lock-step\nfrom time t to time t+1, a system we refer to as syn-\nchronous Cellular Automata, or SCA.\nThe ﬁrst concern (lattice regularity) is overcome\nby a generalization of CA called Network Automata\n(NA)[52], where the network topology itself is an ar-\nbitrary network of nodes which may be either static,\nas in the ﬁxed infrastructure constraints of railroads,\nfreeways and ﬂight paths along which human agents\ncan travel, or more generally, an evolving topology\nwhich itself is a function of not only the previous-\nstep conﬁguration of the network but of the state of\nthe cells/agents as well.\nAs described by Smith[52]:“While a networks\ntopology constrains the type of dynamics that may\nunfold on it, in many scenarios the dynamical pro-\ncess may inﬂuence the subsequent evolution of the\ntopology - meaning that the structural properties of\nthe network are coupled to its function. A real-world\nexample might be the evolution of transport links\nwithin a city. The dynamics of the human population\nusing this network in turn aﬀect the reinforcement or\nremoval of the those transport links and the feedback\nprocess is apparent.\nA similar situation may arise\nin the context of social networks, where ones current\nsocial opportunities and dynamics are limited by the\nexisting network structure, but they can be widened\nby extending the network.”\nThe second concern (global synchronicity) is\nsomewhat less appreciated, but signiﬁcantly more\nproblematic as we consider ABS’s as a new form of\nmathematics. An assumption of some intrinsic ﬂow of\ntime outside of the cell or agent, and its complimen-\ntary notion of simultaneity [Ref Jammer: Concepts\nin Simultaneity] is simply unsupportable within rel-\nativity, which is one of our most successful and ex-\nperimentally experimentally validated scientiﬁc prin-\nciples. Simply put: simultaneity is a myth, and it has\nproven devilishly diﬃcult to eradicate our distributed\nalgorithms from its seductive familiarity with the way\nwe as humans experience time.\nCA and ABS infrastructures available today in-\nvariably employ some form of simultaneity assump-\ntion, either obviously in the case of synchronous op-\neration (everything occurs within a global time step),\nor even in weakly asynchronous systems (agents may\ncompute asynchronously, but they retain a “tacit as-\nsumption of a global clock” [ref Predrag Tosic - Cel-\nlular Automata for Distributed Computing: Models\nof Agent Interaction and Their Implications] ).\nGenuinely asynchronous systems appear to be ab-\nsent in current academic and commercial ABM/CA\nresearch, despite their clear congruence with the way\nphysics tells us our universe really works. Any explic-\nitly or implicitly created assumption of simultaneity\nis physically unrealistic and must be examined with\nthe utmost care.\nIn strongly asynchronous CA nearby nodes pro-\nvide not only inputs to the update rule for each given\nnode, they “are” the events that trigger the updates.\nThis notion of agent “interaction” as the triggering\nfunction for state machine or network topology evo-\nlution is illuminating: Serialization is determined lo-\ncally from the perspective of each node and all ref-\nerence, conceptual or otherwise, to the notion of a\nglobal clock may now be eliminated. We refer to this\nnotion of agent “interactions” being more fundamen-\ntal than a background time assumption, as Interac-\ntive Cellular Automata, or ICA. This is to distin-\nguish our terminology from previously claimed Asyn-\nchronous Cellular Automata (ACA) which implicitly\npreserved some notion of an external ﬂow of time,\noutside of the agents themselves.\nIt is not diﬃcult to imagine that ICA is a more\nfaithful model of reality than SCA, or even regular\nACA, and there is pretty much conclusive evidence,\nbased on SR alone to justify this model’s elimination\nof simultaneity in its axiomatic structure.\nThe CA transition function is then executed asyn-\nchronously upon the arrival of individual messages\nfrom nodes in its neighborhood, and a subtle but im-\nportant distinction can be seen: all agent updates are\nserialized (their order is determined by the “observa-\ntion” made by the self agent), as discussed above in\nthe section in observables, this order of events may\nbe unique for each agent (observer) and we cannot\nformulate any coherent GEV view of events in a dis-\ntributed system, unless additional (artiﬁcial) order-\ning constraints are forced on the system operation,\nsuch as with a global clock, or some form of Lamport\ntimestamps (scalar, vector, or matrix), which while\nthey have the desirable property of preserving the\norder of events emitted by each source, also have the\nundesirable property of artiﬁcially constraining the\navailable concurrency in the system.\nConﬁdential: REPLICUS Software. Under NDA. CMF. DRAFT November 22, 2010\nPage 20 of 25\n14.2\nObservables and Interactions\nThis key discovery, over a century ago now, that time\nis relative to the observer provides a sobering les-\nson to anyone trying to simulate reality in a com-\nputer model. However, recent progress in physics has\ntaken this one step further: Rovelli[33] has identiﬁed\na startling conclusion based on the elimination of the\nnotion of a privileged role of an observer in physics.\nIn this perspective, all properties of a system can only\nbe determined relative to an observer, not just dura-\ntions of time, or lengths within a Minkowski space-\ntime as in special relativity. Furthermore, a system’s\nevolution is fundamentally perturbed by any observa-\ntions, because they are interactions too. Rovelli goes\non to show that even the notion of observer-observee\nmust be symmetric: all agents are relative observers\nof each other in a ﬁeld of mutual interactions, each of\nwhich inﬂuence the evolution of the overall system.\nIn probability theory, the Borel paradox relates to\nthe conditional probability with respect to an event\nof probability zero (the null set). The paradox lies in\nthe fact that a conditional distribution with respect\nto such an event is ambiguous unless it is viewed as an\nobservation from a continuous random variable. Fur-\nthermore, it is dependent on how this random vari-\nable is deﬁned.\n14.3\nBackground Independence\nThe duality of Agent Based Models (ABM) and\nAgent Based Systems (ABS) can be seen as a vali-\ndation of the isomorphism of the simulation to ob-\nserved reality. Unlike diﬀerential equations, ABM’s\ncan directly map the number and types of agents in\nthe ABS to the number and types of entities in the\nreal world we wish to simulate.\nAll forms of CA have in common the notion of\na fundamental neighborhood (A set of neighbors N,\nto which each agent is directly connected). NA al-\nlows us to construct real or virtual topologies, where\nthe links between cells represent spatial or other con-\nstraints along which interactions can occur.\nIt be-\ncomes natural, therefore, to separate out the layer of\ninteractions which exist on top of the layer which de-\nﬁnes the network topology. NA allows the network\ntopology to evolve also. Smith et al.[52] also deﬁne a\nresource layer which keeps track of the resources pro-\nvided to or available for future interactions in their\nmodel of fungal growth.\nProviding a layered abstraction has proven invalu-\nable in many computer architecture (and other in-\nfrastructure designs). However, we would like to add\none more layer, which to the best of our knowledge\nhas never before appeared in theories of computer\nmodeling, or for that matte, in distributed systems\ndesign. This is the layer that physicists have called\nthe background. General Relativity is a Background\n-independent Theory, whereas conventional Quantum\nMechanics “exists” (∃) within a background of space\nand time which is static and considered to be evolv-\ning. By insisting on a layer in ABS that we call the\nbackground layer, we can more faith fully represent\nthe relational context between agents, and treat time\nas a source of change, and not as some Newtonian\nBackground that was proven incorrect over a hundred\nyears ago. In this way, we no longer need to implic-\nitly accept the temporal structure of simultaneity or\na synchronous global clock as the water in which our\ndistributed systems must swim as ﬁsh.\n15\nConclusions\nThe primary motive for this architectural alternative\nis the conjecture that there is something fundamental\nmissing from our understanding of how to build reli-\nable distributed systems out of computers and soft-\nware. The computer literature is ﬂooded with proofs\nof undecidability, impossibility, or other forms of cor-\nrectness; but being correct is not the same as being\nright37. History has shown the limitations of certi-\ntude regarding the potential for completeness, when\nconstrained to a limited domain of discourse38.\n[]\n37Alexander Stepanov: Elements of Programming. Lecture given at Stanford University, 3-Nov-2010\n38Wir m¨ussen wissen. Wir werden wissen. David Hilbert, 1862-1943\nConﬁdential: REPLICUS Software. Under NDA. CMF. DRAFT November 22, 2010\nPage 21 of 25\nReferences\n[1] IBM,\n“An architectural blueprint for autonomic\ncomputing.”, white paper, 2004.\n[2] Microsoft\nResearch,\n“The\nrise\nand\nrise\nof\nthe\ndeclarative\ndatacen-\ntre”,\nhttp://research.microsoft.com/en-\nus/events/riseandrise/, 2008.\n[3] Robert Goldblatt, “Mathematical modal logic: A\nview of its evolution”, in Handbook of the History of\nLogic. Dov M. Gabbay and John Woods (Editors).,\nvol. 6. Elsevier BV, 2005.\n[4] dido,\n“God\nmade\nthe\nintegers,\nall\nelse\nis\nthe\nwork\nof\nman@Everything2.com”,\nhttp://everything2.com/title/God+made+the+integers%252C+all+else+is+the+work+of+man,\n2004.\n[5] G. J Chaitin,\n“Algorithmic information theory:\nSome recollections”, math/0701164, Jan. 2007.\n[6] G. Chaitin, “How real are real numbers?”, Interna-\ntional Journal of Bifurcation and Chaos in Applied\nSciences and Engineering, vol. 16, no. 6, pp. 1841,\n2006.\n[7] Paul. J. Cohen, “The independence of the contin-\nuum hypothesis (Part II and part II)”, Proceedings\nof the National Academy of Sciences of the United\nStates of America, vol. 50, no. 6, pp. 1143–1148,\nDec. 1963.\n[8] Stuart Kauﬀmann, “Is there a ’Poised realm’ be-\ntween the quantum and classical worlds?\n: 13.7:\nCosmos and culture : NPR”, Mar. 2010.\n[9] Jacob D. Bekenstein, “Black holes and entropy”,\nPhysical Review D, vol. 7, no. 8, Apr. 1973.\n[10] C. E Shannon, “A mathematical theory of commu-\nnication”, The Bell System Technical Journal, vol.\n5, no. 1, pp. 55, 2001.\n[11] Alessandro Artale, Enrico Franconi, Frank Wolter,\nand Michael Zakharyaschev, “A temporal descrip-\ntion logic for reasoning over conceptual schemas and\nqueries”, 2002.\n[12] David H Wolpert,\n“Physical limits of infer-\nence”, 0708.1362, Aug. 2007, PhysicaD237:1257-\n1281,2008.\n[13] Robert I Soare,\n“Computability and recursion”,\nBulletin of Symbolic Logic, vol. 2, pp. 284—321,\n1996.\n[14] Douglas Bridges and Steve Reeves,\n“Construc-\ntive mathematics, in theory and programming prac-\ntice”, 1997.\n[15] K. Ambos-Spies and P. A Fejer, “Degrees of un-\nsolvability”, to appear, 2006.\n[16] Jeannette Wing, “Five deep questions in comput-\ning”, Communications of the ACM, vol. 51, no. 1,\nJan. 2008.\n[17] Lee Smolin,\n“The case for background indepen-\ndence”, July 2005.\n[18] Fotini Markopoulou,\n“New directions in back-\nground independent quantum gravity”, 2007, Ap-\nproaches to Quantum Gravity - toward a new un-\nderstanding of space, time, and matter, Cambridge\nUniversity Press.\n[19] Oregon State, “The mondology of G.W. leibniz”,\nhttp://oregonstate.edu/instruct/phl302/texts/leibniz/monadology.ht\n2009.\n[20] Carl Hewitt, “Actor model of computation”, ArXiv\n1008.1459, Aug. 2010.\n[21] Paul\nL.\nBorrill\nand\nLeigh\nS.\nTesfat-\nsion,\n“Agent-Based\nmodeling:\nThe\nright\nmathematics\nfor\nthe\nsocial\nsciences?”,\nhttp://www.econ.iastate.edu/tesfatsi/ABMRightMath.PBLTWP.pdf\n2010.\n[22] R. Laubenbacher, A. S Jarrah, H. Mortveit, and\nS. S. Ravi, “A mathematical formalism for agent-\nbased modeling”, Arxiv preprint arXiv:0801.0249,\n2007.\n[23] Neil Gershenfeld, The Physics of information Tech-\nnology,\nCambridge University Press, Cambridge,\nNew York, 2000.\n[24] Gregory\nChaitin,\n“Leibniz,\ncom-\nplexity,\nand\nincompleteness”,\nhttp://www.cs.auckland.ac.nz/˜chaitin/apa.html,\n2007.\n[25] Gregory Chaitin, “The search for the perfect lan-\nguage”, 2009.\n[26] Robin Milner, Joachim Parrow, and David Walker,\n“A calculus of mobile processes (Parts i and II)”,\nInformation and Computation, vol. 100, pp. 177,\n1992.\n[27] Robin Milner, “The polyadic pi-calculus: a tuto-\nrial”, Tech. Rep. ECSLFCS91180, Laboratory for\nFoundations of Computer Science, Department of\nComputer Science, University of Edinburgh, UK,\nOct. 1991,\nAppeared in \\em Proceedings of the\nInternational Summer School on Logic and Alge-\nbra of Speciﬁcation, Marktoberdorf, August 1991.\nReprinted in \\em Logic and Algebra of Speciﬁca-\ntion, ed. F. L. Bauer, W. Brauer, and H. Schwicht-\nenberg, Springer-Verlag, 1993.\n[28] Peter Selinger,\n“Categorical structure of asyn-\nchrony”, Electronic Notes in Theoretical Computer\nScience, vol. 20, pp. 158–181, 1999.\n[29] Neil D Jones and Nina Bohr, “Call-by-value termi-\nnation in the untyped lambda-calculus”, 0801.0882,\nJan. 2008, LMCS-2007-238.\nConﬁdential: REPLICUS Software. Under NDA. CMF. DRAFT November 22, 2010\nPage 22 of 25\n[30] Benjamin C Pierce,\n“Programming in the Pi-\nCalculus: a tutorial introduction”, 1996.\n[31] Jeanette M. Wing, “FAQ on $\\pi$-calculus”, Mi-\ncrosoft Research Journal, 2002.\n[32] L. Lamport, Arbitration-free synchronization, 2003.\n[33] Carlo Rovelli,\n“Relational quantum mechanics”,\nquant-ph/9609002, Aug. 1996,\nInt. J. of Theor.\nPhys. 35 (1996) 1637.\n[34] Lorenzo Maccone,\n“Quantum solution to the\nArrow-of-Time dilemma”, Physical Review Letters,\nvol. 103, no. 8, pp. 080401–4, 2009.\n[35] Seth Lloyd, Programming the Universe: A Quan-\ntum Computer Scientist Takes On the Cosmos,\nKnopf, 1st edition edition, Mar. 2006.\n[36] Daniel B. Miller and Edward Fredkin, “Two-state,\nreversible, universal cellular automata in three di-\nmensions”, in Proceedings of the 2nd conference on\nComputing frontiers - CF ’05, Ischia, Italy, 2005,\np. 45.\n[37] Stephen Wolfram, A new kind of science, Wolfram\nMedia, Champaign IL, 2002.\n[38] Peter Selinger,\n“First-Order axioms for asyn-\nchrony”, IN PROC. CONCUR, vol. 1243, pp. 376—\n390, 1997.\n[39] Kohei Honda and Mario Tokoro, “An object cal-\nculus for asynchronous communication”, Proceed-\nings of the European Conference on Object-Oriented\nProgramming (ecoop, vol. 512, pp. 133—147, 1991.\n[40] Cdric Fournet, Georges Gonthier, Jean-Jacques\nLvy, Luc Maranget, and Didier Rmy, “A calculus\nof mobile agents”, in 7th International Conference\non Concurrency Theory (CONCUR’96), Pisa, Italy,\nAug. 1996, p. 406421, Springer-Verlag, LNCS 1119.\n[41] Romain\nBeauxis,\nCatuscia\nPalamidessi,\nand\nFrank D. Valencia, “On the asynchronous nature\nof hte pi-calculus”,\nin Concurrency, Graphs and\nModels:, vol. 5065 of Lecture Notes in Computer\nScience. Springer Berlin Heidelberg, Berlin, Heidel-\nberg, 2008.\n[42] E Haghverdi and P Scott, “A categorical model for\nthe geometry of interaction”, Theoretical Computer\nScience, vol. 350, no. 2-3, pp. 252–274, 2006.\n[43] Benjamin C. Pierce, Basic category theory for com-\nputer scientists, MIT Press, Aug. 1991.\n[44] Herbert A. Simon, “The architecture of complex-\nity”, Proceedings of the American Philosophical So-\nciety, vol. 106, no. 6, pp. 467–482, Dec. 1962, Ar-\nticleType: research-article / Full publication date:\nDec. 12, 1962 / Copyright\n1962 American Philo-\nsophical Society.\n[45] Paul Borrill, “Designing systems for ultra resilience.\nslide presentation, see slides 16, 18, 19, 21”, in Con-\nference Notes, Brussels, Belgium, July 2002, TTI\nVanguard.\n[46] Joseph A Goguen, “Sheaf semantics for concurrent\ninteracting objects”,\nMathematical Structures In\nComputer Science, vol. 2, pp. 159—191, 1992.\n[47] Kenneth\nLloyd,\n“A\nCategory-Theoretic\nap-\nproach to agent-based modeling and simulation -\nSwarmWiki”, Santa Fe, NM, 2010, Watt Systems\nTechnologies.\n[48] John C Baez and Mike Stay,\n“Physics, topol-\nogy, logic and computation:\nA rosetta stone”,\n0903.0340, Mar. 2009.\n[49] Keith Allan, “Vantage theory and linguistic relativ-\nity”, Language Sciences, vol. 32, no. 2, pp. 158–169,\nMar. 2010.\n[50] A. M. Turing, “On computable numbers, with an\napplication to the entscheidungsproblem”, Proceed-\nings of the London Mathematical Society, vol. s2-42,\nno. 1, pp. 230–265, 1937.\n[51] Kurt Godel,\nOn Formally Undecidable Proposi-\ntions of Principia Mathematica and Related Sys-\ntems, Dover Publications, Apr. 1992.\n[52] David M. D Smith, Jukka-Pekka Onnela, Chiu Fan\nLee, Mark Fricker, and Neil F Johnson, “Network\nautomata: Coupling structure and function in real-\nworld networks”, physics/0701307, Jan. 2007.\n[53] MM Fokkinga,\n“A gentle introduction to cate-\ngory theory — the calculational approach”, Lecture\nNotes of the STOP 1992 Summerschool on Con-\nstructive Algorithmics, 1992.\n[54] Michael J. Fischer, Nancy A. Lynch, and Michael S.\nPaterson,\n“Impossibility of distributed consensus\nwith one faulty process”, J. ACM, vol. 32, no. 2,\npp. 374–382, 1985.\n[55] Maurice P Herlihy and Jeannette M Wing, “Lin-\nearizability: a correctness condition for concurrent\nobjects”, ACM Transactions On Programming Lan-\nguages and Systems, vol. 12, no. 3, pp. 463—492,\nJuly 1990.\n[56] Benjamin Wester, James Cowling, Edmund B.\nNightingale, Jason Flinn, Peter M. Chen, and Bar-\nbara Liskov, “Tolerating latency in replicated state\nmachines”.\n[57] Robert Jan van Glabbeek,\n“Comparative con-\ncurrency semantics and reﬁnement of actions”,\nhttp://theory.stanford.edu/˜rvg/thesis.html#introduction.\n[58] Matteo Smerlak and Carlo Rovelli,\n“Relational\nEPR”, Foundations of Physics, vol. 37, no. 3, pp.\n427–445.\nConﬁdential: REPLICUS Software. Under NDA. CMF. DRAFT November 22, 2010\nPage 23 of 25\n[59] W. K Lin, D. M Chiu, and Y. B Lee, “Erasure code\nreplication revisited”, in 4th International Confer-\nence on Peer-to-Peer Computing. IEEE, 2004, pp.\n90—97.\n[60] Leslie Lamport,\n“Marked graphs (A discussioin\nin lamport’s Arbitration-Free synchronization pa-\nper).”, 2003.\n[61] Edith Cohen, Eran Halperin, Haim Kaplan, and Uri\nZwick,\n“Reachability and distance queries via 2-\nHop labels”, 2002.\n[62] L. Lamport and P. M. Melliar-Smith, “Synchroniz-\ning clocks in the presence of faults”, Journal of the\nACM (JACM), vol. 32, no. 1, pp. 52–78, 1985.\n[63] E. N. ( Mootaz) Elnozahy, Lorenzo Alvisi, Yi min\nWang,\nand David B Johnson,\n“A survey of\nRollback-Recovery protocols in Message-Passing\nsystems”, 1996.\n[64] David H Wolpert and Gregory Benford,\n“What\ndoes newcomb’s paradox teach us?”,\n1003.1343,\nMar. 2010.\n[65] M. Smerlak,\n“Relational quantum mechanics”,\n2006.\n[66] Alessandro Duminuco, Ernst Biersack, and Taouﬁk\nEn-Najjary,\n“Proactive replication in distributed\nstorage systems using machine availability estima-\ntion”, Proceedings of CoNEXT 07, Dec. 2007.\n[67] Matthias Radestock and Susan Eisenbach, “What\ndo you get from a pi-calculus semantics?”.\n[68] Joachim Parrow and Davide Sangiorgi,\n“Alge-\nbraic theories for Name-Passing calculi”,\nJour-\nnal of Information and Computation, vol. 120, no.\n2, pp. 174197, 1995,\nAn earlier version appeared\nas University of Edinburgh technical report EC-\nSLFCS93262 and in the proceedings of the REX\nSummer School/Symposium 1993, (Springer Ver-\nlag, LNCS 803).\n[69] R. J. van Glabbeek, “The linear time\nbranching\ntime spectrum II (The semantics of sequential sys-\ntems with silent moves)”, in Proceedings of CON-\nCUR ’93, 1993, p. 6681.\n[70] R. J. van Glabbeek, “The linear time\nbranching\ntime spectrum”,\nin Proceedings of CONCUR’90,\nJ. C. M. Baeten and J. W. Klop, Eds. 1990, LNCS\n458, p. 278297, Springer-Verlag.\n[71] James P Crutchﬁeld, Christopher J Ellison, and\nJohn R Mahoney,\n“Time’s barbed arrow:\nIr-\nreversibility, crypticity, and stored information”,\n0902.1209, Feb. 2009.\n[72] Martijn Oostdijk, Generation and Presentation of\nFormal Mathematical Documents, PhD thesis, Uni-\nversiteitsdrukkerij, Eindhoven, 2001.\n[73] Gregory Chaitin, “The halting probability omega:\nIrreducible complexity in pure mathematics”, 2006.\n[74] Alonzo Church, “A note on the entscheidungsprob-\nlem”, Journal of Symbolic Logic, vol. 1, no. 1, Mar.\n1936.\n[75] David Chiyuan Chu,\nBuilding and Optimizing\nDeclarative Networked Systems.,\nPhD thesis, UC\nBerkeley, UCB/EECS-2009-91, June 2009.\n[76] Leslie\nLamport,\nLeslie\nLamport,\nand\nKeith\nMarzullo,\n“The Part-Time parliament”,\nACM\nTRANSACTIONS ON COMPUTER SYSTEMS,\nvol. 16, pp. 133—169, 2000.\n[77] Julian Gutierrez, “Logics and games for true con-\ncurrency”, 1011.1172, Nov. 2010.\n[78] Alexander Stepanov and Paul McJones, Elements\nof Programming,\nAddison-Wesley Professional, 1\nedition, June 2009.\n[79] Donald E. Knuth, Art of Computer Programming,\nVolume 4, Fascicle 4: Generating All Trees–History\nof Combinatorial Generation, Addison-Wesley Pro-\nfessional, 1 edition, Feb. 2006.\n[80] Roberto Bruni, Fabio Gadducci, and Alberto Lluch\nLafuente, “An algebra of hierarchical graphs”, Lec-\nture Notes in Computer Science.\n[81] Peter Sewell, Pawe T. Wojciechowski, and Asis Un-\nyapoth,\n“Nomadic pict”,\nACM Transactions on\nProgramming Languages and Systems, vol. 32, no.\n4, pp. 1–63, 2010.\n[82] Edward N. Zalta, Basic Concepts in Modal Logic,\nCenter for the Study of Language and Information\nStanford University, 1995.\n[83] A.S. Yessenin-Volpin, J. Myhill, and R.E. Vesley A.\nKino,\n“The Ultra-Intuitionistic criticism and the\nantitraditional program for foundations of mathe-\nmatics”,\nin Intuitionism and Proof Theory: Pro-\nceedings of the Summer Conference at Buﬀalo N.Y.\n1968, vol. Volume 60, pp. 3–45. Elsevier, 1970.\n[84] A.S.\nYessenin-Volpin,\n“Le\nprogramme\nultra-\nintuitioniste des fondements des mathematiques”,\nInﬁnitistic Methods, vol. 1961, pp. 201–223, 1961.\n[85] Fred Richman, Ed., Constructive Mathematics, vol.\n873, Springer Berlin Heidelberg, 1981.\n[86] Mathieu Marion, Wittgenstein, Finitism, and the\nFoundations of Mathematics,\nOxford University\nPress, Sept. 2008.\n[87] Miguel Castro and Barbara Liskov,\n“Practical\nbyzantine fault tolerance and proactive recovery”,\nACM Transactions on Computer Systems, vol. 20,\nno. 4, pp. 398–461, 2002.\n[88] Emil Sit, Andreas Haeberlen, Frank Dabek, Byung\ngon Chun, Hakim Weatherspoon, Robert Mor-\nris, M. Frans Kaashoek, and John Kubiatowicz,\nConﬁdential: REPLICUS Software. Under NDA. CMF. DRAFT November 22, 2010\nPage 24 of 25\n“Proactive replication for data durability”, In Pro-\nceedings of the 5th Intl Workshop on Peer-to-Peer\nSystems (iptps, 2006.\n[89] Lera Boroditsky, “Linguistic relativity”.\n[90] Lera\nBoroditzky,\n“Boroditsky\n-\npapers”,\nhttp://www-psych.stanford.edu/˜lera/papers/,\n2010.\n[91] Zahia Guessoum and Jean-Pierre Briot, “From ac-\ntive objects to autonomous agents”, 1999.\n[92] Gul Abdulnabi Agha,\n“ACTORS: a model of\nconcurrent computation in distributed systems”,\nhttp://dspace.mit.edu/handle/1721.1/6952, 1986.\n[93] Yong Shi, Geert Dick Albada, Jack Dongarra, and\nPeter M. A. Sloot, Eds.,\nComputational Science\nICCS 2007, vol. 4489, Springer Berlin Heidelberg,\nBerlin, Heidelberg, 2007.\n[94] Benjamin C. Pierce, Types and Programming Lan-\nguages, The MIT Press, 1 edition, Feb. 2002.\n[95] “The\nphilosophy\nof\ncomputer\nscience\n(Stanford\nencyclopedia\nof\nphilosophy)”,\nhttp://plato.stanford.edu/entries/computer-\nscience/.\n[96] “DigitalPhilosophy.org\n>\nhome”,\nhttp://www.digitalphilosophy.org/.\n[97] Benjamin C Pierce and David N Turner, “Pict: A\nprogramming language based on the pi-calculus”,\nProof, Language and Interaction: Essays in Hon-\nour of Robin Milner, pp. 455—494, 1997.\n[98] Henk Barendregt, S. Abramsky, D. M Gabbay,\nT. S. E Maibaum, and H. P Barendregt, “Lambda\ncalculi with types”,\nHANDBOOK OF LOGIC\nIN COMPUTER SCIENCE, vol. 2, pp. 117—309,\n1992.\n[99] C. A. R Hoare,\n“Communicating sequential pro-\ncesses”, pp. 666—677, 2004.\n[100] Davide Sangiorgi,\n“Locality and non-interleaving\nsemantics in calculi for mobile processes”, THEO-\nRETICAL COMPUTER SCIENCE, vol. 155, 1994.\n[101] Peter Selinger, “A survey of graphical languages for\nmonoidal categories”, 0908.3347, Aug. 2009.\n[102] Jean Krivine, Vincent Danos, Jerome Feret, and\nWalter Fontana, “Programs as models: Kappa lan-\nguage basics”, Oct. 2008.\n[103] Jean Krivine, Vincent Danos, Jerome Feret, Russ\nHarmer, and Walter Fontana, “Programs as mod-\nels: Execution”, Oct. 2008.\n[104] Joachim Parrow, “An introduct to the pi-Calculus”,\nin Handbook of Process Algebra, editors: Bergstra,\nPonse and Smolka. Elsevier, 2001.\n[105] Peter Selinger, “Lecture notes on the lambda cal-\nculus”, 0804.3434, Apr. 2008.\n[106] Martin\nFrer,\n“Deterministic\nautopoietic\nau-\ntomata”, 0911.2324, Nov. 2009, EPTCS 9, 2009,\npp. 49-53.\n[107] Pierpaolo Degano, Rocco Nicola, and Jos Meseguer,\nEds.,\nConcurrency,\nGraphs and Models,\nvol.\n5065,\nSpringer Berlin Heidelberg, Berlin, Heidel-\nberg, 2008.\nConﬁdential: REPLICUS Software. Under NDA. CMF. DRAFT November 22, 2010\nPage 25 of 25\n"
  },
  {
    "filename": "FAQ/CASE.pdf",
    "content": "æthernet and switched networks\n1\nThe Case for Reliable Atomic Links\nRcv\nSnd\nSnd\nRcv\nBob\nAlice\nGreen: Forward Evolution\nBlue: Reverse Evolution\nForward Progress (+1)\nReverse Progress (-1)\nTernary Logic Link\nEquilibrium = 0\nFigure 1: Two CELLs and a LINK with\nconserved quantities, epistricted with\nTernary, or Three-valued logic [1]\nPROBLEM:\nMany latency, Inconsistency, and Unbounded problems encountered in\ndistributed systems today arise from our inability to distinguish between\na node that is merely slow from one that has failed or become unreach-\nable due to network failure.\nWe take the two most recognizable elements in datacenters today:\nservers and switches, and refactor them into simpler, fully independent\nfailure domains: CELLs and LINKs. A CELL is a universal node: an\nautonomous unit of compute, storage and packet processing. A LINK\nis a bidirectional communication-element; an autonomous commu-\nnication entity between two CELLs)1. Physically, the LINK comprises\n1 Think of CELLs in Cellular automata.\nThink of LINKs as compute elements\nwith their own autonomous and in-\ndependent failure domain (Local\nINformation and Knowledge). In the\nsame way devices within a single ex-\necution environment are considered\na single failure domain; the LINK can\ndetect device and cable errors and make\nthe machine stop. The challenge is how\nto get it started again. The solution is\ntriangle networks: Tripartite directly\nconnected graphs.\nthe cable and SerDes’ on both ends to form a self contained execution\nenvironment.\nUnifying node elements makes things simpler because we have\nonly one type of node to manage instead of two. We raise the notion\nof a LINK to first order – a first-class citizen in the infrastructure – a\nbipartite element of conserved information with two complementary\nhalves – persistable through failure and recovery events. i.e., a com-\nmunication object that doesn’t rule out that some local fault-detection\nand computation is involved.\nPhysical LINKs Implement utilities that used to be in logical link\ndomains above L2: in L3, L4, or L7; composed into an abstraction of\nlogical links. This is an illusion. If the pairing of Shannon informa-\ntion is thrown away at layer 2, it cannot be recovered in higher layers.\nThis is addressed in more detail in the Key Issue section below.\nAn example2 LINK utility is The I Know That You Know That I Know\n2 Synchronization of timing domains\nin computers generally start from the\nprocessor clock on the motherboard,\nand fan out through the logic into the\nI/O subsystems. IUI lives in the LINK\nbetween two independent computers,\nand although it receives information\nfrom either side, it is not synchronized\nwith either side. This independent\nasynchronous domain (already ex-\nploited in the HFT Industry) – enables\nfailure independence and atomicity.\n(TIKTYKTIK) property; which enables us to address some of the most\ndifficult and pernicious problems in distributed systems today.\nAnother example LINK utility is Indivisible Unit of Information (IUI).\nUnlike replicated state machines (RSM’s) used throughout distributed\napplications today, LINKs are state machines: the two halves of which\nmaintain shared state through hidden packet exchanges. When a local\nagent or actor is ready, theIUI protocol transfers indivisible tokens\nacross the LINK to the other agent, atomically (all or nothing) 3.\n3 LINKs are exquisitely sensitive to packet\nloss. This is intentional: we turn the\nFLP result upside down, and use “a\nsingle unannounced process death” to\nguarantee the atomic property for IUI.\n[2]\nTIKTYKTIK andIUI properties are mathematically compositional.\nTrees of LINKs provide a deterministic conserved quantities mech-\nanism to reliably distribute indivisible tokens among agents on an\napplication graph. Intermediate CELLs promise [3] 4 to never lose\n4 The alternative definition of Fu-\ntures/Promises also applies: execution\nis primed to create future liveness events.\nIUI tokens. This defends against lost tokens because if any part of\nthe chain (or trtee) breaks. Alternate paths are available to seamlessly\næthernet and switched networks\n2\nrecover the conserved quantity and continue operation5.\ndation for distributed system services for\napplications: consensus, atomic broad-\ncast, leader election, cluster member-\nship and distributed arithmetic, Which,\nin-turn, enable higher level functions\nsuch as network-assisted-transactions\nwhich serve, for example, distributable\n(scale-out), persistable (durable), and\nlightweight (but-accurate) accounting\nof conserved quantities associated with\napplication state or resource usage.\nFor maximum efficiency, both sides of the link should be ple-\nsiochronous [4]; keeping snakes circulating at the same rate through\nboth transmit and receive channels.\nA New Law: Conservation of TOKENS\nBy strengthening the system model, LINK s and IUI tokens provide a\ngeneral foundation to solve many distributed-systems problems such as\nfailure detection, consensus, and atomic transactions.\nProblem\n• Sixteen years ago, CPU-Bound tasks, such as buffer pool and con-\ncurrency control, were the primary bottlenecks in OLTP databases.\nToday, communication overhead is the dominant factor affecting\nperformance [5].\n• Timeouts & retries (TAR) are the “root of all evil\" in distributed\nsystems [6]. They lead to Congestion, Cascade Slowdowns: Retry\nStorms, Metastable Failures, Limpware, Transaction Failure, and\nSilent Data Corruption – which leads to lost and corrupted trans-\nactions in all distributed systems, including databases.\nFailure Modes\nOne might imagine6 if each host (or its SmartNIC) maintains its half\n6 Such a recovery mechanism is not\navailable through conventional\nswitched networks; because of the\nuncertainty of how many packets\nwere lost, exactly where along the\npath through the switched network\nthey were lost, how many were dupli-\ncated, and how they might have been\nre-ordered in the switched network.\nof the shared state, then shouldn’t the switched network be able to\nact as a proxy for a single logical LINK? When a switched network\nfails, and reroutes, can’t the two sides (SmartNICs) just stitch the two\nhalves of the shared state back together again? we could achieve the\nproperties of LINKs over existing switched networks.\nThis simple hazard analysis7 misses a fundamental issue: networks\n7 Typical hazards: (1) Servers with a\nLINK to a single Top of Rack Switch\n(ToR) are unable to heal at all; there is\nonly one path from the server to anyone.\n(2) ToRs represent SPoFs; when they\nfail, many servers (in that rack) also\nbecome unavailable. Worse still: the\nservers don’t go down, they keep on\ncomputing but don’t know they are\nisolated. ToRs have also been known to\nexhibit complex cascade failures where\na firmware failure triggered in one will\ntake down many neighbor TORs.\ndon’t maintain state on behalf of applications. Switches drop packets\n(and state) whenever they feel like it, so there are many more ways\nfor logical link ts to get confused over switched networks [7] and\ncompromise the integrity of the shared state.8\n8 Even without failures, the behavior\nof switched networks forces us into a\nhigh overhead approach. If packets can\nbe indiscriminately dropped, delayed,\nduplicated and reordered, we have no\nchoice but to implement TCP/IP sender\ntimeouts, Even in optimal situations,\nTCP introduces high complexity and\noverhead and unbounded latency\nfor all operations, which is too slow.\nThere is no escape: if we drop, delay\nduplicate or reorder packets, you have\nto effectively implement TCP. If we can\neliminate duplication and re-ordering,\nrecovery is far simpler, and removes the\ntail latency from normal operations.\nKey issue: Switched networks drop packets anywhere along the\nnetwork path; eradicating state and events needed to maintain\npromises and liveness respectively. When a LINK fails, both sides\nare preserved. If there is an atomicity violation in the IUI it can\nalways be detected, and retransmissions occur only on a real fail-\nure (such as disconnection–where alternative routes are explicitly\næthernet and switched networks\n3\ncoordinated with applications), thus enforcing that IUI tokens\nhave no duplicate or out of order deliveries on the LINK.\nSwitched Networks\nWhen packets are dropped in a switched network, more than infor-\nmation is lost, events are lost, and it becomes extraordinarily difficult\nto recover both sides of a shared state that stretches across even a sin-\ngle switch. 9\n9 LINKs do not reorder or duplicate\npackets so we can now use a high-\nperformance payload operator in\nAtomic Ethernet for coherence; only\npaying the performance cost of TCP\nwhen it fails for real, i.e. disconnection.\nRemarkably, this also paves the way for\nvery high bandwidth utilization for dat-\nacenter to datacenter application flows,\nbecause it eliminates the most difficult\naspects of reordering and duplication\nof packets. In scale-out/massively\ndistributed architecture.\nNot sure dropped packets are the right hazard to mention here “the protocol is\nexquisitely sensitive to packet loss”. What really destroys state as shown in the\nAfek et al. paper was RACE CONDITIONS on every packet transmission (delay +\nreorder), with the proposed solution being essentially E2E Stop and wait [8]\nA directly connected LINK can promise [3] three things a switched\nnetwork cannot: (a) maintain an ordering of events (heal, send\npackets, fail, heal again, send more packets) – essential for non-\nidempotent and non-commutative operations. (b) not drop certain\npackets without notification – essential for recovery. And (c) main-\ntain complementary direction state – essential for distributed self-\nstabilizing algorithms with local rerouting rules for reliable trees. 10\n10 Actually, a LINK can promise many\nmore than just these three things: what-\never property the agent or application\nwishes to attach to the bipartite LINK\nobject.\n11\n11 Reversible IUI enables the rever-\nsal of non-idempotent structures in\ndistributed applications.\nWhat’s necessary is an entanglement between state machines – lock-\ning them together silently in normal operation, and failing locally\nat the first failure. The entanglement cannot be recovered if infor-\nmation from events can disappear. This is the only solution to the\nlatency–disconnection ambiguity [9]. To put it in terms an engineer\ncan internalize, a system that fails instantly, can heal immediately.\nBipartite Integrity and the E2E Principle\nThe End-to-End (E2E Principle 12\n12 The end-to-end principle states that in\na general-purpose network, application-\nspecific functions ought to reside in the\nend hosts of a network rather than in\nintermediary nodes, provided that they\ncan be implemented “completely and\ncorrectly” in the end hosts. Our claim\nis that it is impossible to implement\nbidirectional synchronization primitives\n“completely and correctly” without\nIUI (or something very much like it).\nThe datacenter is not the Internet, and\nSaltzer, Reed, & Clark considered one-\nway (unidirectional) file transfer, not the\nbidirectional synchronization of replicas\n(token coherency) described here.\nThe shared state property is strengthened by mechanisms to recover\nfrom each type of failure. The more types of failures, the more com-\nplex and intractable this becomes. The LINK combines the failure\ndomains of SerDes, cables, connectors and are independent failure\ndomains, with (effectively) one failure hazard: disconnection13; which\n13 In any physical system it is possible\nto drop packets, it will be much rarer\nbut it is still possible. LINKs can recover\nfrom individually dropped or corrupted\npackets, and shared state integrity can be\nmaintained through out the successive\nreversibility recovery – back to the\nequilibrium state.\nis straightforward to recover from. Switched networks, on the other\nhand, have many more failure hazards: they indiscriminately drop,\ndelay, duplicate and reorder packets – that’s just the way networks\nbehave – justified by the end-to-end argument [7], [10]\næthernet and switched networks\n4\nReversibility\nIn physics, time-symmetry is the universal property by which energy\nis conserved. In OAE, reversibility ensures the conservation ofIUI\ntokens because traffic on the link stops, and the complimentary state\non both sides of the link is preserved until higher level protocols\n(triangle relationships) where the 3rd CELL (Transaction Manager\nRole) is able to perform “successive reversibility\", heal the link, and\nreturn the protocol back to the equilibrium state.\nThe shared state TIKTYKTIK property can also be used to mitigate\nbroadcast storms in network rendezvous, timeout storms in microser-\nvices, or reconstruction storms in erasure coded storage14. InIUI,\n14 LINKs also coalesce heartbeats to\nmake microservices more scalable, and\nmake failure detectors reliable.\npackets are not merely dropped, they are replaced with special events\ndenoting failure, to maintain liveness. Because LINK failures are inde-\npendent (from node failures) we can successively recover individual\ndisconnection failures.\nThis single step recovery mechanism paves the way forIUI to\nreverse one or more steps in distributed systems which use non-\nidempotent or non-commutative data structures. 15.\n15 The shared state can be compromised\nby duplicated or reordered packets, but\nit is resilient to lost or delayed packets.\nDisconnection is the Most Likely Failure Hazard in LINKs\nPackets delayed by disconnected LINKs don’t threaten liveness or the\nintegrity of the shared state. Switched network hazards include: indiscrim-\ninately dropped, delayed, duplicated and reordered packets. Conventional\nmitigations (e.g. TCP) add significant complexity and performance over-\nheads, and still fail to solve the problem.\nExamples\nThe advantage of the shared state is that both sides know the LINK is\nbroken which can’t be done through a switched network with even\na single switch in series. LINKs simplify some important distributed\nsystem algorithms such as consensus ,two-phase commit, and reliable\ntree generation:\nPaxos [11] 16 “Agents operate at arbitrary speed, may fail by stop-\n16 Paxos is mentioned first because it\nis a clearer example how reliable L2\nimpacts the application consistency\ntradeoffs. Reliable Paxos probably\ncould be its own paper.\nping, and may restart. Since all agents may fail after a value is cho-\nsen and then restart, a solution is impossible unless some informa-\ntion can be remembered by an agent that has failed and restarted”.\n17 The assumption is when a node has failed and restarted, it can’t\n17 Prepare phase is not about bad\nnetworking, but to coordinate between\ncompeting proposals. It cannot be\neliminated, but its performance can\nbe improved by no longer relying on\ntimeouts.\nremember the state it needs to recover. WithIUI, the other half of\nthe LINK can tell it the state to recover from. This avoids the per-\nformance cost of heavyweight transactions and persistent storage.\næthernet and switched networks\n5\nTwo-phase commit [12] The prepare phase is asking if the receiving\nagent is ready to accept the token. This serves two purposes: com-\nmunication liveness and agent readiness. LINKs18 provide the\n18 LINKs exploit a unique combination\nof physics, electrical engineering and\ncomputer science. Think ofIUI as the\ndistributed systems (network- based)\nequivalent of the atomic Compare And\nSwap (CAS or just plain SWAP) primitive\nused in shared memory architectures.\nThe result is handshake-free messaging\nwith strong liveness, recoverability and\nsecurity properties.\ncommunication liveness test, and we can avoid blocking on agent\nready, by having the LINK store the token on the receiving half of\nthe LINK. If there is a failure, both sides (senders and receivers in\nboth NICs) know; and both sides know what to do next.\nWhy can’t the sending side on Paxos keep the information the\nreceiving side needs in case it fails? The other side of the LINK\nknows: the state that was lost in the crash is maintained by the\nhalf of the LINK on the other side. In leader election a master sends\na request to a worker (prepare) and it doesn’t get the ack. With\nIUI, the master knows definitively, if it is a neighbor.\nIn two-phase commit (2PC) there is no safety proof. In three-phase\ncommit, there is no liveness proof. Can we also often eliminate the\nprepare phase in consensus and 2PC? 19 which improves perfor-\n19 And in three-phase commit, the\npre-prepare phase?\nmance.\nOne or more corner cases are eliminated where the replicated state\nmachine can get blocked due to loss of acknowledgement .\nAtomicity\nAtomicity in IUI provides significant advantages in distributed com-\nputing by making corner cases disappear, it makes it simpler to im-\nplement those distributed algorithms correctly, and the number of\ncircumstances where things go wrong is reduced by (potentially)\nseveral orders of magnitude.\nReliable tree generation [13] Binary LINK reversal algorithms20 work\n20 Charron-Bost et. al. generalize the\nGafni-Bertsakas (GB) binary LINK\nreversal algorithm.\nby reversing the directions of some edges. Transforming an arbi-\ntrary directed acyclic input graph into an output graph with at\nleast one route from each node to a special destination node. The result-\ning graph can thus be used to route messages in a loop-free man-\nner21. LINKs store the direction of the arrow (head and tail);IUI\n21 LINK reversal algorithms don’t gen-\nerate shortest paths, just some paths.\nHowever, they do generate multiple\nloop-free routes. This allows the LINK\nto inform the agent (and the applica-\ntion, if needed) when switching to an\nalternate failover tree. As long as pre-\ncomputed failover paths are available,\nwe used the Dynamic Tree Algorithm\n(DTA). Only when CELLs lose all their\npaths do they need to participate in the\nLINK-reversal algorithms, which means\nless communication overhead and more\nstability.\nfacilitates the atomic swap of the arrow’s tail and head to maintain\nloop-free routes during failure and recovery.\nThose examples are applications using multiple links composed\ntogether, as depicted in our Atomic Ethernet logo.\nAlso, liveness becomes trivial in paxos. As long as a majority is\nup, progress is guaranteed. The real problem is cluster membership,\nwhen new nodes join, or when old nodes leave, either voluntarily or\ninvoluntarily.\næthernet and switched networks\n6\nFAQ\n[QUESTION I still do not understand how two devices connected us-\ning a full duplex Ethernet link can support reliable communications\nwithout time outs and retries\n[ANSWER] You are right at a conceptual level, but the reality\nof timeouts and retries is so different with a Stop-and-Wait (SaW)\nprotocol as to make you wrong. Let us explain.\n• In current networks, timeouts and retries are end to end concepts.\nAlice sends an application message to Bob with TCP, which at-\ntempts to guarantee delivery by sending ACKs. Those ACKs can\nbe lost on the way from Bob’s node to Alice’s. Alice has no way to\nknow if part of the message or the ACK was lost or delayed, so she\nretries after a timeout.\n• With Stop and Wait (SaW) (the alternating bit protocol) , reliability\nis at the link level, where the protocol provides sufficient common\nknowledge to address the majority of the issues. In particular, if\nthe link doesn’t break, the packets get through. There’s no need to\ndrop a packet due to a full buffer, because the SaW signal is credit\nbased flow control.\n• If the link breaks noisily (both sides get a signal), both sides know\nwhich phase of the protocol they are in, so they know which one is\nresponsible for forwarding the packet. I think you’d be stretching\nthe concept if you said A sending the packet on the new path is a\nTCP-like retry,\nIf the link breaks silently or even in only one direction, both sides\nknow that a SaW signal hasn’t arrived. Since both sides know that\nboth sides know (common knowledge), each can declare the link\ndead with full knowledge that the other side will eventually declare\nit dead too. Of course, knowing when to stop waiting for the signal is\nthe moral equivalent of a timeout, but there’s no need to coordinate\non a value. I’d say that’s quite different from the timeouts you’re\nthinking of.\nEnd Notes:\n18. Charron-Bost et. al. generalize the Gafni-Bertsakas (GB) binary\nLINK reversal algorithm. Which works by reversing the directions of\nsome edges. Transforming an arbitrary directed acyclic input graph\ninto an output graph with at least one route from each node to a special\ndestination node. Charron-Bost et. al.\næthernet and switched networks\n7\n19. Link reversal algorithms don’t generate shortest paths, just\nsome paths. However, they do generate multiple loop-free routes.\nThis allows the LINK to inform the agent (and the application, if\nneeded) when switching to an alternate failover tree. As long as\nprecomputed failover paths are available, we used the Dynamic Tree\nAlgorithm (DTA). Only when CELLs lose all their paths do they need\nto participate in the LINK-reversal algorithms, which means less\ncommunication overhead and more stability.\n20. The shared state integrity of the single physical LINK is a\npromise that two NIC’s can make with each other only over a single\nphysical LINK. This is explicitly an anti-promise for conventional\nswitched networks.\nConclusion\nÆthernet LINKs require a direct physical connection; their benefits cannot\nbe achieved over switched networks composed of a chain of unreliable\nlinks. Atomicity + Self-stabilizing algorithms, provide a general founda-\ntion to solve many distributed systems problems, and mitigate broadcast,\ntimeout and reconstruction storms in networks and distributed storage.\n22\n22 The shared state integrity of the\nsingle physical LINK is a promise that\ntwo NIC’s can make with each other\nonly over a single physical LINK.\nThis is explicitly an anti-promise for\nconventional switched networks. [14]\næthernet and switched networks\n8\nDescription\nPROBLEM with Synchronous Universe\n1. When A sends a packet and ‘assumes’ it gets there, this is New-\ntonian point of view with a Zynchronous Universe reliability.\n2. Conventional Networks this is unreliable\n3. The more links you have, the worse it becomes.\n4. The more you concentrate packets on critical links (e.g. between\nthe switches in the Clos) the more of a blast radius to all packets.\n5. Non- Bayesian Analysis\nReferences\n[1]\nThree-valued logic, en, Wikipedia, Page Version ID: 1281826018, Mar. 2025.\n[2]\nJ. Fischer and A. Lynch, “Impossibility of distributed consensus with one\nfaulty process,” en, ACM, 1985.\n[3]\nFutures and promises, en, Wikipedia, Page Version ID: 1274823809, Feb. 2025.\n[4]\nPlesiochronous system, en, Wikipedia, Page Version ID: 1066482699, Jan. 2022.\n[5]\nX. Zhou, V. Leis, X. Yu, and M. Stonebraker, “Oltp through the looking glass 16\nyears Later: Communication is the new bottleneck,” en, CIDR, 2025.\n[6]\nP. Borrill, Timeout and Retry in Distributed Systems, Slides, Dec. 2024.\n[7]\nP. Bailis and K. Kingsbury, “The network is Reliable: An informal survey of\nreal-world communications failures,” Queue, vol. 12, no. 7, pp. 20–32, Jul. 2014.\n[8]\nY. Afek et al., “Reliable communication over unreliable channels,” ACM,\nvol. 41, no. 6, pp. 1267–1297, Nov. 1994.\n[9]\nE. A. Lee, R. Akella, S. Bateni, S. Lin, M. Lohstroh, and C. Menard, Consistency\nvs. availability in distributed Real-Time systems, arXiv:2301.08906 [cs], Jan. 2023.\n[10]\nJ. H. Saltzer, D. P. Reed, and D. D. Clark, “End-to-end arguments in system\ndesign,” en, ACM Transactions on Computer Systems, vol. 2, no. 4, pp. 277–288,\nNov. 1984.\n[11]\nL. Lamport, “Paxos made simple,” en-US, ACM SIGACT News (Distributed\nComputing Column) 32, 4 (Whole Number 121, December 2001), pp. 51–58, Dec.\n2001.\n[12]\nOracle, Database Administrator’s guide, en, Developer Documentation, 2025.\n[13]\nB. Charron-Bost, A. Gaillard, J. L. Welch, and J. Widder, “Link reversal routing\nwith binary link Labels: Work complexity,” en, SIAM Journal on Computing,\nvol. 42, no. 2, pp. 634–661, Jan. 2013.\n[14]\nPromise theory, en, Wikipedia, Page Version ID: 1263003319, Dec. 2024.\n"
  },
  {
    "filename": "FAQ/FAQ-Addressing.pdf",
    "content": "FAQ: Addressing\nOne of the deepest and most pernicious problems in computer science is naming and addressing.\nWhat hides underneath, is the deeper question of identity and individuality.\nThe Problem\nIP-based Addressing in datacenters today operates much the way the US post-office (mail system)\ndoes. You provide the address of the intended destination, and the infrastructure delivers your\nmessage. Unless the recipient has moved, that is. Then, everyone sending to that recipient needs to\nupdate the address.\nThis approach works well enough in a mostly static environment, but it breaks down when things\nmove, as frequently happens in modern microservices applications, and especially for serverless\nfunctions. Elastic applications frequently add and remove instances; components migrate from one\nserver to another; a microservice on a failed server gets restarted on a new one. All these changes\nrequire global address updates, which is a major source of complexity when managing microservice\nenvironments.\nTopology\nThe DAEDAELUS ‘Address-Free Ethernet’ method of naming, addressing and routing was designed\nto work in the highly dynamic east-west environment of microservices in modern datacenters,\ndramatically simplifying address management.\nA microdatacenter built to DAEDAELUS (DAE) specifications consists of ultra-converged ‘cells’,\neach providing compute, storage, and packet processing. Each cell has ∼8 ports, each with one link\ndirectly connecting to a port on a physically nearby cell. The connections need not be regular; the\ninfrastructure will discover the topology, and automatically heal around failures while maintaining\nvery low latency connectivity.\nLink Protocols\nAn DAE datacenter can use standard (Ethernet) network cards, but the DAE software implements\nits own protocols, typically in the SmartNIC. These protocols are completely event driven; there\nare no timeouts or heartbeats. Each side of the link waits for an event before sending an event.\nMaking the link synchronous in this way avoids many problems that plague distributed computing\nalgorithms.\nThe liveness protocol, which runs when there are no data packets to send, transmits empty\npackets that just serve to generate these events. The Reversibility Token (ERTP) protocol uses two\nround trips to atomically transfer a packet from one side of the link to the other. The result is that\nthe packet is guaranteed to be seen on one side of the link or the other, but it can never be seen on\nneither or on both. In addition, both sides know which side has the packet. AIT can be used to do\natomic operations across the network, such as compare-and-swap (CAS), previously practical only\nwithin the shared memory of a single server.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 1 of 45\nBootstrap\nWhen a cell joins the network, it participates in a discover process that builds a spanning tree with\nthat cell as the root. At the same time, the new cell joins the spanning trees of all other cells. Each\ncell only has local information about these trees, e.g., for each tree it knows which port points\ntoward the root, which ports point to child cells, and which ports are connected to links not on that\ntree. There is no global representation of these trees. Hence, while the total amount of data scales\nas O(N2), each cell only has O(N) data.\nResilience\nThings break. Resilience is a property that makes sure the right thing happens when they do. The\nTF discovery process keeps metadata needed to route around failures. Should a link fail, the two\ncells on either side find a path around the broken link and start routing packets on the new path.\nThis process takes only a few packet round trips, which means applications will be completely\nunaware of the link failure. Once a new path is found, the packet stream continues with no packet\nloss.\nShould a cell fail, each of its neighbors initiates the link failure algorithm. Each of them will\ndetermine that there is no path to the failed cell. In other words, the resilience mechanism provides\na reliable failure detector (RFD) in addition to finding routes around the failed cell.\nAddressing\nApplications written to the API use tree-based addressing. Launching an application consists of two\nsteps. First a tree containing a subset of the cells is created by sending a Graph Virtual Machine\n(GVM) equation on a tree instead of editing a configuration file explicitly listing which cells are\nin the subset. For example, a GVM might say, ‘join this tree if you are within 5 hops of the root’\nEach cell will evaluate this equation using its local context to decide whether or not to join the tree.\nNote that there is no need to know exactly which or even how many cells are on the new tree.\nThe next step is to deploy the application on all cells of that tree. Once the application is\nrunning on a cell, that instance of the application can send messages to other instances by naming\nthe tree and sending messages down from the root or up to the root. The application can also create\nother trees if it needs to deploy other components or constrain communications to a subset of the\ncells.\nThe Transaction Fabrix ‘Tree addressing’ scheme dramatically simplifies managing elastic\napplications that add and remove cells depending on load. In a conventional approach, such as\nKubernetes, each cell needs the address of every cell it must communicate with. When that set of\ncells changes, those addresses need to be updated. That is not the case with tree-based addressing.\nA server that needs more resources can simply extend its tree locally without coordinating with any\nother part of the application.\nPacket Flow\nStart with a microservice sending a message to another one. The sender specifies the tree on which\nthe message is to be sent and delivers the packetized message the TF. A packet forwarder uses the\ntree identifier to look up the proper forwarding table entry. If the message is going leafward, the\nforwarder sends the packet on each child port; if rootward, on the parent port.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 2 of 45\nWhen a port receives a packet from the link it’s connected to, it looks up the forwarding entry\nfor the tree identifier and forwards the packet on its parent or child ports and to the microservice\nrunning on that cell if that cell is on the named tree.\nApplications can rely on properties of the Transaction Fabrix (TF) that are not provided by\nconventional fabrics. Since messages are sent on trees, the TF network guarantees in-order delivery\n(multi-pathing is supported, but the ordering guarantees are not enforced). In addition, the TF\ndoes not drop certain packets. The result is that a leafward message is a reliable multicast. This is\nparticularly powerful for cells 1 hop away, which we call the Consensus Tile (see FAQ-Database for\ndetails).\nThe fundamental difference in the Transaction Fabrix:\nInstead of viewing the Network Interface Controllers as peripherals to computers.\nWe invert things: think instead of the computers as peripherals attached to the fabrix.\nThe Transaction Fabrix is the computer.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 3 of 45\nList of Questions\nQ1\nWhat problem are you solving? . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\nQ2\nWhy do we need a new addressing method? . . . . . . . . . . . . . . . . . . . . . .\n7\nQ3\nIsn’t Daedaelus server topology different enough that it’s an obstacle to adoption?\n8\nQ4\nCan you use the existing Open19 cabling into a switch to directly connect the cells?\n8\nQ5\nHow is address management done today for containers?\n. . . . . . . . . . . . . . .\n8\nQ6\nWhy can’t we do address management at the application layer? . . . . . . . . . . .\n8\nQ7\nHow does DAE’s Tree-based address these problems? . . . . . . . . . . . . . . . . .\n9\nQ8\nHasn’t this problem been solved already, didn’t IP addressing win? . . . . . . . . .\n9\nQ9\nWhat’s wrong with the way we solve it today with IP protocols?\n. . . . . . . . . .\n10\nQ10\nHow do I know what tree to name to reach a particular service? . . . . . . . . . . .\n10\nQ11\nHow does Self-Organizing TRAPHs improve Economic Efficiency?\n. . . . . . . . .\n10\nQ12\nHow does this differ to Roger Day’s perspective? . . . . . . . . . . . . . . . . . . .\n11\nQ13\nWhy is RAFE important to Datacenter Energy Efficiency? . . . . . . . . . . . . . .\n11\nQ14\nWhat is Self-Organization, and why is it important to Datacenters? . . . . . . . . .\n12\nQ15\nHow can self-organization and the ‘Address-Free’ approach improve Power Efficiency? 12\nQ16\nHow can the ‘Address-Free’ approach and TRAPHs improve Security? . . . . . . .\n12\nQ17\nWhy is flat addressing in a Clos network bad? . . . . . . . . . . . . . . . . . . . . .\n13\nQ18\nWhat are the other reasons for this alternative (graph oriented) addressing philosophy? 13\nQ19\nIsn’t this a Network Management Plane problem? . . . . . . . . . . . . . . . . . . .\n13\nQ20\nWhat is the simplest way to understand this new design philosophy? . . . . . . . .\n13\nQ21\nHow do you intend to go about solving it? . . . . . . . . . . . . . . . . . . . . . . .\n13\nQ22\nWhat is Kubernetes? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n14\nQ23\nWhy does Kubernetes have an addressing problem? . . . . . . . . . . . . . . . . . .\n14\nQ24\nHow do you compare with Aspen Mesh? . . . . . . . . . . . . . . . . . . . . . . . .\n15\nQ25\nDoesn’t the concept of Pets vs. Cattle solve this problem? . . . . . . . . . . . . . .\n15\nQ26\nWhat does this mean in terms of locality? . . . . . . . . . . . . . . . . . . . . . . .\n16\nQ27\nLets get back to Kubernetes, why does it have a problem? . . . . . . . . . . . . . .\n16\nQ28\nHow does Kubernetes do Address Management?\n. . . . . . . . . . . . . . . . . . .\n16\nQ29\nCan we run the GVM on an installed Infiniband (IB) network? . . . . . . . . . . .\n16\nQ30\nCan you use a 4-port NIC instead of an 8 port NIC? . . . . . . . . . . . . . . . . .\n17\nQ31\nWhat does Mark Burgess Say?\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\nQ32\nHow does routing work? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\nQ33\nHow does the Cellular Fabrix (Transaction Fabrix) do Naming? . . . . . . . . . . .\n19\nQ34\nWhat does CF Tree Addressing do that IP/Ethernet src/dst addressing can’t?\n. .\n19\nQ35\nWhy are Addressing and Naming different?\n. . . . . . . . . . . . . . . . . . . . . .\n19\nQ36\nHow does the routing protocol work? . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\nQ37\nSo everything is broadcast? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\nQ38\nHow do you compare to conventional Distance Vector/Path Vector Protocols? . . .\n19\nQ39\nWhat’s wrong with Any-to-Any (A2A) addressing? . . . . . . . . . . . . . . . . . .\n20\nQ40\nBut isn’t reliable multicast impossible? . . . . . . . . . . . . . . . . . . . . . . . . .\n21\nQ41\nWhat does your packet format look like? . . . . . . . . . . . . . . . . . . . . . . . .\n22\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 4 of 45\nQ42\nWhat are the permissible encodings of the CFTI? . . . . . . . . . . . . . . . . . . .\n22\nQ43\nBut what about the src, dest, EtherType, message length etc.? . . . . . . . . . . .\n23\nQ44\nWhat does a Key-Value Store (KVS) on the wire look like?\n. . . . . . . . . . . . .\n24\nQ45\n“But how do I ...” ?\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\nQ46\nHow would you implement some common protocol features from this structure? . .\n24\nQ47\nHow do we make things legacy compatible? . . . . . . . . . . . . . . . . . . . . . .\n25\nQ48\nHow are you compatible with Docker and Kubernetes? . . . . . . . . . . . . . . . .\n25\nQ49\nBut what about performance? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n25\nQ50\nWhat is the basic principle behind the Tree Addressing Scheme?\n. . . . . . . . . .\n26\nQ51\nWhat alternative structures can the CFTI represent? . . . . . . . . . . . . . . . . .\n27\nQ52\nWhat does this have to do with today’s Networking? . . . . . . . . . . . . . . . . .\n27\nQ53\nBut what if the area of bits in the TreeID conflict with where the Ethertype would\nbe? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n27\nQ54\nHow do I distinguish packet types? . . . . . . . . . . . . . . . . . . . . . . . . . . .\n27\nQ55\nBut what if I am a leaf and I want to send a message to nearby cells?\n. . . . . . .\n27\nQ56\nWhat other clues are there to Simplicity?\n. . . . . . . . . . . . . . . . . . . . . . .\n27\nQ57\nWhy doesn’t RINA solve the problem? . . . . . . . . . . . . . . . . . . . . . . . . .\n29\nQ58\nCan you detect and recover from GUID collisions? . . . . . . . . . . . . . . . . . .\n29\nQ59\nHow do you relate to P4? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n29\nQ60\nHow to you relate to eBPF? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n29\nQ61\nWhy can’t you use ipables?\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n31\nQ62\nHow do you calculate the number of clock cycles to make a forwarding decision?\n.\n31\nQ63\nHow fast can you make the Hash table? . . . . . . . . . . . . . . . . . . . . . . . .\n31\nQ64\nIs there any relationship to Elon Musk’s Starlink routing protocol? . . . . . . . . .\n31\nQ65\nWhat does relative addressing look like? . . . . . . . . . . . . . . . . . . . . . . . .\n33\nQ66\nHow do you build and stack trees? . . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\nQ67\nHow do the protocols and their acknowledges work?\n. . . . . . . . . . . . . . . . .\n34\nQ68\nWhy don’t you use naming services? . . . . . . . . . . . . . . . . . . . . . . . . . .\n35\nQ69\nWhy can’t we continue with today’s domain names, IP addresses, and MAC addresses? 36\nQ70\nWhat can you do with ENS that we can’t with what we have today? . . . . . . . .\n36\nQ71\nIsn’t creating trees harder than connecting things with endpoint addresses? . . . .\n36\nQ72\nDoes this mean I have to rewrite all my software to use the EARTH naming service? 37\nQ73\nIf the socket endpoints aren’t neighbors, can’t nodes in the middle see what’s sent?\n38\nQ74\nCan I have my program create trees with any communication pattern I choose? . .\n38\nQ75\nWhat is the GVM? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n38\nQ76\nWhat is Neighbor to Neighbor (N2N) addressing? . . . . . . . . . . . . . . . . . . .\n38\nQ77\nWhy is this interesting?\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n40\nQ78\nHow does addressing relate to physical layout of servers? . . . . . . . . . . . . . . .\n40\nQ79\nWhat would Absolute Addressing look like? . . . . . . . . . . . . . . . . . . . . . .\n40\nQ80\nWon’t programmers find it simpler to use a GEV coordinate address like this? . . .\n40\nQ81\nWhat would Relative Addressing look like?\n. . . . . . . . . . . . . . . . . . . . . .\n40\nQ82\nDoesn’t (R, θ) addressing seem awkward?\n. . . . . . . . . . . . . . . . . . . . . . .\n41\nQ83\nWhat’s the difference between Absolute (GEV) instead of Relative (LOV) addressing? 41\nQ84\nWhat else is Relative LOV) addressing good for? . . . . . . . . . . . . . . . . . . .\n41\nQ85\nWhat would be the practical justification for this?\n. . . . . . . . . . . . . . . . . .\n41\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 5 of 45\nQ86\nIsn’t the routing table just a Key-Value Store . . . . . . . . . . . . . . . . . . . . .\n41\nQ87\nCan this topology and gradient mechanisms be used to support ML/DL Algorithms? 42\nQ88\nWhy don’t Cell Trees need a destination address? . . . . . . . . . . . . . . . . . . .\n42\nQ89\nThen how does one cell communicate with another?\n. . . . . . . . . . . . . . . . .\n43\nQ90\nWhy go to all this trouble? Why not just have a destination address?\n. . . . . . .\n43\nQ91\nHow does the DAEDAELUS Formal model reduce Complexity? . . . . . . . . . . .\n44\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 6 of 45\n[Q1]\n[A1] We are solving the complexity of managing naming and addressing in modern datacenter\nnetworking. IP addressing is like a mailing address to a fixed house or business; or old-style telephone\nnumbers associated with land lines. Datacenter networks have not yet evolved to mechanisms\nequivalent to mobile numbers, which can follow an individual around. We define complexity as: “a\nmeasure of how much work it takes to bring a system up to its intended state of operation; or back\nto its intended state of operation after a perturbation”.\n[A1] Current Ethernet/IP based addressing requires the management of different addresses on each\n‘interface’ (MAC addresses, + IP/port addresses). This has created massive complexity in datacenter\nmanagement. There are no solutions, only palliatives. And we still don’t have a strong, unique node\nidentifier needed for the provisioning and management of datacenter assets (the question marks in\nthe figure below):\n[Q2]\n[A2] We are a climate-positive company.\nOur software enables microservices, and serverless\nfunctions, to continually self-organize to optimize the energy usage of datacenters. The execution\nentity consolidation approach began with Virtual Machines, which allowed customers to pack more\nvirtual servers on fewer physical servers to save energy; and whose temporal intimacy is 10s of\nminutes. This continued with containers, whose temporal intimacy is is 10’s of seconds. Our\ntechnology allows this to be done with serverless functions, whose temporal intimacy is in the 10’s\nof milliseconds.\nWithout our Reliable Address-Free Ethernet technology, datacenters today are limited to\ncentralized orchestrators, such as Kubernetes, which struggle with address management of containers\nbecause entities have to change their address when they move. This is why containers have to be\nstateless.\nOur Reliable Address-Free Ethernet (RAFE) technology will prove inevitable for serverless,\nwhich today are both stateless and address-less. Being able to dynamically migrate functions (and\ntheir state) will revolutionize the ability for datacenters to continually self-organize to optimize\ntheir energy usage.\n[A2] We are a cybersecurity-positive company. Our software provides mechanisms embedded in the\ninfrastructure, that can form a new substrate of ‘trust’ that developers and operators can understand\nand control. See McKinsey’s Risk-based approach to cybersecurity.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 7 of 45\n[Q3]\n[A3] Not at all: It’s not about re-wiring the racks, it’s about getting the switches out of the way.\nAll our problems (in distributed systems) are in protocols we don’t want. We don’t get to solve the\nproblems of bang bang bang networking by banging harder. We can’t compensate for DReDDful1\nswitch behavior by adding IP mapping functions at layer 7 (application layer).\n[A3] Clean virtualization of networks requires that we hoist legacy protocols to a higher abstraction\nlayer and put something much simpler under it, just like VMWare did with VMs and VMMs when\nthey virtualized compute. Our form of network virtualization works in a very similar way: a clean\nvirtualization that leaves legacy untouched but revolutionizes how the components can now be\nmanaged, without getting bogged down in the complexity of the ‘heritage’ hardware, software and\nmanagement processes.\n[Q4]\n[A4] Yes. If a customer insists on familiar cabling, we can provide a layer 1 switch2, a ToR switch\nthat provides short-circuit connections in the pattern we want for direct cell to cell connections.\nThe essence of our breakthrough is being able to manage the networks from a developer API (from\neach cell) instead of a proprietary switch API, e.g. Broadcom.\n[A4] Please don’t think of this as “rewiring the racks”, this is a conceptual trap that will send\nthe wrong message to customers and investors. Think of it instead of “getting the switches out of\nthe way”. All of DAEDAELUS’s technology is predicated on eliminating the problems caused by\nswitches. This is the central issue, it cannot be finessed, or papered over with stuff ”on top”. Please\nread: The Network is Reliable.\n[Q5]\n[A5] Each framework for managing containers does it differently, but there are commonalities. All\nframeworks rely on a centralized manager that is responsible for making elasticity, migration, and\nfailover decisions. It then notifies individual components when addresses change. These updates\ncan take seconds to propagate, in which time further address changes are likely to have occurred.\nThe result is continual retries as microservices attempt to communication with components that\nhave moved.\n[Q6]\n[A6] Because the underlying addresses (at the Network/IP layer) are fixed ‘house location’ or\n‘land-line’ type addresses, that no longer serve today’s microservice architectures – which require\nexecution entities (VMs, containers, lambda’s) to be continuously moblie. Most of the complexity in\naddress management comes from the requirement to change addresses when these execution entities\nmove around in a datacenter.\n1DReDDful: Drop, Reorder, Duplicate, and Delay packets.\n2See FAQ-Hardware for an example of how to do this with the Open19: Replace conventional switches with a\nLayer 1 switches (a set of wires that connect the cables in a pattern with bit-for-bit signal pass-through). See Arista’s\nLayer 1 guide.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 8 of 45\n[A6] In essence, the existing frameworks do address management at the application layer. They\neither provide an address management library to be linked with the application, or they provide a\nproxy that mediates all network interactions. There is a substantial performance penalty due to the\nneed for updates to be communicated to and from the application manager.\n[A6] The figure below shows four layers of potential packet flows. The lower the level we do\nforwarding, the less ‘mechanism’ in the path, the faster it will be and, most importantly, the more\nreliable it will be.\n[A6] In conventional datacenter networks, address management occurs at two levels: link and\nnetwork layers. The currency at the link layer are 48-bit Ethernet (MAC) addresses for each of source\nand destination. The currency at the Network Layer are 32-bit or 128-bit ‘IP addresses’. These\ntwo incompatible methods of Naming, Addressing and Routing are an artifact of how networking\nevolved from its beginnings.\n[A6] The above figure shows only the protocol layers seen by the main CPU. Our mechanisms are\nimplemented on a SmartNIC below what the main CPU (and device drivers) see as Layer 2. This is\nwhat we call ‘clean virtualization’. We can do anything we want under this traditional CPU/OS\nLayer 2.\n[Q7]\n[A7] Tree-based addressing is independent of where a particular microservice is running. It’s address\ndoesn’t change if it migrates on a tree (the direction pointers always follow the gradient to the root),\nif it is replicated with the new instances on the same tree, if it is restarted on another server on the\nsame tree.\n[A7] This basic simplification in naming at the lowest layer provides important benefits. Configura-\ntion changes can be made locally far more rapidly than with conventional addressing. Elasticity,\nmigration, and load balancing decisions can be made locally without communicating with a central\nmanager. Further, staging updates, such as resharding, can be done far more simply.\n[Q8]\n[A8] No. Internet addresses are like mailing addresses, fixed to a geographic location. This works\ngreat when a person remains at the same location for long periods of time. It doesn’t work when a\nperson moves a lot. The same is true for microservices in datacenters, which need to move around\n(and expand and shrink) a lot.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 9 of 45\n[A8] This is why conventional networks have DNS as a way to convert a name to an address. While\nthe additional latency of getting the address is small compared to other parts of Internet access, it’s\nmuch too large (and variable) for latency sensitive microservices. Caching lookups doesn’t work\neither, because addresses change far too rapidly in the datacenter. DNS is also a major security\nchallenge.\n[Q9]\n[A9] This is the core of the problem: Like mailing addresses, IP addresses are fixed – they are\nbound to a particular physical node. And, they are implemented, throughout the internet, just like\nthey are through the mail system (USPostal Service) – each post office manages a set of fixed ZIP\ncodes.\n[A9] Once we understand that Kubernetes ‘Pods’ are like blocks of addresses within ZIP codes, we\ncan begin to see why the problem of ‘lack of mobility’ of execution entities in datacenters is such a\nhuge problem. Imagine if we had to kill and then resurrect a human being in order to move them to\na different ZIP code? In container deployments in datacenters, thats exactly what we have to do3.\nIt’s even worse for serverless, which are not only stateless, they are address-less. Which makes it\nproblematic for developers to maintain the topology relationships they have in mind.\n[A9] Once bound to a particular geographic area, they can’t be changed, at least not without\nconsiderable pain and difficulty. IP Addresses are like ZIP codes. Just like a mailing address, an\nIP address has many parts. The earlier parts of the address identifies the country network and\nthe regional network of the device. Then come the subnetworks. Then, finally the address of the\nspecific device.\n[A9] Most users never see or care about internet addresses. DNS Associates IP addresses with\nhuman readable names (www.example.com) with their corresponding addresses. Your computer\nlooks the DNS to look up domains to get the associated IP addresses, so it can then connect to\nthe destination on the Internet. This dependency on DNS servers has created many challenges,\nparticularly in its susceptibility to cyber attacks (e.g. DNS spoofing).\n[Q10]\n[Q11]\n[A11] Economic profitability implies efficient utilization of an asset. One of DAE’s great strengths\nis its ”High Resolution Accounting”. Our ability to self-organize (on graphs) allows systems and\nresources to be used at their highest utilization. Like the steel industry of afore, being able to use\neach engine to a higher utilization brings profits.\n[A11] DAE’s Address-Free Ethernet allows execution entities to dynamically migrate, toward\nattractors (for latency optimization) and repulsers (for distance safety). These self-organization\nalgorithms require relative addressing, not the cartesian coordinate addressing modes used in todays\nnetworks.\n3Kubernetes and other orchestration services can move around and ‘reuse’ IP addresses only within a Pod, not\nbetween them.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 10 of 45\n[Q12]\n[A12] Its very similar. In their presentation at Stanford, Roger identifies (from his patterns boo)\nOne Packet only and other curiosities that:\n1. Applying Saltzer to the Internet.\nThe most striking feature is that half of the addressing architecture is missing.\n- no wonder there are addressing problems\n- The only identifier we have is an IP address.\nThere are no node addresses and no application names.\n- And the point of attachment is named twice!\n- Domain names are synonyms of IP addresses. URLS are pathnames through the stack and\nlocation-dependent.\n[As if your computer worked only with absolute memory addresses.\n2. It is impossible to locate something without also identifying it.\nThis pseudo-problem arises from not having a complete address architecture,\nWhen all you have is a hammer, everything looks like a thumb.\nAs we have see, the problem isn’t separating location from identification, But logical location\nfrom physical coalition. -logical and physical are relative.\nLoc/ld split is yet another band-aid, a static one and hence won’t scale Need to be able aggregate\nidentifiers - don’t.\nThe identifier names an ‘endpoint.’ The endpoint can only be an application- ntity-instance.\nThis takes us from a quarter of an architecture to a third an architecture.\n[Q13]\n[A13] We are not moving fast enough on tackling climate4, and Datacenters are a major culprit:\n1. With RAFE, we can improve Power Efficiency (can migrate and self-organize execution\nentities). When mobility of executable entities is fluid, we can do it easier, faster and without\nlosing data as the serialization foci migrate. Moreover we can spin up and down elastic services\nmore quickly.\n2. Just using SmartNICs alone can help reduce power dissipation [ref].\n3. See Energy Computer note. Landauer limit. the energy demand of computers will soon equal\nthe entire world’s total demand. We can do something about this with the direction we can\ntake the industry in with our Quantum inspired protocols, which dissipate zero energy in the\nlimit.\n4. And our address-free TRAPHs enable self organization of bin packing based on graph coloring\nalgorithms which can be most easily implemented on our protocols\n5. Self-Organization - From NKD Document - also get other notes there)\n4According to the Department of Energy, data centers account for about 2 percent of ALL electricity use in the\nUS. .\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 11 of 45\n[Q14]\n[A14] NKD Doc. XXXXXXX\n- [ ] Add concept “Application Level Network Control” (or topology control)\n- [ ] Changing pointers causes staleness (out of date forwarding, cascading retries), incoherence\n(loss of liveness), and inconsistency (loss of trust)\n- [ ] Self-organization (from NKD document - also get other notes there)\n[Q15]\n- [ ] FAQ-addressing - serverless self org and energy efficiency - see note and NKD\n- [ ] Just using SmartNICs alone can help reduce power dissipation (Find paper)\n- [ ] Add Power Efficiency (can migrate and self-organize execution entities). According to the\nDepartment of Energy, data centers account for about 2 percent of ALL electricity use in the US.\n- [ ] Wired article: https://www.wired.com/story/amazon-google-microsoft-green-clouds-and-\nhyperscale-data-centers/\n- [ ] companies are not moving fast enough on tackling climate and Datacenters are a major\nculprit - we can improve that significantly. When mobility of executable entities is fluid, we can do\nit easier, faster and without losing data as the serialization foci migrate. Moreover we can spin up\nand api down elastic services more quickly\n- [ ] See Energy Computer note. Landauer limit. the energy demand of computers will soon\nequal the entire world’s total demand. We can do something about this. Our Quantum inspired\nprotocols dissipate zero energy in the limit. And our address-free TRAPHs enable self organization\nof bin packing based on graph coloring algorithms which can be most easily implemented on our\nprotocols\n[Q16]\n- [ ] The second biggest problem with the A2A, E2E mode of addressing is mobility without loss\nof consistency. if the entity moves, the address changes. This gives rise to the artificial requirement\nof indirection servers, (name) servers, such as DHCP and DNS and directories, AD. Now we have\n3rd party services we need to trust (security issue), to depend on (reliability issue) and manage\n(complexity issue). This gives rise to endless band aids to try and mitigate the security issues and\nadditional (specialized) hardware to provide redundancy.\n- [ ] We are boiled like a frog, thinking we can just add one more band aid. But its those extra\nband-aides that bring the vulnerabilities, hidden beneath their endless skirts of complexity.\n[A16] The security of TRAPHs is automatic, and far easier to manage with Address-Free TRAPHs.\n- [ ] Focus first on security - you cannot create a secure system by adding things to an already\nhopelessly secure system.\n- [ ] The biggest problem with the A2A mode of addressing is Security. This is the biggest\nproblem in the IT world today and as far as we know, we are the only technology that can genuinely\naddress the security crisis. Our TRAPHs are exactly that, traps for\n- [ ] Name Servers (pointer servers) introduce attack points and vulnerabilities. Unnecessarily\nincreases what we have to trust.\n- [ ] Add application level security management.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 12 of 45\n[Q17]\n[A17] A Clos network builds a spanning tree on the switches to give the servers a view of a flat\nnetwork. That’s a bug not a feature. A flat network allows any node to address any other node,\nwhich adds both complexity and vulnerability, and deprives the distributed system programmers\nwith the information they need to manage their topologies.\n[Q18]\n[A18] Whenever you want to deploy a graph applications, which include not only microservice\ndecomposition of business logic, they also include other areas such as ML/AI, which is used\nfor natural language processing, interactive voice response, chat bots, fraud detection, etc. The\nimportant perspective here is that the ‘model’ in ML, is a graph. Nowhere is the importance of\nstable topologies of these execution elements more important.\n[A18] By being able to deploy, manage, protect and tear down topologies under API control, we\nare in a position to dramatically improve the speed, reliability, latency (inference time) of ML/AI\napplications. All distributed applications communicate on a graph in which a given component\ntalks to some others but not to all of them. The addressing we use today gives the programmer\nthe view that any component can talk directly to any other component. This mismatch leads to\ncomplexity and vulnerability.\n[Q19]\n[A19] Yes, in a way, and the lack of innovation in the management plane is a well known problem.\nHowever, no one understands how to solve it. All attempts so far try to “paper over” the top fo\nthe problem, leaving the core issues to fester underneath. See 2020 examples from: The New Stack\n(TBD).\n[Q20]\n[A20] We have changed the vantage point of the protocols to achieve a dramatic simplification.\nInstead of a vantage point based on the switches, our vantage point is from the cells (servers).\nThe dramatic simplification comes because the cells (within their confinement domains) are now\nresponsible for building, managing and tearing down the routing trees, instead of the switches. Thus\ndevelopers can now use the tools, workflows and environments they are used to, to drive the API’s\nthat manage topologies of their microservices.\n[Q21]\n[A21] The addressing problem cannot be solved by ‘adding’ things to legacy networking (such as\nservice meshes or Kubernetes on top of SDN); it can only be solved by taking things away, and\nboiling down the problem of naming and addressing to its simplest possible form: trees.\n[A21] We replace the source/destination naming and addressing system by hijacking the Ether-\nnet (Or Infiniband) frames, and programming them differently. Tree-addressing allows the cells\n(servers/nodes) to be in charge of the trees built on them, instead of the switches. See description\nat the beginning of this FAQ.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 13 of 45\n[Q22]\n[A22] Kubernetes is an application-shard-deployment centric, and\ntherefore inherently server centric, toolset for deploying and man-\naging application/microservice shards on a fungible pool of con-\ntainers.\n[A22] “In essence, Kubernetes is the sum of all the bash scripts\nand best practices that most system administrators would cobble together over time, presented as a\nsingle system behind a declarative set of APIs.”\n[Q23]\n[A23] The model for IP addressing used by Kubernetes uses IP addresses, and ties the IP address\nof a deployed container not to the name or identity of the service, but rather to the geography where\nthat container is deployed. One could say that when an application or service shard is deployed, it\nis assigned to an IP address based on the server resource(s) it happens to occupy. It is also given\nthe IP addresses of all of the services/shards it will need to invoke.\n[A23] If everything were ideal, with nodes and links never failing and service shards never crashing,\nthis would be fine. But having bound that container to an IP address and named all of the resources\nit calls by IP addresses, as soon as something breaks, and the contents of some container or set\nof containers have to be rebooted in a different physical location, the problem of updating every\nreference to the old IP address (in every container it’s been given to) is simply intractable.\nLikewise the problem of giving a short lived application or service instance an IP is that when it\nterminates the next thing deployed in that location will likely get that IP or another recently used\none, risking not only other containers having stale pointers to that IP, but also stale permissions in\nthe network.\n[A23] The fix for this is conceptually simple, but impossible to implement in the current IP centric\nworld. Name the identity, not the location, and when an application or service shard is instantiated\nin a container, give it the identities rather than the locations of the services it may call. Ignoring\na lot of important detail, what both Cisco-LISP and this corner of IPv6 do is assign (say) a cell\nphone an identity IP address on a permanent basis, which has a physical proxy that can be found\nby navigating to that IP address as a physical location. But then the user takes the phone on a\nbusiness trip, and when the plane lands in London the roaming carrier assigns it a physical IP and\nnotifies the physical proxy of the identity IP of the new temporary physical IP address.\n[A23] In a data center, that means the container would be instantiated with an identity IP address,\nand told only about the identity IP addresses of the services it was permitted to call. An intermediary\n(perhaps a sidecar) would then do a virtual-to-physical translation of that IP address, convey the\nframe over the network based on physical address to the intermediary next to the recipient, which\nwould then receive the packet at its identity address. Networking has far too many tools to solve\nthis problem, between a plethora of encapsulations (e.g., IP-in-IP) and address translations. An\nanalogy to storage virtualization appliances which the industry attempted 20 years ago extends\nthis address translation to parsing the request itself, for example looking at the key in a KVS or\nmemcached request and directing that request to the correct shard, relieving the caller of needing\nto have a current list of shards and know the division of keys among them.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 14 of 45\n[A23] The fix for the problem storage virtualization solved was distributed storage systems\nimplemented over servers that happened to have disk drives in them, obsoleting not just virtualization\nappliances but also storage systems as we knew them 20 years ago. (Yes, the legacy will still be\nselling in Enterprises for another 20 years or more. But no surviving cloud company chose those\nstorage systems.) Learning from this, there is probably money to be made in the short term adding\nthings like sidecars which virtualize container networking, but the long haul technology winner will\neither be some legacy no one expects that just entrenches itself, or will be something simple and\nreasonably cheap that bypasses network addressing as we know it today (one example of which is\nour vision at DAEDAELUS).\n[Q24]\n[A24] Aspen Mesh, like many other Mesh Technologies (including Istio and what Kubernetes is\nnow turning into) run as an ‘overlay’ on top of conventional network at layer 7. The Transaction\nFabrix is an underlay, that runs underneath a conventional network. Only from that vantage point\ncan we provide the new, far simplier protocol foundations that distributed system programmers\nneed for their microservices.\n[A24] Aspen Mesh adds enterprise features “on top” of Istio providing all the functionality and\nflexibility of open source, plus features, support and SLOs that are critical to operating applications\nin the enterprise.\n“If you’re scaling microservices on Kubernetes, it’s only a matter of time until you’ll need a\nservice mesh to get the most out of your distributed systems. And as you gain speed and agility\nwith your microservices, you’ll need to think more about stability and security. This is where a\nservice mesh can be a game-changer.”\n“It’s no surprise that companies are adopting Istio as their service mesh of choice. It provides\na powerful toolbox that addresses all sorts of microservice challenges. But it does come as a\nsurprise to many enterprises who find there are extra stability and guarantees required. It makes\nsense, though. The complexity and distributed nature of enterprise engineering teams also means\nmore features are needed to address observability, policy and security.”\n[A24] We cannot continue to assume that cybersecurity can be managed with humans in the loop.\nML/AI will not solve the Cybersecurity problem. If an architecture is unsuitable for human beings\nto understand and be able to express simple, verifiable, rules for ‘confinement of information’ in\neven small and medium size businesses, then ML/AI will not be able to either.\n[A24] This problem cannot be solved by papering over existing pile of complexity, by adding more\n‘on top’ of the pile. it can only be managed by replacing todays foundations by something much\nsimpler and more secure. Legacy compatibility can only then be provided by a ‘clean’ virtualization\nof heritage protocols.\n[Q25]\n[A25] The distinction between Pets and Cattle in modern microservices was promulgated by Adrian\nCockcroft. It tries to separate out the notion of identity (naming) from individuality (a member of a\nhomogenous set). With IP-based E2E (src,dst/port) addressing we can solve only half the problem.\nIf we continue the metaphor, we haven’t named our pets, we’ve named the house they live in, or for\ncattle, the pen on the farm in a particular county.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 15 of 45\n[Q26]\n[A26] It means that executing entities (VM’s, Containers, Lambdas) can migrate around a system\nat will, without changing their identity. This enables things like the optimization of datacenter\nenergy usage, enabling the collection (confinement) of compatible entities on fewer servers (based\non an attractor in the GVM) so that unused servers can be powered down, thereby saving energy.\nWhile is something existing systems try to do at a coarse level, it has proven to be problematic for\nstateful microservices, and will be shown to be intractable for serverless.\n[Q27]\n[A27] Back to Kubernetes: Kubernetes was created for a world without virtualization of IP\naddresses. It is what it is. Lots of people are trying to bolt something onto the side of Kubernetes\nto fix its networking problem. The solution to this problem is a natural monopoly (there’s really\nonly room for one in the world, although I’d grant one each at AWS, Azure, and GCP).\n[A27] Our view is that communication from containers should use capabilities (with a capability\nrepresenting a queue pair or shared memory region from this app/service shard to another one) and\nthat no location or addressing information of any kind, other than the capabilities it’s given, should\nbe visible to the code running in a container. This is expressed the capability in terms of what 20\nyear old InfiniBand views as its machine model, and which was adopted by Gen-Z, which will not\nnecessarily be the best and highest machine model. That is, we want to design the problem out, not\nsolve it. Just means the networking interface/substrate has to be able to resolve the capability to a\nphysical location and get the action to that location.\n[Q28]\n[A28] A description of the basics starts at Virtual IPs and service proxies. Fortunately, the answer\nto the question doesn’t need any of those details.\n[A28] Kubernetes splits address management into two pieces, service discovery and service invocation.\nFirst, it does service discovery to find the IP addresses of the service instances, then it uses one\nof those addresses when invoking the service. In a dynamic environment, the set of IP addresses\ncan change between those two steps, so there’s a need for something to continually monitor those\nchanges.\n[A28] Things would be far simpler if service discovery could be combined with service invocation.\nThe invoker would name the service, and the infrastructure would look up the address. That’s\nexactly what DNS does. Unfortunately, the lookup takes time, and caching is ineffective because\nthe microservices environment is so dynamic.\n[A28] DAE seamlessly combines the two steps. Service discovery results in a TreeID that is used\nfor invocation. There is no need to change addresses as long as service instances are on the tree.\n[Q29]\n[A29] No. For the same reason we can’t run it on an installed Ethernet network. We need to get\nthe switches out of the way. IB does have some improvements as far as dropping fewer packets, but\nit never solved the complexity of address management as we do.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 16 of 45\n[A29] It’s relatively easy to send a GVM equation out to a bunch of servers and let them report\nback if they are joining the set even on Ethernet. That might be an interesting open source project\nthat could even be incorporated into Kubernetes. But that’s someone else’s business.\n[A29] The key point is that the GVM on the Transaction Fabrix provides a lot of other advantages,\nsuch as no address management. We won’t get that even on IB. Nor do we get the reliable failure\ndetector or rapid failover, because there’s no concept of ‘neighbor’ of a node. In a conventional,\nso-called ‘flat’ network, all nodes are virtual ‘neighbors’ of all the other nodes. Some systems try to\nfake that at the cost of packet forwarding in user space, but at a horrendous performance penalty.\n[Q30]\n[A30] Yes. But this would somewhat constrain the benefits of architecture. The ‘Goldilocks\nZone’ of our graph theory algorithms is 8 ± 2 ports (our recommended cell valency is 8). However\nthere would still be sufficient benefits to justify such a deployment. The only reason to deploy\nless than 8 ports, would be to ease customer adoption5, by making it easier (initially) to try out\nour solution, with more potentially available off-the-shelf Ethernet SmartNIC’s that support 4\ncopper-only ports directly on the front panel of a PCIe card, instead of the 1 or 2 QSFP ports that\ndominate conventional NIC’s.\n[Q31]\n[A31] I think complexity reduction is the right approach. The cloud is still way too hard, and\nthe full complexity of networking is simply hurled at developers and kubernetes admins. Service\nmeshes like Istio / Linkerd claim to simplify the networking, but as far as I can see they only pile on\ncomplexity and layers of inertia. Moreover, they assume a local clustering model. You can’t easily\nsew together edge computing with datacenter computing for IoT. This is what we wanted to do in\nAljabr.\nThere are still no good solutions for that. But see Solo.io - Init Levine is a smart cookie.\nCilium is also a decent linux kernel technology for dealing with some of the interconnection issues.\nhttps://cilium.io/\nThe service mesh idea is to double up every application container in K8S with a “sidecar”\nrunning a microservice that forwards packets and does the automated assignment of addresses. It\ncan also do some tracing of packets. Developers have been shut out of software tracing tools by\ncontainers because you have no access...so they are trying to replace everything by packet tracing at\nthe TCP level—a bit like network intrusion detection. It’s an incredibly hopeful (but not reasonable)\napproach to debugging, which is incredibly wasteful and a performance hit. You end up with twice\nthe service burden for every cluster. Designed to melt the icecaps.\nSocketplane’s vision was to build a scoped directory service approach to coordination, using\na library on application level, a bit like what eventually because Consul and etcd in Kubernetes.\nIt was based on the ”Workspaces” ideas we wrote about back in 2014. It was never implemented\nbecause the founders sold the company to Docker very quickly just to hire a couple of the people.\nThey sold out and implemented a plugin architecture instead so that Docker would support the\necosystem of (rather bad) solutions that were already out there. Some of these have since died and\nsome have become extra layers on top of an already heavy stack.\n5Similar to the way the Electric Car industry went through its ‘hybrid’ stage, with gasoline and electric motors in\none vehicle.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 17 of 45\nThe issues are the usual ones: -Identity -Discovery -Load sharing\nGoogle has no interest or clue about the networking part, as they have their own internal\nnetworking solution which is not portable.\nNetworks (even without semantics) are being brought up to layer 7 instead of adding smart\nbehaviours down the stack to lead applications free from silly chores, like setting port numbers.\nAt Aljbar, we wanted to realise what the providers call ”NFV” - i.e. smart data pipelines. Most\npeople have a limited view of this - and this its only for data processing, e.g. machine learning.\nData processing Pipelines are basically smart Petri Nets, which could be made very efficient\n(workspaces - https://arxiv.org/abs/1907.01796) but people are doing the opposite. It’s because\nof the microservices wave. I think that’s a temporary aberration, and what we need is to make\na compiler that treats the network just as a normal memory bus, making all communication\ntransparent and scale independent.\nMy personal take is that inexperienced developers are trying to expose everything at layer\n7 because they want to take over all functions themselves. But this is in opposition to sensible\nabstraction principles, and its very wasteful.\nRE your FAQ\nIt strikes me that you are too hard core in some of the answers. You could still use IP addressing,\njust at a higher layer.\nPeople will still need IP, including addresses and ports to make their\napplications run, even though they shouldn’t need to talk about those things. It seems they still\nhave to.\nAgain, these were issues we wanted to make disappear with Aljabr, but just couldn’t keep the\nteam together. Eventually, I imagined that it would be natural to talk to you about Earthcomputing\nas a network.\nThis is not too much, but it’s what jumps out at me, off the top of my head.\n[Q32]\n[A32] “For every hop along the network, each device has\nto make a decision what to do with the packet. If you put\nyourself in the packet’s perspective, you can figure a lot of\nstuff out”.\n[A32] Our LOV! (LOV!) packet perspective has only one\nthing to do: tell the forwarding engine what its TreeID is.\nThe forwarding engine can then make a local decision based\nonly on:\n• For each TreeID in its forwarding table:\n– Which port the packet came in on (i.e. was it the root port, or a child port for that tree).\n– Which ports in the routing table have forwarding bits set to forward the packet on (with\nthe exception of the port it came in on).\n• For any TreeID NOT in its forwarding table:\n– Send the packet to the Cell Agent.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 18 of 45\n[Q33]\n[A33] Everything is a Cellular Fabrix Tree Identifier (CFTI). A 128-bit GUID which appears to\nthe architecture as having no no structure (all bits appear to be entropy).\n[Q34]\n[A34] With Tree Addressing, we can migrate with less management overhead. When we migrate,\nthe sender doesn’t have to know who the recipients are, and the fabric forwarding pointers follow\nthem (instead of having to be re-stitched up after migration as is required in L2 or L3 Protocols, for\nKubernetes).\n[Q35]\n[A35] Using IP addresses conflates name with location. The Transaction Fabrix makes a careful\ndistinction between identity and individuality. Addressing is about individuality; naming is about\nidentity. On the TF, named things (containers, VM’s lambda’s) can move around without having to\nchange their name.\n[Q36]\n[A36] Instead of conventional Any-to-Any (A2A) addressing, using source-destination pairs in the\nprotocol, we use a single (e.g.128-bit) Tree Identifier as the ‘destination’. All members of the tree\nreceive and process all packets sent leafward by the root, and all intermediate cells forward (without\naction) all rootward packets sent to the root by any other cell.\n[Q37]\n[A37] No. Set membership is controlled by recursively subsetting the tree (the graph cover or\nsubtree) under local API control. Think of programmatically reducing the ‘broadcast domain’ to\nonly the set of cells desired by the application is on a given tree. The smallest graph can be just\ntwo cells adjacent to each other. The conceptual difference is critical: Both cells write only to the\nentity named by the TreeID. There is no notion of source and destination. The sender is implicitly\nthe source, the entire tree is the destination.\n[Q38]\n[A38] First, lets establish some terminology from Difference between Distance vector and path\nvector protocol:\nDistance Vector Routing. (DVR) sends distances, and is used DVR is used inside a domain.\nPath Vector Routing. (PVR) sends paths. This is used between domains. e.g. BGP is a PVR\nprotocol.\nTree Vector Routing. (TVR) DAEDAELUS uses a Tree-Vector Protocol. Every cell builds a\ntree rooted on itself. It gets to decide the name if its tree, and be the arbiter of who can do\nwhat on it. There are in principle, only two operations:\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 19 of 45\n• If you are a child of some other cell’s tree, then you can only do a rootcast. All rootcast\nmessages are passed through all intermediate cells by the forwarding engine from any\nchild port to the rootward port, until the packet reaches the root.\n• If you are the root, the only operation you can do is a treecast. Everyone on the tree\ngets a best effort copy of the message. Endpoints are no longer managed by the source,\nwho knows only its own treeID it can send packets out on6. Endpoint sets are managed\nby stacking a subset tree. Trees can be indefinitely stacked, all the way down a degenerate\nconnection between two cells.\n[Q39]\n[A39] While there are many times you want anyone to communicate with your service, e.g.,\nfacebook.com, there are more times when you wish to control the communication, e.g., robocalls.\nA2A addressing means you need some other mechanism that addressing to enforce the controls,\nsuch as NAT boxes and firewalls that are notoriously difficult to manage.\n[A39] In a microservices environment, A2A addressing makes it all to easy to inadvertently connect\ncomponents that should not talk to each other. It also makes it easy for an attacker to leverage the\ncompromise of a single component.\n[A39] According to RFC 1627. [A 1994 document]: “A common – if not universal – ideal for the\nfuture of IP is for every system to be globally accessible, given the proper security mechanisms.\nWhether such systems comprise toasters, light switches, utility power poles, field medical equipment,\nor the classic examples of ‘computers’, our current model of assignment is to ensure that they can\ninteroperate.”\n[A39] This question was originally explored by John Shoch and J. Saltzer. Following this theme,\nwe have their general model:\n• The ‘name’ of a resource indicates *what* we seek,\n• An ‘address’ indicates *where* it is, and\n• a ‘route’ tells us *how to get there*.\n[A39] We manage this model by taking standard Ethernet hardware, connect them together without\nswitches, so we can ‘hijack’ the Ethernet frames, and do what we want with them. By having our\nfunctionality embedded transparently in the SmartNIC, we can do routing differently, we can do\nprovisioning differently, and we can do security differently. This opens up an enormous opportunity\nto solve some of these most vexing problems in todays networks. Our goal is to make distributed\nsystems vastly simpler to program.\n[A39] In the Transaction Fabrix Tree Vector Routing (TVR) scheme, the name is something that\nis local but can be globally unique7. In principle, it only has to be locally unique. For example we\ncan have two “John Smith’s” containers in different, but non-overlapping domains (they will have\ndifferent GUID’s).\n61-hop neighbors will prevent anyone trying to send a treecast who is not 1 hop away. Only roots can send\ntreecasts.\n7We ensure unique names using standard GUID techniques (128- or 96-bits of entropy in a datacenter, 256-bits\nworldwide).\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 20 of 45\nThe address is where its root is. i.e., in graph theory, a spanning tree rooted on a self-cell that\ntreats as the only legitimate distinguished cell.\nThe route, when appropriately separated from the other concepts above, will be dynamic. For\nexample, if a human being moves around with their cell phone, their number will remain the same,\nbut the route will dynamically follow them.\n[Q40]\n[A40] Not on the Cellular Fabrix (CF). ‘Confirmed multicast’ (and its twin, atomic broadcast)\nis impossible on networks that drop, reorder, duplicate and delay packets. On the CF, every cell\n(member of the set) is resolved) to be LIVE before the operation starts, and complete, when the\ntransaction has succeeded.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 21 of 45\n[Q41]\n[A41] Compare the standard Ethernet Header (in 64-bit packet format):\n0\n1\n2\n3\n4\n5\n6\n0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|\nDestination MAC Address\n|\nSource MAC Address\n|\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|\nSource MAC Address\n|\nEthertype = C-Tag 802.1Q\n|\nVLAN Tag Information\n|\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n| Ethertype = 0x0800\n|\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n[A41] With the DAEDAELUS Ethernet Header (64-bit packet format):\n0\n1\n2\n3\n4\n5\n6\n0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|\n|\n|\nCellular Fabrix Tree Identifier (CFTI)\n(e.g. 128-bit GUID)\n|\n|\n|\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|\n|\n|\nNothing but the payload.\n|\n|\n|\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n• discover is a packet header containing a TreeiD that has not been seen before (rootport may\nbe encoded in the TreeID).\n• discoverd is a packet header containing a TreeiD that is recognized by the root as it’s own\nCellID, and by all intervening cells as a rootcast (forward to the root).\n• stacktree is a packet header containing a base TreeiD in the Key, and a new tree to be\nstacked in the payload).\n• stacktreed is a packet header sent back (from the root toward the root of the NEW tree.\n• ENTL (and other link-local packets) include the initiator TreeiD.\n[Q42]\n[A42] The CFTI is a blank slate, we ‘try not’ to put arbitrary encodings into it, as has been the\ncase with previous protocol designs, because such arbitrary encodings prove to be constraining as\nthe technology evolves. However, fundamental architectural features may be encoded. Such as:\n• Scope (e.g, constrain to one hop or to every cell downstream on that branch? [zero, one, ∞].\n• Liveness bits (e.g. the 4+ bits required for ENTL/ENTT).\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 22 of 45\n• Transaction bits (e.g. the additional bits + 64 bit 128 bit identifiers that uniquely define a\ntransaction.\n[Q43]\n[A43] They don’t (need to) exist. The bits on the wire are the bits in memory; there is no transport\nlayer. This is a new kind of simplicity that may initially make some experts uncomfortable. This is\na paradigm shift, not an incremental redesign of conventional networking. Think ‘Key-Value Store’\non the wire8.\n8We don’t need to be pedantic here, it is possible to build this on top of a conventional transport layer. However,\ngetting this key idea over illustrates something important: ‘just how simple this can get’ when we take advantage of\n‘clean virtualization’\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 23 of 45\n[Q44]\n[A44] Like this:\n0\n1\n2\n3\n4\n5\n6\n0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|\n|\n+-\nKey\n(128 bits)\n-+\n|\n|\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|\n|\n+-\n-+\n|\n|\n+-\n-+\n|\n|\n+-\n-+\n|\n|\n+-\nValue (rest of packet)\n-+\n|\n|\n+-\n-+\n|\n|\n+-\n-+\n|\n|\n+-\n-+\n|\n|\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n[Q45]\n[A45] Network experts will try to fit these ideas into the existing categories they already know.\nThis will turn out to not be possible (in general). All humans suffer from confirmation bias. The\nbeliefs of the current networking industry were developed incrementally over a long period of time,\nand their most basic assumptions are so deeply embedded this makes it difficult to even see what\nthese assumptions were.\n[A45] RAFE is not a conventional transport layer. it’s a ‘key’, and ‘value’ with duals on the wire,\nand in the memory. In its basic design, it doesn’t need conventional transport layer ‘fields’. There\nis no serialization and deserialization. This is the beauty of our approach. We don’t try to be overly\ncompatible with legacy ideas and standards, Economy of mechanism is our guiding principle.\n“Any intelligent fool can make things bigger, more complex, and more violent.\nIt takes a touch of genius – and a lot of courage to move in the opposite direction.”\n– Ernst F. Schumacher\n[Q46]\n[A46] Of course. Here are a few examples:\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 24 of 45\n1. Source and destination (for both the MAC layer, and the IP layer) are combined into a single\n‘treeID’ to target all operations.\n2. The Header is 16 bytes. All bytes are used for the CFTI. There is no ‘type’ encoding (e.g.\nEthertype, EARTHType, or whatever encoding field, and no version numbers as there are in\nIP.).\n3. There is no packet size, message size, or any other size. The payload is always fixed size.\nEverything else is legacy compatible, and gets pushed through a regular protocol stack.\n4. There is no VLAN Tag. We replace the entire notion of VLAN’s (and VxLAN’s) with stacked\ntrees.\n5. The discover packet should include: (a) the root TreeID (b) the TreeID’s of each of the directly\n(one hop) cells. (c) the portID of the root (which identifies the primary branch of that root’s\ntree). Note that (b) and (c) are directly related.\n6. Hopcount. This is the primary clue for where a descendent cell is in the graph relative to the\nroot cell. This is for the GVM.\n7. Port ID for root (each cell maintains this information for itself)\n8. Child Mask (each cell maintains this information for itself)\n[Q47] For example, to conventional virtual machines, operating systems and containers?\n[A47] We construct a two-cell tree when a legacy application connects one cell to another and\ntunnel the legacy Ethernet frame in the payload of the packet. When the application specifies an IP\naddress, our library translates that address to an TreeID. Our stacked TRAPHs guarantee that\nlegacy applications cannot send or snoop on any packets not intended for them.\n[Q48]\n(and related tools for container management & API gateways?)\n[A48] We run Kubernetes in legacy mode by tunneling conventional IP packets ‘on top’ of our\nprotocols. However, we can do better by providing a library or sidecar that uses the DAE API\nfor managing components. For example, instead of relying on the application master for elasticity\ndecisions, we can make those locally. In essence, we compliment or enhance many of the tools these\nsystems provide, such as Linkerd, Kong, Robin Systems and Kasten – we are a very significant\nenhancer for them by improving the foundation on which their IP protocols run, and make it simpler\nand more reliable to do things they currently do with great difficulty and limited success.\n[Q49]\n[A49] Performance is secondary to Simplicity, Resilience and Security. Having said that, performance,\nlatency in particular, will often be better (far better) on the Transaction Fabrix.\n[A49] Think of the mistakes we have been making for years in trading off performance for security9.\n9See: Meltdown and Spectre\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 25 of 45\n“If you optimize everything, you will always be unhappy”\nDonald Knuth\n[Q50]\n[A50] The basic principle: each cell is the center of its own universe. All it needs to know is which\n‘direction’ to go to find the replicas of its Key-Value store. Destination addresses are replaced by\n‘direction’ indicators. This way, replicas can migrate back and forth along the branches of a tree,\nwithout needing to change their names; the direction indicators simply guide any packet along the\nbranches of the tree.\n[A50] As far as we can tell, the DAEDAELUS Stacked-Tree based naming and addressing system is\nthe only design for a rack-scale interconnect that can work properly ‘in principle’. Our architectural\ninnovation is a fully distributed set of ‘independent trees’ with ‘intrinsic multicast’ addresses\nthe master failure problem, and dramatically simplifies load balancing while allowing component\nmigration and elasticity decisions to be made locally in milliseconds, without having to stitch up a\nbunch of endpoint address afterwards, as V-Motion does at Layer 2, or Kubernetes does at Layer\n310.\n10There are some surprising benefits of this approach such as the ability to migrate ‘serialization foci’ for transaction\noperations, making location independence, failover, load balancing and VM/Container migration a practicality.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 26 of 45\n[Q51]\n• 128-bit Universally Unique Identifier GUID. This is the default, what we call the “base\narchitecture”.\n• Everything else is premature optimization (the root of all evil).\n[Q52]\n[A52] There are 3 ways to do networking: (1) By destination, (2) By path, and (3) By name.\nThe latter is by far the most interesting; mobile entities don’t have physical destinations and their\npaths change constantly. ‘Confirmed multicast’ is an intrinsic property, superior to all previous\nconceptions of ‘reliable multicast’, because our protocols resolve the uncertainty of whether these\noperations failed or succeeded atomically.\n[Q53]\n[A53] Because they won’t ever be on the same wire. We are in charge of the NIC’s11. No one\nelse should be sending or receiving these packets in the Transaction Fabrix except us. We are\n‘compatible’ with legacy Ethernet NIC’s only in one aspect: we are constrained to do on the wire\nwhat existing NIC’s are capable of being programmed to do – and not by what some standards say\nthey should do.\n[Q54] Such as rootward, leafward rootcast and leafcast?\n[A54] A separate opcode filed is the standards way, but may be unnecessary – these operations can\nbe made implicit (see description at beginning) e.g.:\nRootward can be detected by (TreeiD is not equal to MyTreeID), therefore the message I’m sending\nmust be for the root. Send it on the rootward port only.\nLeafward You are not allowed to send leafward packets unless you are the root. Therefore if\nTreeiD is equal to MyTreeID then the message must be leafward (all members of my tree are\nbroadcasted to).\n[Q55]\n[A55] Leaves may only send messages to the root. Intermediate cells will forward your packets (on\nthat tree) until they reach the root.If you want to send messages to other cells, then send them on\ntheir tree.\n[Q56]\n[A56] The basic idea is to replace the conventional idea of encoding (for each protocol layer) some\n‘fixed’ or standardized description of what the protocol does at this layer, with the Tree approach:\n11We could chose a TreeID that is compatible in some way with the Ethertype Identifier. Choosing one that is\ndeliberately incompatible with existing hardware will help us identify and inhibit penetration by legacy systems.\nHowever, this is subsumed by the “special TreeID’s” in a particular implementation of the mint(TreeID) function.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 27 of 45\nRoot sends to the entire tree, everyone but the root sends to the root only. Any “special” functions\nmay be encoded as special TreeID’s (See the CFTI description)12\nFools ignore complexity. Pragmatists suffer it.\nSome can avoid it. Geniuses remove it. – Alan Perlis\n12This allows us to have additional tree constraints the higher we stack our trees. Base (black) trees have the least\nconstraints, and each stacked tree can have additional “control identifiers” expressed as TreeID’s that an application\nis not allowed to use. The higher the stack, the greater the constraints and the lesser the tree above is able to do.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 28 of 45\n[Q57]\n[A57] RINA13 goes a long way in identifying the problem, and the reasons why IP went astray but\nit tries to address it by replacing IP on the internet, competing directly with IP, instead of working\nunder or over it.\n[A57] The TF protocols on the other hand do a ‘clean virtualization’, and don’t try to compete,\nor even ‘mix’ the protocols at the same level of abstraction. i.e. we solve the customer adoption\nproblem by coexisting with TCP/IP, not by trying to replace it. From: Patterns in Network\nArchitecture:\n“In Saltzer on addressing. In 1982, Jerry Saltzer at MIT published one of the most cited papers on\nnaming and addressing in computer networks. Saltzer (1982) outlined how a network must have application\nnames, which map to node addresses, which map to point of attachment addresses, which map to routes.\nThese are all of the necessary elements of a complete addressing architecture means in a graph. While\neveryone cites this paper and agrees that it is the right answer, there have been no proposals to implement it.\nBut in all fairness, Saltzer doesn?t provide much help with how his abstractions might be applied to the\nexisting Internet or what location dependent means in a graph.”\n[Q58]\n[A58] Yes. It’s called the “ask Bob” protocol:\n• Consider some cell A. When A receives a discover message with GUID x on some port p1, A\nsends a nonce n1 on p1 to the root of that tree. When the root receives that nonce, it sends it\nback on the same path so that A receives it on p1. When A receives a discover message with\nGUID x on anther port p2, A sends a nonce n2 on p2 to the root of that tree. If that root\nhas seen n1, it sends n2 on a path that reaches A on p1. A now knows that both discover\nmessages come from the same cell.\n• Say that A receives a third discover message with GUID x on a third port p3. A sends a\nnonce n3 on p3 to the root of that tree. Say that this time the root is a cell that has not\npreviously seen a nonce from A. The root sends n3 back to A so that it arrives at p3. A now\nknows that there are two cells that claim GUID x.\n• We can recover from this GUID collision. A creates two different GUIDs and sends one on p1\nand the other on p3. The recipients change their GUIDs, send out messages to cancel their\nDiscover messages with GUID x, and then send Discover messages with their new GUIDs.\nThis protocol works in all situations, including more than two cells claiming the same GUID, multiple\ncollisions, and more than one cell detecting the collision\n[Q59]\n[Q60]\n[A60] eBPF is absolutely on our radar, and we’ve been discussing it for a couple of years now with\nNetronome. We support eBPF, however, all it does is allow safe forms of c-code to be inserted\n13See: Patterns in Network Architecture: A Return to Fundamentals, John Day (2008). Book. Free Chapter.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 29 of 45\nin network flows. The rest of the industry cares about network flows. We don’t. We care about\nprotocol closures – i.e. those elements that are complete from\n”I suspect it’s the newest / best competitor for duck-tape on steroids trying to overcome\nthe complexities of tcp/ip.” [Bill Jackson]\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 30 of 45\n[Q61]\n[A61] iptables has been a blessing and a curse: a blessing for its flexibility and quick fixes. A\ncurse during times debugging a 5K rules iptables setup in an environment where multiple system\ncomponents are fighting over who gets to install what iptables rules.\n[A61] A recent KubeCon talk examined kube-proxy performance in all details. The talk presents\nmeasurements showing unpredictable latency and reduced performance as the number of services\ngrows. It also reveals another major weakness of iptables: lack of incremental updates. The entire\nlist of rules has to be replaced each time a new rule is added. This leads to a total duration of 5\nhours to install the 160K iptables rules representing 20K Kubernetes services.\n[A61] Using IP/port based mechanisms has many other obvious disadvantages in general, in\nparticular in the age of application containers. Containers are deployed and torn down frequently.\nThis can lead to a short lifetime of individual IP addresses. An IP address may be used by a\ncontainer for just seconds and then gets reused by another container a couple of seconds later. This\nputs stress on systems which rely on using IP addresses for security filtering purposes as all nodes\nin a cluster must be constantly aware of the latest IP to container mapping. While this is barely\ndifficult within a cluster, it becomes incredibly challenging across clusters\n[A61] These are only some of the reasons why we have to change from IP/port based routing\nto TRAPH-based routing based on stacked trees. By moving from an E2E based IP addressing\nsystem, to a Tree-based (relative) addressing system, we allow execution entities to migrate across\nthe datacenter, without the pain and difficulty of fixed IP addressing.\n[Q62]\n[A62] Achieving high forwarding rates is not a matter of the number of clock cycles needed to\nmake a forwarding decision, but instead is one of cache hit rates; what fraction of packet forwarding\ncan be done based on the forwarding of previous packets. This applies both to software, and to\nhardware switches.14.\n[A62] From: A flow caching mechanism for fast packet forwarding:\n“We show by model analysis that flow caching performance is not very sensitive to the\nflow cache table lookup speed but it is sensitive to the cache hit ratio.”\nSee also Hash, Don’t Cache for a similar perspective in hardware routers.\n[Q63]\n[A63] As always, speed depends on size. However, Modern implementations are far faster than\nthey used to be a few years ago. For example: A new fast hash table in response to Google’s new\nfast hash table.\n[Q64]\n14See Rethinking Packet Forwarding Hardware.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 31 of 45\n[A64] There isn’t a lot of detail about what protocol Starlink uses. Musk has said that it is ‘simpler\nthan IP’, and ‘IP-Less’. The current beliefs in the industry is that it uses a proprietary MANET\n(Mobile Ad-Hoc NETwork) protocol. [Hackaday]\n[A64] It should be kept in mind that the purpose and requirements for a Starlink protocol are\nquite different to the Transaction Fabrix (TF). Starlink is much more like a conventional switched\nnetwork, which transports packets to endpoints which are the servers (or client computers) that use\nthem. Whereas the TF is an integrated cell-link architecture where each of the nodes does useful\ncomputational work.\n[A64] In all likelihood, the protocols will be entirely different. It’s entirely possible that Starlink is\njust a different Transport Layer, with a conventional MAC for Layer 2, whereas the TF effectively\nreplaces layer 2 by operating under at layer 1-1/2. The physics of the protocol is also entirely\ndifferent: The Starlink MANET is necessarily a wireless broadcast protocol, whereas the Transaction\nFabrix must be a bipartite (2-party only) link protocol for it provide the exactly-once semantics\nguarantees we offer.\n[A64] More importantly, the TF replaces the ‘absolute addressing scheme’ used in Ethernet/IP\nwith a ‘relative addressing scheme’ so that it can natively support load-balancing, elastic expansions\nand shrink, and consensus protocols among its neighbors.\n[A64] Having said that, the TF protocols do have some similarity to MANET (Mobile Ad-Hoc\nNETwork) protocols. Our black trees (the groundplane) will discover any topology it is given in a\ndatacenter, and could even be potentially optimal for rapidly evolving topologies such as Starlink.\nHowever, the trees stacked on top of them are designed not for routing ‘flows’ but for computation\n‘closures’, such as consensus, two or three phase commit, and atomic transactions.\n[A64] For a deeper dive into the comparison of protocols, see ZRP.pdf, SHT.pdf and Reviews-\nOnly.pdf in the Cassiopeia FAQ.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 32 of 45\n[Q65]\n[A65] Like this:\nEstablished Link (on Tree)\nPruned Link\nFrontier Link (not yet on Tree)\nP0[0]\nP1[1]\nP6[1]\nP5[1]\nP4[1]\nP3[1]\nP2[1]\nP2[2]\nP1[2]\nP1[2]\nP4[2]\nP4[2]\nP5[2]\nP5[2]\nP6[2]\nP6[2]\nP3[2]\nP3[2]\nP2[2]\nP2[3]\nP2[3]\nP2[3]\nP3[3]\nP6[3]\nP5[3]\nP5[3]\nP5[3]\nP1[3]\nP6[3]\nP6[3]\nP1[3]\nP1[3]\nP4[3]\nP4[3]\nP4[3]\nP3[3]\nP3[3]\nFigure 1: Note that there are only three categories of things that can be distinguished by the root cell: [Self\n(singleton - 0 hops); Immediate neighbor cells 1 hop away (finite – valency limited); everything else (out to infinity)\ncannot be uniquely distinguished]. The thick lines represent the base tree constructed using discover and discoverd\npackets. The thin lines represent physical links that have been pruned from that tree (but remain available as standby\npaths), and the dotted lines represent frontier links not been accessed yet by the tree-building process.\n[Q66]\n[A66] Like this:\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 33 of 45\n[A66] There are seven stacked trees on 32 cells in the figure above (red, orange, yellow, green, blue,\npurple and violet). The procedure to build the trees is as follows:\n• The red tree is built as flood and prune by discover and discoverd packets. Imagine this is\ndone from one of the center cells (it doesn’t matter).The red tree is ‘owned’ by one cell, and\nspans all 32 cells15.\n• The orange tree is built ‘on top’ of the red tree by rootcast’ing a stacktree message. Because\nthe base (red tree above) already exists, this takes the place of the discover/discovered on\ntop of an existing tree. The orange tree may be built on the same root as the red tree (e.g.\none of the cells in the middle.\n• The yellow tree is a subset of the orange tree (graph cover over 8 cells). It can be initiated by\na different member of the orange tree by rootcast’ing the stacktree message, and setting up\na Routing Table (CA aware) tree. The root (of the parent tree) responds by sending a new\nstacktreed message builds the tree, not with its root pointers pointing back to itself, but\npointing forward to the new root for the stacked tree. This stacktreed message is retired by\nthe initiating cell, which is now the root for that stacked tree.\n[Q67]\n[A67] Ours is a symmetric, event-driven protocol.\nWe prefer not to use the concepts of re-\nquest/acknowledge at the lowest levels in our tree.\n1\n3\n6\n9\n12\n0\n1\n2\n3\n4\n5\n6\n7\n10\n7\n4\n2\nPackets in flight …\n!\nDiscoverable Zone\nReachable Zone\nStrange Zone\nUnknown\nDiscovered\nKey Transition is for ‘strange”\nCriteria for decision - all ports present & accounted\nfor (have either sent or received a discover packet on\nall active ports).\nRecommendation: at least one port is charmed (leaf)\nWe may still end up with later arrival of a discover packet on other\nports, but at least we now have a basis on which to make a\npreliminary decision.\nCode: message.modifier(p/P) p ports discovered, of a total of P\nDiscover(0)\nDiscover(1)\nDiscover(2)\nDiscover(3)\nDiscover(4)\nDiscover(5)\nDiscovered (1/4)\nStrange.rootward (3/4)\nStrange.rootward (4/4)\nStrange.rootward (4/4)\nStrange.rootward (4/4)\n5\n8\n11\n14\n13\n15There are other ‘physical’ links between each of these cells not shown in the figure because they have been pruned.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 34 of 45\n[Q68]\n[A68] EARTH provides an alternative less-\nbrittle and more secure concept for name reso-\nlution; dispensing entirely with the need for name servers (including DNS – except for compatibility\nwith unmodified legacy applications) and is represented by a new concept, which we try to capture\nin the term “Neighbor to Neighbor (N2N) addressing on a tree”.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 35 of 45\n[Q69]\n[A69] The latency for lookup is too high for microservices, and caching lookups is ineffective because\nthe environment is too dynamic. For serverless, this overhead would be intractable.\n[A69] Those names are ‘brittle’ which means a small change in the environment can cause problems.\nEver had a “404 Not Found” error when surfing the web? Maybe that’s because a server was\nrenamed or the entry in the DNS name service was updated incorrectly16.\n[A69] The EARTH Name System (ENS) recognizes that distributed systems are inherently dynamic\nand that fault tolerance requires replication. But how should we differentiate the replicas by name?\nRather than directly naming what you want to use, which requires knowing where it is or using a\nservice that does, ENS connects replica sets on named trees rather than a singular thing. As long as\nthat thing stays on a server subscribed to that tree, your request will reach it. ENS also means you\ncan have multiple replicas of that thing, and your messages will reach all of them, and you don’t\neven have to know how many there are. The result is a name system that is immune to the kinds of\nfailures we are currently forced to deal with.\n[Q70]\n[A70] Let’s say I have a stateless service running on the root of a tree that starts getting overloaded.\nThat service can replicate itself to some of its child nodes on the tree. Since all requests from lower\nin the tree must pass through those child nodes to reach the root, the requesters will have no idea\nthat anything changed. When the load drops, the child nodes can just start forwarding request to\nthe root again.\n[A70] Another application is a sharded key value store in which different nodes hold the values\nassociated with different keys. In a conventional system, clients use the key they want to look up to\nfigure out the address that should get the request. That works fine until we need to redistribute the\nkeys to balance the shards, because updating the clients with the new addresses is an issue.\n[A70] Things are far simpler with the EARTH Naming System (ENS) (within a datacenter). We\nstart with the client requests coming to the root of the tree and the shards deep in it. When a shard\nneeds to be split, it distributes the keys and their values among the child nodes; when it needs to be\njoined with another shard, we combine them into a parent. At no point need the clients be aware of\nthese changes.\n[Q71]\n[A71] You’re thinking that we need a GEV! (GEV!) of the whole system. Actually, it’s far simpler\nif we stick to a LOV!. When a node comes up, it transmits a special message on all its ports. As\nthis message propagates through the system, each receiving node records information about which\nof its ports points to the parent of the tree with the new node as the root, which point to children,\nand which of its ports are connected to links that aren’t part of that tree.\n16The A2A! (A2A!) names we use today (IP, DNS) are a security hazard. Famously, the domain sex.com was\nhijacked, but DNS happily directed all requests to the hijacker’s servers. Dangling references enable an abandoned\ndomain names to be picked up later by a malicious party. Anyone with an old link to pages under that name is\nsusceptible to attack.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 36 of 45\n[A71] This approach has many other advantages. For example, it doesn’t depend on knowing the\nactual wiring. If a cable is misrouted, our algorithms figure this out automatically. Also, each node\nkeeps data necessary to know what to do when a link breaks, which allows us to fix things locally\nvery fast.\n[Q72]\n[A72] No. Our system comes with a library that supports legacy applications. When you open a\nsocket on a specific port at a given IP address and someone connects to it, our library will construct\na two-node tree consisting of the endpoints. Any requests on that connection will be sent by naming\nthat tree. You’re not going to get all of the advantages of ENS, but you’ll be able to migrate your\ncode a bit at a time.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 37 of 45\n[Q73]\n[A73] No. When we build the tree, we specify which nodes can send to and receive from that\nparticular tree. The lowest level in the intervening nodes simply forward the message on the trees;\nwe call this transit forwarding. All transit traffic is invisible to the upper layers of the cell that’s\ndoing the transit forwarding.\n[Q74]\n[A74] Yes, as long as that pattern is a tree. You describe what cells you want in the new tree by\nspecifying what we call a GVM Equation. You send out the GVM on a particular tree, and the\nsystem uses the GVM to pick a subset of the nodes on that tree to be in the new one. Because\neverything is LOV, you can start sending requests on the new tree immediately. That’s a lot easier\nthan creating lists, in todays systems.\n[A74] These execution environments are our TCB. We use the hardware protection mechanisms\n(MMU, IOMMU) in the main processor to protect the Cell Agent, and the isolated protection\nenvironment in the SmartNIC to further protect the mechanisms from attack.\n[Q75]\n[A75] The Graph Virtual Machine (GVM) Is a mechanism in each agent that interprets ‘GVM\nequations’ in their current LOV! environment. If the equation evaluated in the local context\nevaluates to true, the cell joins the tree. (Joining the tree means that messages sent on that tree\nwill be forwarded to one or more applications running on that cell.) If the equation evaluates to\nfalse, the cell will only forward packets sent on that tree.\n[Q76]\n[A76] This question cannot be answered without a context of the distinctions between the GEV,\nand the LOV! (see FAQ here). It is extraordinarily easy for most computer scientists and engineers\nto conflate these two vantage points. So lets try and explain this step by step:\n[A76] Any to Any (A2A) addressing implies a set of endpoints that can logically connect with each\nother through a switched network. i.e., any endpoint can in theory have a ‘reference’ to any other\nendpoint, whether it is guessable or not. This concept is common to object oriented design, shared\nmemory references, and to capability based systems which manage the access to resources using the\nconcept of a ‘reference’.\n[A76] Neighbor to Neighbor (N2N) implies that the only entity you can directly address on ones\nown tree, is a neighbor one hop away (i.e. separated by a single Link, OR entire branch(s) of ones\nown tree connected to one or more ports on this (self) cell). This is Tree addressing: Integrity and\nmembership of the tree is maintained by distributed algorithms, not by knowledge at each endpoint\nof all the other individual endpoints that can participate in the algorithm.\n[A76] At this point, an informed reader may raise the objection: ‘then how can cell Cx talk to\ncell Cy?’ The answer is that Cy can always communicate with Cx on Cx’s tree, and Cx can always\ncommunicate with Cy on Cy’s tree. I.e., a rootcast message is always forwarded on the parent\nport for that tree, by any cell that is not the root, until the packet arrives at the root (a ‘promise’)\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 38 of 45\nthat every cell makes to any discover/discoverd packet exchange. This provides unidirectional\naddressing: any cell can communicate with the root cell on the tree owned by that root. If necessary,\nreplies to the sender can be on the sender’s tree.\n[A76] The next objection from an informed reader is ‘does not provide acyclic communications,\nwhich enables the In-Order-Delivery (IOD) property’. The answer is that for Cy to communicate\nback to Cx on Cx’s tree, there must be a Zubzcribe, which ‘stacks’ a tree ‘on top’ of Cx’s tree: at\nthis point this would be a degenerate case of a chain of links from Cx to Cy, i.e. Cx can treat Cy as\nan endpoint and Cy can treat Cxas an endpoint on the same tree (without each having to know\nhow far they are apart). All addressing is now done as a direction (through a specific port on Cx\ndown the chain, into a specific port on Cy). We now have established a communications relationship\nbetween these two cells, where both these entities can now ‘migrate’ closer or further away from\neach other on that segment of the tree, but the addressing (related to TreeID and port number\nnaming) remains the same.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 39 of 45\n[Q77]\n[A77] Because now applications (e.g. some member of a microservice set) can use this scheme to\nconsistently address other members of the microservice set, through all kinds of perturbations: load\nbalancing, elastic expansion and contraction based on normal or abnormal traffic load, or more\nimportantly: failure & recovery.\n[Q78]\n[A78] Connecting servers in a regular lattice (with 4 connections E,W,N,S) is appealing in its\nsimplicity because human beings like regularity, and such a scheme appears to be naturally supported\nby the physical rack and row structure in a datacenter. However, the Cellular Fabrix does not\nrequire a regular mesh; that would be fragile to link or node failure. We fundamentally improve the\nrobustness of the network by abandoning the need for nodes to have destination addresses. When\nwe move away from A2A addressing, there are two primary ways to address the servers (cells) in\nthis network: Absolute, and Relative.\n[Q79]\n[A79] Absolute addressing: a GEV! cartesian coordinate system (X, Y ), where we number the\ncomputers (Y ) by say counting from the top, and we number the racks racks (X) from left to right.\nThis is typical of many hypercube interconnects work in HPC.\n[Q80]\n[A80] That would only work in a fixed, perfectly reliable system. By avoiding the need for discovery\nand we don’t have to lay them out on the fly. In this model, programmers can ‘trust’ the topology\n(as a service). It will be there over long timescales relative to the computations perform. This is far\nsimpler algorithmically.\n[Q81]\n[A81] Relative addressing – an (R, θ) coordinate system, where every node builds a coordinate\nsystem rooted on itself when it comes up by building a spanning tree. Every other node is then\naddressed by (θ), the direction, i.e. port number, from a Local Observer View (LOV) and has a\nlocality: a (R), radial distance, or hop-count, relative to the root. However, the root generally does\nnot know the radial coordinates of any of its children, because it doesn’t have any means to identify\nthem. This is deliberate. If a root sends an object down one of the branches for some purpose, then\nit knows it can retrieve it by sending a request down that same direction, and the request packet\nwill eventually find it, no matter how far it has migrated (including to one of the leaves where it\ncan go no further).\n[A81] More importantly, named entities can migrate back and forth along the branches of such\nan addressing system, without having to change the address. All the source node needs to know\nwhen it is trying to read the named entity, is its name; all packets are sent out on a “direction port”\nfrom a requestor will travel down the branch (following the intrinsic direction pointers) to find their\ntargets.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 40 of 45\n[Q82]\n[A82] Not at all. Nodes appear to have different addresses depending on the origin of the (R, θ)\ncoordinate system, i.e. the root of a particular cell’s tree. Whereas in the absolute GEV! addressing\nscheme, all cells have a consistent address defined by a single origin. This is a compelling picture,\nbut is incorrect on several levels. The apparent simplicity and reasoning behind this GEV! scheme\nis a fallacy in practice.\n[Q83]\n[A83] In any GEV! numbering scheme, human administration will be required to set the origin.\nOf course, this appears ’easy’ for a human being. From a GEV! perspective, this is an arbitrary\ndecision, it has to be made by a human. This tiny little detail makes the difference of the system\nbeing auto-configurable, and requiring human attention.\n[A83] Every regular lattice will decay over time, and it is much harder to route around failures.\nThe lattice will inevitably have holes, will be extended (or shrunk) over time, and will accumulate\nfailures. This is a perfect case where A2A has difficulty scaling, and adds significant complexity to\nthe healing algorithms.\n[Q84]\n[A84] (R, θ) addressing is ideally suited to growing and shrinking networks. When things break,\nthey can be healed locally (all trees are graphs, if you include the pruned links for failover). We\n‘can’ also create a higher level ‘cartesian coordinate’ system on top of the base trees17\n[A84] At the level of a GUI / Management dashboard, human beings would like a GEV! view to\nat least monitor their network. In the bowels of the system where discovery, presence management,\nrecovery and serialization foci live, working from a Local Observer View (LOV) principle has\nfundamental benefits.\n[Q85]\n[A85] Humans need a GEV perspective to manage their systems, but protocols have to build them\nout of LOV mechanisms. This is why, at the lowest level systems can only be built from (R, θ)\naddressing. Once we have those, we can build any other coordinate system we want for the GEV\nperspective.\n[A85] At a deeper level, we use promise theory as a key architectural principle. This allows us to\nbuild systems from the ground up that have desirable emergent properties (such as persisting a\nminimum number of replicas). This is in contrast to the GEV! architectures employed in today’s\ncloud orchestrations services such as Kubernetes and Mesos. The advantage is threefold: systems\nremain simple as they scale, more adaptable to changes (and hence more resilient), and secure\nagainst many more attack vectors.\n[Q86]\n17Transforming from (R, θ) to X, Y is a simple algorithm that can be implemented in Javascript in a browser.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 41 of 45\n[A86] Yes. The key is a 128-bit name18 plus a bit mask describing what other ports the tree goes\nout on. The value is the message.\n[Q87]\n[A87] Yes. See: Learning Topology Topological Methods for Unsupervised Learning, and our\nFAQ-DL.\n[Q88]\n[A88] Cell Trees are built as Directed Acyclic Graphs (DAG’s). DAG’s are not necessarily trees: at\neach node, there may be one or more paths to the root, called port-trees. Those directed paths to\nthe root are not only redundant paths they also have their own ‘gradient’, which, if followed along\nany set of paths, will lead to the root. This is particularly true for leaf cells, which may have two\nor more nearly ‘equal’, or ‘equivalent’, ports they can go out on leading to a path to the root (for\nfailover or multi-pathing).\n[A88] Confinement Trees (TRAPHs) are well defined subsets (graph covers) of the Cell Tree layer.\nA cell may create one or more Cell Trees rooted on itself, using some distinguishing tokens, in a\ndisjoint field to the TreeID data structure. When there’s only one Cell Tree, it is tree 0. When\nthere are more, they are in the set 0,1,2 .. 15. Four bits are reserved for the adjunct field. This\nspecifies one of 16 multi-trees. There ‘may’ be a separate bit to request that the tree be disjoint (i.e.\nusing only links that have not been used by a lower tree).\n[A88] Cell (black) trees allow any cell on the tree to communicate with the root. They failover\n(automatically on failure, with notification that goes up into the cell to notify (the agent) using the\npreviously pruned links at that level. Typically, if a cell fails, it notifies only its children (descendants\non its branch). If the root cell fails, each of its immediate neighbors in the cluzter19 become aware\n(because of ENTL failure) and take whatever steps are necessary to support that tree and migrate\nservices off it. If one of the cohorts in the cluzter fail, the entire branch is notified through their\nneighbors.\n[A88] Cell Trees do not enable the root to communicate with a specific cell on the tree – the\nroot cells on the Cell Trees are unable to even address them uniquely. This is part of our security\narchitecture. A root advertises itself to its descendants on its tree using the recursive discover\npacket, but an explicit ‘publish’ and ‘subscribe’ are required (on a higher layer Logical Segregation\nTree) before direct communication can take place. There is one exception to this rule: a root cell\ncan uniquely address its immediate (1 hop away) neighbors, because they are directly connected to\na port on the root cell, and a root cell can always chose which port to communicate on without\nauthentication.\nThis mechanism is used to support our ‘Tree Paxos’ consensus algorithm, which is available as\na fundamental service at the lowest layer, one hop out from each cell. For physical cells with 8\ndirectly connected links, there are a total of 9 members of the set. Consensus protocols uses an odd\nnumber (3, 5, 7, 9) members to perform their election algorithm and maintain consensus in the face\nof failures.\n18We could easily use a 256-bit name, and a type field to assist parsing; or a 96-bit name, leaving the Ethertype\nintact.\n19A cluzter is a set of cells maintained coherently using ENTT - by definition – they are only one hop away from a\nmaster.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 42 of 45\n[A88] It is worthwhile mentioning here the critical importance of this asymmetry in communication\nability. The Cell Tree mechanism, as described above, is intended purely to define the extent of a\nTRAPH, and a one-way mechanism for cells on the tree to address the root. In the stacked layers\ndescribed later, we show how each root cell advertises not only its unique ID in that TRAPH, but\nalso any ‘service’ that it offers to other cells in the TRAPH. Zygote cells have not yet been designated\nto offer a particular service, so they offer only a ‘free service’ which implies their availability and\nreadiness for general provisioning byKubernetes.\n[Q89]\n[A89] In order for two cells to communicate directly with each other, we need another mechanism.\nOne such mechanism could be that cell B communicates with cell A, on cell A’s tree, and cell\nA communicates on Cell B’s tree. But this would not provide number of key properties of the\ntree-based communication, which provides guarantees for: (a) delivery of packets in FIFO order,\n(b) collision of coherency threatening operations, and (c) distributed (in-network) cacheing and\n(d) reliable distributed counters (such as those needed by the transactional recovery paths for the\nreversible timestamp service).\n[A89] Instead, we use a unique form of publish and subscribe: a bipartite mechanism to construct\na single direct route from an anonymous subscriber to a known publisher. A subscribe operation\nfollows the Cell Tree path and sets bits in the forwarding table of each cell as it passes through\nthem. The subscribe operation requires that the subscriber present its own Cell Identity in the\nclear, so that it can be verified (as unique, or otherwise), by not only the root, but by other cells.\nWhen the subscribe packet arrives at the root, it presents its credentials, and a subscribe key (a\nstrong identity public key that allows the root to privately communicate back to the subscriber\ncell. A two-way communication mechanism is now set up between the tow nodes. Note that several\ncells may subscribe into a named treecast group, which enables a root to send out the same\ncommunication on multiple paths (ports) when it needs to be multicast. This is used, for example,\nby the distributed cache coherency mechanism in the higher level object layers.\n[Q90]\n[A90] The critical difference between conventional (IP) routing with destination or endpoint (A2A)\naddresses and Tree Vector Routing (TVR) with only neighbor-to-neighbor (N2N) addresses is that\nin TVR, the destination(s) can be mobile; i.e., they can move around at will on the network. This\nalso supports the ‘replica management’ capability in our Data Asset Layer (DAL), which the cellular\nfabrix was invented for. This is a form of Content Addressable Networking (CAN).\n[A90] To see how it works, imagine a degenerate case of a chain of say 10 cells {a, b, c, d, e, f, g, h, i, j}\nand 9 links {[a, b], [b, c], [c, d], [d, e], [e, f], [f, g], [g, h], [h, i], [i, j]}, and further imagine that a replica of\nan object exists in cell j, but cell a might want to get a copy of it. The labels “{a, b, c, d, e, f, g, h, i, j}”\nare global, a scheme that we might perhaps assign from our God’s-Eye-View (GEV) perspective.\nHowever, cell a has no idea what these labels are from its Local-Observer-View (LOV) perspective;\nall it can see is the link to cell b {[a,b]}. All that cell a knows is that when it created the object20\n20Yes, the existence ∃of an object is known to cell a only because it created it – this is one reason that it also\nknows that it might want it back. Other cells may also know ∃because the object went through it, and it remembered\nit in its routing tables. This is why forwarding tables are persistent. i.e. any object that becomes known to a cell is\n‘remembered indefinitely’. This is part of the recovery mechanism for perturbations; transaction response as well as an\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 43 of 45\n(and gave it a GUID of its own choosing), it somehow lost track of where it went when it migrated\nthroughout the network. Right now, it’s on cell j, but the agent on cell a doesn’t know that because\nwhile the protocol allows migration – the replication and evaporation of objects along a path – these\nare local-only protocols. There is no ‘announcement’ to the rest of the world that the object at\nsome point moved from cell d to cell f, or at some other point from cell i to cell j. In other words,\nin the cellular routing scheme, the global (GEV) labels are useless, the only thing that counts is\nthe “direction” in which a packet can go to find that object (with that GUID) and the “trail” of\nbreadcrumbs that provides way-pointers in the forwarding tables of each cell that goes by.\n[A90] Now, in our degenerate case of a chain, we can see that cell “a” has only one pointer (bit in\nits forwarding table) to tell it how to go get the object (GUID) that it wants. Cell a has no idea\nhow far it must go (in hop-count), only that it must keep going in that direction until it finds it.\n[A90] There’s an elementary proof (based on spanning trees) that shows that anything that works\non a chain, also works on a tree. i.e., you always know at each cell which direction to go in for a\nparticular object. In a multiple-replica system, there may be one or more replicas, so the forwarding\ntables will have a corresponding one or more bits marking the exit ports to find a replica in each\ncell’s forwarding table.\n[A90] From a Local-Observer-View (LOV) perspective, cell a knows only about the link {[a, b]},\ncell b knows only about the links {[b,c] [c,d]}, etc. somewhat more subtlety, cell a doesn’t even\nknow its called “a”, it knows only its built-in base identity, from which it can create a certificate\nchain, one of which is presented as the cellid (GUID) which it uses to identify its Cell Tree(s).\nConversely, the link {[a, b]} is known only by cells a and b, and they may choose, or not, to label\nthe link. When they do label the link, they do so jointly with some prescriptive combination of\nGUIDa and GUIDb, and the port number that cells a and b each use to talk across that link21.\n[Q91]\n[A91] The standard answer (Forward Networks) is: “Network verification is a rapidly emerging\ntechnology that is a key part of Intent-Based Networking (IBN). Verification can help avoid outages,\nfacilitate compliance processes and accelerate change windows. Full-feature verification solutions\nrequire an underlying mathematical model of network behavior to analyze and reason about policy\nobjectives and network designs. A mathematical model, as opposed to monitoring or testing live\ntraffic, can perform exhaustive and definitive analysis of network implementations and behavior,\nincluding proving network isolation or security rules.”\n[A91] By changing the way we do naming and addressing, we are able to fundamentally alter\nthe game. Our Transaction Fabrix provides hardware enforced ‘confinement’ as a much simpler\ngraph model, instead of the list-based model used in conventional networks, we manage each graph\n(a spanning subset of a tree) providing a single name (handle) that names an entire entity. This\nreduces the exponent of the complexity that has to be managed, by at least one.\n[A91] We do ‘clean virtualization’ of networking protocols. We push all legacy protocols up to\na higher layer of abstraction. We can do this because our functionality is in the SmartNIC, we\noperate below layer 2 – as viewed by the main CPU. Our ‘subvirtualization’ mechanisms in the\nSmartNIC provide support for layer 4 and 5 functionality through an interface similar to RDMA.\nintrinsic audit mechanism for security.\n21This link identity is used with recoverable tokens in the Atomic Information Transfer (AIT) protocol for recovery.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 44 of 45\n[A91] The most important answer in this FAQ – because our protocols are distilled down to the\nsimplest possible mathematical expression, we can implement them with an economy of mechanism\nthat has been lost in conventional protocols. Because our protocols are so simple, we can express\n(and hence verify) them formally. This has an enormous impact in limiting the behavior of our\nprotocols to within a vastly smaller set of states, which makes them easier to implement, easier to\nverify, and easier to predict.\nPerfection is achieved, not when there is nothing more to add, but when there is nothing left to\ntake away.\n– Antoine de Saint-Exupery\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 45 of 45\n"
  },
  {
    "filename": "FAQ/00027.pdf",
    "content": "Dr. Edward G. BELAGA\nI.R.M.A. - C. N. R. S. /  Université Louis Pasteur\n7, rue René Descartes,  F-67084 Strasbourg Cedex, FRANCE\ntél.: 33.3.88.41.64.24.    FAX: 33.3.88.61.90.69.     e-mail: belaga@dpt-info.u-strasbg.fr\n                                                                                                                                   \nJune 2000\nMathematical Infinity, Its Inventors,\nDiscoverers, Detractors, Defenders, Masters,\nVictims, Users, and Spectators\nThe definitive clarification of the nature of the infinite\nhas become necessary, not merely for the special interests of\nthe individual sciences, but rather for the honour of t h e\nhuman understanding itself. The infinite has always\nstirred the emotions of mankind more deeply than any other\nquestion; the infinite has stimulated and fertilized reason as\nfew other ideas have ; but also the infinite, more than other\nnotion, is in need of clarification. 1\n[Hilbert 1925], pp. 370-371.\nHad I been present at the creation, I would have given some\nuseful hints for the better ordering of the universe.\nAlfonso X the Wise, King of Castile (1252-84), \ncited in [ODQ 1980], p. 3.\nAbstract. Is Mathematical Infinity adequately captured by Cantor’s set\ntheory ? Or, for that matter, by Zermelo-Fraenkel, ZF(C), axiomatic and\nits modern extensions ? What is the meaning of the «foundational\ncrisis of nearly unprecedented magnitude» (paraphrasing [Friedman\n1986], p. 93) which the higher set theory is going through, almost\nuninterruptedly, for the last hundred years, and what are the good\nmathematical lessons one can learn from it ? We address here these and\nrelated questions, extensively using in our search widely conflicting, but\nalso immensely rich ideas of many of the leading researchers in set\ntheory and beyond.\nKey words and phrases : Set theory, Zermelo-Fraenkel axiomatic,\naxioms of infinity, transfinite recursion.\n1991 Mathematical Subject Classification : 04-02, 04A10, 04A30\n                                                                                                                                   \nEdward G. BELAGA\npage:    1\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\n1 In this and the following epigraphs, words in bold type have been emphasized by the author of the\ncorresponding epigraph.\nhal-00129653, version 1 - 8 Feb 2007\n§1. Preamble.\nNo one shall be able to drive us from the paradise that Cantor\ncreated for us.\n[Hilbert 1925], p. 376.\nLet us start by the following trivial observation of a pure phenomenological\ncharacter : before Georg Cantor has entered the scene of mathematical infinity, two\ntypes of infinite totalities were already known experimentally to the mathematical\ncommunity, and at least as early as at the time of Euclid, - we are talking here about\ndenumerable and continuum-like totalities. \nTechnically, Cantor’s legacy includes : first, a remarkable clarification of the\nnotions of both the denumerable ω (or \n0)\n2\nand the continuum ; second, the\ndiscovery of the huge gap between them, \n0 < ; third, the invention of an\nuncountable host of new infinite totalities supposed either to fill the gap between 0\nand , or to go far beyond . Cantor’s followers invented even more formidable\ninfinite totalities; they also have tried hard to fill the hiatus {\n0 , }, albeit without\nmuch success.\nOf course, such modest phenomenological technicalities cannot be held\naccountable for what really happened in mathematics after Cantor. The truth is that\nmathematical infinity has become both an attractive and perilous mathematical\n«Klondike» of sorts : a gold-mine for some infinity prospectors, a moral and\npsychological ruin for others, with the founder [Dauben 1979], [Meschkowski\n1964] and his most perspicacious follower [Feferman 1986], belonging, sadly, to\nthe last category. Many mathematical «fortunes» were made there, and even more\nhopes were dashed, provoking from time to time sudden and powerful mathematical\nand philosophical «quakes» which could be felt far away from the «infinite\nepicentre». Fratricidal wars were waged, won and lost [van Dalen 1990].\nAnd, similarly to what has happened to the American gold-rush, the risky\n«infinite» adventure has led to a tremendous expansion of mathematics : first, into\nlogic, philosophy, then into computer science, physics, and back into mathematics.\n(It is outside the scope of the present paper to dwell upon these developments.) \nHowever, the «infinite» dust is still very far from being settled! \nA leading researcher into infinite has still to write papers with titles and\npreliminaries sounding both defensive and soothing [Shelah 1992] (on another\noccasion, the same author wonders without a shadow of irony, why so «many of my\ncolleagues, including the best minds in the field of set theory, feel apologetic\nabout their subject» [Shelah 1993], p. 2; cf. also [Jensen 1995], p. 407).\nMeanwhile, his well-known contemporary flatly dismisses his and his colleagues\nefforts of «setting up new axioms in the never-never land of large cardinals»\n                                                                                                                                   \nEdward G. BELAGA\npage:    2\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\n2\nWhereas ω notations correspond to ordinal infinite totalities, their \ncounterpants\ncorrespond to cardinal infinite totalities ; see below §3 and, e. g., [Hrbacek, Jech 1984].\nhal-00129653, version 1 - 8 Feb 2007\n[Mac Lane 1983]. To consummate the disunion, on the «infinite» side, dramatic\nannouncements abounds, both apocalyptic [Friedman 1986] and exuberant [Fremlin\n1993], whereas the other side remains unconvinced, indifferent, unaware, if not\noutright hostile.   \nThis painful discord continues to be accompanied by no less painful conflicts\nof foundational philosophies of mathematics [Hersh 1979] (cf. also an almost\npathetic dialogue [Henle 1991], [Paris 1992], [Henle 1992], in this magazine), as\nwell as of educational methodologies [Bishop 1985], [Bishop, Bridges 1985], and\nof policies of funding mathematical research [Smorynski 1988], [Mathias 1992]. In\nfact, the integrity of mathematics [Simpson 1988], if not its very existence [Arnold\n1995], are at stake.\nThe question is now : Why? Why it always happens to «us», people searching\n(and, in fact, so successfully!) for, and into, the infinite? Why not to «them», to\n«others», working in other fields of mathematics? Or less humorously, and more\nresponsibly : \nWhat is the meaning of this «foundational crisis of nearly unprecedented\nmagnitude» (paraphrasing [Friedman 1986], p. 93), and what are the good lessons\nwe can learn from it ?\nTo address these, as well as a couple of others, naive and yet pertinent\nquestions (called below Frequently Asked Questions, FAQ) concerning modern\nset theoretical and foundational research, one needs to look closely, and in a broader\ncultural and intellectual context, at both the multifaceted Mathematical Infinity and\nthe century-long attempts, called Set-Theoretical Infinity, of its scientific\nappropriation and customization. \nHowever, to venture into the unsafe ground of set theory ([Cohen 1971] p.\n15), with its surrealist landscape ([Mathias 1979] p. 109), in search for genuine\nsamples of Mathematical Infinity, one needs to pay as much attention to the\nglamorous pictures of official travel guides as to from-sober-to-bitter assessments\nof experienced, occasionally disgruntled infinity prospectors, or just to friendly\nwarnings and testimonies of often incredulous, never malicious compagnons de\nroute. The considerable attention which these contradicting insights are enjoying in\nthis study might be, in the final analysis, its only (if any) merit and novelty.\nThe present paper is a very personal tribute to both the exceptional beauty of\nthe subject and the wealth and depth of mathematical and philosophical\ncontributions of many contemporary mathematicians, starting with Georg Cantor.\nThe abundant quotes, these pearls borrowed from many authors on the occasion of\nour friendly Get-Together at Mathematical Infinity, are acknowledged here with\nthe author’s deep gratitude and self-effacing admiration. \nAn Apology. For the good understanding we must appeal to the reader’s\npatience and indulgence : not everything can be said at once, and many important\nissues simply cannot put in an appearance, at least explicitly, in such a short article.\nThus, axiomatic aspects of set-theoretical investigations will come to light much\nlater, and in much more modest form, than it might be expected by a knowledgeable\nreader. This will be even more true with respect to formal philosophical\ndeliberations. Also, we beg pardon for a couple of, possibly too overt, smiles  (could\nthey be compared to a laughter in Paradise?) which were intended to extenuate the\noccasional embarrassment of our official and not-so-official set-theoretical guides. \n                                                                                                                                   \nEdward G. BELAGA\npage:    3\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\n§2. Answering the First Frequently Asked Question.\nInfinity in Mathematics : Is Cantor Necessary ?\n[Feferman 1987], the title.\nA team of Hollywood techno-wizards set out to “bring ‘e\nback alive” ... So they took a little artistic license ... [a\ndecided to make them half again as large. Anyway, what \nbooks know? Then a surprising thing happened. In Uta\npaleontologists found bones of a real raptor, and it was the s\nof the movie’s beast. “We were cutting edge”, says the film\nchief modelmaker with a pathfinder’s pride. “After we create\nit, they discovered it.”\n[Dorfman 1993], p. 53.\nAs many visionaries and prophets before him, Georg Cantor has been not\ngranted the grace to see good fruits of his set-theoretical revelations; typically, quite\nthe opposite happened, and the immediately ensuing set-theoretical controversies\nhave had disastrous consequences for his scientific activity, as well as for his moral\nand mental health [Dauben 1979]). \nAnd yet, after all, elegant and powerful extra-set-theoretical applications have\ncompletely vindicated at least some of the crucial features of Cantor’s vision of\nMathematical Infinity.\nA recent research paper on termination proof techniques for Term Rewriting\nSystems (TRS play an important role in Theoretical Computer Science, in\nparticularly, in automated deduction and abstract data type specifications) starts as\nfollows [Dershowitz 1993], p. 243: \n«Cantor invented the ordinal numbers\n0, 1, 2, 3, ... , n, n+1, ... ω, ω+1, ... ω2, ... ωn , ... ω2, ... ωn , ... ωω, ... ω n ,\n... ε0, ... ε0\n, ... ε1, ... ε\n, ... , and so on .\nEach ordinal is larger than all preceding ones, and is typically defined\nas the set of them all :\nω = the set of all natural numbers;\nω2 = ω \n{ω+n \nn \nω};\nωn  =  \ni < n ωi ;\nω2 =  \nn [ ω ωn ;\nω n  =  \ni < n ω i ; \nε0 =  ω\n=  \nn [ ω ω n ;\n                                                                                                                                   \nEdward G. BELAGA\npage:    4\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\nε0\n=  ω\n;\nε1 =  \nn [ ω ε0 n .\nThe notation α n represents a tower of n αs.»\nAfter this most succinct and transparent introduction to Cantor’s transfinite\nnumbers, the author demonstrates, and all this on just 6 pages, how the ordinal\ndescent can be used to prove termination for specific TRSs. The general TRS\ntermination problem (which is, of course, a specialization of the halting problem for\nTuring machines) is undecidable.\nOrdinal descent is an important special case of descent along partially ordered\nsets (say, along trees). One of Cantor’s most fruitful ideas has been the notion of a\nwell-ordering, WO, i. e., of a linearly ordered set fulfilling the conditionof finite\ndescent, FD, i. e., of termination after a finite number of steps of any descending\nsubsequence (ordinals are, of course, special WOs). The principal merit of the FD\ncondition is the extendibility of the mechanism of Mathematical Induction beyond\nnatural numbers to any WO and, in particular, to any ordinal. \nNotice that, typically, «Cantor invented» or «created», not «discovered», the\nordinal numbers. Later, it was Gerhard Gentzen [Gentzen 1936] who has\ndiscovered that, assuming the validity of the law of mathematical induction along\nCantor’s ordinal segment \n[ 0, 1, 2, 3, ... ω, ω+1, ... , ... ε0 ] ,\none can prove the consistency of Peano arithmetic. Then, a remarkable general\ninterpretation of (explicitly defined denumerable) ordinals as succinct symbolic\nnotations for algorithmic structures with multiple loops has been given by Alan\nTuring [Turing 1950], and his approach has substantially contributed to the\ndevelopment of the modern theory of program verification. \nEven before Turing, and building on [Gentzen 1936], Reuben L. Goldstein\nhas constructed a truly elementary function n \ng(n) whose arithmetic structure\nmimics Cantor’s transfinite hierarchy up to ε0, and whose iterates gk(n) ultimately\nterminate at0 for any n. However, with n growing, it takes them very long indeed to\narrive at 0, which means that the function\nK(n) = min (k, gk(n) = 0)\nis growing so fast, that any proof of this fact necessary uses a mathematical\ninduction through transfinite numbers up to ε0 [Goodstein 1944]. The case has\nbecome a paradigm of an independent confirmation of the existence of an infinite\ntotality through its necessary use in a proof of an elementary  theorem.\nTaking the lead, Harvey Friedman discovered a remarkably transparent,\nfinitistic version, called FFF, of Kruskal’s theorem concerning infinite sequences\nof finite trees. The proof of FFF demonstrably requires mathematical induction up\nto the first impredicative denumerable ordinal\nΓ0 [Gallier 1991]. (The\nimpredicativity of Γ0 signifies, in particular, that no explicit transfinitely recursive\nformula for it, similar to those for ε0, ε1, and ε\n, could be displayed.)\n                                                                                                                                   \nEdward G. BELAGA\npage:    5\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\nVerily, «after Cantor created ordinals, they have discovered them» !\nMoreover, Friedman proposed that any newly invented infinite totality might be\nrediscovered through its necessary uses in a «natural» solution of a «natural»\nfinitistic, i. e., number-theoretical or combinatorial problem : \n«For at least twenty years, a principal issue in set theory has been the\nextent to which abstract set theory is necessary for proofs in normal\nmathematical contexts where abstract set theory plays little or no role\nin the formulation of the results.» [Friedman 1986], p. 192.\n§3. Flying over Cantor’s Paradise with One’s Cup of Tea.\nLet us say that the assertion of a large cardinal property is a\nstrong axiom of infinity. The adaptation of strong axioms\nof infinity is thus a theological venture, involving basic\nquestions of belief concerning what is true about the universe.\n... There is here a pleasant analogy: In order for a true believer\nto really know Mount Everest, he must slowly and painfully\ntrudge up its forbidding side, climbing the rocks amid the snow\nand the slush, with his confidence waning and his skepticism\ngrowing as to the possibility of ever scaling the height. But in\nthese days of great forward leaps in technology, why not get\ninto a helicopter, fly up to the summit, and quickly survey the\nrarefied realm - all while having a nice cup of tea?\n[Kanamory, Magidor 1978], pp. 103-104.\nEmboldened by the outstanding confirmations of Gentzen, Goodstein, Turing,\nFriedman (to mention just those four leading researchers), a common and shy\nmathematical fellow is finally ready to follow the friendly invitation and to\ncontemplate in peace the awe-inspiring beauty of the transfinite universe :\n«This appears to me to be the most admirable flower of the\nmathematical intellect and in general one of the highest achievements\nof pure rational human activity.» [Hilbert 1925], p. 373 \nStarting from the 0 level, our «helicopter» passes the natural numbers and enters the\nregion of infinite (denumerable) ordinals described above, §2 :\nω, ω+1, ... ω2, ... ωn , ... ωω, ... ... ε0, ... ... ε\n, ... and so on .\nTo ascend further, one asserts that all countable (i. e., finite or denumerable) ordinals\nare followed by the first uncountable ordinal, ω1, which, in its turn, is followed by\nω2 , the first ordinal beyond ω1 and not equipotent with ω1, etc. :\n0, 1, 2, 3, ... ω = ω0 ,  ... ω1 , ... ω2 , ... , and so on .\nTo accelerate ascent, one introduces «absolute set-theoretical values» of ordinals,\nor cardinals, with, say, ω0\n= \n0 . The notion is based on the equivalence\n                                                                                                                                   \nEdward G. BELAGA\npage:    6\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\nrelationship introduced by Cantor and called one-to-one correspondence, or\nequipotency. Different but equipotent ordinals correspond to one cardinal, as,\nsay, \n0 corresponds to ω, ε0, ε\n, etc., - in short, to all denumerable ordinals :\n0, 1,  ... ω0 ,  ... ω1 , ... ω2 , ... , and so on\n0 ,   \n1 , \n2 , ...\nThose are already very strong assumptions of existence of new infinite totalities.\nAny step behind the last «and so on» should involve a new notion, a new\nconstruction, a new «theological venture» [Kanamory, Magidor 1978], p. 104. \nHere is the most modern and very-large-scale map (borrowed, with minor\naesthetical modifications, from [Jech 1995], p. 414) of Cantor’s mountainous\nParadise :\n      ???????\n»       \ninconsistency\n» »         \nj :  Vλ\nVλ\n» » »         \nhuge\n» » » »         \nsupercompact\n» » » » »         \nWoodin\n» » » » » »         \no(κ) = κ++\n» » » » » » »         \no(κ) = 2\n» » » » » » » »         \nmeasurable\n» » » » » » » » »         \nRamsey\n» » » » » » » » » »         \n0#\n» » » » » » » » » » »         \nweakly compact\n» » » » » » » » » » » »         \nMahlo\n» » » » » » » » » » » » »         \ninaccessible\n» » » » » » » » » » » » » »         \n1\n» » » » » » » » » » » » » » »        \n0\n                                                                                                                                   \nEdward G. BELAGA\npage:    7\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\n» » » » » » » » » » » » » » » »     0\nThe experienced guides direct the attention of a flying-by spectator to two\nremarkable features of this splendid transfinite landscape. First, the infinite universe\nhas a «roof» called the inconsistency ceiling. (Which means that the axiomatic\nfoundations of Cantor’s Paradise would «crumble» under any new «storey» built\non its top. Those foundations are ZFC, Zermelo-Fraenkel’s axioms with the axiom\nof choice.) The second impressive feature of Cantor’s Paradise, - its linearly ordered\nstructure :\n«As our edifice grew, we saw how one by one the large cardinals fell\ninto place in a linear hierarchy. This is especially remarkable in view\nof the ostensibly disparate ideas that motivate their formulation. As\nremarked by H. Friedman, this hierarchical aspect of the theory of large\ncardinals is somewhat a mystery ... In other words, is there a hierarchy\nof set-theoretical principles in another galaxy above ZFC, disjoint and\nincomparable to our large cardinals ?» [Kanamory, Magidor 1978], p.\n104.  \n(In what follows, the spectator turned Devil’s set-theoretical advocate, will be\ncompelled to submit a less glamourous assessment, as well as to search for a quite\ndifferent interpretation, of the same infinite phenomena, §§6, 7, 12-14.)\nOur «quick survey of the rarefied realm», and with it, the «nice cup of tea»,\nbeing drawn to the end, we are leaving the friendly «helicopter» with a mixed\nfeeling. It has been nice, of course, and very reassuring indeed, to rub shoulders on\nthis breath-taking adventure with such luminaries as Saunders Mac Lane [Mac Lane\n1992], and to meet there our old friends, natural numbers, resting nicely between the\nfirst two levels, from 0 to \n0, of the transfinite mountain. After all, it’s nothing to be\nsurprised about : Mac Lane has been always frank about both his foundational\npreferences [Mac Lane 1986] and his interest in a good pastime [Mac Lane 1994],\nand the linear transfinite ascent has been somehow modelled on natural numbers! \nBut our guides assume (or are they just begging the question ?) that all\nexisting or imaginable infinite totalities are somewhere on the steep slope, out to\npasture. Then :\n3.1. Frequently Asked Question. What about the continuum ,\nwhere is it to be located on this transfinite surrealistic landscape ?\nEverybody knows that Cantor has strongly believed to unmask as the covert\n1 (this is the ordinal version of Cantor’s Continuum Hypothesis, CH : cf. FAQ\n7.3). During the trip, our mathematical yokel has somehow overheard that Kurt\nGödel has been inclined to believe that the continuum size should be \n2, the second\nuncountable cardinal [Moore 1990], p. 175. As they  tell us, a recent paper, referring\nto «the actual evidences accumulated by 30 years of forcing considerations»\n[Judah, Roslanowski 1995], p. 375, tends to confirm Gödel’s intuition and, building\non the previous work, develops a sophisticated machinery toward the eventual proof\n                                                                                                                                   \nEdward G. BELAGA\npage:    8\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\nof Gödel’s conjecture.\nUnfortunately, official travel guides are either silent about this, or worse still,\nare optimistically elusive :\n«Despite efforts of Cantor himself and others, the question ... remained\nunanswered until the emergence of methods of modern logic.» [Jech\n1995], p. 409.  \nThey are just forgetting to add that it remains unanswered ever after : it has been\nshown that the Continuum Hypothesis can be neither proved (the famous forcing\nmethod of Paul Cohen [Cohen 1966]), nor disproved [Gödel 1964] in Zermelo-\nFraenkel’s set theory.\nWorse still, «the generalized continuum hypothesis can fail everywhere»\n[Foreman, Woodin 1991] (the issues of the continuum and the Generalised\nContinuum Hypothesis, GCH, will be raised anew, and in a more serious vein, in\n§§7, 11) ... Tell me another, fumes bombastically Mac Lane : \n«I admire Gödel’s accomplishments, but I suspect that it is futile to\nwonder now what he imagined to be the «real» cardinal of the\ncontinuum. Those earnest specialists who still search for that cardinal\n                                                                                                                                   \nEdward G. BELAGA\npage:    9\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\nmay call to mind that infamous image of the philosopher - a blind man\nin a dark cellar looking for a black cat that is not there.» [Mac Lane\n1992], p. 121.\nThe above cartoon\n3 will hopefully help to dissipate the unpleasant aspects of\nthe ongoing, and very important, discussion of the nature and future of\nMathematical Infinity :\n§4. But How Do We Know Indeed That\nAll These New Infinite Totalities Really Exist ?\nJust think : in mathematics, this paragon of reliability and\ntruth, the very notions and inferences, as everyone learns,\nteaches, and uses them, lead to absurdities. And where else\nwould reliability and truth be found if even mathematical\nthinking fails?\n[Hilbert 1925], p. 375.\nBack home from the splendid transfinite trip, with his confidence deep shaken,\none has to confront the bitter truth : the Cantorian and post-Cantorian dreams about\ninfinity have become a nightmare. Let’s face it : the first crisis provoked by set\ntheory, that of logical paradoxes (in Hilbert’s words, «absurdities»), has given\nplace to the modern crisis of the arbitrariness of both transfinite insights and of\nextremely elaborated formal notions and constructions inspired by those insights.\nNowhere in mathematics (or, for that matter, in natural sciences) does one need to\nblindly believe in so many conceptual inventions and infinite artifacts without any\nbenefit of illumination and/or confirmation [Maddy 1988].\nHis usual naive mathematical sobriety intact, our mathematical country cousin\ntimidly but distinctly utters :\n4.1. Frequently Asked Question. Emotions and travel guides aside,\nbut do they really exist ?!\nHave all new infinite totalities discovered by Cantor and after him «the same\nstrong claim to existence» (a paraphrase of [Barwise 1975], p. 113) as the\ndenumerable and the continuum known already to the Greeks ? In other words, what\nare our reasons to be committed to their existence, as we are committed to the\nexistence of the natural numbers ω and of the continuum \n? \nPoor yokel : how could he expect that such simple and natural mathematical\nquestions are invariably provoking a terrible storm ...\nFor Georg Cantor [Dauben 1979], pp. 132-133, and David Hilbert [Hilbert\n1925], pp. 375-376, the answer was straightforward and generous in extremis : all\nmathematical objects, whose definitions do not contradict the formal framework of a\n                                                                                                                                   \nEdward G. BELAGA\npage:    10\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\n3\nBorrowed from International Herald Tribune, November 18, 1993, and slightly modified, with\nthe permission which is here gratefully acknowledged. The original cartoon, created by KAL,\nrepresents «Washington crossing the Dinnerware» into a «Theme Park based on US History to be\nbuild by Disney». The rejoinder «This worries me» belongs to KAL.\nhal-00129653, version 1 - 8 Feb 2007\ntheory, exist. In other words, consistency is the only condition for existence. \nOn the other hand, for Luitzen Brouwer and Henri Poincaré, neither of new\n(uncountable) infinite totalities exists as a matter of principle, because neither has\nbeen ever properly defined : the advanced definitions did not satisfy some a priori\ncriteria of philosophical correctness, for example, they employ the law of the\nexcluded middle, or lack predicativity. Here is a more modern brand of a violent\ndenial of Cantor’s and Hilbert’s existential generosity :\n«At the beginning of this century a self-destructive democratic principle\nwas advanced in mathematics (especially by Hilbert), according to\nwhich all axiom systems have equal right to be analyzed, and the value\nof mathematical achievement is determined, not by its significance and\nusefulness as in other sciences, but by its difficulty alone, as in\nmountaineering. This principle quickly led mathematicians to break\nfrom physics and to separate from all other sciences. In the eyes of all\nnormal people, they were transformed into a sinister priestly caste of a\ndying religion, like Druids.» [Arnold 1995], pp. 7-8.\nThe persistence of such extreme, mutually (and violently) incompatible\nattitudes explain how the issue has become a hostage in the war of mathematical\nhabits and philosophical tastes.\nThe atmosphere surrounding, from its very beginning [Dauben 1979], [Moore\n1982], [van Dalen 1990] this extremely difficult problem has been, and still is, so\nopinionated, the arguments have been, and still remain, so personal, arbitrary [Jensen\n1995], p. 401 (note 18), and even violent [Mac Lane 1992], p. 121, that the people\nwho prefer to stick to their set-theoretical interests have become somewhat cynical\nabout it. Some are just going after their formal kills, having freed themselves from\nany ontological fetters; as Craig Smorynski has uncharitably put it:\n«The subject attracted careerists, who were trained to solve problems,\nto belittle anything that wasn’t hard, and who were not taught anything\nabout the history or philosophy of their subject and quickly learned that\nsuch knowledge did not help their careers.» [Smorynski 1988], p. 13.\nOthers are acknowledging the legitimacy of the problem, only to address it\nstraightaway in the «didn’t ask, wouldn’t tell» manner :\n«The question “what large cardinals are there?” is, although\nundecidable (unless there are none) surely a natural one. Not that these\nstrong inaccessibles obviously exist; but if caution was to be exercised\nit should have been exercised a long way earlier. Anyone who is happy\nabout unlimited application of the power set operation can feel few\nqualms about an inaccessible». [Dodd 1982], p. xxii.\n(Incidentally, and in anticipation of the ensuing deliberations, §§8, 11, the present\nauthor has been never «happy about unlimited application of the power set\noperation» [Belaga 1988], and thus, according to [Dodd 1982], he is somehow\nentitled to feel qualms about new infinite totalities). \nClearly, at stake is so much that one cannot but understand and deeply respect\nthe indignation of Kurt Gödel, who has written more than thirty years ago :\n                                                                                                                                   \nEdward G. BELAGA\npage:    11\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\n«Brouwer’s intuitionism is utterly destructive in its results. The whole\ntheory of \n’s greater than \n1 is rejected as meaningless.» [Gödel 1964],\np. 257.  \nOurs is not a destructive attitude, and we are not rejecting anything. And yet, risking\nto offend the sensitivity of high-handed dwellers of Cantor’s Paradise, we feel\nrelieved to be at this fateful juncture in the company of such good mathematicians\nand serious thinkers as Luitzen Brouwer, Henri Lebesgue, and Harvey Friedman :\npeople’s infinite fantasies have to be somehow independently verified and\nconfirmed. Moreover, we even have a few ideas how it could be done in the spirit of,\nand with all due respect to the achievements of our transfinite colleagues, §6. But the\nstorm we have provoked not only continues unabated, it grows even more bizarre\nand destructive ...  \n§5. Worse Still : Does Mathematical Infinity Exist at All ?\nTo be sure, the discussion of the paradoxes of set theory led\nresearch in the foundation of mathematics a long way from the\nclassical view of the nature of mathematics so passionately\ndefended by Cantor. Intuitionists and formalists are united in\ntheir effort to eliminate all metaphysical elements from the\nfoundations of exact sciences. .... Georg Cantor, schooled in\nPlato and scholastics, thought differently about the matter. ....\nIt is part of the tragedy of our investigator’s life, so full of\ndisappointments, that his own theory gave rise to a new\nconcept of mathematics which, for good reasons, put an end to\nbasing the exact sciences on metaphysics.\n[Meschkowski 1964], pp. 94, 95.\nThus, before even attempting to reflect on the above existential problem, one is\nconfronted with a much more formidable one : \n5.1. Frequently Asked Question. Does Mathematical Infinity exist\nat all ? Or, in other words : Can one «really know» anything about infinity ?\nThe answers of two leading modern schools of thought, formalism and\nconstructivism, which split between them the majority of votes of philosophically\naffiliated members of the mathematical community, vary from a mild «Not very\nmuch indeed» to the unapologetic «Nothing, and do not make a fool of yourself».\n(We apologize to the reader of a Platonist or any other idealistic persuasion for\nclassifying him as an ideological minority, and we implore him to wait for a while\npatiently in line. As to nominalists and other pragmatists, they do not belong here\nanyway.)\nThe ultimate intuitionist, or constructivist, reason is philosophical, even a\nreligious one : the understanding of man as a purely finite being having no reliable\naccess to infinite. Pushing Brouwer’s original and deep vision to its almost absurd\nlimits, Errett Bishop claims : \n                                                                                                                                   \nEdward G. BELAGA\npage:    12\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\n«Our point of view is to describe the mathematical operations that can\nbe carried out by finite beings, man’s mathematics for short. In\ncontrast, classical mathematics concerns itself with operations that can\nbe carried out by God.» [Bishop 1985], p. 9.\nAnd\n«If God has mathematics of his own that needs to be done, let him do it\nhimself.» [Bishop, Bridges 1985], p. 5.\nOf course, not every constructivist could easily swallow such a brutal brand of the\nintuitionist philosophy ; Hermann Weyl, for once, has been of another opinion :\n«Mathematics has been called the science of the infinite. Indeed, the\nmathematician invents finite constructions by which questions are\ndecided that by their very nature refer to the infinite. That is his glory.»\n[Weyl 1985], p. 12.\nAs to the formalist school, whose historical raison d’être has been the urgent\nneed to defend the mathematical Vaterland from the onslaught of intuitionism, and\njudging by what we have heard from David Hilbert in the first epigraph to the\npresent paper, one might expect that it would defend the infinite with at least as\nmuch good will as Weyl did ... Surprisingly, Hilbert’s defence against Brouwer’s\nfoundational critique of classical mathematics has been based on not less sweeping\na denial of the «real existence» of the infinite than Bishop’s [Hilbert 1925], p. 392.\nYet, the dubious honour to unambiguously and terminally affirm the formalist\ndeath of the infinite, and to do this confessedly, on the grounds of the absence of\nany inspiring philosophical convictions, fell finally to Abraham Robinson (who, too,\nhas been just pushing the founder’s original vision to its clearly absurd limits) :\n«My position concerning the foundations of Mathematics is based on\nthe following two main points or principles. ( i ) Infinite totalities do\nnot exist in any sense of the word (i. e., either really or ideally). More\nprecisely, any mention, or purported mention, of infinite totalities is,\nliterally, meaningless . (ii) Nevertheless, we should continue the\nbusiness of Mathematics “as usual”, i. e., we should act as i f infinite\ntotalities really existed.» [Robinson 1965], p. 230.   \nTwo «merits» of this famous doctrine bear on the subject of the present study.\nFirst, it plagiarizes, with minor adjustments, another famous maxim : that, of\n                                                                                                                                   \nEdward G. BELAGA\npage:    13\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\nall things ... of Aristotelian Physics\n4 !! The Greeks strike again ...\nSecond, Robinson’s dictum has been the final affirmation that Hilbert’s\nformalism à la Robinson, and the inherent in it schizophrenic vision of the\nmathematical theory and practice [Cohen 1971], [Hersh 1979], [Bishop 1985], have\nbecome a normative mathematical thinking.\n§6. The Greeks Strike Again and Again : \nProblems versus Paradoxes.\nYes, I once gave a lecture with the flamboyant title, «Set\ntheory is obsolete.» In this and few others contentious\narticles, I have violated one of the cardinal principles of\nmathematical activity : Mathematicians do not make\npronouncements; they prove theorems. My apologies.\n[Mac Lane 1992], p. 119. \nAlthough the ills of modern set theory, as the reader might have already\nnoticed, are numerous, the present author is convinced that it is neither obsolete, not\nterminally sick. Still, in the light of all important (and only partially mentioned in the\npresent paper) pronouncements concerning the past [Dauben 1997], [Hallett 1984],\n[Moore 1982], present [Jech 1995], [Jensen 1995], [Mac Lane 1992], and future\n[Shelah 1993] of set theory, a simple and down-to-earth set-theoretical diagnosis\nwould be no luxury. The rest of this study, §§6-14, represents such a diagnosis.\nOur first observation : all above Frequently Asked Questions have about\nthem an air of somehow touching a mystery, and not just an unknown. This is a\ntypical phenomenon :\n6.1. Frequently Asked Question.\nWhat makes the problems\nconcerning Mathematical Infinity more akin to logical paradoxes than to open\nproblems of other mathematical domains ? \nHere are a few words of explanation. Open problems excite the imagination of\na mathematician, some of them for years, others for decades, still others for\n                                                                                                                                   \nEdward G. BELAGA\npage:    14\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\n4\nAs a matter of fact (to the best knowledge of the present author), neither Abraham Robinson,\nno any other source mention the striking similarity between the spirit and letter of Robinson’s\ndictum and the following passage from Physics of Aristotle (we following the translation of [Hintikka\n1996], p. 201) : \n«Our account does not rob the mathematicians of their study, by disproving the actual\nexistence of the infinite ...  In point of fact they do not need the infinite and do not use it.\nThey postulate only that the finite straight line may be produced as far as they wish. It is\npossible to have divided in the same ration as the largest quantity another magnitude of\nany size you like. Hence, for the purposes of proof, it will make no difference to them to\nhave such an infinite instead, while its existence will be in the sphere of real\nmagnitudes». [Phys. III, 7, 207b27-34]\nOf course Aristotle’s is a more consistent and, from the modern point of view, more radical\nassertion : in the up-to-date parlance it would be dubbed something like «ultra-intuitionistic\ncriticism»  [Yessenin-Volpin 1970].\nhal-00129653, version 1 - 8 Feb 2007\ncenturies (as, for example, Fermat’s Last Problem), even millennia (Euclid’s Fifth\nPostulate). Yet, impenetrable and deep as an open problem might be, it represents an\nexact question raised in an exact mathematical context. An open problem can be\ncompared to a clearly marked trail leading into as yet inaccessible but\nabsolutely real terra incognita. \nBy contrast, paradoxes do not have such a privilege : a deep mathematical or\nlogical paradox is a double-edged question concerning both the object and the\nsubject of study, - the subject being our intellectual ability to decently handle the\nobject. An unresolved paradox is similar to a mirage, with its clear but\ndeceptive image, deprived of any certitude of reality, not speaking about\npossible ways to eventually reach it. In particular, to answer a good paradox, one\nneeds to invent from scratch a proper conceptual (mathematical, logical, or even\ncultural) context in which the hidden in the paradox question becomes explicit and\nexact, in other words, becomes an open problem. Also, if a problem is solved, then it\nis definitely solved; by contrast, a good paradox tends to remain open and attractive\nin every generation, after it has been «successfully resolved» as many times as many\nphilosophers have addressed it. \n6.2. Meta-Paradox of Mathematical Infinity. The most salient\nfeature of all inquiries into Mathematical Infinity, starting with the Greeks \n5, has\nbeen, and still remains, their «disconcerting tendency to produce» (a paraphrase\nfrom [Shelah 1992], p. 197)\n(i) more new paradoxes than new open problems, \n(ii) and more new (often, extremely sophisticated) refinements of known\nparadoxes than new solutions of known problems.\nLet us illustrate these statements by one of the most marvellous set-theoretical\nstories concerning the existence of the countable and the continuum, as well as of\nthe relationship between them :\n6.3. Example of an Apparently Resolved But in the Last\nAnalysis, Aggravated Paradox. The confrontation between the countable\nand the continuum, from Zeno to Cantor, and beyond.\nThe Greeks have been the first to «colonize» two basic (and fundamental for\nus as well) infinite mathematical habitats, the natural numbers and the\ncontinuum, ω and in modern notations. They existed for the Greeks (as they exist\nfor us, present-day mathematical yokels) simply because of :  \n6.4. The Criterion of «Real Existence» of an As Yet Only\nIntuitively Perceived Mathematical Notion. Beautiful mathematical\ntheories about and around it, rich in fruitful applications.\nNotice that this criterion is neither platonist, nor constructivist, nor formalist\n: it just doesn’t claim anything about the «object behind the notion». For the\nPlatonist, the existence is related to an «object» :\n                                                                                                                                   \nEdward G. BELAGA\npage:    15\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\n5\n«A “foundational crisis” occurred already in Greek mathematics, brought about by the\nPythagorean discovery of incommensurable quantities. It was Eudoxos who provided new\nfoundations, and since then Greek mathematics has been unshakeable. If one reads modern\nmathematical textbooks, one is normally told that something very similar occurred in modern\nmathematics.» [Lorenzen 1958], p. 241.\nhal-00129653, version 1 - 8 Feb 2007\n«But, despite their remoteness from sense experience, we do have\nsomething like a perception also of the objects of set theory, as is seen\nfrom the fact that the axioms force themselves upon us as being true.»\n[Gödel 1964], p. 268.\nFor the Constructivist, the existence of an object is sine qua non condition for a\ntheory to be mathematics, and there exist only constructively defined objects. For\nthe Formalist, nothing existential matters. \nBecome acquainted with ω and \nexperimentally, the Greeks have been\nabsolutely fascinated by the obvious to them differences in the «origins» and\n«natures» of these two infinities, as it is clear from the paradoxes advanced by Zeno\nof Elea (C. 464/460 B.C.) [Bochenski 1970], p. 26, [Anglin, Lambek 1995], pp. 54-\n57. \nIn particular, Zeno’s paradox «Achilles and Tortoise» clearly demonstrates\nthe conceptual confrontation between two different types of experiences which led\nto two different models of infinity. One type is best encapsulated by the counting\nexperience (through observations of hearth-beatings, walking as a step-by-step\nmovement, building of towers, etc.), - the only humanly available «accumulation of\ninfinity» by finite and discrete portions. The second type can be observed in the\nexternal world as a continuous infinity (points on the horizon, the flight of an arrow,\netc.). Zeno clearly doubted that the two infinities could be reconciled : one can run,\nbut one cannot «understand» this phenomenon, because our understanding is\nfinite and discrete, whereas our movement (a mystery in itself) is, as the sky itself,\ncontinuous. \n6 This does not mean, of course, that Zeno doubted the existence of\nthe continuum.\nCantor has resolved this particular aspect of Zeno’s paradox \n7 by inventing an\nabsolutely new mathematical universe, his Set Theory, unavailable to Zeno, where\nthe relationship between two, previously incompatible infinite «habitats» can be\nsuccessfully conceptualized, and then formally studied and understood. \nIn fact, all what we are now know about the continuum for sure (and what\nremains one of Cantor’s most striking and important discoveries), can be explained\nto a schoolgirl or -boy : \n6.5. Cantor’s Powerset \nConstruction and Proof of t h e\nInequality \n0 < . (i) Cantor’s construction, or definition, of the continuum as\nthe set of all subsets (called the power set) of the set ω of natural numbers, \n                                                                                                                                   \nEdward G. BELAGA\npage:    16\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\n6\nMore than two thousand years later, apparently the same intuition has motivated Brouwer’s\nefforts to re-define Cantor’s mathematical continuum [Brouwer 1981] ! On the other hand,\naccording to the Bible, a few thousands years before Zeno, the people of Shinar had no such\nscruples :\n«And they said: Come, let us build a city and a tower, whose top may reach to heaven.»\n(Genesis 11:4).\nThey have been, of course, mistaken ... Still, as some argue, modern set theory is far from being\ncompletely free from a similar imperious insanity.\n7\nOther aspects of this paradox are still vividly discussed by philosophers. Thus, for\ninstance, Henri Bergson (1859-1941) is thoroughly discussing and forcefully «explaining» Zeno’s\nparadox anew in his book [Bergson 1959], pp. 1259, 1376, 1377.\nhal-00129653, version 1 - 8 Feb 2007\n= powerset(ω) = P(ω).\n(ii) The proof, based on Cantor’s formidable diagonal argument, that this\nfact implies the uncountability of the continuum, \n0 < .\nNotice that this inequality has as yet nothing to do with the above ordinal-cardinal\nhierarchy. It just means that (i)\nhas a subset equipotent with ω, (ii) a conjecture\nthat ω can be put into one-to one correspondence with leads to contradiction over\nan extremely weak subset of ZF.\nFor better or worse, this has not been the end of the story. Falling in an even\ndeeper trap than Zeno, Cantor «freed himself of all fetters and manipulated the\nset concept without any restriction» (as Hermann Weyl puts it disapprovingly in\n[Weyl 1949], p. 50). Most important, Cantor has invented transfinite ordinals with\nthe explicit purpose to be capable to do exactly what Zeno realized he has been\nunable to do : namely, to «count up» the continuum ! (The details will be discussed\nlater, §§11, 12).\nThe resulting state of affairs in set theory far surpasses in its discordancy all\nknown Greek precedents. In particular, the cleavage between the discrete (or\nPythagoreanas, as Ronald Jensen has chosen to call it [Jensen 1995], p. 401) and\ncontinuous (Newtonian, according to Jensen) accounts of the world has become\neven more acute and irreconcilable : \n6.6. The Fundamental Problem of the Continuum in Modern\nSet-Theory. There is as yet no definitive demonstration of the fact\n(conjectured by Cantor and proved by Ernest Zermelo in ZFC set theory from\neven more complicated conjectured properties of sets) that the continuum, as\nwe know it mathematically, can be embedded into the aforementioned ordinal-\ncardinal hierarchy.\n§7. More FAQs Concerning the Continuum and \nthe Ordinal-Cardinal Hierarchy.\n«For me the essential point is the existence of infinite\ntotalities. The attitude toward infinite sets has traditionally\nbeen the great dividing line between mathematicians.» \n[Cohen 1971], p. 10. \nAssuming Cantor’s Paradise, as it is described above in §3, exists and shelters\nsomehow the continuum, one can ask about such a continuum many (often\ncontradicting) questions and receive many (mostly, mutually incompatible) answers\n[Judah, Just, Woodin 1992]. Assuming, however, that the problem of the\ncontinuum’s sojourn in the Paradise is still open (Fundamental Problem 6.6), one is\nleft with at least two open questions, whose merit is their unambiguous and universal\nmathematical importance.\n                                                                                                                                   \nEdward G. BELAGA\npage:    17\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\n7.1. Frequently Asked Question. Could it be that the continuum\nbelongs, in fact, to an «hierarchy of set-theoretical principles in another galaxy\nabove the linearly ordered hierarchy of §3 ?» (Paraphrazing [Kanamory,\nMagidor 1978], p. 104, cf. §3.) In other words, is it possibly that, in reality,\nthe continuum cannot be well-ordered ? \nIf the answer would be in affirmative, then\n7.2. Frequently Asked Question. Would be all members of the linear\nordinal-cardinal hierarchy comparable to the continuum, or would be it\n«disjoint and incomparable to some or even all of our large cardinals» ?» (More\nparaphrazing [Kanamory, Magidor 1978], p. 104, cf. §3.) \nTwo following questions can be answered affirmatively immediately:\n7.3. Frequently Asked Question. Does the Continuum Hypothesis\nmake sense outside the linear ordinal-cardinal hierarchy ?\nThe obvious answer is : yes, it does, if one understands Cantor’s inequality in\nthe spirit of his construction 6.5 : one looks for a subset, say, \nof , which\nencloses the set \nof natural numbers, \n, and such that \n<\n< , in\nthe same sense as \n0 < . CH states that no such \nexists.\nInterestingly enough, while Cantor still talks about his conjecture in both of its\npossible forms, «no cardinal value \nstrictly between \nand\n» and «\n1 =\n»,\nKurt Gödel’s attitude becomes rigid and single-minded : he completely identifies\nMathematical Infinity with its ZFC formalization, CH with «\n1 =\n», insisting\nwith the determination of a martyr of the new set-theoretical faith that «the axioms\nforce themselves upon us as being true» [Gödel 1964], p. 268.\nWe will return to Gödel and his tragedy later, in Cantor’s Transfinite Dream,\n11.2; now comes the next\n7.4. Frequently Asked Question. What might be the criterion of\n«real existence» of members of the linear ordinal-cardinal hierarchy ?\nOur answer follows Kurt Gödel’s [Gödel 1964] and Harvey Friedman’s\n[Friedman 1986], p. 192, suggestions (cf. §2) : \n7.5. The Criterion of «Real Existence» of a New Infinite\nTotality Defined in a Fixed Axiomatic Framework : It Mast B e\nRelevant and Even Necessary (Okham’s Razor).\n(CRE0) Its existence is directly confirmed by displaying of a verifiably\ntrue theorem from number theory, combinatorics, etc., which demonstrably\nneeds in its proof the mathematical induction up to this particular infinite\ntotality.\nThe following can be regarded as a supporting evidence : \n(CRE1) The totality is an object of a rich, beautiful, and multifaceted\ntheory.\n(CRE2) This theory fruitfully interacts with theories from other\nmathematical domains, and has nontrivial and interesting applications there.\n                                                                                                                                   \nEdward G. BELAGA\npage:    18\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\nThe following are the instructions for the razor’s user : \n(CREU) A most lenient, liberal, and cautious use of the above razor is\nadvisable. Still, until the existence of an infinite totality has been\nindependently confirmed, it would eke out a bare formal notational existence,\nremaining open to different interpretations, critique, and even to an outright\nrejection.\nOf course, the actual absence of such a confirmation does not give to anybody\nthe right to apply Okham’s razor as the butcher’s axe, proclaiming modern set-\ntheoretical research irrelevant, or to strive for its permanent transfer to mental\ninstitutions [Mac Lane 1992], p. 121 (quoted in §3).\nAfter introducing in the next section Cantor’s basic mechanisms of fabricating\nnew infinite totalities, we will discuss in §13 what one really knows today, beyond\nthe examples of §2, about independent confirmation (the criterion CRE0) of the\nreal existence of new infinite totalities. Then we proceed to review the status of\ninfinite totalities whose existential credential are restricted to CRE1-2, or less.\n§8. Entering Cantor’s Paradise on Foot.\nFor inaccessible or measurable cardinals our intuition is\nprobably not yet sufficiently developed or at least one\ncannot communicate it. Nevertheless I feel that this is a\nuseful task, to develop our mystical feeling for which\naxioms should be accepted. Here of course, we must\nabandon the scientific program entirely and return to an\nalmost instinctual level, somewhat akin to the spirit with\nwhich man first began to think about mathematics. I, for\none ... feel impelled to resist the great aesthetic temptation\nto avoid all circumlocutions and to accept set theory as an\nexisting reality ... The reader will undoubtedly sense the\nheavy note of pessimism which pervades these attitudes.\nYet mathematics may be likened to a Promethean labour,\nfull of life, energy and great wonder, yet containing the\nseed of an overwhelming self-doubt. ... Through all of this,\nnumber theory stands as a shining beacon. ... This is our\nfate, to live with doubts, to pursue a subject whose\nabsoluteness we are not certain of, in short to realize that\nthe only “true” science is itself of the same mortal,\nperhaps empirical, nature as all other human undertakings.\n[Cohen 1971] p. 15.\nUnless one becomes (paraphrazing [Smorynski 1988], p. 13) a «careerist\nbelittling anything he does not understand», one needs to go back to §3, and to\nclimb the transfinite slope in person, riveted by the vision of Cantor’s Paradise, with\nits flying-by helicopters carrying our mathematical country cousins [Maddy 1988].\nThe beautiful Greek icon below, §12, faithfully portrays our dangerous ascent ...\nEntering Cantor’s set-theoretical edifice on foot, one discovers :\n                                                                                                                                   \nEdward G. BELAGA\npage:    19\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\n(i) a foundation, with its two powerful primitive concepts, that of set-\ntheoretical object, and that of set-theoretical relationship between objects; any\nmathematical object or structure can be, according to Cantor, stripped of all its\nproperties, down to the state of being a structureless collection, or set, or\n((in)finite) totality, composed of its elements, who, in their turn, belong to the\ntotality (cf. the Axiom of Extensionality below, this section); the only criterion of\nequality between totalities is that of the one-to-one correspondence;  \n(ii) four «pillars» resting on the foundation, which are four different (and not\nalways mutually independent) methodologies, or meta-procedures, of fabrication of\nnew infinite totalities from the known ones; \n(iii) the «dome», Cantor’s transfinite theory, or superstructure, of ordinals\nand cardinals, supported by the four pillars, with Cantor’s Well-Ordering Principle\nserving as the «keystone». \nCantor’s naive set theory could be axiomatized in many ways. The best known\nZermelo-Fraenkel axiomatic system, ZF [Fraenkel, Bar-Hillel, Lévy 1973] (ZFC\ndenotes ZF plus the Axiom of Choice, AC), comprises four types of axioms: \n(i) the Axiom of Extensionality, AE, which, in fact, is a definition of the\nnotion of set with respect to the relationship of membership \n: to «know» a set, it\nis enough to «know» all its elements;\n(ii) two axioms of existence, each one postulating the existence of two\nspecific sets, of the empty set and of the (countable) infinite one : Empty Set\nAxiom, ESA, and Axiom of Infinity, AI;\n(iii) three axioms of construction, which, given a set x, a pair of sets x, y, or a\nset z of sets, postulate the existence, respectively, of the power set of x, P(x), of the\npair set (x, y), and of the union z of member-sets of z : Power Set Axiom, PSA,\nAxiom of Pair, AP, Axiom of Union, AU;\n(iv) an axiom schemata (i. e., a recipe to design axioms) of construction,\nwhich, given a set x and a «property», or «condition», expressed by a formula,\npostulate the existence of the image of x under the function (mapping) defined by\nthe given formula : Axiom Schemata of Replacement, ASR. \n8\nPresenting below Cantor’s naive set theory, we indicate in brackets the\ncorresponding axiomatic means formalizing Cantor’s intuitive notions in the ZFC\nframework.\n§9. The Main Principle : Invoking Mathematical Infinity\nin One Full Swoop : Just Say «And So On !».\nI am about to introduce a symposium on infinity. I do so, not\nbecause I can claim any special intimacy with the infinite, nor yet\nbecause I feel myself specially competent to unravel its intricacies,\nbut because I think it all-important that a notion so fundamental\n                                                                                                                                   \nEdward G. BELAGA\npage:    20\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\n8\nTo these axioms one usually adds an axiom banning the existence of some «pathological» sets,\nwhich are members of themselves, either directly, or through other members, or have any similar\nproperty of infinite descent through the membership relationship : the Axiom of Foundation.\nhal-00129653, version 1 - 8 Feb 2007\nshould be rescued from the grip of the experts, and should be brought\nback into general circulation. It is a notion so common and so clear as\nto lie behind practically every use of the ordinary phrases “and so\non” or “and so forth”, but it is non the less capable of giving rise to\nvertiginous bewilderments, which may lead, on the one hand, to the\nmystical multiplication of contradictions, as also, on the other hand,\nto that voluntary curtailment of our talk and thought on certain\nmatters, which is as ruinous to our ordered thinking. A notion which is\nat once so tantalizing and so ordinary plainly deserves the perpetual\nnotice of philosophers. Throughout the history of human reflection the\nfogs of an interesting, and often interested obscurity have surrounded\nthe infinite; they were dispersed for a brief period by the sense-\nmaking genius of Cantor, but have since gathered about it with an\nadded, because wilful, impenetrability. In the growing illiteracy of our\ntime, when the lamp of memory barely sheds its beams beyond the\npast two decades ...... I must attempt, at any rate, to do what others,\nbetter qualified than myself, have so entirely neglected; it is better\nthat someone should discuss this topic with the freedom of\nphilosophy, than that all talk about it should be allowed to flow along\nthose technical channels which, whatever else they may do, never\nenrich our philosophical understanding. \n[Findlay 1953], pp. 146-147.\nThe dome superstructure being discussed in §11, we are entering now\nCantor’s factory of infinities. \nAmong four «pillars» of Cantor’s set theory, one is central and distressingly\ngeneral. In fact, it represents a fundamental meta-philosophical principle of\nreaching out for new infinite totalities, with three others methods being its (meta-)\nmathematical specifications.\n                                                                                                                                   \nEdward G. BELAGA\npage:    21\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\nCantor’s \n«Beyond \nthe \nUpper-Limits» \nPrinciple, \nBULP \nPrinciple \nof \nthe \nUltimate \nAccessibility \nof \nAny \nSet-Theoret\nInaccessible). The set-theoretical world you see around you has a limit, and\nbehind this limit a new world starts. So let’s go and take a look at it !\nThe spirit of the procedure is aptly captured by the old engraving above.\nOne cannot underestimate all importance of this principle for theory of sets. In\nfact, rarely in the history of science or mathematics can one find a vast and full-\nfledged theory with such a predominance, both conceptional and formal, of a single,\nand for that matter, extremely controversial idea ! \nStarting with Cantor’s first and historically unprecedented affirmation that any\npotential, or incomplete, or improper infinity can be viewed, and subsequently dealt\nwith, as an actual, or proper, or complete one [Dauben 1979], p. 97, - through\ninaccessibility and indescribability [Kanamory 1994], - and up to the most-recent\ninconsistency ceiling for all known strong hypothesis of infinity, §3, -\neverywhere one meets and needs the omnipresent, omnipotent, and, as many are still\nhoping, omniscient Cantor’s «beyond-the-upper-limits» Symbol of Set-Theoretical\nFaith. Notice that in its generality, BULP is independent of a specific axiomatic\nframework, ZFC including.\n                                                                                                                                   \nEdward G. BELAGA\npage:    22\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\n§10. Three Lesser Principles of \nFabrication of New Infinite Totalities.\n10.1. Transfinite Counting. The first offshoot of Cantor’s general\naccessibility principle has been his method of extension of the usual counting\nprocedure, 1, 2, 3, ..., beyond its infinite «ceiling», as it has been described above,\n§2. Notice that in the standard set-theoretical expositions, the first (transfinite\ncounting) procedure is usually formally incorporated into the third (functional)\nscheme, via Cantor’s concept of well-ordering. (In ZFC, one needs here, among\nother things, AES and AI.)\n10.2. Combinatorial Method.\nThe second method extends the\naforementioned Powerset Construction 6.5 to any set, including the continuum\nitself, 1 = powerset( ) = P( ), and beyond. It also employs such basic\ncombinatorial operations over infinite totalities as the sum, product, pairing. (The\naxioms PSA, AP, AU in ZFC.) \n10.3. Functional (or Descriptive) Scheme(s). This method designs,\nor rather nominates, new infinite totalities by pure descriptive (or functional)\nmeans. Typically, one assembles together all already existing or hypothetically\navailable totalities with a chosen property into a «basket», and then one declares\nthat the «stuffed» in such a way basket must necessary represent an infinite totality.\n(The axiom schemata ASR.) \n10.4. Example of the Application of the Functional Scheme :\nCantor’s Construction of the First, Second, etc., Uncountable\nOrdinals. One collects all countable ordinals into one «basket», called Cantor’s\nfirst number class. It has to be an ordinal, and it must be (by definition) greater\nthan any one from the first class, - thus, the smallest uncountable ordinal, ω1 =\nL(ω) (L stands for the transfinite Limit operation; our notation). All ordinals,\nwhich follow ω1 and are equipotent with it, form Cantor’s second number class\nfollowed by ω2 = L(ω1), ... «and so on» ! \n§11. Cantor’s Transfinite Superstructure.\nStill, Cantor has been not satisfied with the emerging transfinite universe, and\nnot without reason : after being created according to one (or several) of Cantor’s\nthree methods, some of his new infinite totalities bear forever the «marks of their\ninfinite origins», which do not let them to effectively «mix» with other infinities,\nleaving them «disjoint and incomparable» ([Kanamory, Magidor 1978], p. 104;\n§§2, 7; FAQs 7.1-2).\nTo overcome these inbred shortcomings, Cantor has conjectured two\nfundamental and far-reaching properties of the old and new infinite totalities, which\nforcefully amalgamate disparate infinities into one linearly ordered (in fact, well-\nordered) transfinite universe, but which strike an attentive observer (see, e. g.,\n                                                                                                                                   \nEdward G. BELAGA\npage:    23\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\n[Lebesgue 1905], to mention only one of many prominent critics, past and present)\nas coming out of nowhere, a sort of a politically motivated, transfinite «affirmative\naction».\nAnd here it is how it apparently happened. As Cantor has discovered, the\npower set construction «creates» an uncountable (the continuum) from the\ncountable, \n= P(ω) (Cantor’s Powerset Construction 6.5). But so does Cantor’s\ntransfinite limit procedure, ω1 = L(ω) (Example 10.4) ! Also, two operations share\nan important general property : applied to a set, they increase its cardinal power :\n< P( ),  \n< L( ) .\nIn the case of L, it is true by (the ordinal) definition, for P Cantor has discovered a\ngeneral, simple, elegant, and influential diagonal argument (mentioned in 6.5) which\ndoes not depend on Cantor’s ordinal construction.\n11.1. Cantor’s Transfinite Dream. Our guess is, Cantor believed\nthat both operations have the same cardinal strength and create the same\nthings. \nIn other words, for cardinals, P = L. But, being enacted on ordinals, L is a\nmuch more subtle, rich, transparent, and good-behaving operation : (i) it defines the\nminimal uncountable totality ω1; (ii) more generally, it increments the cardinal\npower by the minimal transfinite «quantum». In a word, a perfect assembly line\nwonderfully explaining away the somewhat obscure and recalcitrant P !\nCantor never claimed that. Instead, he proposed :\n(H1) Any set (the continuum including) can be well-ordered, or, in other\nwords, is equipotent with some ordinal (Cantor’s Well-Ordering Principle).  \n(H2) The Continuum Hypothesis in Its Ordinal Form (CH) : the\ncontinuum and the first uncountable ordinal are equipotent, ≈ ω1. Later on, the last\nconjecture has been vastly extended :\n(H2*) The Generalized Continuum Hypothesis (GCH) : Pα(ω) ≈\nLα(ω).\nThe fact is, taken together, the conjectures H1, H2, H2* amount in Cantor’s\nnaive set theory to exactly  P = L ! In axiomatic set theory, the constructible\nuniverse L of Kurt Gödel, together with the conjecture V = L [Devlin 1984],\nrepresent the closest and most exquisite formal realization (with necessary\nadjustments) of Cantor’s last set-theoretical will. After all, Gödel has been the most\nfaithful, gifted, subtle, and, inescapably, most pathetic [Feferman 1986] of Cantor’s\nheirs :\n11.2. Kurt Gödel’s Intellectual Martyr : Believing, first, that\nall of them really exist, and second, that ZFC represents t h e\nheaven-sent (sorry, Platon-sent) axiomatic basis for any adequate\nformalism capable to eventually \ncapture the «true nature» o f\nMathematical Infinity.\nNever since Hamlet, the famous Prince of Denmark, has lived and acted such a\nbrilliant and relentlessly analytic mind, who would be so puerile and credulous in\n                                                                                                                                   \nEdward G. BELAGA\npage:    24\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\nhis fundamental existential beliefs ! \nTwo examples illustrate this intrinsic paradox in an almost tragicomic, if not\ntragic, way. First, remember how this gentle man [Feferman 1986] would\ncharacterize Brouwer («utterly destructive», cf. §4; [Gödel 1964], p. 257), only\nbecause of the latter’s critical (even if intellectually and mathematically perfectly\njustified, both a priori and a posteriori) attitude toward Cantor’s infinite\nconstructions. \nSecond, read the hilarious account, in [Feferman 1986], p. 12, of Gödel’s, this\nconsummate European and ex-Viennese, acquiring US citizenship. He has been\nassisted in this endeavour by two faithful ex-European lieutenants (themselves\nluminaries of sorts : Albert Einstein and Oskar Morgenstern) who have succeeded\nto save the formal proceedings from Gödel’s initiative to correct in the United States\nConstitution a «logical-legal possibility by which the U. S. A. could be\ntransformed into a dictatorship».\n11.3. Historical Aside. As the reader probably already knows, the fates\nof two conjectures, H1 and H2, turned out to be very different : \n(1) Cantor’s Well-Ordering Principle, or WOP, originally conceived by him\nas \n«a fundamental law of thought, rich in consequences and particularly\nremarkable for its general validity» (cf. [Hallett 1984], p.73),\nhas become a theorem in ZFC. The nontriviality and controversial history of the\nAxiom of Choice are well known [Moore 1982]. The axiom has been invented in\n1904 by Ernst Zermelo with the express purpose to prove the WOP. \nLess known is the fact that Zermelo’s proof (or, for that matter, any other\nproof) of WOP depends in equal measure on Cantor’s powerset construction, or the\nPower Set Axiom, PSA, as well. (It is clear from the above remark of [Dodd 1982]\nin §4, why this particular technical feature is worth to be mentioned here.)\n(2) In fact, they are PSA and ASR, who form together the potent «motor»\ncapable to propel us into Cantor’s transfinite Paradise, and beyond . Still new and\nmore powerful motors are needed to even more accelerate our transfinite ascent.\nSuch motors are called strong axioms of infinity (cf. the quotation from\n[Kanamory, Magidor 1978] in §3), and in this «quest for new axioms of infinity»\n[Jensen 1995], p. 401, one has already invented a throng of them [Jech 1995] ...\n(3) As to the validity of the Continuum and Generalized Continuum\nHypothesis, CH and GCH, they remain open problems, in fact, the most famous\nopen problems of modern set theory [Jech 1995]. \n(4) Still, Cantor’s implicit expectation hidden (as we affirm above) behind the\ncombination WOP + CH, that of the identity of two transfinite operations, P = L ,\nhas been definitively abandoned : each of the two mutually excluding conjectures  P\n> L and GCH are consistent with ZFC [Gödel 1964], [Cohen 1964].   \n§12. Cantor’s Dream and the Post-Cantorian Nightmare.\nAnd he dreamed, and behold a ladder set up on the earth, and\n                                                                                                                                   \nEdward G. BELAGA\npage:    25\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\n9\nWithout ASR, one cannot even assemble the ordinal ω + ω = ω2, §8, from the sets ω +n :\nsee, e. g., [Hrbacek, Jech 1984], p. 144.\nhal-00129653, version 1 - 8 Feb 2007\nthe top of it reached to heaven; and behold the angels of God\nascending and descending on it ... And Jacob awoke out of his\nsleep, and he said: Surely the Lord is in this place; and I knew\nit not. And he was afraid, and said: How dreadful is this place!\nThis is no other than the house of God, and this is the gate of\nheaven.\nGenesis 28:12, 16, 17.\nOur understanding is : Cantor’s transfinite programme has been inspired by\nhis powerful and deep extra-mathematical interests. These interests have shaped\nCantor’s set theory, and they implicitly continue to shape the bulk of «theological\nventures» of modern set theory.  \nIn short : if angels could ascend and descend on the ladder set up on the earth\nand reaching to heaven, why not men ? Our guess is, such has been the inspiration\nof Georg Cantor (this was a deeply religious man [Dauben 1979]), who conceived\nand constructed the transfinite ladder with the express purpose to ascend from the\nfinite («earth» of a mathematician), through the countable (the lower part of the\nladder), to the continuum («heaven» of the Greeks), and then beyond (to the\n«heaven» of scholastics?). A beautiful Greek icon, this true precursor of the\ntransfinite ladder of §3, perfectly captures his vision. \nHas Cantor been directly influenced by this icon, or was it a famous classic of\nthe VIIth century, «The Ladder of Divine Ascent» [Climacus 1982], that has\nenticed him ?... As nowadays, Zen or Tao are enticing some physicists [Capra 1991]\nwho view them as the privileged and most powerful para-spiritual engine of their\nscientific research.\nCantor himself was quite unapologetic about his motives. Here he is, writing\nhundred years ago to Father Thomas Esser in Rome:\n«The establishing of the principles of mathematics and the natural\nsciences is the responsibility of metaphysics. Hence metaphysics must\nlook on them as her children and as her servants and helpers, whom she\nmust not let out of her sight, but must watch over and control, as the\nqueen bee in a hive sends into the garden thousands of industrious\nbees, to suck nectar from the flowers and then together under her\nsupervision, to turn it into precious honey, and who must bring her, from\nthe wide realm of the material and spiritual world, the building blocks\nto finish her palace.» [Meschkowski 1964], p. 94.\nSo far, so good ... The only trouble is, Cantor’s haughty metaphysics has been\noverburdened with silly ideological (in parlance of philosophers, reductionists)\nplatitudes which have dominated his (and to some degree, our) age. \nThus, Cantor has shared with Karl Marx, Charles Darwin, and Sigmund Freud\nthe key idea that the raison d’être of the word around us can be fully understood as\na linear progress towards an encompassing, assembly-line like universe\n(respectively, of sets, societies, organisms, or human beings), beginning from\n                                                                                                                                   \nEdward G. BELAGA\npage:    26\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\nscratch (call it the empty set, primitive society, cell, monkey , or baby), and driven\nby a single, blind, algorithmic force (be it the transfinite enumeration or other\ntransfinite mechanisms which will be discussed later, the class struggle, struggle for\nbiological survival, or libido). \nThis ideological liability has considerably distorted, in the present author’s\nopinion, the future development of set theory. \n§13. Another Apocalyptic Scenario :\nAnd What if Mahlo Infinite Totalities Really Exist ?!\nNevertheless, it will be argued below that the necessary\nuse of higher set theory in mathematics of the finite\nhas yet to be established. Furthermore, a case can be\nmade that higher set \ntheory is \ndispensable \ni n\nscientifically applicable mathematics ... Put in other\nterms : the actual infinite is not required for the mathematics\nof the physical world.\n[Feferman 1987], p. 153.\nIn particular, the carefree hastiness of Cantor’s passage through newly created\nby him uncountables, \nω0 ,  ...  ω1 , ... ω2 , ... , and so on !\nwithout any understanding of the necessity of an independent justification of their\nexistence, has provoked a deep crisis of confidence, and this chasm is still hunting\nus. Sure, would be he right in his (CH) conjecture that \n1 = , the real existence of\n(at least some of) new uncountables would be assured ...\nIn the absence of such a proof, one has to look for other justifications. Thus,\nrecently, some people have become convinced that Harvey Friedman’s outstanding\nresult (mentioned above, §2) concerning an independent finitistic confirmation of\nthe existence of Γ0 (the first impredicative denumerable ordinal), shows «a\ncommitment to Γ0 to entail a commitment to the [existence of the first]\nuncountable [ordinal ω1]» [Smorynski 1982], p. 186. As the eloquent Craig\nSmorynski writes in this magazine:\n«Harvey Friedman, who has the most original mind in logic today, has\nshown a simple finite form of Kruskal’s Theorem, FFF, to be\nindependent of a theory much stronger than formal number theory.\nThrough its unprovability in theories of strength greater than Γ0 , i. e.,\nthe impredicative nature of any proof of it, FFF illustrates beautifully\nthe fallacy of predicativity: FFF is a concrete assertion about finite\nobjects instantly understandable to any predicativist (predicatician?);\nbut any proof of it must appeal to impredicative principles. In short,\nFFF would have been meaningful to Poincaré, but he would not have\n                                                                                                                                   \nEdward G. BELAGA\npage:    27\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\nbeen able to prove it, disprove it, or accept any proof of it given to\nhim.» [Smorynski 1982], pp. 182, 187.\nConvincing, isn’t it ? Yet, with all due respect to Friedman’s remarkable\ndiscovery, let us make it clear that the result in question demonstrates only that\npredicativity is too restrictive a concept to fully formalize the notion of «finite and\nelementary»; of course, this is in itself a remarkable achievement ! However, it is still\na far (more precisely, uncountably far) cry from a necessary use of even the first\nuncountable ordinal ω1.\nNow, if one cannot prove as yet that Cantor’s «minimal» uncountable\n«independently» exists (Criterion 7.5), why not to go far ahead and to find some\nnew, huge and «mathematically useful» infinite totality, whose existence would\nradically justify all «little guys» behind it, including ω1 ? This is what is hidden, in\nparticular, in the following radical affirmation :\n«Here we give necessary uses of the outer reaches of the abstract set\ntheory in a finite mathematical context … These outer reaches of\nabstract set theory actually go significantly beyond the commonly\naccepted axiomatic framework for mathematics (as formalized by ZFC),\nand are based on the existence of Mahlo cardinals of finite order …\nThese are among the so-called small large cardinals … We believe that\nthe example is sufficiently convincing to open up for the first time the\nrealistic possibility, if not probability, that strong abstract set theory\nwill prove to play an essential role in a variety of more standard finite\nmathematical contexts. Of course this would open up a foundational\ncrisis of nearly unprecedented magnitude since we seem to have no\nway of convincing ourselves of the correctness of consistency of such\nset theoretic principles short of faith in our very uneasy intuition about\nthem.» [Friedman 1986], p. 93.\nThis dramatic pronouncement made ten years ago has remained ever since neither\ncommented on, nor justified or explained, either by Friedman, or by his followers\nand admirers. The reason is, of course, the far-fetchedness of the claim that the\nexistence of a Mahlo cardinal is necessary to prove Friedman’s combinatorial\ntheorem. Our alternative explanation of Friedman’s result will appear elsewhere (cf.\nalso [Feferman 1987]).\nNote that the radical justification of the existential reliability of new infinite\ntotalities by their necessary uses in some well established mathematical domains\ncan be somewhat weakened : the uses could be just useful, or even just serve as an\nalternative approach to otherwise discovered mathematical facts [Gödel 1964],\n[Jensen 1995]. A limited analogy can be drown with the case of elementary and\nanalytical methods in number theory : although analytical methods are dispensable\nin some cases, they still sometimes provide even in those cases useful alternative\ninsights.  \nStill, even this weakening of the independent confirmation requirements did\nnot bring us any closer to a proof of the viability of the uncountable part of Cantor’s\nParadise ...\n                                                                                                                                   \nEdward G. BELAGA\npage:    28\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\n§14. Philosophical Postlude.\nThe author ... has come to believe that the debate between\nvarious philosophies of mathematics is a particularisation of\nthe debate between various accounts of the world. [Thus,]\nparallels may be drawn between Platonism and Catholicism,\nwhich are both concerned with what is true; between\nintuitionism and Protestant presentation of Christianity,\nwhich are concerned with the behaviour of mathematicians\nand the morality of individuals; between formalism and\natheism, which deny any need for postulating external\nentities; and between category theory and dialectical\nmaterialism.\n[Mathias 1977], p. 543.\nJust compare the aforementioned Cantorian and post-Cantorian conjurations,\n§§3, 9, 10, of infinite totalities out of nowhere with the following famous lines :\n«And God said, Let there be light : and there was light. And God saw\nthe light, that it was good : and God divided the light from the darkness.\nAnd God called the light Day, and the darkness he called Night.»\n(Genesis 1:3-5).\nWe propose to systematically apply this divine methodological scheme to all new\ninfinite totalities : first, invent it, then see if it is good, and only then «divide a\nname» them. We also submit that the Existential Criterion 7.5 might serve as a\ngood approximation to the divine «see that it is good».\nTo an agnostic (or even atheistic) reader who might be displeased by so many\nidealistic, if not outright theological references, we express here all our sincere\nunderstanding. The fact is, set theoretic research has really become an open\n«theological venture» ([Kanamory, Magidor 1978], p. 104, if not a «mystical\nexperience» [Cohen 1971], p. 15. \nMore precisely, one introduces new axioms of infinity following her or his\n«theological» beliefs, and then one pretends (according to Robinson’s formalist\nmaxim, §5) to just do some formal mathematics :\n«The adaptation of strong axioms of infinity is thus a theological\nventure, involving basic questions of belief concerning what is true\nabout the universe. However, one can alternatively construe work in\nthe theory of large cardinals as formal mathematics, that is to say the\ninvestigation of those formal implications provable in first-order logic.»\n[Kanamory, Magidor 1978], p. 104.\nIt is enough to browse the faithful reporting, called «Believing the Axioms» and\nwritten during a helicopter flight by an honestly credulous spectator [Maddy 1988],\nto fully grasp the frivolity of the cohabitation of all this «theology» with\nmathematics. \nAnd this leaves us with the grave responsibility to answer the following naive\n                                                                                                                                   \nEdward G. BELAGA\npage:    29\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\nbut inescapable question : \n14.1. (Not So) Frequently Asked Question. Lacking necessary\nfaith into ZFC and its extensions, how have one to face the challenge of the\nadvanced ZFC research without resorting to one or another form of a purely\nnegative and «utterly destructive» (§4, [Gödel 1964], p. 257) attitude ?\nLet’s face it the second time : we do not share the widespread conviction that\nZF axiomatic captures adequately the nature of mathematical infinity. Sure, the\nproblem starts not with ZF itself but with Cantor’s original set-theoretical vision of\nwhich ZF is the most faithful and best researched formalization.\nThe opinion that ZF is lacking in some, still to discover and to formalize, basic\nprinciples of infinity, both «qualitative» and «quantitative» (whatever these qualifiers\nmight mean in a specific context), is widespread. In fact, the notion is forced on us\nby the discoveries of Kurt Gödel and Paul Cohen of the independence of CH over\nZFC. (See, e. g., [Jech 1995] on the most influential and advanced methods to feel\n«infinite axiomatic gaps» in ZF). However, what makes our pronouncement about\nthe deficiency of ZF different is the fact that it is coupled with the claim of its\nredundancy. Namely, we believe that some axioms of ZF are superfluous, because\nthey do not capture any «infinite reality» : they are just instances of our wishful\naxiomatic thinking about infinity.\nThe following technological metaphor might help : imagine one wants to build\na flying device, say, helicopter, but only knows how to design cars. ZF, which has\nbeen conceived to «fly», is, as it where, a very powerful and fast «racing car» (much\nmore powerful and fast than drivers usually need [Barwise 1975], [Mathias 1992]).\nAnd even after being outfitted with all those brand-new and extra-powerful\n«engines» (very large cardinal axioms), the overburdened ZF still cannot «fly». Just\nadding two «wings» (principles still to discover) would not help : ZF would still\nremain a heavy «racing car with two wings». \nThe trouble is hidden exactly where our ZF pride resides : in the powerful\nbuilt-in iterative mechanism of set generation. Here is the crucial meaningful\ndistinction (we borrow this expression from several very clever methodological\nformulas of [Bishop 1985]) : (i) one thing is our ability to build recursively some\ninternal (or inside) mathematical objects in a given axiomatic framework : and here\none can be justly proud of the recursive power of the weakest nontrivial subsystem\nof ZF, the Kripke-Platek axiomatic system, KP [Barwise 1975], [Mansfield,\nWeitkamp 1985], [Mathias 1992]; (ii) quite another thing is, however, to recursively\nre-create, in ZFC, an external (or outside) set-theoretical universe [Parsons 1977],\n[Shoenfield 1977] : a modern, but still absolutely illusory attempt to outperform the\nbuilders of the Babylonian tower (Genesis 11:4).\nIt is obvious that ZF has gained in its creative power on the expense of its\ndescriptive power; or, as Jon Barwise has put it : \n«The most obvious advantage of the axiomatic method is lost since ZF\nhas so few recognizable models in which to interpret its theorems.»\n[Barwise 1975], p. 8.\nIn comparison, the axioms of Euclidian geometry are weak in creative power, but\nextremely strong descriptively. In fact, ZF is so powerful that it permits a «user» to\n                                                                                                                                   \nEdward G. BELAGA\npage:    30\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\ncreate his own infinite totalities, which have nothing to do with real infinity :\n14.2. Thesis : ZFC Is an Interactive Programming Language.\n(Let Us Call It Tentatively the ZFC-Calculus of Imaginary Infinite-Like\nConstructions.) (1) The advanced ZFC set theory is a sophisticated and beautiful\nstructure, which is successfully mimicking some aspects of mathematical infinity,\nbut whose main thrust lies with the providing to advanced «users» sophisticated\noptions of creation of, and manipulation with, artificial infinite totalities (similar to\ncomputer graphic images).\n(2) The totalities in question are, in fact, pure mathematical notations not\nrelated to any «reality» outside the tight structure of their definitions and\nrelationships.\n(3) The mathematical beauty of the constructions becomes, thus, a natural\noutcome of the fascinating interplay between the tight intrinsic recursive structure of\nthe «programming language» ZFC (whose «axioms force themselves upon us as\nbeing true» [Gödel 1964], p. 268) and the wealth of mathematical constructions\nfreely (as some contend, arbitrary) borrowed by set-theorists from the treasury of\nour science.\nIn this interpretation finds its proper place the puzzling and «disconcerting»\npredominance in modern set theory of results on ZF consistency and independency: \n«When modern set theory is applied to conventional mathematical\nproblems, it has a disconcerting tendency to produce independence\nresults rather than theorems in the usual sense. The resulting\npreoccupation with «consistency» rather than «truth» may be felt to\ngive the subject an air of unreality.» [Shelah 1992], p. 197. \nWe claim that those consistency results are just the instances of successful program\nverifications. \nWe understand that our interpretation of ZF brings with it the responsibility,\nboth scientific and moral, to propose a dignified «ontological exit» for ZF related\nresearch, which has produced, over almost one hundred years, a wealth of beautiful\nand extremely difficult results and theories. What «mean» those mathematical facts\nif, as we are arguing, the infinite totalities they describe are «preprogrammed» and\nexist only «on paper» ? One possible explanation was hinted at by Stephen\nSimpson : \n«Only the first few levels of the cumulative hierarchy bear any\nresemblance to external reality. The rest are a huge extrapolation based\non a crude model of abstract thought processes. Gödel himself comes\nclose to admitting as much.» [Simpson 1988], p. 362. \nIn other words, ZF related research could be viewed as a sophisticated and\nprotracted exercise in perfecting our skills of inductive and iterative imagination.\nOther interpretations are possible as well, some of them leading to as yet unknown\napplications to future philosophy of reasoning and computing.\n14.3. A Few Farewell Confidential Quips about Mathematical\nInfinity. (1) When invited next time on a transfinite trip, look closely at\nremarkable results concerning the universe of countable ordinals. We are only\nbeginning to penetrate the fringes of the immense wilderness of the\n                                                                                                                                   \nEdward G. BELAGA\npage:    31\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\ndenumerable. There is no doubt that (paraphrazing [Friedman 1986], p. 92) the\n«outer reaches» of the universe of denumerables will become an important\nsubject of future research in set theory, theory of recursive functions, and\nmathematical logic [Wainer 1989], [Aczel, Simmons, Wainer 1993]. \n(2) There exists probably nothing well-ordered beyond the (the author\nconjectures, proper) class of denumerable ordinals, in particular, «because»\nthe continuum cannot be well-ordered.\nBidding good-bye to our good reader, we leave to him the privilege to decide,\nto what category belongs the author of the present study : is he an inventor,\ndiscoverer, detractor, defender, master, victim, user, or spectator of mathematical\ninfinity ? \nAnd who are you, my reader ?\nReferences : \n[Aczel, Simmons, Wainer 1993] \nPeter Aczel, Harold Simmons, Stanley S. Wainer [1993]: Proof \nTheory: A Selection of Papers from the Leeds Proof Theory \nProgramme 1990, Cambridge Univ. Press.\n[Anglin, Lambek 1995] \nW. S. Anglin, J. Lambek [1995]: The Heritage of Thales, Springer-\nVerlag, Berlin.\n[Arnold 1995]\nVladimir I. Arnold [1995]: Will Mathematics Survive? Report on the \nZurich Congress, Mathematical Intelligencer 17:3, 6-10.\n[Barwise 1975] \nJon Barwise [1975]: Admissible Sets and Structures, North-Holland, \nAmsterdam.\n[Belaga 1988]\nEdward G. Belaga [1988]: Are We Really Living in the World Where \nthe Power-Set Axiom Is a Universal Mathematical Truth? Preprint \n362/P-200, ULP, Strasbourg, France. \n[Bergson 1959]\nHenri Bergson [1959]: Œuvres, Presses Universitaires de France, Paris.\n[Bishop 1985] \nErrett Bishop [1985]: Schizophrenia in Contemporary Mathematics, in:\n[Rosenblatt 1985], pp.1-32. \n[Bishop, Bridges 1985] \nErrett Bishop, Douglas Bridges [1985]: Constructive Analysis, \nSpringer-Verlag, Berlin.\n[Bochenski 1970] \nI. M. Bochenski [1970]: A History of Formal Logic, transl. and ed. Ivo \nThomas, Chelsea, New York. \n[Brouwer 1981] \nLuitzen E. J. Brouwer [1981]: Brouwer’s Cambridge Lectures on \n                                                                                                                                   \nEdward G. BELAGA\npage:    32\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\nIntuitionism, ed. by Dirk van Dalen, Cambridge Univ. Press, \nCambridge. \n[Capra 1991] \nFritjof Capra [1991]: The Tao of Physics : An Exploration of the \nParallels between Modern Physics and Eastern Mysticism, \n3rd ed., Flamingo, London. \n[Climacus 1982] \nJohn Climacus [1982]: The Ladder of Divine Ascent, transl. by \nC. Luibheid and N. Russell, Paulist Press, New York.\n[Cohen 1966] \nPaul J. Cohen [1966]: Set Theory and the Continuum Hypothesis, \nBenjamin, New York. \n[Cohen 1971] \nPaul J. Cohen [1971]: Comments on the Foundations of Set Theory, \ni n: ed. D. Scott, Axiomatic Set Theory, Proceedings of \nSymposia in Pure Mathematics, Vol. 13, Part 1, Amer. Math. Soc., \nProvidence, RI, pp. 9-15.\n[Dauben 1979]\nJoseph W. Dauben [1979]: Georg Cantor. His Mathematics and \nPhilosophy of the Infinite, Harvard Univ. Press, Cambridge, Mass.\n[Dershowitz 1993]\nNachum Dershowitz [1993]: Trees, Ordinals and Termination, in:\nProceedings of the TAPSOFT/CAAP ‘93  Symposium, Orsay, \nFrance, LNCS 668, Springer-Verlag, Berlin, pp. 243-250.\n[Devlin 1984]\nKeith J. Devlin [1984]: Constructibility, Springer-Verlag, Berlin.\n[Dodd 1982]\nAnthony Dodd [1982]: The Core Model, London Math. Soc. Lecture \nNote Series 61, Cambridge Univ. Press, Cambridge.\n[Dorfman 1993]\nAndrea Dorfman [1993]: Behind the Magic of Jurassic Park, Times \nInternational, N° 17, pp. 53, 54.\n[Feferman 1986]\nSolomon Feferman [1986]: Gödel’s Life and Work, in: K. Gödel \n[1986]: Collected Works, Vol. I., eds. S. Feferman, et al., Oxford \nUniv. Press, New York., pp. 1-15.\n[Feferman 1987]\nSolomon Feferman [1987]: Infinity in Mathematics: Is Cantor \nNecessary? in: L’Infinito nella Scienza (Infinity in Science), \nInstituto dello Enciclopedia Italiana (1987), pp. 151-209.\n[Findlay 1953]\nJohn N. Findlay [1953]: The Notion of Infinity, Proceedings of the \nSymposium of the Aristotelian Society and Mind Association, \nDublin, July 1953; also in: J. N. Findlay [1963]: Language, Mind \nand Value, George Allen & Unwin, London , pp. 146-164.\n[Foreman, Woodin 1991]\n                                                                                                                                   \nEdward G. BELAGA\npage:    33\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\nMatthew Foreman, W. Hugh Woodin [1991]: The Generalized \nContinuum Hypothesis Can Fail Everywhere, Ann. of Math.\n133, 1-35.\n[Fraenkel, Bar-Hillel, Lévy 1973]\nAbraham A. Fraenkel, Yehoshua Bar-Hillel, and Azriel Lévy \n[1973]: Foundations of Set Theory, North-Holland, Amsterdam.\n[Fremlin 1993]\nDavid H. Fremlin [1993]: Real-Valued-Measurable Cardinals, in:\n[Judah 1993], pp. 151-304.\n[Friedman 1986]\nHarvey Friedman [1986]: Necessary Uses of Abstract Set Theory in \nFinite Mathematics, Adv. in Math. 60, 92-122.\n[Gallier 1991]\nJean H. Gallier [1991]: What’s so Special about Kruskal’s Theorem and \nthe Ordinal Γ0 ? A Survey of Some Results in Proof Theory, Ann. \nPure Appl. Logic 53, 199-260.\n[Gentzen 1936]\nGerhard Gentzen [1936]: Die Widerspruchsfreiheit der reinen \nZahlentheorie, Math. Annalen 112, 493-565; translated in:\nG. Gentzen [1969]: The Collected Papers of Gerhard Gentzen, \ned. M. E. Szabo, North-Holland, Amsterdam, pp. 132-213.\n[Gödel 1964]\nKurt Gödel [1964]: What is Cantor’s Continuum Problem? in: [Gödel \n1990], pp. 176-187. \n[Gödel 1990]\nKurt Gödel [1990]: Collected Works, Vol. II., eds. S. Feferman, et al., \nOxford Univ. Press, New York.\n[Goodstein 1944]\nReuben L. Goodstein [1944]: On the Restricted Ordinal Theorem, \nJ. Symb. Logic 9, 33-41.\n[Hallett 1984]\nMichael Hallett [1984]: Cantorian Set Theory and Limitation of Size, \nClarendon, Oxford.\n[Henle 1991]\nJames M. Henle [1991]: The Happy Formalist, Mathematical \nIntelligencer 13:1, 12-18. \n[Henle 1992]\nJames M. Henle [1992]: Letter to the Editor, Mathematical \nIntelligencer 14:1, 8. \n[Hersh 1979]\nReuben Hersh [1979]: Some proposals for Reviving the Philosophy of \nMathematics, Advances in Mathematics 31, 31-50.\n[Hilbert 1925]\nDavid Hilbert [1925]: Ueber das Unendliche, Math. Ann. 95, 161-190;\nreferences to the translation: On the Infinite, in: ed. J. van \nHeijenoort [1967]: From Frege to Gödel: A Source Book in \n                                                                                                                                   \nEdward G. BELAGA\npage:    34\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\nMathematical Logic, 1879-1931, Harvard Univ. Press, Cambridge, \npp. 369-392.\n[Hintikka 1966]\nJaakko Hintikka [1966]: Aristotelian Infinity, The Philosophical \nReview of Cornell University 75, 197-218.\n[Hrbacek, Jech 1984]\nKarel Hrbacek, Thomas Jech [1984]: Introduction to Set Theory, \n2nd. ed., Marcel Dekker, New York.\n[Jech 1995]\nThomas Jech [1995]: Singular Cardinals and the pcf Theory, Bull. Symb. \nLogic 1, 408-424.\n[Jensen 1995]\nRonald Jensen [1995]: Inner Models and Large Cardinals, Bull. Symb. \nLogic 1, 393-407.\n[Judah 1993]\nHaim Judah, ed. [1993]: Set Theory of the Reals, Bar-Ilan University, \nBar-Ilan.\n[Judah, Just, Woodin 1992]\nHaim Judah, Winfried Just, Hugh Woodin, eds. [1992]: Set \nTheory of the Continuum, Springer-Verlag, New York.\n[Judah, Roslanowski 1993]\nHaim Judah, Andrzej Roslanowski [1993]: On Shelah’s \nAmalgamation, in: [Judah 1993], pp. 385-414.\n[Kanamori 1994]\nAkihiro Kanamori [1994]: The Higher Infinite : Large Cardinals in \nSet Theory from Their Beginnings, Springer, Berlin.\n[Kanamory, Magidor 1978]\nAkihiro Kanamori, Menachem Magidor [1978]: The Evolution of \nLarge Cardinal Axioms in Set Theory, in: eds. G. Müller, D. Scott, \nHigher Set Theory, LNM 669, Springer-Verlag, Berlin, pp. 99-275.\n[Lebesgue 1905]\nHenri Lebesgue [1905]: Lettre à Émile Borel, Bull. Soc. Math. France \n33, 264-269; also in: Jacques Hadamard [1968]: Oeuvres, Tomes \n1-4, Editions du C.N.R.S., Paris, Tome 1, pp. 338-343; translated \nin: Alain Connes [1994]: Noncommutative Geometry, Academic \nPress, New York, pp. 74-77.\n[Lorenzen 1958]\nPaul Lorenzen [1958]: Logical Reflection and Formalism, J. Symb. Logic\n23, 241-249.\n[Mac Lane 1983]\nSaunders Mac Lane [1983]: The Health of Mathematics, Mathematical \nIntelligencer 5:4, 53-55.\n[Mac Lane 1986]\nSaunders Mac Lane [1986]: Mathematics: Form and Function, \nSpringer-Verlag, Berlin.\n[Mac Lane 1992]\n                                                                                                                                   \nEdward G. BELAGA\npage:    35\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\nSaunders Mac Lane [1992]: Is Mathias an Ontologist?, in:\n[Judah, Just, Woodin 1992], pp. 119-122.\n[Mac Lane 1994]\nSaunders Mac Lane [1994]: Responses ..., Bull. Amer. Math. Soc. 30, \n190-193.\n[Maddy 1988]\nPenelope Maddy [1988]: Believing the Axioms. I, II, J. Symb. Logic \n53, 481-511, 736-764.\n[Mansfield, Weitkamp 1985]\nRichard Mansfield, Galen Weitkamp [1985]: Recursive Aspects of \nDescriptive Set Theory, Oxford Univ. Press, New York.\n[Mathias 1977]\nAdrian R. D. Mathias [1977]: The Real Line and the Universe, in:\neds. R. Gandy, M. Hyland, Logic Colloquium ‘76, North-Holland, \nAmsterdam, pp. 531-546.\n[Mathias 1979]\nAdrian R. D. Mathias [1979]: Surrealist Landscape with Figures (A\nSurvey of Recent Results in Set Theory), Periodica Mathematica \nHungarica 10, 109-175.\n[Mathias 1992]\nAdrian R. D. Mathias [1992]: What is Mac Lane Missing, in:\n[Judah, Just, Woodin 1992], pp. 113-118. \n[Meschkowski 1964] \nHerbert Meschkowski [1964]: Ways of Thought of Great \nMathematicians: An Approach to the History of Mathematics, \nHolden-Day, San Francisco.\n[Moore 1982]\nGregory H. Moore [1982]: Zermelo's Axiom of Choice: Its Origins, \nDevelopment, and Influence, Springer-Verlag, Berlin.\n[Moore 1990]\nGregory H. Moore [1990]: Introductory Note to 1947 and 1964, in:\n[Gödel 1990], pp. 174-175.\n[ODQ 1980]\nThe Oxford Dictionary of Quotations [1980], 3rd ed., Oxford \nUniv. Press, Oxford.\n[Omnès 1994]\nRoland Omnès [1994]: The Interpretation of Quantum Mechanics,\nPrinceton Univ. Press, Princeton.\n[Paris 1992] \nAlan Paris [1992]: Letter to the Editor, Mathematical Intelligencer\n14:1, 6-8.\n[Parsons 1977] \nCharles Parsons [1977]: What is the Iterative Conception of Set? in:\nCh. Parsons, Mathematics in Philosophy. Selected Essays, \nCornell Univ. Press, Ithaca, 1983, pp. 268-297.\n[Pohlers 1996] \n                                                                                                                                   \nEdward G. BELAGA\npage:    36\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\nWolfram Pohlers [1996]: Pure Proof Theory : Aims, Methods and \nResults, Bull. Symb. Logic 2, 159-188.\n[Robinson 1965]\nAbraham Robinson [1965]: Formalism 64, in: Proc. Internat. Congr. \nfor Logic, Methodology and Philos. Sci., Jerusalem 1964, North-\nHolland, Amsterdam, pp. 228-246.\n[Shelah 1992]\nSaharon Shelah [1992]: Cardinal Arithmetic for Skeptics, Bull. Amer. \nMath. Soc. 26, 197-210.\n[Shelah 1993]\nSaharon Shelah [1993]: The Future of Set Theory, in: [Judah 1993], \npp. 1-12.\n[Shoenfield 1977]\nJoseph R. Shoenfield [1977]: Axioms of Set Theory, in: ed. J. \nBarwise, Handbook of Mathematical Logic, North-Holland, \nAmsterdam, pp. 321-344.\n[Simpson 1988]\nStephen G. Simpson [1988]: Partial Realizations of Hilbert’ Program, \nJ. Symb. Logic 53, 349-363.\n[Smorynski 1982]\nCraig A. Smorynski [1982]: The Varieties of Arboreal Experience, \nMathematical Intelligencer 4:4, 182-189.\n[Smorynski 1988]\nCraig A. Smorynski [1988]: Against Mac Lane, Mathematical \nIntelligencer 10:3, 12-16.\n[Turing 1950]\nAlan M. Turing [1950]: Checking a Large Routine, in: Report of a \nConference on High Speed Automatic Calculating Machines, \nInstitute of Computer Science, University of Toronto, Toronto, \nOntario, Canada (also: University Mathematics Laboratory,\nCambridge, England), pp. 67-69. \n[van Dalen 1990]\nDirk van Dalen [1990]: The War of the Frogs and Mice, Or the Crisis of \nthe Mathematische Annalen, Mathematical Intelligencer 12:4, \n17-31.\n[Wainer 1989]\nStanley S.Wainer [1989]: Slow Growing Versus Fast Growing, J. \nSymb. Logic 54, 608-614.\n[Weyl 1949]\nHermann Weyl [1949]: Philosophy of Mathematics and Natural \nScience, Princeton Univ. Press, Princeton.\n[Weyl 1985]\nHermann Weyl [1985]: Axiomatic Versus Constructive Procedures in \nMathematics, ed. by Tito Tonietti, Mathematical Intelligencer\n7:4, 10-17, 38.\n[Yessenin-Volpin 1970]\nA. S. Yessenin-Volpin [1970]: The Ultra-Intuitionistic Criticism and the \n                                                                                                                                   \nEdward G. BELAGA\npage:    37\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\nAntitraditional Program for Foundations of Mathematics, in: eds. A. \nKino, J. Myhill, R. E. Vesley [1970]: Intuitionism and Proof \nTheory, North-Holland, Amsterdam, pp. 3-45.\n                                                                                                                                   \nEdward G. BELAGA\npage:    38\nComputational Insights into the Problem of Existence of Big Sets\n6/29/00\nhal-00129653, version 1 - 8 Feb 2007\n"
  },
  {
    "filename": "FAQ/FAQ-Amazing.pdf",
    "content": "FAQ-Amazing\n[Q1]\n[A1] Let us count the ways:\n1. We have an amazing technology. It solves relevant problems that the biggest names of the\nday can’t solve and the academics think can’t be solved. We eliminate complexity, we address\nthe cost, and we solve security.\n2. We have an amazing Business Model. By paying close attention to the key scaling princi-\nples of the business, we can eliminate complexity in ways that no one else has thought of. We\nfirst address the primary cost of computation: the cost of programmers. We then address the\ncost of deployment and maintenance: the cost of administration. Finally, we address the most\nglaring problem of all: the failure of the networking industry to solve the security problem.\n3. We are Solving an Amazing Problem. We are solving the mother of all problems in data-\ncenters: Gratuitous complexity, caused by decades of architectural neglect.\nThat’s what amazing looks like.\n[Q2]\n[A2] Because our infrastructures have grown beyond the size where we can manage them as we\nhave in the past. The human cost of coordination is simply too high; it causes burnout of people,\nhigh costs, and unnecessary degradation of the overall availability of our Cloud-based systems.\n[A2] We are entering a third human revolution, where we partner with our machines to achieve new\ngoals. We have yet to go from the equivalent of horse drawn ploughs to self-driving GPS-enabled\ntractors.\n[A2] Daedaelus is at the leading edge of solving this problem. We’ve been working on it for decades.\n[Q3]\n[A3] These problems are related. The problem is a human one, particularly in the eyes of economists.\nAs eloquently described by Bill Janeway1, “the consequence in the failure of solving the admin\ncomplexity problem is that the industry would devolve into a high cost (people) industry, which\nwould throttle the health and growth of the industry”.\n[A3] The industry has once again devolved, the most glaring example is the manual and pseudo-\nmanual management of networks by Kubernetes. We must go ‘beyond automation’ to solve this\nproblem, and we do. Daedaelus has a powerful answer to this issue, but to become widely adopted,\nwe have to overcome the widespread blind insistence on ‘legacy compatibility’. We think we’ve\nfound a way to do that.\n1William H. Janeway: ‘Doing Capitalism in the Innovation Economy’.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 1 of ??\n[A3] In a very real way, we are lifting developers out of poverty. Instead of using the equivalent of\nspoons and shovels to do agriculture, we are giving them the equivalent of modern tractors2.\n2Milton Friedman was traveling to an Asian country in the 1960s and visiting a worksite where a new canal was\nbeing built. He was shocked to see that, instead of modern tractors and dirt movers, the workers had shovels. He\nasked why there were so few machines? The government bureaucrat explained: “You don’t understand. This is a jobs\nprogram.” To which Milton replied: “Oh, I thought you were trying to build a canal. If it’s jobs you want, then you\nshould give these workers spoons, not shovels.”\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 2 of ??\n"
  },
  {
    "filename": "FAQ/Case-for-Reliable-Atomic-Links-OLD-V01.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\næthernet and switched networks\n1\nThe Case for Reliable Atomic Links\nRcv\nSnd\nSnd\nRcv\nBob\nAlice\nGreen: Forward Evolution\nBlue: Reverse Evolution\nForward Progress (+1)\nReverse Progress (-1)\nTernary Logic Link\nEquilibrium = 0\nFigure 1: Two CELLs and a LINK with\nconserved quantities, epistricted with\nTernary, or Three-valued logic\nMany (1) latency (2) Inconsistency, and (3) Unbounded problems\nencountered in distributed systems today arise from our inability\nto distinguish between a node that is merely slow from one that\nhas failed or become unreachable due to network failure.\nWe take the two most recognizable elements in datacenters today:\nservers and switches, and refactor them into simpler, fully independent\nfailure domains: CELLs and LINKs. A CELL is a universal node: an au-\ntonomous unit of compute, storage and packet processing. A LINK is\na bidirectional tunnel-element; an autonomous communication entity\nbetween two CELLs)1. Physically, the LINK comprises the cable and\n1 Think of CELLs in Cellular automata.\nThink of LINKs as compute elements\nwith their own autonomous and in-\ndependent failure domain (Local\nINformation and Knowledge). In the\nsame way devices within a single ex-\necution environment are considered\na single failure domain; the LINK can\ndetect device and cable errors and make\nthe machine stop. The challenge is how\nto get it started again. The solution is\ntriangle networks: Tripartite directly\nconnected graphs.\nSerDes’ on both ends to form a self contained execution environment.\nUnifying node elements makes things simpler because we have\nonly one type of node to manage instead of two. We raise the notion\nof a LINK to first order – a first-class citizen in the infrastructure – a\nbipartite element of conserved information with two complementary\nhalves – persistable through failure and recovery events. i.e., a com-\nmunication object that doesn’t rule out that some local fault-detection\nand computation is involved.\nPhysical LINKs Implement utilities that used to be in logical link\ndomains above L2: in L3, L4, or L7; composed into an abstraction of\nlogical links. This is an illusion. If the pairing of Shannon informa-\ntion is thrown away at layer 2, it cannot be recovered in higher layers.\nThis is addressed in more detail in the Key Issue section below.\nAn example2 LINK utility is The I Know That You Know That I Know\n2 Synchronization of timing domains\nin computers generally start from the\nprocessor clock on the motherboard,\nand fan out through the logic into the\nI/O subsystems. IUI lives in the LINK\nbetween two independent computers,\nand although it receives information\nfrom either side, it is not synchronized\nwith either side. This independent\nasynchronous domain (already ex-\nploited in the HFT Industry) – enables\nfailure independence and atomicity.\n(TIKTYKTIK) property; which enables us to address some of the most\ndifficult and pernicious problems in distributed systems today.\nAnother example LINK utility is Indivisible Unit of Information (IUI).\nUnlike replicated state machines (RSM’s) used throughout distributed\napplications today, LINKs are state machines: the two halves of which\nmaintain shared state through hidden packet exchanges. When a local\nagent or actor is ready, the IUI protocol transfers indivisible tokens\nacross the LINK to the other agent, atomically (all or nothing) 3.\n3 LINKs are exquisitely sensitive to packet\nloss. This is intentional: we turn the\nFLP result upside down, and use “a\nsingle unannounced process death” to\nguarantee the atomic property for IUI.\nTIKTYKTIK and IUI properties are mathematically compositional.\nTrees of LINKs provide a deterministic conserved quantities mech-\nanism to reliably distribute indivisible tokens among agents on an\napplication graph. Intermediate CELLs promise 4 to never lose IUI to-\n4 The alternative definition of Fu-\ntures/Promises also applies: execution\nis primed to create future liveness events.\nkens. This defends against lost tokens because if any part of the chain\n(or tree) breaks. Alternate paths are available to seamlessly recover\nthe conserved quantity and continue operation5.\n5 LINKs also provide a more reliable\nfoundation for distributed system\nservices for applications: consensus,\natomic broadcast, leader election,\ncluster membership and distributed\narithmetic, Which, in-turn, enable\nhigher level functions such as network-\nassisted-transactions which serve, for\nexample, distributable (scale-out),\npersistable (durable), and lightweight\n(but-accurate) accounting of conserved\nquantities associated with application\nstate or resource usage.\næthernet and switched networks\n2\nFor maximum efficiency, both sides of the link should be ple-\nsiochronous; keeping worms circulating at the same rate through\nboth transmit and receive channels.\næthernet and switched networks\n3\nA New Law: Conservation of TOKENS\nBy strengthening the system model, LINKs & IUI tokens provide\na general foundation to solve many distributed systems problems\nsuch as failure-detection, consensus and distributed transactions.\nProblem\nSixteen years ago, CPU-Bound tasks, such as buffer pool and con-\n* OLTP Through the Looking Glass 16\nYears Later: Communication is the new\nBottleneck\ncurrency control, were the primary bottlenecks in OLTP databases.\nToday, communication overhead is the dominant factor affecting per-\nformance*. Timeouts and retries (TAR) are the “root of all evil\". in\ndistributed systems. They lead to Cascade Slowdowns: Retry Storms,\nMetastable Failures, Limpware, Transaction Failure, and Silent Data\nCorruption that leads to lost and corrupted transactions.\nFailure Modes\nOne might imagine6 if each host (or its SmartNIC) maintains its half\n6 Such a recovery mechanism is not\navailable through conventional\nswitched networks; because of the\nuncertainty of how many packets\nwere lost, exactly where along the\npath through the switched network\nthey were lost, how many were dupli-\ncated, and how they might have been\nre-ordered in the switched network.\nof the shared state, then shouldn’t the switched network be able to\nact as a proxy for a single logical LINK? When a switched network\nfails, and reroutes, can’t the two sides (SmartNICs) just stitch the two\nhalves of the shared state back together again? we could achieve the\nproperties of LINKs over existing switched networks.\nThis simple hazard analysis7 misses a fundamental issue: networks\n7 Typical hazards: (1) Servers with a\nLINK to a single Top of Rack Switch\n(ToR) are unable to heal at all; there is\nonly one path from the server to anyone.\n(2) ToRs represent SPoFs; when they\nfail, many servers (in that rack) also\nbecome unavailable. Worse still: the\nservers don’t go down, they keep on\ncomputing but don’t know they are\nisolated. ToRs have also been known to\nexhibit complex cascade failures where\na firmware failure triggered in one will\ntake down many neighbor TORs.\ndon’t maintain state on behalf of applications. Switches drop packets (and\nstate) whenever they feel like it, so there are many more ways for log-\nical link ts to get confused over switched networks and compromise\nthe integrity of the shared state.8\n8 Even without failures, the behavior\nof switched networks forces us into a\nhigh overhead approach. If packets can\nbe indiscriminately dropped, delayed,\nduplicated and reordered, we have no\nchoice but to implement TCP/IP sender\ntimeouts, or something very much like\nit (which is unlikely to have the matu-\nrity and robustness of the existing tried\nand tested implementations). However,\neven in optimal situations, TCP intro-\nduces high overhead and unbounded\nlatency for all operations, which is too\nslow. There is no escape: if we drop,\ndelay duplicate or reorder packets,\nyou have to effectively implement TCP.\nIf we can eliminate duplication and\nre-ordering, recovery is far simpler, and\nremoves the tail latency from normal\noperations.\nKey issue: Switched networks drop packets anywhere along the\n‘network’ path; eradicating state and events needed to maintain\npromises and liveness respectively. When a LINK fails, both sides\nare preserved. If there is a failure in the IUI it can always be\ndetected, and retransmissions occur only on a real failure (such as\ndisconnection–where alternative routes are explicitly coordinated\nwith applications), thus enforcing that tokens have no duplicate\nor out of order deliveries on the LINK.\næthernet and switched networks\n4\nSwitched Networks\nWhen packets are dropped in a switched network, more than infor-\nmation is lost, events are lost, and it becomes extraordinarily difficult\nto recover both sides of a shared state that stretches across even a sin-\ngle switch. 9\n9 LINKs do not reorder or duplicate\npackets so we can now use a high-\nperformance payload operator in\nAtomic Ethernet for coherence; only\npaying the performance cost of TCP\nwhen it fails for real, i.e. disconnection.\nRemarkably, this also paves the way for\nvery high bandwidth utilization for dat-\nacenter to datacenter application flows,\nbecause it eliminates the most difficult\naspects of reordering and duplication\nof packets. In scale-out/massively\ndistributed architecture.\nNot sure dropped packets are the right hazard to mention here “the protocol is\nexquisitely sensitive to packet loss”. What really destroys state as shown in the\nAfek et al. paper was RACE CONDITIONS on every packet transmission (delay +\nreorder), with the proposed solution being essentially E2E Stop and wait\nA directly connected LINK can promise three things a switched net-\nwork cannot: (a) maintain an ordering of events (heal, send packets,\nfail, heal again, send more packets) – essential for non-idempotent\nand non-commutative operations. (b) not drop certain packets with-\nout notification – essential for recovery. And (c) maintain comple-\nmentary direction state – essential for distributed self-stabilizing algo-\nrithms with local rerouting rules for reliable trees. 10 11\n10 Actually, a LINK can promise many\nmore than just these three things: what-\never property the agent or application\nwishes to attach to the bipartite LINK\nobject.\n11 Reversible IUI enables the rever-\nsal of non-idempotent structures in\ndistributed applications.\nWhat’s necessary is an entanglement between state machines – lock-\ning them together silently in normal operation, and failing locally at\nthe first failure. The entanglement cannot be recovered if information\nfrom events can disappear. This is the only solution to the problem\nin the latency–disconnection ambiguity [Ref: CAP Theorem Trade-\noffs]. To put it in terms an engineer can internalize, a system that\nfails instantly, can heal immediately.\nBipartite Integrity and the E2E Principle\nThe End-to-End (E2E Principle 12\n12 The end-to-end principle states that in\na general-purpose network, application-\nspecific functions ought to reside in the\nend hosts of a network rather than in\nintermediary nodes, provided that they\ncan be implemented “completely and\ncorrectly” in the end hosts. Our claim\nis that it is impossible to implement\nbidirectional synchronization primitives\n“completely and correctly” without\nIUI (or something very much like it).\nThe datacenter is not the Internet, and\nSaltzer, Reed, & Clark considered only\n(unidirectional) file transfer, not the\nbidirectional synchronization of replicas\n(token coherency).\nThe shared state property is strengthened by mechanisms to re-\ncover from each type of failure. The more types of failures, the more\ncomplex and intractable this becomes. The LINK combines the fail-\nure domains of SerDes, cables, connectors and atomic rays?? (Idea\nis no matter what happens, the link freezes If anything is amiss, you\ncan remove if flow is better – into one failure hazard LINKs are in-\ndependent failure domains, with (effectively) one failure hazard:\ndisconnection13; which is straightforward to recover from. Switched\n13 In any physical system it is possible\nto drop packets, it will be much rarer\nbut it is still possible. LINKs can recover\nfrom individually dropped or corrupted\npackets, and shared state integrity can be\nmaintained through out the successive\nreversibility recovery – back to the\nequilibrium state.\nnetworks, on the other hand, have many more failure hazards: they\nindiscriminately The Network is Reliable An informal survey of real-world\ncommunications failures drop, delay, duplicate and reorder packets\n– that’s just the way networks behave – justified by the end to end\nargument\næthernet and switched networks\n5\nReversibility\nIn physics, time-symmetry is the universal property by which energy\nis conserved. In OAE, reversibility ensures the conservation of IuI\ntokens because traffic on the link stops, and the complimentary state\non both sides of the link is preserved until higher level protocols\n(triangle relationships) where the 3rd CELL (Transaction Manager\nRole) is able to perform “successive reversibility\", heal the link, and\nreturn the protocol back to the equilibrium state.\nThe shared state TIKTYKTIK property can also be used to mitigate\nbroadcast storms in network rendezvous, timeout storms in microser-\nvices, or reconstruction storms in erasure coded storage14. In IUI,\n14 LINKs also coalesce heartbeats to\nmake microservices more scalable, and\nmake failure detectors reliable.\npackets are not merely dropped, they are replaced with special events\ndenoting failure, to maintain liveness. Because LINK failures are inde-\npendent (from node failures) we can successively recover individual\ndisconnection failures.\nThis single step recovery mechanism paves the way for IUI to\nreverse one or more steps in distributed systems which use non-\nidempotent or non-commutative data structures. 15.\n15 The shared state can be compromised\nby duplicated or reordered packets, but\nit is resilient to lost or delayed packets.\nDisconnection is the most likely failure hazard in LINKs. Packets\ndelayed by disconnected LINKs don’t threaten liveness or the\nintegrity of the shared state. Switched network hazards include:\nindiscriminately dropped, delayed, duplicated and reordered packets.\nConventional mitigations (e.g. TCP) add significant complexity\nand performance overheads, and still fail to solve the problem.\nExamples\nThe advantage of the shared state is that both sides know the LINK is\nbroken which can’t be done through a switched network with even\na single switch in series. LINKs simplify some important distributed\nsystem algorithms such as consensus ,two-phase commit, and reliable\ntree generation:\nPaxos 16 “Agents operate at arbitrary speed, may fail by stopping,\n16 Paxos is mentioned first because it\nis a clearer example how reliable L2\nimpacts the application consistency\ntradeoffs. Reliable Paxos probably\ncould be its own paper.\nand may restart. Since all agents may fail after a value is chosen\nand then restart, a solution is impossible unless some information\ncan be remembered by an agent that has failed and restarted”.\n17 The assumption is when a node has failed and restarted, it\n17 Prepare phase is not about bad\nnetworking, but to coordinate between\ncompeting proposals. It cannot be\neliminated, but its performance can\nbe improved by no longer relying on\ntimeouts.\ncan’t remember the state it needs to recover. With IUI, the other\nhalf of the LINK can tell it the state to recover from. This avoids\nthe performance cost of heavyweight transactions and persistent\nstorage.\næthernet and switched networks\n6\nTwo-phase commit The prepare phase is asking if the receiving agent\nis ready to accept the token. This serves two purposes: communi-\ncation liveness and agent readiness. LINKs18 provide the communi-\n18 LINKs exploit a unique combination\nof physics, electrical engineering and\ncomputer science. Think of IUI as the\ndistributed systems (network- based)\nequivalent of the atomic Compare And\nSwap (CAS or just plain SWAP) primitive\nused in shared memory architectures.\nThe result is handshake-free messaging\nwith strong liveness, recoverability and\nsecurity properties.\ncation liveness test, and we can avoid blocking on agent ready, by\nhaving the LINK store the token on the receiving half of the LINK. If\nthere is a failure, both sides (senders and receivers in both NICs)\nknow; and both sides know what to do next.\nWhy can’t the sending side on Paxos keep the information the\nreceiving side needs in case it fails? The other side of the LINK\nknows: the state that was lost in the crash is maintained by the\nhalf of the LINK on the other side. In leader election a master sends\na request to a worker (prepare) and it doesn’t get the ack. With\nIUI, the master knows definitively, if it is a neighbor.\nIn two-phase commit (2PC) there is no safety proof. In three-phase\ncommit, there is no liveness proof. Can we also often eliminate the\nprepare phase in consensus and 2PC? 19 which improves perfor-\n19 And in three-phase commit, the\npre-prepare phase?\nmance.\nOne or more corner cases are eliminated where the replicated state\nmachine can get blocked due to loss of acknowledgement .\nAtomicity in IUI provides significant advantages in dis-\ntributed computing by making corner cases disappear, it\nmakes it simpler to implement those distributed algorithms\ncorrectly, and the number of circumstances where things go\nwrong is reduced by (potentially) several orders of magnitude.\nReliable tree generation Binary LINK reversal algorithms20 work by\n20 Charron-Bost et. al. generalize the\nGafni-Bertsakas (GB) binary LINK\nreversal algorithm.\nreversing the directions of some edges. Transforming an arbitrary\ndirected acyclic input graph into an output graph with at least one\nroute from each node to a special destination node. The resulting graph\ncan thus be used to route messages in a loop-free manner21. LINKs\n21 LINK reversal algorithms don’t gen-\nerate shortest paths, just some paths.\nHowever, they do generate multiple\nloop-free routes. This allows the LINK\nto inform the agent (and the applica-\ntion, if needed) when switching to an\nalternate failover tree. As long as pre-\ncomputed failover paths are available,\nwe used the Dynamic Tree Algorithm\n(DTA). Only when CELLs lose all their\npaths do they need to participate in the\nLINK-reversal algorithms, which means\nless communication overhead and more\nstability.\nstore the direction of the arrow (head and tail); IUI facilitates the\natomic swap of the arrow’s tail and head to maintain loop-free\nroutes during failure and recovery.\nThose examples are applications using multiple links composed\ntogether, as depicted in our Atomic Ethernet logo.\nAlso, liveness becomes trivial in paxos. As long as a majority is\nup, progress is guaranteed. The real problem is cluster membership,\nwhen new nodes join, or when old nodes leave, either voluntarily or\ninvoluntarily.\næthernet and switched networks\n7\nFAQ\n[QUESTION I still do not understand how two devices connected us-\ning a full duplex Ethernet link can support reliable communications\nwithout time outs and retries\n[ANSWER] You are right at a conceptual level, but the reality\nof timeouts and retries is so different with a Stop-and-Wait (SaW)\nprotocol as to make you wrong. Let us explain.\n• In current networks, timeouts and retries are end to end concepts.\nAlice sends an application message to Bob with TCP, which at-\ntempts to guarantee delivery by sending ACKs. Those ACKs can\nbe lost on the way from Bob’s node to Alice’s. Alice has no way to\nknow if part of the message or the ACK was lost or delayed, so she\nretries after a timeout.\n• With Stop and Wait (SaW) (the alternating bit protocol) , reliability\nis at the link level, where the protocol provides sufficient common\nknowledge to address the majority of the issues. In particular, if\nthe link doesn’t break, the packets get through. There’s no need to\ndrop a packet due to a full buffer, because the SaW signal is credit\nbased flow control.\n• If the link breaks noisily (both sides get a signal), both sides know\nwhich phase of the protocol they are in, so they know which one is\nresponsible for forwarding the packet. I think you’d be stretching\nthe concept if you said A sending the packet on the new path is a\nTCP-like retry,\nIf the link breaks silently or even in only one direction, both sides\nknow that a SaW signal hasn’t arrived. Since both sides know that\nboth sides know (common knowledge), each can declare the link\ndead with full knowledge that the other side will eventually declare\nit dead too. Of course, knowing when to stop waiting for the signal is\nthe moral equivalent of a timeout, but there’s no need to coordinate\non a value. I’d say that’s quite different from the timeouts you’re\nthinking of.\næthernet and switched networks\n8\nEnd Notes:\n18. Charron-Bost et. al. generalize the Gafni-Bertsakas (GB) binary\nLINK reversal algorithm. Which works by reversing the directions of\nsome edges. Transforming an arbitrary directed acyclic input graph\ninto an output graph with at least one route from each node to a special\ndestination node. Charron-Bost et. al.\n19. Link reversal algorithms don’t generate shortest paths, just\nsome paths. However, they do generate multiple loop-free routes.\nThis allows the LINK to inform the agent (and the application, if\nneeded) when switching to an alternate failover tree. As long as\nprecomputed failover paths are available, we used the Dynamic Tree\nAlgorithm (DTA). Only when CELLs lose all their paths do they need\nto participate in the LINK-reversal algorithms, which means less\ncommunication overhead and more stability.\n20. The shared state integrity of the single physical LINK is a\npromise that two NIC’s can make with each other only over a single\nphysical LINK. This is explicitly an anti-promise for conventional\nswitched networks.\nConclusion: Atomic Ethernet LINKs require a single physical\nconnection; their benefits cannot be achieved over switched net-\nworks composed of a chain of unreliable links. 22\n"
  },
  {
    "filename": "FAQ/FAQ-AIT.pdf",
    "content": "Chapter 1\nFAQ: Reversible Token (AIT)\nList of Questions\nQ1\nSay more about the Reversibility Token Protocol?\n. . . . . . . . . . . . . . . . . .\n1\nQ2\nWhy is RTP Important? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1\nQ3\nWhat can RTP be used For?\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1\nQ4\nWhat are distributed counters? . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1\nQ5\nCan you add and subtract with distributed counters? . . . . . . . . . . . . . . . . .\n2\nQ6\nWhat are Reversible vector timestamps? . . . . . . . . . . . . . . . . . . . . . . . .\n2\nQ7\nCan RTP be used for Flow Control between applications? . . . . . . . . . . . . . .\n2\nQ8\nDoes RTP provide performance benefits over and above the 1-link hop between\nfunctional tiers? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2\nQ9\nHow is this better than regular heartbeats? . . . . . . . . . . . . . . . . . . . . . .\n2\n1\nAdditional Questions about the AIT mechanism\n[Q1]\n[A1] The Reversibility Token protocol (RTP) exploits a unique combination of physics, electrical\nengineering and computer science.\nThink of AIT as the distributed systems (message-based)\nequivalent of the Compare And Swap (CAS) primitive used in shared memory architectures.\n[Q2]\n[A2] Most computer scientists believe that time flows constantly everywhere, and is irreversible. In\nphysics and real world systems, the truth is far stranger. We have invented a radical way to exploit\nthis new scientific understanding, and designed it in to the secure links used for communication\nbetween servers in datacenters; and thereby uniquely solving fundamental distributed systems\nproblems, such as: robust failure detectors, secure consensus, reversible vector clocks and network\nassisted transactions.\n[Q3]\n[A3] We start with these atomicity mechanisms, which enable us to build far more robust network\nprotocols. The SVL can be used to build stacked trees and TRAPHs (TReegrAPH’s) ) on top of which\nwe build new network communication primitives into a subvirtualization layer to address multi-tenant\ncommunication among sets of virtual machines which contain containers and microservices.\n[Q4]\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 1 of 3\n[A4] Replicas of counters which use the AIT primitive, in conjunction with application bindings,\nto create reliable ‘sums’ of chosen parameters in a distributed system. Because our protocol is\nreversible, we also create reliable ‘subtractions’ of chosen parameters. These two properties combined\nenable EQ/CQ invariants, which allows reliable distributed arithmetic across replicas on different\ncells.\n[A4 Insight: ]RTP allows us to distinguish idempotent operations from non-idempotent operations,\nand provide a new class of distributed data structures which combine liveness, persistence and\nreversibility.\n[Q5]\n[A5] Yes. Thats precisely the reason for the ‘successive’ nature of the protocol. This isn’t a Fetch\nAnd Add (like Infiniband), its a genuine conserved quantities protocol. Distributed counters are\nsigned (preferably 1’s compliment) integers, they can go up, and down, and are required to be\nsuccessive, i.e. cannot jump large intervals in the number space without being detected.\n[A5 Insight: ]It is not necessary to require distributed counters to be monotonic. It is sufficient,\nfor recovery purposes, to depend on their successiveness property. This also defends against certain\nkinds of attack, errors and data corruption, because failure of successiveness is easily detectable.\n[Q6]\n[A6] They are distributed counters acting on a per-tree, and per-object basis, to track causality in\nthe updates to distributed data, and provide a deterministic (within bounds) method of reversing\ncomputations when errors or failures occur.\n[A6 Insight: ]Two-phase commit overcomes its lack of partition tolerance by doing a rollback.\nThis is nothing but a primitive form of reversible computing. This is why we say, at the most basic\nlevel, our links exhibit reversibility. Without this, it would not be possible to achieve exactly once\nsemantics.\n[Q7]\n[A7] Yes. The reversible vector timestamps are just counters, which can be reversed (along with\nthe movement of data from a receive buffer back to a transmitting buffer if necessary).\n[A7 Insight: ]RTP + reversible counters provide end to end flow control, without the need to\nreject packets when the buffers get full. Think of them as a more general form of credit-based flow\ncontrol.\n[Q8]\n[A8] Yes, Immediate fast/fail of send packets. The application can ‘know’ that a transmission failed\nwithout waiting for a timeout.\n[A8] We independently provide a significant reduction in latency, simply by directly connecting\nthe communicating cells (servers) without the switch delays. This will also lead to a performance\nbenefit, but it will require benchmarking of real hardware and workloads to characterize correctly.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 2 of 3\n[Q9]\n[A9] Because it provides heartbeat coalescing for more scalable clusters.\n[A9 Insight: ]We no longer need to have N2 heartbeats traversing the network, where N is the\nnumber of nodes (or containers, or microservices) maintaining presence with each other.\n[A9] Because it solves the common knowledge problem for distributed systems.\n[A9] Because it provides a basis for exactly once delivery.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 3 of 3\n"
  },
  {
    "filename": "FAQ/FAQ-AWS.pdf",
    "content": "FAQ: AWS\nWerner Vogles AWS Reinvent Keynote 2017\nVersion 0.2. May 30, 2025\nReview of Werner Vogels AWS Keynote 2017\n[Q1]\nAt the AWS re:invent 2017 conference, Werner Vogels, CTO of Amazon, presented a\nkeynote on core concepts for building “21st Century Architectures” on the cloud.\n[A1] We have a very high regard for what Werner has achieved. There are some areas where we\ncould do some things differently, such as eventual consistency and gossip protocols. These are a\nmanifestation of the lack of understanding of the nature of time by conventional computer scientists.\n[A1] There are some also conventional technology issues where Werner appears to have an incomplete\nunderstanding: For example, his description of latency in his 2016 keynote was incorrect. Either he\nwas’t aware of this technical issue or his focus was on marketing. See Gil Tene’s 2014 description of\nlatency (2 years before this keynote)\n[Q2]\n• Operational excellence\n• Security\n• Reliability\n• Performance efficiency\n• Cost optimization\n[A2] This keynote highlights what Amazon believes are their current strengths: Comments are:\nOperational Excellence. A relative statement about best practices; a platitude. The architecture\ndocument is well written, but similar to what we tried to introduce at VERITAS in 2001, and\nApple in 2015.\nSecurity - IOT is fundamentally flawed. It has proven extremely difficult using Linux as a base, or\nwith the A2A addressing architecture of current IP and Ethernet protocols.\nReliability - will be compromised as long as they rely on the End to End Principle (E2E) principle.\nAlthough AMZN claims a strength in availability, reliability & resilience, this only relative other\ncloud alternatives. The Transaction Fabrix (TF) is a fundamentally more resilient architecture,\norders of magnitude beyond what they have achieved (within a single attachment). However,\ntheir multi-datacenter approach is fundamentally sound and I can think of only a few minor\nimprovements over what they are already doing.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 1 of ??\nPerformance Efficiency - Whichever way we look at it, TF is higher performance (e.g. bandwidth\nand latency) than what AMZN is currently able to achieve with a Clos network.\nCost Optimization - Whichever way we look at it, TF is lower cost than what AMZN is currently\ndoing.\n[Q3]ow does DAEDAELUS compare to Amazon’s architecture foundation? Werner Vogels on “21st\nCentury [Cloud] Architectures”: Availability, Reliability and Resilience\n[A3] The keynote was focussed on:\n• Availability\n• Reliability\n• Resilience\n[A3] This focuses on what Amazon currently considers to be their strengths. This compares to\nDAE Computing (EC)’s fundamental value proposition:\n• Simplicity\n• Resilience\n• Security\n[A3] We don’t believe that security is possible without resilience. And we don’t believe that\nResilience is possible without Simplicity. It took Amazon a long time to understand that containers\nare a simpler and lower overhead deployment unit than virtual machies. Now they are having to\nplay catch up to Google with Kubernetes.\n[Q4]hat do you think about Amazon’s notion of Evolutionary Architectures?\n[A4] REPLICUS was doing this 14 years ago (see NGA proposal self-organizing storage systems).\nThose original ideas are still substantially ahead of both AMZN and Dropbox. Although we do\nconcede that Amazon has executed extraordinarily well.\nI have quarrel with their stance on availability: AZ’s and regions.\nCircuit breakers are good. Fallback: release all the resources they need.\nMinimize bimodal Failure.\nMultics (MIT) half of code is for no reason, Richie - replaced with PANIC. Helps with faster\nrecovery. Instead of massive trees of recovery code.\n[A4] Werner talks about “Static capacity planning”. This is pass´e. What the world needs is\ndynamic self organization.\n[Q5]\n[A5] A cop-out. When everyone is responsible, no one is responsible. Its clear that Werner, like\nmany in the industry, belive that security is an unsolvable problem, and is trying to dump the\nresponsibility on their customers.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 2 of ??\n[A5] Security “best practices” are insufficient. Encryption is a crutch, used by people who believe\nthat security cannot be solved. This cannot be further from the truth.\n[A5] Protecting data in transit doesn’t work when (a) someone can see the data in transit (it\ngoes through switches and routers you don’t control). (b) someone has better technology than you\n(e.g. The NSA knows how to fake out standards so people pick weak inputs to their encryption\nalgorithms, and (c) someone is socially smarter than you - they can fool you into giving up your\ncredentials. The problem is key management.\n[Q6]\n[A6] This is a Break-fix philosophy. It can easily be superseded by better architectural principles and\na deeper understanding of failures and perturbations. Compare this hazard list to the DAEDAELUS\n3-segmented power law distribution. [See FAQ-Resilience]\n[Q7]\n[A7] This is not optimal. Events should not be blocked indiscriminately. Liveness is destroyed\nwhen events are blocked.\n[Q8]\n[A8] Recovery Oriented Computing ̸= Snapshots. Each communication does reversible snapshots.\n[Q9]\n[A9] See our Stanford Presentation: The Time-Less DataCenter Full Video\nDemo Only\nSlides\n[Q10]\n[A10] Automating existing manual operations is insufficient at scale. Our approach goes beyond\nautomation, where the underlying architecture is expressed, not as a set of manually edited\nconfiguration files, or scripts, but as an equation which expresses the datacenter computation on a\ngraph.\n[Q11]\n[A11] Because we can eliminate the baggage that came along with taking old human interfaces (CLI’s\nand scripts in particular), and instead, express datacenter computations in a natural mathematical\nform devoid of unnecessary complexity.\nNotes: “Ultimate in Availability Designs”\nRegian 1 AZ’s\nOne AZ - 99%\nTwo AZ - 99.9%\nThree AZ - 99.99%\nThats the best you can do with 3 AZ’s.\nWith two Regions - can get to 99.999% Availability\nassume 99% is takes 30 minutes to identify a failure, and 10 minutes to fix it.\n4 failures a year\n280 minutes\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 3 of ??\n../../FIGURES/AWSAvailability.png\nFigure 1: AWS Availability\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 4 of ??\n"
  },
  {
    "filename": "FAQ/FAQ-Architecture.pdf",
    "content": "FAQ: Architecture\nDAEDAELUS is reimagining the datacenter to be simple to manage, resilient under failure, and\nsecure. We start with a new link protocol running on standard Ethernet hardware that provides\nliveness detection without heartbeats or timeouts, enables fast recovery following link or node\nfailures, and makes possible confinement of untrusted applications. These features allow us to\nuse a novel addressing scheme that dramatically simplifies datacenter management. Instead of\nmanaging services by editing lists, we manage them by specifying equations. The combination\nof reliable failure detectors and our addressing scheme makes many classes of attacks against\nexisting datacenters inexpressible.\nList of Questions\nQ1\nWhat is the big problem you are solving?\n. . . . . . . . . . . . . . . . . . . . . . .\n2\nQ2\nWhat are the Primary goals (benefits) of the DAEDAELUS (EC) Architecture? . .\n2\nQ3\nWhat are the Architectural Approaches Used to Achieve These Benefits? . . . . . .\n2\nQ4\nHow does this compare to say Reactive threads in Java? . . . . . . . . . . . . . . .\n4\nQ5\nHow does this compare to Async/await in Rust?\n. . . . . . . . . . . . . . . . . . .\n4\nQ6\nWhat are the main components of the Superstrucure?\n. . . . . . . . . . . . . . . .\n4\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 1 of 5\n[Q1]\n[A1] As our systems scale, they exhibit unpredictable behavior when faced with unexpected\nperturbations. From Steven D. Gribble, “Robustness in Complex Systems”:\n“Floyd and Jacobson demonstrated that periodic signals (such as router broadcasts)\nin the Internet tend to become abruptly synchronized, leading to patterns of loss and\ndelays. Druschel and Banga [4], demonstrate that web servers running on traditional\ninterrupt-driven operating systems, a slight increase in load beyond the capacity of the\nserver can drive the server into a persistent state of livelock, drastically reducing its\neffective throughput. Arpaci-Dusseau et al. demonstrate that with conventional software\narchitectures, the difference in performance resulting from placing data on the inner\ntracks vs. outer tracks of a single disk can affect the global throughput of an eight node\ncluster of workstations by up to 50%. A final example is that of BGP ‘route flap storms’:\nunder conditions of heavy routing instability, the failure of a single router can instigate\na storm of pathological routing oscillations. There have been cases of flap storms that\nhave caused extended Internet outages for millions of network customers.”\n[Q2]\n[A2] In order of Priority:\n• Zero Touch (Simplicity)\n• Zero Time to Recover (Resilience)\n• Zero Trust (Security)\n[Q3]\nThis Architecture comprises three principal layers: delivered sequentially as products into the\nmarketplace. The Network Asset Layer (NAL), Data Asset Layer (DAL) and Computation\nAsset Layer (CAL).\n[A3] Not Necessarily In-Order:\nEvent Driven Everything is event driven. From our lowest level protocol to the services we\nsupport and the applications we tune our tools for. We go far beyond what the industry\nnormally means by this term: we replace all aspects of the notion of ‘duration’ (timeouts,\nheartbeats, etc.) with a purely event-only paradigm1, and (in our Sub-virtualization substrate)\nwe eliminate all notions of time. VM’s Operating systems and Applications can create their\nown services if needed.\n1References: Sagas: a long lived transaction is a transaction whose execution, even without interference from\nother transactions, takes a substantial amount of time, probably on the order of hours or days. Ben Stopford on\nEvents/Microservices: Clojure approach to state. The Value of Values. The Language of the System: Rich Hickey\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 2 of 5\nBuilt-in Consensus The groundplane supports ‘tiled’ cluzters of 9 physical cells (self/leader cell\nplus 8 cohorts connected one link away) is a cluzter. At the heart (root) of every tree is a\n“free Paxos”. Its there all the time, doesn’t need to be turned on, and happens silently in the\nbackground by “decorating” the ENTL packets with state to maintain liveness, and equipping\nthe link with ENTT to transfer ownership AIT if the self cell fails. Because there is no state\ntransfer over multiple links, the free bandwidth on the links are is used to good effect without\naffecting the rest of the cells in the datacenter. Long range clusters can be stitched together\nwith Kleinberg (or Virtual Kleinberg) links. Multiple (hierarchical) levels are provided each\ntime a new TRAPH is stacked on top of the existing one.2.\nImmutable Event Log Capture changes arriving at edge cells to an immutable event ‘stream’3\nand reactively compute the derived states, and materialize views from the event log.\nFully Distributed In a Paul Baran ‘distributed’ sense, i.e. not ‘decentralized’ or ‘centralized’. In\nthe base substrate of the system, there are no Single Point’s of Failure (SPoF’s), or Bottlenecks.\nWe are now living in an era in which we cannot guarantee the survivability of a single point.\nHowever, we can design systems in which system destruction requires the enemy to pay the\nprice of destroying n of n stations. If n is made sufficiently large, it can be shown that highly\nsurvivable system structures can be built – even in the thermonuclear era4.\nNeighbor to NeighborAddressing (N2N) Instead of Any-to-Any (A2A) Addressing. Most\nof todays’ conventional attacks are inexpressible. The architecture is designed to be hyper-\nevolvable: to be able to react and evolve faster than any attacker.\nUnikernel Based Foundation Unikernels5 in a Guest VM. Think of them as a single purpose,\nsingle-process virtual appliance. Statically linked image of your Application and a hypervisor\n(no general OS or extra library code). From a security perspective, they have a tiny attack\nsurface: there are no extraneous services, no shell, no system calls, no fork() to start additional\nprocesses. (See the Security-FAQ, on why shell’s are a dangerous attack vector, and why\nUnikernels are more secure.\n[A3] AWS Lambda is an event-driven computing service for dynamic applications6. All data\nis expressed as events: Receive HTTP, Ingest custom interpretation, ingest more HTTP, emit\nresults, logs, metrics, errors, all as events that other functions can receive. Similar to Google Cloud\nFunctions, Azure Functions.\n2DAEDAELUS’s logical and virtual TRAPHs have access to a ‘LPaxos’ and ‘VPaxos’ state for transactions, and\nZAB operations\n3A multidimensional data structure and associated stream(s) we call the MetaData Tensor (MDT)\n4On Distributed Communications – Paul Baran\n5Unikernels are specialized, single-address-space machine images constructed by using library operating systems.\nUnikernels shrink the attack surface and resource footprint of cloud services. They are built by compiling high-level\nlanguages directly into specialized machine images that run directly on a hypervisor, such as Xen, or on bare metal.\nSince hypervisors power most public cloud computing infrastructure such as Amazon EC2, this lets your services run\nmore cheaply, more securely and with finer control than with a full software stack. Unikernels provide many benefits\ncompared to a traditional OS, including improved security, smaller footprints, more optimization and faster boot\ntimes.\n6What we realized, is that this idea goes much deeper. First we provide extreme reliability in not losing an event,\nthen extreme resilience in making sure that its persistent results from events are not lost or corrupted (immutable),\nthen we make sure that other events are reliably created downstream, in a simple, resilient and secure way.\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 3 of 5\n[A3] How do you compare to Amazon Keyspaces?\n[This should go in FAQ-Competitive]\n[Q4]\n[A4] Reactive or nonblocking processing is a core part of the DAEDAELUS architecture. We\ntake this nonblocking7 concept to an entirely new level not previously understood. One particular\ndistinction is the thread model. Differences in differences are as follows:\n• “Reactive Programming is the processing of the asynchronous event stream, on which you can\nobserve”\n• Distributed Dynamic Data Structure is processing the asynchronous event stream, from the\nvantage point of each cell-tree. Observation of asynchronous event streams is enforced by the\ntree order, and guaranteed to be conflict-free by the reversibility mechanisms built into the\nlinks and processing\n[Q5]\n[A5] See Writing an OS in Rust. This is a well written (but conventional) view of the concurrency\nand multitasking by highly competent developer. The notion of ‘futures’ was an important step\nforward along the path of understanding the nature of concurrency by computer scientists, and we\nare delighted to see these kinds of advanced thinking starting to emerge as mainstream in many\nprogramming languages. The challenge is two underlying notions that challenge the intuition of\nexperts. The first is the (naiive) expectation that if we just tried harder, we could eventually make\nthings deterministic. The second is\nWe are in the same mode (as security):\n1. There is no problem\n2. There is no solution\n3. There is no free-lunch\n[Q6]\n[A6] In each cell, you will find a Superstructure\n7See: FAQ-Concurrency and FAQ-Consistency details on our ‘obstruction free (lock-free, wait-free, etc.).\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 4 of 5\n../../FIGURES/Architecture.pdf\nFigure 1: The DAEDAELUS Software Stack\nMay 30, 2025\nConfidential © 2023 Daedaelus / Atomic Innovations\nPage 5 of 5\n"
  },
  {
    "filename": "FAQ/@Filelist.pdf",
    "content": "FAQ: Filelist\n1. FAQ-Addressing\n2. FAQ-AIT\n3. FAQ-Architecture\n4. FAQ-ATT\n5. FAQ-AWS\n6. FAQ-Bandwidth\n7. FAQ-Business\n8. FAQ-Causality\n9. FAQ-Claims\n10. FAQ-Cloudplane\n11. FAQ-Competitive-Landscape\n12. FAQ-Consistency\n13. FAQ-Cost\n14. FAQ-Deﬁnitions\n15. FAQ-ENTL\n16. FAQ-ENTL-AHK.tex\n17. FAQ-General\n18. FAQ-GenZ\n19. FAQ-Hardware\n20. FAQ-Harry\n21. FAQ-HOWDO\n22. FAQ-Interconnects\n23. FAQ-IOT\n24. FAQ-Latency\n25. FAQ-Legacy\n26. FAQ-LoadBalancing\n27. FAQ-Market\nFebruary 21, 2018\nConﬁdential © 2008-2018 Earth Computing Corp.\nPage 1 of ??\n28. FAQ-Market-AHK.tex\n29. FAQ-Monitoring\n30. FAQ-Nerdy\n31. FAQ-Network-Management\n32. FAQ-Networks\n33. FAQ-Objections\n34. FAQ-Physics\n35. FAQ-RAFE\n36. FAQ-Resilience\n37. FAQ-Security\n38. FAQ-SignalFire\n39. FAQ-Simplicity\n40. FAQ-Subtime\n41. FAQ-Trees\n42. FAQ-Trees-AHK\n43. Introduction\n44. Legal\nFebruary 21, 2018\nConﬁdential © 2008-2018 Earth Computing Corp.\nPage 2 of ??\nFebruary 21, 2018\nConﬁdential © 2008-2018 Earth Computing Corp.\nPage 3 of ??\n"
  },
  {
    "filename": "SPEC/dae-spec-full.pdf",
    "content": "S A H A S M U N A M A L A , PAU L B O R R I L L\nO P E N AT O M I C\nE T H E R N E T\nO P E N C O M P U T E P R O J E C T – O A E W O R K S T R E A M\nContents\n1\nPrinciples of Operation\n1\n1.1 Symmetric Reversibility\n1\n1.2 Interactions, not Bandwidth\n2\n1.3 Fixed size Slots, Perfect Information Feedback\n3\n1.4 Race Conditions and Conserved Quantities\n3\n1.5 From API to Bits-on-the-wire\n4\n1.6 Simple Rules, Nearest Neighbors\n5\n2\nBits and Bytes\n7\n2.1 64-Byte Record\n7\n2.2 RISC Protocol Design: OPCODE (Information)\n10\n2.3 RISC Protocol Design: LIVENESS (Knowledge)\n11\n3\nCells and Links\n17\n3.1 Cells\n17\n3.2 Links\n18\n3.3 Initial Discovery\n19\n3.4 It takes Two to Tango, and Three to Party\n20\n3.5 Fault Detection Model\n20\n3.6 Failure Model\n20\n3.7 Link count\n20\n3.8 Reliability configurations\n21\n3.9 Set Reconciliation of Shannon Slots\n21\n3.10 FAQ\n22\n4\nReversible Transactions\n25\niv\n4.1 Mathematical Foundations\n25\n4.2 Atomic Transactions on Æ-Link\n26\n4.3 Flow Control and Backpressure\n26\n4.4 Transactions on Trees\n26\n5\nArchitecture\n27\n5.1 Slice Engine Design\n27\n5.2 Architectural Framework: Four Shannon-like Levels\n28\n5.3 Short-Range ANT (Local) Scouting\n29\n5.4 Long-Range BEE (Global) Scouting\n30\n5.5 ANT Specification: Triangle Packet Clocks in 3 × 3 Tiles\n30\n5.6 ANT Specification: Race-Free Packet Clocks in 3 × 3 Tiles\n30\n5.7 Beyond Packet Clocks\n31\n5.8 Packet Clocks in Larger Tiles\n31\n5.9 Local decisions and emergent global organization\n32\n5.10 Bidirectional Shannon Channels\n36\n6\nTopology\n39\n6.1 Graph Aware Determinism\n39\n6.2 A Resilience Metric for Mesh Networks\n39\n7\nHistory\n43\n7.1 ALOHA\n43\n7.2 ATM\n44\n7.3 Ethernet\n46\n8\nTheory\n49\n8.1 Introduction\n49\n8.2 IP Foundations\n51\n8.3 Two-State Vector Formalism\n53\n8.4 Common Knowledge\n55\n8.5 TIKTYKTIK\n56\n1\nPrinciples of Operation\nRcv\nSnd\nSnd\nRcv\nBob\nAlice\nGreen: Forward Evolution\nBlue: Reverse Evolution\nForward Progress (+1)\nReverse Progress (-1)\nTernary Logic Link\nEquilibrium = 0\nFigure 1.1: Two CELLs and a LINK with\nConserved Quantities (CQ) in dynamic\nequilibrium (Alternating Bit Protocol),\nepistricted with Ternary Logic\nThis chapter defines the foundational principles that govern op-\neration over LINKs in Atomic Ethernet (Æthernet). While traditional\nprotocols prioritize throughput by maximizing raw bit rates, Æth-\nernet focuses on reversible, causally deterministic, and information-\nconserving communication. Rather than treating bandwidth as a fun-\ngible resource, Æthernet embraces a model rooted in equilibrium, to-\nken transfer, and fixed-sized transactional units.\nThis framing en-\nables high reliability and high throughput data movement even in\nfailure-prone environments, where every deviation from equilibrium\nis accounted for and correctable. We describe the architectural conse-\nquences of these choices, highlighting symmetry, liveness, and feedback-\ninformed interaction.\n1.1\nSymmetric Reversibility\nAt the heart of Atomic Ethernet lies a symmetric, reversible link proto-\ncol, governed by deterministic state machines operating on both ends\nof a point-to-point connection. Together, these machines co-create a\nunified, bidirectional construct called a LINK. LINKs are not merely a\npassive channel, but an active agent with its own failure domain, causal\nboundaries, and defined error recovery semantics.\nA LINK is thus a joint stateful system. Both peers (e.g., Alice and\nBob) implement identical state machines that evolve synchronously\nvia the exchange of fixed-size, causally significant tokens. These to-\nkens encode both data and flow-control intent, and their transitions\nare mirrored on each end. There is no concept of master/slave — ei-\nther side may assume the role of INITIATOR or RESPONDER, depending\non who possesses the token.\nopen atomic ethernet\n2\nDefinitions\nsymmetric: each side executes the same logic, defined by the same tran-\nsition rules, enabling fully mirrored behavior.\nNo global sequencing is\nrequired beyond token ownership.\nreversible: for every operation on the link, there exists a logically defined\ninverse that restores the prior state.\nTogether, a symmetric, reversible protocol enables new guarantees\non the network:\n• Partial transactions can be aborted cleanly, returning to an equilib-\nrium where no partial, unconfirmed state is leaked on either side.\n• Errors (e.g., bit flips, packet loss) can be rolled back without cor-\nrupting state.\n• All token transfers are atomic: they either complete fully or leave\nthe system unchanged.\nThese properties allow LINKs to resume normal operation even in\nthe presence of transient failures. No global reset is needed; instead,\nlocal error recovery and rebalancing maintain the equilibrium between\npeers.\nThis symmetry and reversibility simplify correctness proofs, enable\nformal verification of protocol behavior, and provide a foundation for\nconstructing reliable distributed systems from fundamentally unreli-\nable components.\n1.2\nInteractions, not Bandwidth\nTraditional networks treat bandwidth as a fungible resource; Like a\npipe to be filled as much and as fast as possible. Success is measured in\nutilization, and failure in dropped packets. In contrast, Æthernet rede-\nfines communication as a series of causal interactions between peers,\nwhere each exchange has semantic weight and is governed by LINK\nstate machines.\nIn this model, throughput is an emergent property of sustained,\nreversible token exchanges — not burst transmission. Initiators flow\nframes toward responders without waiting, and responders flow re-\nsponses back in kind. The rate of progress is governed not by the raw\nlink speed, but by the rate of acknowledged interaction. This change\nin framing brings several practical consequences:\n• Stable Congestion Behavior: Systems built on causal flow control\nnaturally avoid head-of-line blocking and buffer overflows, espe-\ncially under sustained high load.\n• Implicit Clock Recovery: Each interaction provides timing and syn-\nchronization cues, enabling robust clock alignment without separate\ntiming channels.\nopen atomic ethernet\n3\n• Minimized Latency Variance:\nBecause there are no speculative\ntransmissions, queuing and jitter are dramatically reduced, even\nunder full load.\n• Atomic Forward Progress: A transfer either completes causally or\nis fully rolled back, preserving global consistency without the need\nfor speculative multi-path packet spraying.\nWire Length and Occupation Time:\nBecause each transmission occupies\nthe physical wire for longer than it takes for a signal to traverse it, ac-\nknowledgments from the receiver can begin arriving before the sender\ncompletes transmission of the next wire slot.\n1.3\nFixed size Slots, Perfect Information Feedback\nÆthernet operates exclusively on fixed-size records, or slots, ensuring\nevery transaction carries a known, bounded amount of entropy. This\nconstraint, far from limiting expressiveness, unlocks a powerful class\nof deterministic behaviors aligned with the structure of digital hard-\nware and the limits of information theory. Each transaction transfers\nexactly one slot: a fixed-length, self-contained unit of data and control.\nBecause slots are of known and equal size, flow control is dramat-\nically simplified.\nThis ensures that the sender knows exactly how\nmuch information is in flight, and the receiver can verify complete-\nness without ambiguity. There is no need to infer transfer boundaries,\nnegotiate variable lengths, or guess at incomplete frames. Every in-\nteraction is atomic and unambiguous. The result is a link state that\nevolves in predictable, stepwise increments.\nDefinitions\n• Shannon Slots, the logical atomic units of information maintained in\nthe protocol state machine (typically within FPGA registers).\n• Wire Slots, the physical representation of a slot as it is serialized across\nthe wire.\nThe transition from Shannon Slot to Wire Slot is a fixed-length en-\ncoding operation — deterministic, invertible, and clock-aligned. Tim-\ning closure in the FPGA limits the frequency at which these slots can\nbe emitted or consumed. However, because the slot size is constant\nand interaction is feedback-governed, the system avoids speculative\noverrun and maintains perfect pacing even at high utilization.\n1.4\nRace Conditions and Conserved Quantities\nFor short-range ≤1m links, intrinsic\n(internal ASIC or FPGA) rates of the\nSerDes dominate, making cable propa-\ngation ‘time’ and RTT irrelevant because\nthe occupation length of the packet\nexceeds the length of the wire.\nWith appropriate buffering and pipeline\nmanagement,\nmaximum\nEthernet\nthroughput\nbecomes\nachievable,\nstrongly favoring short-range intercon-\nnects for high-performance and ultra-\nlow-latency Ethernet.\nwhile providing\nreliable (ACK/NAK) transfers ?\nAtomic Ethernet treats Shannon slots as conserved quantities. Each\nslot represents an indivisible unit of knowledge. Slots are never silently\nopen atomic ethernet\n4\ndropped, corrupted, or left in undefined states.\nThis conservation\nprinciple draws a key distinction from best-effort packet-switched net-\nworks, where data loss is expected and recovery is probabilistic. In\nÆthernet, every Shannon slot is not merely a container of bits, but a\nsemantic object with causal responsibility.\nAtomic Ethernet is fully reversible; on any error the receiver can\nreverse the transfer of a token returning ownership, and return re-\nsponsibility for correct operation to the initiator (e.g. Hardware Error,\nProtocol violation, Software Error or resource exhaustion error).\n1.5\nFrom API to Bits-on-the-wire\nÆthernet introduces a fundamentally new substrate for reliable com-\nmunication.\nEvery transmission is atomic, reversible, and causally\nconsistent. To application developers, this creates the illusion of an\nunbreakable network, where transactions either succeed completely or\nfail without side effects.\nYet to enable adoption, Æthernet must integrate seamlessly with\nexisting infrastructure.\nThe compatibility boundary is the IP layer.\nAbove this layer, applications continue to operate as before. Below\nit, Æthernet provides a drop-in replacement for traditional Ethernet,\nunobservable by legacy systems, but dramatically more reliable in be-\nhavior.\nHowever, the true potential of Æthernet lies beyond emulation. Its\natomic transaction model enables a new class of guarantees – deter-\nministic delivery, fault-local reversibility, and programmable transport\nsemantics – that cannot be expressed in the traditional IP or TCP ab-\nstractions. To expose these capabilities to applications, a new vertically\nintegrated stack is needed.\nThis stack must:\n• Extend from the API boundary (e.g., sockets, RPC, shared memory\ntransport) down to the bits on the wire.\n• Preserve atomicity and reversibility guarantees across all abstrac-\ntion layers.\n• Offer language-level semantics (e.g., async/await, futures, or trans-\nactions) that map directly to causal protocol operations.\nIn essence, Æthernet is not just a new physical protocol. It is a new\nfoundation for building distributed systems, one in which software\nand hardware speak the same language of atomic, bidirectional flow.\nNew transaction guarantees can be offered to applications, but re-\nquires a entirely new networking stack from API to bits on the wire\nopen atomic ethernet\n5\nthat propagates the same guarantees of atomicity and reversibility into\nthe languages that application developers write code with.\n1.6\nSimple Rules, Nearest Neighbors\n2\nBits and Bytes\n2.1\n64-Byte Record\nSlice 1 (8 Bytes)\nSlice 2 (16 Bytes)\nSlice 3 (24 Bytes)\nSlice 4 (32 Bytes)\nSlice 5 (40 Bytes)\nSlice 6 (48 Bytes)\nSlice 7 (56 Bytes)\nSlice 8 (64 Bytes)\nFigure 2.1: 64-Byte Record. 8 × 8 byte\nslices, pre-emptible by responders\nFrame size of 64 Bytes. Follows a log2 increase in slot size. The first\nslot (Context) corresponds to the arrival of the first slice off the bits on\nthe wire. Remaining slots follows a Hadamard multiple (1, 2, 4, or any\nmultiple of 4 slices).\n2.1.1\nCONTEXT Processing : From the Inside Out\nSlice 1 [8 Bytes LINK Context] Protocol <RTL>\nSlice 2 [8 Bytes CELL Context] Context] <FSA> <Linear Algebra>\nSlices 3-4 [16 Bytes TILE Context] <State Machines><Petri-Nets>\nSlices 5-8 [32-Bytes ] ULL App PAYLOAD> <Address Bridging>\n2.1.2\nProtocol hierarchy: Four levels of Reversibility:\n• Context Slice Reversibility\n• Shannon Information (Operand Zone A in Serdes)\n• Spekkens Knowledge (Operand Zone B FPGAs, 2-3 clock cycles in)\n• Metcalfe Semantics (Operand Zone C in FPGA, 5-8 clock cycles in)\n2.1.3\nExtended Addressing Modes for Legacy Compatibility\nTo guarantee that no information is lost1the slots must be fixed size.\n1 All distributed systems need transac-\ntions.\nEven applications that run on a\nsingle (multicore) machine need them. If\nit runs in the cloud, it needs a transac-\ntional infrastructure underneath.\nPCIe and CXL attempt to transfer 64 bytes minimum. This makes the\nlatency (occupation time on the wire) too long for ULL applications.\nInstead, we propose a minimum of the first slice (Protocol – Context).\nOptional second slice (Reliability/Recoverability). The rest is payload\nfor local Ultra-Low-Latency (ULL) Transactions.\nContext (Slice 1 [0..7] 8 Octets)\nOperand Zone A  (Slice 2 [8..15] Octets)\n Operand Zone B (Slices 3-4 [16..31 Octets)\nOperand Zone C (Slices 5-8 [32-64 Octets])\n64 Bits\nArrival order of slices in SerDes\nFigure 2.2: Slice Arrival order (Temporal\nIntimacy Depth)\nMode 1 - N2N Neighbor Self-Addressing\nMode 2 - Ethernet MAC Addressing\nopen atomic ethernet\n8\nMode 3 - 32-Bit IP Addressing\nMode 4 - 128-Bit IP Addressing (Container virtual addresses?)\nMode 5 - 10-Bit Cluster Addressing 12-bit VLAN Addressing.\nModes 6..8 - Reserved\nMode 7 - Reserved\nMode 8 - Reserved\n2.1.4\nFlow Transactions\nOperator (4B)\nPayload  (4B)\n64-bits (8B)\n1 Slice\nFigure 2.3: 1 Slice Flow Subtransaction\nULL protocol designers play around with 32 bits as the minimum unit\nof transactional transfer, but experiments demonstrate the difficulty\nof making this consistently reliable i; the general consensus is that\nmodern SerDes’ work best with ≥64 bit (8 Byte) slices/flits. Ethernet\nhas a minimum frame size of 64 bytes (although only 42 bytes were\navailable for the payload).\n2 Slices\nPayload  (12B)\nOperator (4B)\nOperand\nFigure 2.4: 2 slice Flow SubTransaction\nWe therefore choose a fixed 64 Byte frame for the Shannon Slots, but\nmake them pre-emptable so that even the minimum size frame does not\nneed to occupy space on the wire, increase latency, or FPGA processing\nsteps, when the receiver has something more important it wishes to\nsend (e.g. local status messages sent in the background can be pre-\nempted, giving way to a two phase commit (2PC) transaction).\n4 Slices\nPayload  (28B)\nOperator (4B)\nOperand\nFigure 2.5: 4 4 slice Flow SubTransaction\nwith 28B payload (operand)\nSome transactional systems are sensitive to making transactions re-\nliable, but don’t mind missing events, such as highly perishable market\ndata. We might call these one-phase commit (1PC) transactions. These\ncan be made to flow at maximum line rate, even though each individ-\nual slice is being acknowledged. This is particularly important in HFT\nfor example.\nWe therefore provide the following “flow\" transactions in the en-\ncoding scheme:\nPayload  (60B)\nOperator (4B)\n8 Slices\nOperand\nFigure 2.6: 1 × 8 slice Flow Transaction\nwith 60B payload\n2.1.5\nBack Propagation Encodings\nThis encoding scheme (with slice acknowledgements), guarantees com-\nmon knowledge in a flow of transactions, and their backpropagation\npacked into a single frame. Examples shown here include:\n1. One Flow Transaction in with 4B payload in a single slice (addi-\ntional encoding in TX beats:\n01 I intend to send only one slice.\n10 I intend to send 2 slices, count down from there in replies\n11 I intend to send 4 slices, count down from there in replies\nOperator (4B)\nPayload  (4B)\nOperator (4B)\nPayload  (4B)\nOperator (4B)\nPayload  (4B)\nOperator (4B)\nPayload  (4B)\nOperator (4B)\nPayload  (4B)\nOperator (4B)\nPayload  (4B)\nOperator (4B)\nPayload  (4B)\nOperator (4B)\nPayload  (4B)\n8 Slices\n64-bits (8B)\nFigure 2.7: 8 independent Flow Transac-\ntions in a one frame\n2. One Two Slice Flow Transaction context with 12B of Payload\n3. One Four Slice Flow Transaction context with 28B of Payload\nopen atomic ethernet\n9\n4. Eight one-slice Flow Transactions context with 60B of Payload\n2.1.6\nMixing and Matching Flow Transactions\n2.1.7\nTwo 4 slice Flow Transactions\nOperator (4B)\nPayload \nPayload  (28B)\nOperator (4B)\nPayload  (28B)\nOperator (4B)\nOperand\nOperand\n8 Slices\n64-bits (8 Octets)\nFigure 2.8: 2 × 4 slice Flow Transactions\nYou can also mix them in the same frame, but remember, they can\nonly be used for One-Phase-Commit (1PC) in a single stream of trans-\nactions. This is because 1PC requires only one \"round trip\", whereas\n2PC requires two round trips (although this scheme can be made to\nwork for 2PC, and perhaps 4PC, but they have not yet been tested).\n2.1.8\nFour 2 slice Flow Transactions\nPayload  (12B)\nOperator (4B)\nOperand\nPayload  (12B)\nOperator (4B)\nPayload  (12B)\nOperator (4B)\nPayload  (12B)\nOperator (4B)\nOperand\nOperand\nOperand\n8 Slices\n64-bits (8 Octets)\nFigure 2.9: 4 × 2 slice Flow Transactions\n2.1.9\nEight one-slice Flow Transactions\n2.1.10\nMixture of different Flow Transactions\nPayload  (28B)\nOperator (4B)\nOperand\nPayload  (12B)\nOperator (4B)\nOperator (4B)\nPayload  (4B)\nOperator (4B)\nPayload  (4B)\nOperand\n8 Slices\n64-bits (8 Octets)\nFigure 2.10: One 8 slice Flow Sub Trans-\naction with 60B payload\n2.1.11\nLink Efficiency\nTable 2.1: Transaction efficiency by oper-\nator and operand size.\nFlows Operator Operand Efficiency\n1\n4\n4\n50%\n1\n4\n12\n75%\n1\n4\n28\n87.5%\n1\n4\n60\n93.75%\n2\n4\n4\n100%\n2\n4\n12\n150%\n2\n4\n28\n175%\n2\n4\n60\n187.5%\n4\n4\n4\n200%\n4\n4\n12\n300%\n4\n4\n28\n350%\n4\n4\n60\n375%\n8\n4\n4\n400%\n8\n4\n12\n600%\n8\n4\n28\n700%\n8\n4\n60\n750%\nopen atomic ethernet\n10\n2.2\nRISC Protocol Design: OPCODE (Information)\nOPCODE\nJAM\nPROTOCOL\nBEATS\nSLICE\nFigure 2.11: One Byte Provides the entry\npoint for an Entire family of Protocols\n2.2.1\nCONTEXT Frame format: First Slice, First Byte: OPCODE\n8SLICE\n11 -- TX Sender Init\n11 -- RX SACK 1 (8B)\n10 -- RX SACK 2 (16B)\n01 -- RX SACK 3 (32B)\n00 -- RX SACK 4 (64B)\n(SLICE, BEATS, PROTOCOL, JAM) provides state encodings for an\nultra-low-latency, hardware-friendly, and atomic transaction-friendly\nÆthernet protocol.\nSupports transactional operations, structured acknowledgments, and\nreversible flow control (causal backpropagation). Instead of positive-\nonly credits, the first hop receiver provides the equivalent of negative\ncredits, to indicate it is returning previously sent frames.\n4SLICE\n10 -- TX Sender Init\n10 -- RX SACK 3 (32B)\n01 -- RX SACK 1 (8B)\n00 -- RX SACK 2 (16B)\n2SLICE\n01 -- TX Sender Init\n01 -- RX SACK 1 (8B)\n00 -- RX SACK 2 (16B)\n1SLICE\n00 -- TX Sender Init\n00 -- RX SACK 1 (8B)\n2.2.2\nnSLICE\nOn cables shorter than the occupation\ntime on the wire, slice acknowledges are\nsent before the receiver sees the whole\nframe – exploiting full concurrency on\nthe transmit/receive channels.\nSet by the Sender to[00] – indicating a new context.\nModified by the receiver Closing the loop: [11]→[10]→[01]→[00]\nEncodes how many slices of the sender’s 64-byte Frame has been\nreceived so far. A 2-bit field with reversed temporal direction to encode\nthe acknowledgment depth in a power of 2 number of slices. This might\nrepresent the trailing edge of a window in a reversible or partially\ncommitted state machine. The naming “SACK” suggests slot or slice\nacknowledgments, as fine-grained positions in the interaction.\n2.2.3\nBEATS\nBEATS\n00 -- TX 1 FRAME (64B)\n01 -- TX 4 FRAMES (256B)\n10 -- TX 16 FRAMES (1024B)\n11 -- TX 64 FRAMES (4096B)\n00 -- RACK 1 FRAME (64B)\n01 -- RACK 4 FRAMES (256B)\n10 -- RACK 16 FRAMES (1024B)\n11 -- RACK 64 FRAMES (4096B)\nEncodes burst sizes TX (forwardproaga-\ntion) and RX (backpropagation) code to\nframe groupings, enabling optimization\nof bandwidth and latency trade-offs.\nDefines a beat-structured flow control mechanism. Sender declares the\nnumber of frames it plans to send advance. The receiver responds with\na corresponding \"slot acknowledgment\". Aimed at reliable, ordered\ndelivery without the need for heavyweight TCP.\n2.2.4\nPROTOCOL\nPROTOCOL\n000 -- Initialization\n001 -- Liveness\n010 -- State Machines\n011 -- RESERVED\n100 -- RESERVED\n101 -- RESERVED\n110 -- RESERVED\n111 -- ESCAPE\nThis field defines the high-level intent of the frame or transaction, by\nthe sender (causal initiator). The 3-bit code is always in the first (con-\ntext) slice of the Frame. Three of the eight possibilities are defined\nin this specification. The remaining ones are reserved for higher level\nprotocols in this standard. Escape will always be available to escape to\nlegacy protocols. This compact opcode space (3 bits) is similar to what\nRISC architectures do. This simplifies logic at the NIC or SmartNIC\nlevel and allows for deterministic dispatch.\nJAM\nABORT/CANCEL\n2.2.5\nPRE-EMPT/JAM\nThe use of “JAM” evokes classic Ether-\nnet collision handling, but here it’s mod-\nernized for transactional cancellation or\nSet by TX to [0]. Set by RX to [0] to accept, and [1] to pre-empt, for\nerror, or to (cancel/rollback the transaction).\nopen atomic ethernet\n11\n2.3\nRISC Protocol Design: LIVENESS (Knowledge)\nProtocol\nLiveness\nState Machine\nTransition\nFirst Slice: CONTEXT (Packet Mission). All\nbits are green (owned and written by Alice)\n2.3.1\nBipartite Link\nThere are exactly two parties on the DAE Link. We could call them\nalice and bob. We prefer to call them self and not self. From Al-\nice’s perspective, she knows her own identify, but she does not know\nthe identity of the party she is communicating with (yet). We aim to\nachieve mathematical precision in our specifications. This will be im-\nportant when we wish to formally verify the scouting, routing, and\ncluster membership protocols. It will be critical also in formally veri-\nfying confinement properties of the trees above.\nThe encoding supports Intanglement (hidden circulating events in-\nternal to the link) and Extanglement (Atomic Token Passing through\nthe link (Newtons cradle). These protocols obey the mathematics of\nmutual information, and provides some of the properties of quantum\nentanglement, such as superposition, conservation of information, and\nno-cloning. We use these properties to provide our protocols with a\nclear notion of simultaneity (through the synchronization of mutual in-\nformation), and guarantee atomicity for transaction protocols through\nconserved quantities which in-turn guarantees exactly once semantics\n(EOS).\nConventional L2 & L3 networks rely on redundancy, repetition and\nrerouting, in multipartite (1:N) relationships.\nWhich was necessary\nwhen information is disseminated (transmitted blindly hoping the re-\nceiver catches it). When information can also be synchronized, by a\nTx/Rx—T/Rx loop on a bipartite Ethernet link, we can employ Pseudo\nEntanglement: A form of temporal intimacy, where bits shared in a\ncirculating frame can exploit the same mathematics, (but not the full\nquantum properties) of Entanglement. This insight allows us to en-\ngineer a clear notion of simultaneity, and exploit a classical version of\nthe no-cloning theorem to achieve the holy grail in distributed systems\nand database isolation: exactly once semantics.\n2.3.2\nLink Engine\nAlternating Causality (AC) is the name we give to the initialization,\nmaintenance and tear down of Common Knowledge (CK) in the Link.\nExperience with modern SerDes designs leads us to an 8 byte slice\narchitecture for a “minimum irreducible” CK protocol. Symmetry de-\nmands that we use half (4-bytes) for alice (what I know about me)\nopen atomic ethernet\n12\nand the other 4-bytes for bob (what I know about you). Three packet\nexchanges get us from initialization (both sides know nothing about\neach other) to the “I know that you know that I know” (IKT YKT IKT)\nequilibrium state for basic liveness.\nIt takes a while to gain an intuition\nfor this issue of causality, based on the\nphysics. For now, please accept that this\nis way of doing things is essential and\nenables a rich set of transaction types to\nbe built on top, all with immunity to link\nhazards.\nWe don’t use classical (increment only) clocks, counters, or timers in\nthe link. Instead, we use balanced ternary arithmetic [1] The digits of\na balanced ternary numeral are coefficients of powers of 3, but instead\nof coming from the set 0, 1, 2, the digits are -1, 0 and +1. They are\nbalanced because they are arranged symmetrically about zero.\nWe\nuse this symmetry to manage the direction of causality (is alice the\ninitiator of causal flow sending tokens to bob, or the receiver in causal\nflow receiving tokens from bob?). This becomes important as we go\nup the protocol stack and construct reversible subtransactions.\nWe extend the simple ternary arithmetic with plus and minus zero.\n-1,-0,+0,+1. This enables the protocol to differentiate between the posi-\nbits and negabits [2], with an ancilla control over the intended direc-\ntion of the next operation (positive or negative). This is used to control\nthe direction of the state machine when recovering from errors.\nIntanglement is enabled by reserving 4 bits in the frame for CK (2\nbits for Alice, 2 Bits for Bob). One message will let Bob know about\nAlice. A second message lets Alice know that Bob knows, the third\nmessage lets Bob know that Alice knows that Bob Knows, consistent\nwith both Moses and Halpern version of CK, and the Spekkens Knowl-\nedge Balance Principle (KBP). Time, inside the link moves forward\nwhen packets arrive. Time moves backwards when packets depart. It\ndoesn’t matter how many times a packet bounces around, time goes\nforward only when it is received by one end of the link and it stays (is\nabsorbed). Information is then turned into Knowledge.\nIn a similar way to two phase locking, Link CK can be extended\nfrom 2 Ternary bits (Trits) to any number. Since we are using 2 binary\nbits to encode one Trit, we posit that the set of 2-message exchanges\nto synchronize them is 1, 2, 4 and any multiple of 4. This observation\ndrives the encoding for the State Machine Engine, Described below.\nOur Protocol is based on Reversible Computing.\nProtocol\nLiveness\nState Machine\nTransition\nFigure 2.12: First Slice: CONTEXT. Least\nsignificant 32 bits of transmitted packet.\n2.3.3\nSlice Engine\nThe core of the Æ protocol is the Slice Engine. The first slice (or pre-\nframe slice) determines the packet mission, and carries the alternating\ncausality for the Link State Machine (LSM).\nEach 64-bit slice represents an atomic delivery of bits on the wire\nfrom the SerDes. Typically 2 slices will be sent back to back and the\nopen atomic ethernet\n13\nSlice Engine must be prepared to receive both, although the receiver\nmay decide to pre-empt the frame in its immediate response to the\nfirst slice if it wishes to immediately begin a real data or transaction\noperation. The second slice will be on its way, and its Error Detection\nByte must be evaluated before forwarding on other ports (with the\nexception of the port it was received on, which is the entanglement\nmechanism).\nLIVENESS (Knowledge)\nALICE\nBOB\nFigure 2.13: One Byte Provides\nKnowledge\nAlice Token\n8-bits\nBob Token\n4-bits\n4-bits\nAlice \nToken\nBob \nToken\n2-bits\n2-bits\nFigure 2.14: First Rewriting Rule. Alice\nOwns and possesses Context Slice\nThe first slice completely defines the rest of the frame. There are\n4 fields: PROTOCOL, LIVENESS, STATE, and TRANSITION. This is\n“reflected” from the upper half to the lower half by the receiver, so\nthat only the lower 32 bits are modified, and the upper 32 bits remain\nunmodified.\nThe PROTOCOL Byte defines the “mission” of the packet. What each\nside of the link needs the other side to know about the current frame.\nLIVENESS defines the Temporal Intimacy of the link — whether events\non both sides of the link are directly connected or not.\nSTATE Defines which state machine is currently in use. Can be used\nas a sanity check in conjunction with Protocol.\nTransition Defines\nwhich state in the state machine we are in, and which direction we\nare going (forward or reverse).\n2.3.4\nGeneral Principles\nLinks are constantly interacting, at the slice level, instead broadcast-\ning entire frames (or sets of frames) imposing on the other side and\nhoping they catch the bits. This provides opportunities for error detec-\ntion and correction that would otherwise require ECC and FEC. The\ntheory behind this is described in detail in the document “Shannon-\nInteraction-Machine”.\nThe first 4 slices are dedicated to Theseus (scouting protocols). The\npayload (slices 4-7) contain the Theseus Opcode and parameters —\ninstructions to the scout, including what to do if it encounters an ex-\nception (a software or hardware hazard).\nWhen the protocol type is Ariadne (groundplane/trees) the last 4\nslices (payload) contains tree-building instructions, such as the CellID\nof the originator, and the CellID of the Deputy (one hop away from\nroot). This becomes a complete specification for dissemination of the\ntree without unnecessarily revealing secrets which need to be kept\nlocal (confined).\nAnother protocol type is Icarus (legacy connections to the outside\nworld). This represents a more heavyweight protocol which provides\nopen atomic ethernet\n14\na formally verified TPI (Transaction Processing Interface), which pro-\nvides significant guarantees, but with costs.\n2.3.5\nGeneral Frame Format\nB1\nB2\nB3\nB4\nB5\nB6\nB7\nB8\nS1\nProtocol\nLiveness\nState Machine\nTransition\nProtocol\nLiveness\nState Machine\nTransition\nS2\nOperand 1 (2nd Slice)\nS3\nOperand 2 (3rd/4th Slice)\nS4\nS5\nOperand 3  (5th through 8th Slice)\nS6\nS7\nS8\nThis protocol is symmetric. We describe all operations from the per-\nspective of ALICE, with responses from BOB.\n2.3.6\nError Detection and Correction\nThe transmitted first (context) slice is reflected by the receiver back\nto the transmitter – this Perfect Information Feedback [Ref] means that\nthe context byte does not need additional error detection codes such as\nChecksums, CRC or FEC. This is especially true with flow transactions.\nHowever, the rest of the payload is under the complete control of\nthe application, and the Application can append (within the available\nblocks) any coding scheme it wishes to ensure that the data arrives in-\ntact and untampered with. This will often mean that the senders and\nreceivers will have pre-arranged cryptographic keys which allow them\nto manage the entropy and cryptographic strength of the authentica-\ntion.\n2.3.7\nNo EDC or FEC\nEach side of the link maintains two EPI (epistricted) registers : the last\nSee Quantum Ethernet\nslice sent out, and the last slice received. The sender “owns” the lower\n32 bits, and preserves the upper 32 bits. When slice 1 is received, the\nupper 32 bits are swapped with the lower 32 bits. This preserves the\nsymmetry of the protocol, and clearly delineates the causal initiator\nregister field ownership in addition to causal ownership.\nopen atomic ethernet\n15\nThis provides the first level of error detection: the Initiator has Per-\nfect Information Feedback (PIF) and sees. exactly what the receiver\nsees, and compare it to what was sent, And if they don’t agree, declare\nan error and proceed with mitigations to get the link back in sync\nagain.\n2.3.8\nEpistricted registers\nImagine two vectors [abcd] one for Alice and one for Bob. A 4 x 4\nmatrix has 16 slots, which has 216 = 65, 535 possible states. However,\naccording t o the Spekkens Toy model applied to FPGA Registers, there\nare only 12 ’disjoint’ (6 for Alice and a complimentary 6 for Bob).\nInstead of trying to build a EDD/EDC code, we check only the disjoint\nstates by combining them into one register and sending them back and\nforth in the context frame.\n2.3.9\nOVERVIEW\n2.3.10\nProtocol Overview\nTRANSACTION FABRIC: A separate compute realm, sandwiched\nbetween the CXL bus and Ethernet, to support database semantics.\nWe eliminate CAP Theorem tradeoffs, by providing the illusion of\nan unbreakable network: detecting, isolating and healing failures\nfar faster than protocol or application stacks using traditional time-\nouts and retries.\nTHESEUS: Ethernet-based scouting protocols explore local environ-\nments to discover and bring back knowledge of resources, con-\nstraints, and topologies in local (Chiplet) environments. THESEUS\nsilently monitors local connectivity, raising alerts when links be-\ncome flakey or server software hiccups.\nARIADNE: Ethernet based routing protocols dynamically construct\nand tear down communication graphs for consensus, load balancing\nand failover in global (rack-scale) environments. Enables: observ-\nability on demand, fault isolation and distributed debugging.\nICARUS: Connects the secure internal world of the Transaction Fab-\nrix with the hostile external world of legacy systems and networks;\nusing compositional (zero knowledge) techniques: formally verified\nAPIs, comprehensively tested implementations.\nLABYRINTH: A simulator driven toolset for Chiplet based micro-\ndatadatacenters.\nBased on algorithms whose assumptions about\ncausality go beyond simplistic notions of time. We empower dis-\ntributed system developers with formally verified rules and FPGAs\nto execute Reversible Subtransactions ‘invisibly’ and ‘indivisibly’ in\nopen atomic ethernet\n16\nthe Transaction Fabrix.\n3\nCells and Links\nCELLs and LINKs are fundamental elements. LINKs are bipartite causal\nrelationships connected over physical cables (backplanes, coax, fiber).\n3.1\nCells\nA CELL is not merely a general-purpose computer. It is a reactive, self-\ncontained participant in a global program. Each CELL holds local state,\nexecutes transactions, and engages in atomic communication with its\nneighbors. It participates in reversible protocols, encodes causal histo-\nries in state transitions, and makes decisions based on local informa-\ntion while remaining consistent with a global ordering.\nCELLs maintain a timebase, manage a local execution queue, and\nprocess both incoming transactions and local tasks. Their execution\nmodel is event-driven and transactional, but grounded in physical\nlinks—each CELL ’s “world” is bounded by the links it can reach.\nCrucially, CELLs are interchangeable.\nThere is no distinction be-\ntween a compute node, a storage node, or a network switch. Each\nCELL contains a portion of all three. The specialization comes from\nprogrammatic configuration and emergent behavior, not fixed hard-\nware roles.\n3.1.1\nFailure Modes\nCELLs fail in bounded ways. The execution environment guarantees\nthat failure is:\n• Local: A failing CELL does not compromise its neighbors.\n• Detectable: Liveness and responsiveness can be externally verified\nthrough link activity and expected transactions.\n• Reversible: As much as possible, computation and state changes\nat a CELL can be rolled back or isolated through transaction lineage\nand local journaling.\nopen atomic ethernet\n18\nFailures may be:\n• Crash-fail: power loss, watchdog-triggered resets, or thermal shut-\ndowns.\n• Byzantine: misbehavior due to bitflips, radiation events, or mali-\ncious actors.\nThese are constrained by cryptographic and causal\ntransaction tracking.\n• Soft: overloaded slots, or clock skew outside tolerances.\nThe system design assumes failure. What matters is how neighbor-\ning CELLs detect, isolate, and route around the failure using only local\nknowledge.\n3.2\nLinks\nA LINK is a bidirectional tunnel-element; an autonomous communica-\ntion entity between two CELLs. Think of LINKs as compute elements\nwith their own autonomous and independent failure domain. Physi-\ncally, the LINK comprises the cable and SerDes’ on both ends to form a\nself contained execution environment.\nLINKs are autonomous in that they maintain state: pending trans-\nactions, reversibility buffers, sequence tracking, and retry logic. They\nmediate causality between two CELLs and enforce atomic delivery guar-\nantees over physical media that may be noisy, lossy, or delayed.\nA healthy LINK behaves like a lock-free memory bus: it transmits\nevents, ensures ordering, and preserves invertibility for transactional\nsafety. But unlike a memory bus, it must contend with delay, noise,\nand the limits of the speed of light. Its job is to conceal those imper-\nfections behind a deterministic, reversible interface.\nLINKs are not passive – they can be reset, throttled, or even repro-\ngrammed in the field. They may expose telemetry, accept diagnostic\npings, or reconfigure modulation in response to environmental condi-\ntions.\n3.2.1\nLink Utilities\nPhysical LINKs Implement utilities that used to be in logical link do-\nmains above L2: in L3, L4, or L7; composed into an abstraction of\nlogical links. This is an illusion. If the pairing of Shannon information\nis thrown away at layer 2, it cannot be recovered in higher layers. This\nis addressed in more detail in the Key Issue section below.\nAn example1 LINK utility is The I Know That You Know That I Know\n1 Synchronization of timing domains in\ncomputers generally start from the pro-\ncessor clock on the motherboard, and\nfan out through the logic into the I/O\nsubsystems.\nIUI lives in the LINK be-\ntween two independent computers, and\nalthough it receives information from ei-\nther side, it is not synchronized with\neither side.\nThis independent asyn-\nchronous domain (already exploited in\nthe HFT Industry) – enables failure in-\ndependence and atomicity.\n(TIKTYKTIK) property; which enables us to address some of the most\ndifficult and pernicious problems in distributed systems today.\nopen atomic ethernet\n19\nAnother example LINK utility is Indivisible Unit of Information (IUI).\nUnlike replicated state machines (RSM’s) used throughout distributed\napplications today, LINKs are state machines: the two halves of which\nmaintain shared state through hidden packet exchanges. When a lo-\ncal agent or actor is ready, theIUI protocol transfers indivisible tokens\nacross the LINK to the other agent, atomically (all or nothing) 2.\n2 LINKs are exquisitely sensitive to packet\nloss.\nThis is intentional: we turn the\nFLP result upside down, and use “a single\nunannounced process death” to guaran-\ntee the atomic property forIUI.\nTIKTYKTIK and IUI properties are mathematically compositional.\nWhat’s necessary is an entanglement between state machines – lock-\ning them together silently in normal operation, and failing locally at\nthe first failure. The entanglement cannot be recovered if information\nfrom events can disappear. This is the only solution to the problem in\nthe latency–disconnection ambiguity [Ref: CAP Theorem Tradeoffs].\nTo put it in terms an engineer can internalize, a system that fails in-\nstantly, can heal immediately.\n3.2.2\nFailure Modes\nThe shared state property is strengthened by mechanisms to recover\nfrom each type of failure. The more types of failures, the more com-\nplex and intractable this becomes. LINKs are independent failure do-\nmains, with (effectively) one failure hazard: disconnection 3; which is\n3 In any physical system it is possible\nto drop packets, it will be much rarer\nbut it is still possible. LINKs can recover\nfrom individually dropped or corrupted\npackets, and shared state integrity can be\nmaintained through out the successive\nreversibility recovery – back to the equi-\nlibrium state.\nstraightforward to recover from.\n3.3\nInitial Discovery\nFigure 3.1: A Link yet to be discovered,\nor a flakey link that need to be repaired\nCELLs discover connections ∃xist on each of their ports. For connections\nthat once existed (which may have been remembered from previously\nbeing powered up), we will find it impossible to tell whether we are\nbeing woken up for the 1st time, or the Nth time*.\n*Sleeping Beauty paradox: Veritasium:\nThe Most Controversial Problem in Phi-\nlosophy\nAlice and Bob have no knowledge of each other prior to being pow-\nered up for the first time. They discover each other by sending and re-\nsponding to BEACONs on each of their 8 ports {n, ne, de, se, ds, sw, dw, nw}.\nBEACONs are questions: “is anyone there?” They assume neighbor CELLs\nhave SerDes’ that can send & receive @ 25Gb/s (defined by local clocks,\nin their frame of reference). Photon cavities (copper and fiber) are ex-\npected to be in a fixed frame of reference relative to the SELF CELL.\nMobile entities may need to adjust this expectation based on the range\nof doppler shifts expected by CELLs in motion, for example, in moving\nvehicles, cars, planes, and spacecraft.\nAlice sends BEACONs with an exponential backoff: every 1µs, 2µs,\n4µs, 8 µs, etc. The policy for a maximum interval is determined by the\nenvironment, e.g. within a datacenter, one might wish to send BEACONs\nopen atomic ethernet\n20\nevery second, whether you need to or not. This represents a balance\nbetween infrastructure liveness and needless energy dissipation.\nSingle Links are subject to partial or total failure.\nAlthough net-\nworks use the word ‘partition’, for example in the CAP Theorem?, this\nconcept is inappropriate except in the single LINK case, when there’s\nno communication with the other side; the causal universes** are now\n**Quantum Compatible Interpretation\nisolated from each other.\n3.4\nIt takes Two to Tango, and Three to Party\nBecause a single link between Alice and Bob can be causally dis-\nconnected by real-world, permanent or intermittent failures, an alter-\nnative: statistically–independent–failure–path is necessary, to recover\nfrom LINK Failures. This is the heart of the Æ ATOMICITY claim: A local\n(one hop LINK) TRIANGLE is the minimum necessary. See TRIANGLE\nClocks later in this specification.\nFigure 3.2: It takes three to party. Links\nneed an alternate path. This won’t work\nover a Switched (Clos) Network.\nFigure 3.3:\n2 x 2 =4 connected nodes\nwith 6 flakey LINKs. Any one of which\nmay be working in both directions: {11},\nonly one direction: {01} or {10}, or not-\nworking in both directions: {11}.\nFor\n4 nodes, there are\n(n(n−1)\n2\n= 6.\nWith\n4 reliability configurations on each LINK\n{00, 01, 10, 11} This gives us ONE correct\n(all links working correctly) and 46 −1 =\n4095 possible failure modes.\n3.5\nFault Detection Model\nBenefits include (i) Shorter packets and\nmore effective use of bandwidth, (ii)\nmore complete coverage of possible fail-\nure modes. (iii) Guarantees at least the\nfirst slice is perfect (matches what the\ntransmitter knows they sent).\nAE-Links present two major differences to the conventional FEC think-\ning in today’s Ethernet, which exploits the physics from 25Gb/s to\n1.6Tb and beyond:\nPerfect Information Transfer (PIF) Æ-Links use Back-to-Back (B2B) Shan-\nnon Links, where the receiver returns the first 8-byte slice of each\n64-Byte packet to the transmitter. This “here is what I heard you\nsay\" ( Perfect Information Transfer (PIF)?\nEpistricted Registers (EPI) Borrowing from the Spekkens’ toy model for\nquantum entanglement, we narrow down the possible entangled\nstates to a vastly smaller set of possibilities, using the model de-\nscribed in Quantum Ethernet?.\n3.6\nFailure Model\nConsider a network of n nodes connected by undirected Ethernet links.\nEach link can be in one of four independent reliability states, where\nΣ = {00, 01, 10, 11},\n11 means the link works in both directions, 10 or 01 means it works in\nonly one direction, and 00 means it is broken in both directions.\n3.7\nLink count\nBecause every node may attach to at most eight neighbours (an octava-\nlent mesh), the number of physical links is\nL(n) = min\n\b(n\n2), 4n\n\t =\n\n\n\n(n\n2),\nn ≤9,\n4n,\nn ≥9.\nopen atomic ethernet\n21\n3.8\nReliability configurations\nEach link chooses a state from Σ independently, so the total number of\nconfigurations is 4 L(n). Exactly one of these is fully healthy (all links\nin state 11), hence\nFailureModes(n) = 4 L(n) −1.\n3.8.1\nEnumerated results for 2 ≤n ≤20\nn\nL(n)\nFailure modes 4 L −1\n2\n1\n3\n3\n3\n63\n4\n6\n4 095\n5\n10\n1 048 575\n6\n15\n1.074 × 109\n7\n21\n4.398 × 1012\n8\n28\n7.206 × 1016\nTable 3.1: Failure-mode counts for an oc-\ntavalent mesh with n nodes.\n3.9\nSet Reconciliation of Shannon Slots\nThe first claim is that a finite and enumerable number of ‘slots’ exist\non both sides of the LINK. In conventional Ethernet, once these slots\nare exhausted (with for example, a timeout and retry, the XPU CELLS\n(SmartNICs) on both sides of the LINK must evict (erase) the infor-\nmation on one side and then the other. This ‘loss of Koherence’ is the\ncentral problem of Distributed Systems. From an information theoretic\n(Back to Back Shannon channel) perspective, this precipitates a ‘smash\nand restart (SAR) of the Shannon Information – the loss of ‘pairing’\nof information. This is described in more detail in the specification of\nback-to-back Shannon Pairs.\nTimeouts and Retries are the root of all evil. Once a Timeout Storm\noccurs, in a switched network, the distributed systems in the Host pro-\ncessor are all broken. Unless RELIABILITY (maintenance of Shannon\nLink Pairing), the ‘global’ illusion of event ordering in distributed sys-\ntems will be lost, and corruption will occur. This is why queue-pairs\nwork in Infiniband/RDMA. This is why information pairing is essen-\ntial, in Tandem’s Process Pairs, and RDMA’s Queue pairs.\nThe whole point of this specification is to engineer a solution, where\nShannon-pairing is never lost, but if it is, a TRIANGLE healing occurs\nlocally, without the need to depend on a switched or router to discover\nand ‘reconverge’ their routing tables, to re-establish the point to point\nconnections over a different paths in the network.\nThe main mechanism to do this is to make the Æthernet Link main-\ntain Koherence, and when loss occurs, a 3rd party (The Triangle rela-\ntionship) can recover with local information only. This makes XPU/S-\nmartNICs, where the recovery algorithms (healing the tree) occur lo-\ncally, instead of waiting for the switched or routed packets (in a sepa-\nrate switched network.\nThe original Ethernet was unreliable. This was a mistake. Infini-\nband already proved this, and succeeded both in the trust system\narchicitcts have in the far greater. The unique contributions of this\nopen atomic ethernet\n22\nspecification is to go (far) beyond Infiniband’s discovery, and recog-\nnize the fundamental simplifications and benefits that Infiniband (and\nToken Ring, Fibrechannel, and Sonet), in creating ‘Race-Free’ proto-\ncols, where distributed systems can guarantee, not just the ‘ordering\nof events’, but the guarantee of recovery of transactional loss in when\nfailures occur in the middle of, say, a 2 Phase Commit.\nÆthernet (Atomic Ethernet) guarantees that Shannon Pairing is never\nlost, and if a link breaks, that the Coordinator (Charlie, Carol, Chief)\ncan recover with TRIANGLE Relationships, far faster than any proto-\ncol stack in the host processor, or in the RMDA message relationships,\nbut then add, on top of this a true ‘atomic’ relationship between CELLS\n(nodes) in a distributed system.\nThe original Ethernet [ref] was designed around a notion of slots.\nThese were ‘time slots’ on an imaginary timeline that each node on\nthe Ethernet Cable, could manage in a half-Duplex way.\nThe new\nnotion is to replace this with circulating tokens, where each slice is\nindependently acknowledged, providing a guarantee of delivery to\nthe NEXT hop in the network.\nThis is achieved with 1PC (one phase commit), where each Ethernet\nPacket (eight slices) are fully acknowledged in each link. The general-\nization of this is to explicitly manage Shannon slots (data structures on\neach side of the link) to maintain Koherence, even when the link fails\n(in one direction, the other direction, or in both directions at once).\nThis can be done (as in Fibrechannel) by arranging the ‘interaction\nprotocol’ to guarantee the pairing of events, and not resort to Timeout\nand Retry (TAR), which causes cascade failures in networks, both large\nand small.\nThis is achieved with the Link Protocol employing the Alternating\nBit protocol, and adding the Bill Lynch ABP reconciliation, with two or\nmore bits instead of the individual 1 bit of alternation, which required\na round trip to guarantee Shannon Slot Pairing.\n3.10\nFAQ\nQ1 (Alan) What problem are you addressing in the scouting writeup?\nIf it’s discovering routes, it’s not clear to me that ant or bees or even\nboth together do full discovery of the network. In what way are they\nbetter than the flooding algorithm I used?\nA1 This is how to achieve ‘Scale-Independence’ We eliminate the\nneed for every node to do a ‘full discovery’ of the network, which is\nwhat a flooding algorithm would do. ANTs and BEEs explicitly do not\nopen atomic ethernet\n23\ndo “Global\" routing. This is an extra way to limit the size of the secure\nenclave, and not have it able to connect to the outside world.\n4\nReversible Transactions\n4.1\nMathematical Foundations\nIn low-latency, high-throughput Layer 2 environments (e.g., Ethernet\nlinks), it’s useful to model transactions as mathematical operations that\ncan be precisely undone. This enables rollback, audit, and error recov-\nery without heavyweight protocols.\n1. Model data as vectors.\nEach Ethernet frame is viewed as a vector in GF(2)n, treating bits\nnot as opaque payload but as elements in a vector space over a\nfinite field.\n2. Transactions as invertible operations.\nThe sender and receiver maintain a shared state S ∈GF(2)n. A\ntransaction is an invertible linear transformation T applied to that\nstate: S′ = T(S). Because T is invertible, the original state can\nalways be recovered via T−1.\n3. Reversibility via state updates.\nTo reverse a transaction, one sends a message (or derivable sig-\nnal) allowing the application of T−1. This guarantees deterministic\nrollback.\nWe consider a chain of N + 1 nodes labeled A0 →A1 →· · · →AN,\nwhere each node Ai maintains a local state vector Si ∈GF(2)n, typ-\nically initialized to the all-zero vector 0n or some other agreed-upon\nstate. Each link (Ai →Ai+1) between adjacent nodes is associated\nwith an invertible linear transformation Ti,i+1, which governs how\nstate updates propagate along the chain.\n4.1.1\nForward Execution\nTo execute a transaction spanning all links:\n1. At each hop i, node Ai applies Ti,i+1 to its state Si and transmits\nthe transformation to Ai+1.\nopen atomic ethernet\n26\n2. Node Ai+1 applies the same Ti,i+1 to its own state Si+1, maintaining\nlink-local consistency.\nThe result is a chained sequence of transformations:\nS′\ni = Ti,i+1 · Si\nfor i = 0, 1, . . . , N −1,\nS′\nN = TN−1,N · SN.\n4.1.2\nRollback (Reverse Direction)\nReversibility is achieved by applying the inverse transformations in\nreverse order:\n1. Node AN applies T−1\nN−1,N to revert S′\nN to SN.\n2. It signals node AN−1, which applies T−1\nN−1,N and then T−1\nN−2,N−1,\nand so on.\n3. This continues up the chain until A0 applies T−1\n0,1 , restoring the\noriginal S0.\n4.1.3\nExample: XOR-Based Masks\nIf each Ti,i+1 is a simple XOR with mask ∆i,i+1, then:\nSi 7→Si ⊕∆i,i+1,\nSi+1 7→Si+1 ⊕∆i,i+1.\nReversing just involves reapplying the same mask due to ∆⊕∆= 0.\n4.1.4\nNotes on Synchronization\n• Acknowledgments: Each node should confirm that the next node\nhas applied its transformation before committing its own.\n• Composite View: The full transaction across N links is a composi-\ntion:\nTtotal = TN−1,N ◦TN−2,N−1 ◦· · · ◦T0,1.\n• Error Handling: Any failure in transmission or transformation must\nbe detected early, as desynchronization across nodes can compound.\nRedundant encodings, checksums, or commit/abort protocols may\nbe used.\n4.2\nAtomic Transactions on Æ-Link\n4.2.1\nOne-Phase Commit\n4.2.2\nTwo-Phase Commit\n4.2.3\nFour-Phase Commit\n4.3\nFlow Control and Backpressure\n4.4\nTransactions on Trees\n5\nArchitecture\n5.1\nSlice Engine Design\n5.1.1\nTwo independent Metcalfe Channels (Max flow, no Interaction)\nPipelined, No interaction\nETHERNET TX\nETHERNET RX\nRX SERDES\nTX SERDES\nTX SERDES\nRX SERDES\nRX SLICE 1\nRX SLICE 2\nRX SLICE 3-4\nRX SLICE 5–8\nCOMPLETE\nTX SLICE 1\nRX SLICE 2\nRX SLICE 3-4\nRX SLICE 5–8\nBEGIN\nRECEIVE PIPELINE\nTRANSMIT PIPELINE\nTRANSMIT PIPELINE\nRECEIVE PIPELINE\nTX  SLICE 1\nTX SLICE 1\nTX  SLICE 2\nTX  SLICE 3-4\nTX SLICE 5–8\nBEGIN\nRX SLICE 2\nRX SLICE 3-4\nRX SLICE 5–8\nCOMPLETE\nTwo Independent One-Way Metcalfe Channels\nFigure 5.1: Two Independent Metcalfe\nChannels\n5.1.2\nInternal (SACK) Feedback on last slice\nFeedback signal on 8th slice of frame\nETHERNET TX\nETHERNET RX\nRX SERDES\nTX SERDES\nTX SERDES\nRX SERDES\nRX SLICE 1\nRX SLICE 2\nRX SLICE 3-4\nRX SLICE 5–8\nCOMPLETE\nTX SLICE 1\nRX SLICE 2\nRX SLICE 3-4\nRX SLICE 5–8\nBEGIN\nRX SLICE 1\nTX SLICE 1\nRX SLICE 2\nRX SLICE 3-4\nRX SLICE 5–8\nBEGIN\nRX SLICE 2\nRX SLICE 3-4\nRX SLICE 5–8\nCOMPLETE\nSACK8\nFigure 5.2: Feedback signal on slice 8\nopen atomic ethernet\n28\nFeedback signal on 1st slice of frame\nETHERNET TX\nETHERNET RX\nRX SERDES\nTX SERDES\nTX SERDES\nRX SERDES\nRX SLICE 1\nRX SLICE 2\nRX SLICE 3-4\nRX SLICE 5–8\nCOMPLETE\nTX SLICE 1\nRX SLICE 2\nRX SLICE 3-4\nRX SLICE 5–8\nBEGIN\nRX SLICE 1\nTX SLICE 1\nRX SLICE 2\nRX SLICE 3-4\nRX SLICE 5–8\nBEGIN\nRX SLICE 2\nRX SLICE 3-4\nRX SLICE 5–8\nCOMPLETE\nSACK1\nFigure 5.3: Feedback signal on slice 1\n5.1.3\nInternal (SACK) Feedback on first slice\nSee SACK description by Sahas ?\n5.2\nArchitectural Framework: Four Shannon-like\nLevels\nIn the proposal for subdividing a 64-byte packet into 8-byte slices, we\nintroduce partial acknowledgments (SACKs) at four (decrementing)\nboundaries (11, 10, 01, 00). Each of these points reveals an incremen-\ntally deeper level of the receiver’s certainty about the data, the hard-\nware, and the appropriate next step in the protocol. We can interpret\nthis progressive certainty in terms of four conceptual layers reminiscent\nof Shannon’s information theory, but extended to address knowledge,\nsemantics, and understanding. This layering describes how a receiver\n(e.g., the SmartNIC) transitions from raw incoming bits to meaningful\nmessages that can be handed off to the host processor.\nBack-to-Back (B2B) Shannon Channels\nare “Perfect Information Feedback” (PIF)\nas senders see their own transmitted\npacket returning back from the receiver\nand thus can detect channel errors. Thus\nmaking CRCs Checksums, Parity and\nFEC unnecessary. Similar to \"Perfect In-\nformation Feedback\" in: Norm Abram-\nson, “Packet switching with satellites,”\nNCC, 1973\n5.2.1\nLayer 1: Information (Surprisal)\nAt the first level, information refers to the direct \"yes/no\" answer to a\nquestion of interest: the arrival or non-arrival of bits, which Shannon\nfamously treated as the surprisal of a received symbol. At the SACK 00\nboundary, when the receiver detects the first 8-byte slice without error,\nit learns that the link is alive and that the data matches expectations\n(i.e., no immediate mismatch).\nThis is pure information because it\ndistinguishes the event \"we did receive slice #1 correctly\" from \"we did\nnot.\" The mutual information gained here confirms a working cable\nand a functional SerDes.\nAt this early stage, the question posed is binary: \"Did the hard-\nware see valid bits?\" The surprisal is that valid bits were received, as\nopposed to no signal or corrupted data.\n5.2.2\nLayer 2: Knowledge (Captured Information)\nThe second layer, knowledge, arises when the raw bits are stored or\ncaptured in a meaningful structure. This could be as simple as a recog-\nnized slice stored in buffer memory or a pipeline register. By the time\nopen atomic ethernet\n29\nthe second slice arrives, the receiver has captured more bits—16 bytes\nin total—and placed them into NIC-internal registers. It can then per-\nform further checks, such as alignment, partial CRC, or checking for\nexpected header fields. The SACK 01 confirms that the hardware not\nonly saw valid bits but also placed them in the correct buffer location.\nAt this point, the system has a partial understanding of the data.\nIt knows that the 16 bytes are recognized and safely stored, awaiting\ndeeper logic to interpret them.\n5.2.3\nLayer 3: Semantics (Meaning)\nThe third layer, semantics, involves the system deciding what the bits\nmean in terms of subsequent action. This layer determines which state\nmachine or processing path is relevant for the given data. At the SACK\n10 boundary, after 32 bytes have been received, the NIC has gathered\nenough information to partially decode the data. For example, it might\nbe able to determine which protocol or message type is indicated. The\nNIC can confirm that buffer slots or ring descriptors are available and\nthat the correct state machine is loaded (e.g., state machine A for small\ncontrol frames, or state machine B for streaming payloads).\nOnce the NIC signals SACK 10, the sender learns that the hardware\nhas found the data coherent enough to continue. The semantics are\nrecognized sufficiently to proceed without hazard. The receiver has\nnow moved from simply knowing the bits are correct (Layers 1 and\n2) to understanding how to proceed and which internal resources or\nstate machines to activate.\n5.2.4\nLayer 4: Understanding (Syntax)\nThe final layer, understanding, refers to the recognition that the mes-\nsage fits into a finite set of concepts or message types that the NIC\naccepts. This implies that the message has a correct syntax recognized\nby the hardware. At the SACK 11 boundary, which occurs when slices\n5–8 arrive, the full 64 bytes have been received and match a legitimate\nframe or message layout. The NIC is now ready to push the message\nonto the PCIe bus or an internal ring buffer for the host processor.\nAt this stage, the NIC has a full understanding of the message,\nknowing exactly how to finalize the packet, classify it, and pass it\nupstream for higher-level processing. No further layer-2 repairs are\nneeded, and the message is ready for the next step in the protocol.\n5.3\nShort-Range ANT (Local) Scouting\nOnce a link has been established, they are recorded in the local knowledge\nof the cell, and used as a baseline for future algorithmic and policy de-\nopen atomic ethernet\n30\ncisions.\nImmediately after establishing a reliable connection, CELLs may emit\nANT-SCOUTS to explore their local environment. These are ANT’s, which\nobey an initial source routing algorithm, but when encountering a\nfailed or disconnected port in another cell, respond with either clock-\nwise, anticlockwse packet forwarding, which keeps the scout local, or\nrandom, with a hopcount limit, which allows exploration further afield.\nSee ANT Specification for details\n5.4\nLong-Range BEE (Global) Scouting\nCELLs may also emit BEE-SCOUTS to explore the extremities of their\nenvironment. These are BEE’s which obey only one rule: proceed in\nthe same direction as the radial port. BEE’s emitted on the n port may\nonly go n. BEEs emitted on the se port may only go se. Until they\nencounter a disconnected port, whereupon they execute a return path\nalgorithm, accumulating information at each CELL and returning it to\nthe root.\nSee BEE specification for details\n5.5\nANT Specification: Triangle Packet Clocks in\n3 × 3 Tiles\nFigure 5.4: Race-Free Triangle Token\nPacket clocks are initiated by the coordinator, on any of it’s active links.\nThe ANT (source routing) algorithm goes out on any port, and are\nprogrammed to turn left or right at the first available active port. The\nconvention is turning right makes it go clockwise, and turning left\nmakes it go antilockwise, but this is an artificial distinction. As with\nreal ants, they can get lost, and never find their way back to the nest,\nand they die (or return to the nest by inverting their source routing\npaths). This “limited range”, is part of the Security mechanism.\n5.6\nANT Specification: Race-Free Packet Clocks\nin 3 × 3 Tiles\nFigure 5.5:\nSquare Race-Free 1-hop\nClock\nOnce the cell has discovered it’s local environment, it may establish\npacket clocks. These are ANTs, which go out with a pre-defined pat-\ntern, to return events the cell on a periodic basis. Because there is no\nbackground of time, this system will create events, which are guaran-\nteed to occur without race conditions, but will catastrophically fail if\nthere are an broken links around the circuit.\nPackets clocks may be initiated around the closest (one-hop) cell\ntiles, next closest (two-hop) tiles, furthest (three-hop) tiles. Atomicity\n5.6.1\nANT Specification Building a Compass Clock\n8 physical ports per cell. Inactive ports may be:\nopen atomic ethernet\n31\n• Failed (out of service)\n• Standby, ready to go\n• Off, saving energy\n5.6.2\nANT Specification: Counter Circulating Race-Free ANTS\nC (Carol, Charlie, Coordinator, Chief) may initiate clockwise, counter-\nclockwise, and/or both at once. Each is exploring the health of the\nconnectivity local to the center cell.\nThis is what ANT Algorithms\n(source routed, or random) tokens.\nPorts at edge of mesh connected back to same cell on a different\nport to traverse routing table 2nd time to create virtual cut-through\ntorus.\nIf the ANT gets blocked, and either runs out of hopcout resource, it\ndoes ‘reverse path forwarding’ back to the C CELL. and reports what\nit finds. It can either carry all its state in the packet, or (ror BEEs),\nclean up on its way and erase its footprints in the CELLs it visited.\n5.6.3\n7 x 7 Nodes Packet Clock\nFigure 5.8: Green Packet Rateless Clock\n5.7\nBeyond Packet Clocks\nPacket clocks don’t scale (they are not intended to). Instead, they pro-\nvide circulating logical loops ?. The local system policy will establish\nthe radius limit for local exploration. Everything beyond that is in the\ndomain of the BEE scouts .\nPacket clocks can circulate at any physical hop distance. The one-\nhop agents are described above. The two figures on the right show an\nexample of an ANT which goes two hops, or three hops, before the\nANT turns left or right. This give a CELL the opportunity to explore\nlarger hop distances from the coordinator\n5.8\nPacket Clocks in Larger Tiles\nFigure\n5.9:\n3rd-hop\ncircular\npacket\nclocks. Blue Links Complete\n5.8.1\nBEE scouts\nBEE Scouts explore the boundaries of their environment. The are emit-\nted by the Coordinator, and travel as far as they can in ONE direc-\ntion, {dn,ne,de, se, ds, sw, dw, nw}, and then return on the recipro-\ncal path (Compass-Point vector direction) to inform the hive (root) what\nthey discovered, so the root can build it’s model of the topology, and\nEdge resources to perform their function.\nopen atomic ethernet\n32\n5.8.2\nN x N Nodes Packet Search Rays (BEEs)\nBEEs are radial distance scouting agents. Single packets that go in\nonly one direction, and when they reach the end (extremities of the\nCellular interconnect) they execute a reverse path forwarding algo-\nrithm, collecting knowledge on their way, delivering this knowledge\nback to the root, whose agent uses the returned information to build\nit’s model of it’s topology and available resources to offer ‘services’ to\nthe applications.\nThese don’t have to be square, or rectangular. BEE algorithms work\non any arbitrary Topology.\nFigure 5.10: BEE Algorithms explore be-\nyond ANT algorithms\nRadial (Ray) source-routed scouts have two parameters (a) which\nport they go out on, and continue indefinitely until they reach a bound-\nary (or exhaust their hop count resource). And then they return along\nexactly the same path, accumulating knowledge of the CELLS on their\nway (e.g. properties of the cell, do they have a CPU, a GPU, an IPU, or\nQPU?). Most Bees make it back home to the nest (C) but it is also pos-\nsible for a failure to occur between the outbound BEE and the home-\nbound BEE. In which case the packet try’s to make it’s way to ‘Lost and\nFound’, the control structures identified by the Coordinator to provide\nGEV notification of failures. Lost and Found is most likely to be dis-\ncovered by the one or more of the BEEs. Edge nodes (on the corners\nof the interconnect), will always be able to ‘find’ Lost and Found (and\nother external control paths controlled by monitoring or configuration\nLOGICAL Administrator Agentss ) with a ‘due north or south’ dn,ds,\n‘due-east or west’ de,dw BEE Scout.\n5.9\nLocal decisions and emergent global organi-\nzation\n• Scouting/Discovery Phase: Biologically inspired methods (e.g., ant-\ncolony-inspired or pheromone-based algorithms) often employ “scout”\npackets or “explorer” agents that roam the network. These scouts\ncollect local congestion or path-quality information and deposit some\nform of “trail” (akin to pheromones).\n• Emergent Routing Table Updates: Each router or switch updates\nlocal routing information (sometimes called a local “pheromone ta-\nble”).\nOver time, paths that prove consistently “good” get rein-\nforced; less efficient paths fade. This local, probabilistic approach\ncan converge on globally efficient routes with no central coordina-\ntion.\nopen atomic ethernet\n33\n5.9.1\nRelevance to On-Chip or 2D Mesh Topologies\n• Local Compass Directions: In a regular mesh (e.g., 2D grid) or torus,\neach router has up to 4 (N, E, S, W) or 8 ports (adding NW, NE, SW,\nSE). A biologically inspired algorithm can treat each output port as\na possible “direction of travel.”\n• Natural Fit for Scouting: The local directional structure matches\nhow “ants” or “foraging agents” might look around in each direc-\ntion, choosing a route based on local pheromone levels (akin to local\ncongestion or link utilization).\nThus, the scouting/discovery mechanism is all about gathering lo-\ncal “pathworthiness” data and then directing future traffic toward bet-\nter routes—exactly how a local compass-based system can easily be\nintegrated.\n5.9.2\nBufferless (Hot-Potato) Routing\n• No Packet Buffers (or Very Limited Buffers): In a bufferless architec-\nture, every router typically either immediately forwards or deflects\neach incoming packet. Packets cannot wait in large queues when an\noutput port is congested.\n• Hot-Potato / Deflection Character: When the preferred output port\nis unavailable, the packet is sent out of a different (less ideal) port—“hot-\npotato” style—rather than being buffered.\n5.9.3\nConnection with Biologically Inspired Approaches\n• Continuous Movement: Biologically inspired scouts are already de-\nsigned to wander and discover; in a bufferless system, “wandering”\n(via deflections) is also central. This synergy means a router can ap-\nply a heuristic (like a pheromone table) to pick the “best available\nport” quickly, but if that port is busy, the packet must choose an\nalternate direction.\n• Adaptive Reinforcement Over Time: In a bufferless design, a packet\ncannot linger while waiting for the optimal output. However, lo-\ncal “pheromone” or “congestion” metrics can still help route the\nmajority of packets down better ports more often. Over time, high-\ntraffic edges might become less appealing, guiding packets to less-\ncongested directions.\n5.9.4\nDeflection Routing\n• Forced Misrouting / Deflection: If the desired or minimal-distance\noutput port cannot be taken (due to contention), the router picks\nanother output. The packet may travel away from its ultimate des-\ntination (a “deflection”), but eventually, it should be re-routed back\non track.\nopen atomic ethernet\n34\n• Common in Low- or No-Buffer Architectures: Deflection routing is\none way to handle resource contention when buffer space is un-\navailable.\n5.9.5\nTying It Back to the Compass Ports (N, E, S, W, NW, NE, SW,\nSE)\n• Local Prioritization: In an 8-port (or 4-port) router, one can define\na strict or heuristic priority among the directions. For example, a\npacket traveling generally “north-east” might prefer the N or E port\nif free; if both are busy, it might deflect NE, or in the worst case,\ndeflect NW or SE.\n• Biologically Inspired Ranking: The “pheromone” concept can be\nused to rank the output directions. The highest “pheromone” port\nis tried first, then so on down the rank.\nThis effectively merges\na local heuristic (pheromone) with forced deflection for whichever\nports remain free.\nIn practice, such a scheme allows packets to “scout” and reinforce\ncertain directions while still ensuring that they never have to wait for\na blocked port.\n5.9.6\nExample Flow in an 8-Port Router\n1. Receive a Packet coming in from, say, the south port.\n2. Look Up Destination (or partial coordinate heading). For instance,\nthe packet is trying to reach a node in the north-east region, so N\nor E might be favored.\n3. Check Local “Pheromone” or Routing Table: Suppose the local\npheromone table says port NE is the best guess based on past traf-\nfic patterns.\n4. If NE Port Is Free: Forward the packet NE.\n5. If NE Port Is Busy: Check next best local direction (N, E, or NW/SE\nfallback).\n6. If All Preferred Ports Are Busy: Packet is deflected to any open\nport (could be even SW in the worst case).\n7. Local Table Update: The router sees how that choice ended up\naffecting the packet (if it eventually left the region quickly or ended\nup in a congested area). Over time, these experiences feed back\ninto local pheromone levels.\nDespite the forced misrouting (deflections), the biologically inspired\nfeedback approach often keeps net throughput healthy and tries to\navoid systematic congestion “hot spots.”\n5.9.7\nConnection with the Literature\n1. 1. Hot-Potato Routing (Deflection Routing):\nopen atomic ethernet\n35\n• Baran, P. (1962).\nOn Distributed Communications Networks.\nIEEE Transactions on Communications.\n(Early ideas of “hot-\npotato” and distributed routing).\n• Dally, W., & Towles, B. (2004). Principles and Practices of Inter-\nconnection Networks. (Excellent overview of deflection routing\nin modern network design).\n2. 2. Biologically Inspired / Ant-Based Routing:\n• Di Caro, G. A., & Dorigo, M. (1997). AntNet: Distributed stig-\nmergetic control for communications networks. Journal of Arti-\nficial Intelligence Research.\n• Schoonderwoerd, R., Holland, O., Bruten, J., & Rothkrantz, L.\n(1996).\nAnt-based load balancing in telecommunications net-\nworks. Adaptive Behavior.\n3. 3. Network-on-Chip with Deflection/Bufferless Approaches:\n• Moraes, F. et al. (2004). A Low Area Overhead Packet-switched\nNetwork on Chip: Architecture and Prototyping. SBCCI.\n• Fallin, C., et al. (2012). CHIPPER: A Low-Complexity Bufferless\nDeflection Router. HPCA.\nThese resources flesh out how bufferless or deflection routing is\nimplemented (especially in on-chip contexts) and how biologically in-\nspired heuristics can be adapted to local, minimal-knowledge scouting\ndecisions.\n5.9.8\nConcluding Remarks\n• Shared Tenets: Both biologically inspired scouting and deflection-\nbased, bufferless routing rest on local decision making. In biolog-\nically inspired schemes, scouting packets “discover” or “reinforce”\ncertain paths. In deflection routing, each router makes a quick (lo-\ncal) decision when a preferred port is blocked, forcing packets to\nkeep moving.\n• Complementary Mechanics: Because biologically inspired “pheromone”\nupdates naturally reflect congestion and path usage, they integrate\nwell with a bufferless or deflection style—turning forced misroutes\ninto valuable “exploration” signals that feed back into local heuris-\ntics.\n• Directional Routing: The presence of N, S, E, W (plus diagonals)\nsimply defines how many possible local moves each node (router)\ncan attempt. In 2D meshes or tori, these directions make for a con-\nvenient coordinate system that parallels how ants (or other scouts)\nmight sense local gradients or pheromone intensities in each of eight\ncompass directions.\nOverall, if we combine a scouting mechanism (to adaptively find\nneighbors and good routes) with deflection routing (to handle buffer\nconstraints or high contention), we get a dynamic, emergent routing\nopen atomic ethernet\n36\nsystem in which packets flow continuously and local updates shape\nglobal traffic patterns in a self-organizing fashion.\nAll this happens without the need for Source/Destination Addresses,\nwhich present severe security problems by exposing the “identity\" of\nnodes making them vulnerable to attack.\n5.10\nBidirectional Shannon Channels\nFigure 5.11:\nShannon One-Way Chan-\nnels.\nShannon Channels are normally shown in one direction of flow –\nfrom Information source to Information Destination. Here we exploit\ntwo-way communication (signaling) Back to Back Channels with im-\nmediate (slice by slice) feedback. Then the equations tell us something\ninteresting about the symmetry of set reconciliation on both sides of the\nlink.\nWith back-to-back Shannon Channels, with (immediate) slice by\nslice feedback, we get Perfect Information Transfer (PIT) ?. We can\ntherefore dispense with Checksums, CRC’s, FEC or even Parity, be-\ncause the failure modes these EDC and ECC codes address are already\ncovered by PIT. This has two advantages:\n• The elimination of spatial redundancy on the wire makes the pack-\nets shorter\n• The need to calculate increasingly complex codes reduces computa-\ntion and energy dissipation on the link\nRedundancy is a poor crutch when as-\nsumptions about uniform probability\ndistributions are violated (which they al-\nmost always are in practice).\n5.10.1\nMetcalfe Half-Duplex\nFigure 5.12:\nThe original Metcalfe +\nBoggs Ethernet was a bus. A long ca-\nble where ‘stations’ were TAPs on the\nbus.\nThis meant that each station had\nto both listen, and transmit from teach\ntap. In this figure we show two indepen-\ndent streams of packets going in oppo-\nsite direction (forwardpropagation and\nbackpropagation) through a single half-\nduplex link\nopen atomic ethernet\n37\nFigure 5.13: Modern Ethernet Links are\nbidirectional; two sub-channels:\none for transmit, one for receive\n5.10.2\nMetcalfe Half-Duplex Channel\n5.10.3\nFull-Duplex Bi-pipelined Shannon-Metcalfe Channel\nPCIe\nETHERNET TX\nETHERNET RX\nSACK 11\nSACK 10\nSACK 01\nSACK 00\nSACK 11\nSACK 10\nSACK 01\nSACK 00\nInformation\nKnowledge  \nSemantics \nSyntax\nRX SERDES\nTX SERDES\nRX SLICE 2\nRX SLICE 3-4\nRX SLICE 5–8\nTX SLICE 1\nTX SLICE 2\nTX SLICE 3-4\nTX SLICE 5–8\nRX SLICE 1\nTX SERDES\nRX SERDES\nTX SLICE 1\nRX SLICE 2\nRX SLICE 3-4\nRX SLICE 5–8\nRX SLICE 1\nRX SLICE 2\nRX SLICE 3-4\nRX SLICE 5–8\nAlice\nBob\nPCIe\nPCIe\nPCIe\nSACK 11\nSACK 10\nSACK 01\nSACK 00\nFigure\n5.14:\nComplete\nmodel:\nBi-\npipelined full duplex exchange of Æth-\nernet frames.\nComplete with internal\n\"Slice ACKnowledges\" (SACKs) – se-\nquenced with increasing common knowl-\nedge depth inside SerDes/FPGA\nThe figure above is a simple, formally verifiable, mathematical de-\nscription, from API to bits on the wire (Shannon channel).\n6\nTopology\n6.1\nGraph Aware Determinism\nWhen treating the “Network” as an opaque cloud, it’s easy to underes-\ntimate how varied network partitions when link failures are asymmet-\nrical: A can see B, but B can’t see A. In a 4 node setup, there are over\n1295 potential partitions, and a flaky network can reproduce them all.\nFrom a distributed systems (event ordering in a cluster) as an avail-\nability equation, we can easily overestimate how reliable they are, by 3\norders of magnitude.\nLink failures are invisible (hidden) in a Clos. They are 100% Visible\nto us in a local graph of triangular relationships.\nAnd that’s only the clean (binary) binary failures. Real system flakey\nconnections are much worse.\n6.1.1\nTransactions need a coordinator?\nThe Æthernet protocol is designed to be exquisitely sensitive to packet\nloss and corruption We monitor, detect, diagnose link failures, and\nrecover reversibly and automatically.\n6.2\nA Resilience Metric for Mesh Networks\n6.2.1\nGraph Laplacian and Algebraic Connectivity\nThe Graph Laplacian.\nFor a simple, undirected graph G = (V, E) with\nn = |V| vertices, the combinatorial Laplacian matrix L is defined as\nL = D −A,\nwhere\n• A is the n × n adjacency matrix, with Aij = 1 if there is an edge\nbetween i and j, and 0 otherwise,\nopen atomic ethernet\n40\n• D is the n × n diagonal degree matrix, whose diagonal entries are\nDii = deg(i).\nThe Laplacian L is central in spectral graph theory, encoding many\nconnectivity properties of G.\nAlgebraic Connectivity (λ2).\nLet the eigenvalues of L be ordered as\n0 = λ1 ≤λ2 ≤· · · ≤λn.\nThe second-smallest eigenvalue, λ2, is the algebraic connectivity (or Fiedler\nvalue). It satisfies\n• λ2 > 0 if and only if G is connected,\n• A larger λ2 generally indicates stronger connectivity and a larger\ncut is required to disconnect G.\nThus, λ2 is often seen as a “spectral” measure of how robustly G re-\nmains connected under certain disruptions.\n6.2.2\nClassical Connectivity Measures\nBeyond λ2, there are other classical measures:\n1. Edge Connectivity λ(G): The minimum number of edges whose\nremoval disconnects G.\n2. Vertex Connectivity κ(G): The minimum number of vertices whose\nremoval disconnects G.\n3. Expansion or Isoperimetric Constants: Relate cut sizes to the car-\ndinalities of sets being separated.\nThese capture global connectivity but may not reflect the incremental\nor adversarial removal of edges in a constrained-valency network.\n6.2.3\nIncremental Link Failures in Constrained-Valency Networks\nIn HPC or data-center systems (e.g. with IPUs or smartNICs), each\nnode has limited valency (e.g. 8 ports), and edges can fail one by one.\nA single λ2 value may not capture how partial or progressive failures\ndegrade connectivity.\nWhy a single λ2 may not suffice.\n• λ2 is a one-shot global measure.\nIt does not directly model how\nconnectivity degrades as edges fail in sequence.\n• Some topologies might remain connected but experience severe bot-\ntlenecks after a few critical edges fail, which does not show up im-\nmediately in a single baseline λ2.\nopen atomic ethernet\n41\n6.2.4\nPotential Approaches for a “Resilience Metric”\n6.2.5\nSpectral-Based Extensions\n(a) Expected λ2 under random failures.\nIf edges fail independently with\nprobability p, form a random subgraph Gp. One could define:\nE\n\u0002\nλ2(Gp)\n\u0003\nas a measure of average resilience. Larger expected algebraic connec-\ntivity implies better tolerance to random edge losses.\nWorst-case sequence of λ2 values.\nDefine:\nR(k) = min\nF⊆E\n|F|=k\nλ2\n\u0000G −F\n\u0001\n,\nwhere G −F is the graph with edges F removed. R(k) measures the\nsmallest λ2 achievable after k edge removals. A graph is more resilient if\nR(k) remains high for larger k. If R(k) drops to 0, it indicates that with\nk removed edges, G can be disconnected.\n6.2.6\nConnectivity-Based Ideas\n(a) k-Edge Connectivity Functions.\nBeyond the single value of λ(G) (the\nedge connectivity), define\nϕ(k) = min\nF⊆E\n|F|=k\n\u0010\nsize of the largest connected component of G −F\n\u0011\n.\nIf ϕ(k) remains large, it means removing any k edges fails to isolate\nmore than a small fraction of nodes. This complements λ2 by focusing\non component sizes.\n(b) Edge-disjoint path counts.\nUsing Menger’s Theorem, one can track\nthe number of edge-disjoint paths between certain pairs of nodes.\nHigher numbers of disjoint paths generally imply more resilient con-\nnectivity.\n6.2.7\nWeighted or Dynamic Laplacian\nA dynamic Laplacian L(w) might assign weights we to edges. If an\nedge is fully failed, we = 0. Then one can track how λ2\n\u0000L(w)\n\u0001\nevolves\nas edges degrade from weight 1 to weight 0, either in random or ad-\nversarial patterns.\n6.2.8\nA Concrete Proposal\nA practical “resilience function” might be:\nR(k) = min\nF⊆E\n|F|=k\nλ2\n\u0000G −F\n\u0001\n,\nopen atomic ethernet\n42\nwhere the minimum is taken over all subsets F of k edges. Then:\n• R(0) = λ2(G) is the baseline algebraic connectivity.\n• If R(k) > 0, the graph cannot be disconnected by removing any k\nedges.\n• The rate at which R(k) decreases with k reflects how fast the net-\nwork’s connectivity deteriorates under incremental failures.\n6.2.9\nComputational Observations\nExact computation of R(k) can be expensive for large graphs because\nthere are (|E|\nk ) subsets. One may:\n• Use heuristics or approximation algorithms to identify critical edges,\n• Leverage min-cut or max-flow bounds to quickly estimate how easy\nit is to disconnect the graph,\n• Perform sampling over subsets F if a random measure of resilience\nsuffices.\n• The graph Laplacian (and in particular λ2) is a powerful spectral tool.\nIt already gives a measure of connectivity robustness.\n• For incremental or adversarial link failures, a single λ2 value may\nnot capture the full picture. A function R(k) over subsets of size k\ncan indicate how robustly the graph handles multiple simultaneous\nfailures.\n• In constrained-valency networks, certain edges are more critical, be-\ncause each node has fewer possible alternate paths. Thus, a spectral-\nbased metric that accounts for edge removals (like R(k)) can better\nreflect real-world vulnerability.\n• Combined with classical connectivity measures (e.g. λ(G), κ(G)), a\nLaplacian-based incremental approach provides a practical, mathe-\nmatically grounded way to define and quantify resilience of a net-\nwork topology.\n7\nHistory\n7.1\nALOHA\nThis section compares the classical ALOHA protocol with its improved\nvariant, Slotted ALOHA, highlighting differences in their design, col-\nlision behavior, and efficiency.\n7.1.1\nIntroduction\nThe ALOHA protocol1 allows nodes to transmit packets at any time,\n1 Developed in the late 1960s at the Uni-\nversity of Hawaii for radio communica-\ntions\nleading to frequent collisions. Slotted ALOHA2, in contrast, divides\n2 Introduced shortly after by Roberts in\n1972\ntime into discrete slots, allowing transmissions only at the beginning\nof a slot, thereby reducing the chance of collisions.\n??\n7.1.2\nComparison Table\nFeature\nALOHA\nSlotted ALOHA\nTime structure\nAny time\nSlot-aligned\nCollision probability\nHigh\nLower\nEfficiency (max)\n≈18% (1/2e)\n≈37% (1/e)\nImplementation complexity\nSimple\nNeeds synchronization\nAnalogy\nRandom shouting\nTimed shouting\nTable\n7.1:\nKey\ndifferences\nbetween\nALOHA and Slotted ALOHA.\n7.1.3\nVisual Comparison\nFigure 7.1 shows a visual comparison of packet transmissions and col-\nlisions in both protocols.\n7.1.4\nSummary with Sidenotes\nALOHA allows nodes to transmit without coordination,3 but suffers\n3 This freedom results in many partial\ncollisions where packets overlap par-\ntially in time.\nfrom a high collision probability.\nopen atomic ethernet\n44\nFigure\n7.1:\nCollision\nbehavior\nin\nALOHA (left) vs.\nSlotted ALOHA\n(right).\nSlotted ALOHA improves throughput by enforcing transmission\nonly at predefined time slots,4 achieving almost twice the maximum\n4 By waiting until the next time slot\nboundary, nodes avoid partial overlaps.\nthroughput.\nOverall, Slotted ALOHA introduces a modest increase in complex-\nity but greatly improves network performance in high-load scenarios.5\n5 Especially important for early satellite\nand Ethernet networks.\n7.2\nATM\nIn the early 1990s, the ATM Forum became the battleground for a\npivotal debate in networking: how to manage congestion in a cell-\nbased fabric designed to unify voice, video, and data traffic.\nThe\ntwo main contenders were Hop-by-Hop Flow Control and Rate-Based\nFlow Control.\nEach represented a fundamentally different view of\nhow best to achieve performance guarantees and fairness across a het-\nerogeneous, multi-hop network composed of 53-byte cells.\n7.2.1\nThe Challenge: ATM’s Dual Mandate\nATM was envisioned as the unifying transport for all digital commu-\nnication, requiring it to offer both the deterministic timing of circuit-\nswitched networks and the efficiency of statistical multiplexing. This\nmeant that congestion control was not merely a performance tweak,\nbut a contractual necessity to maintain promised QoS levels.\nATM’s cut-through switching and small fixed-size cells eliminated\nmuch of the buffering flexibility available to IP networks. It had to\nprevent congestion, not recover from it.\n7.2.2\nHop-by-Hop Flow Control\nHop-by-hop flow control works by applying local backpressure: each\nswitch monitors its output buffers and signals its upstream neighbor\nto slow or stop traffic as congestion builds.\nFigure 7.2:\nHop-by-hop flow control:\nfeedback loops are short but propagate\nslowly end-to-end.\nopen atomic ethernet\n45\nAdvantages\n• Immediate local reaction to congestion.\n• Fine-grained control over buffer occupancy.\n• Simple logic for small or low-diameter networks.\nDrawbacks\n• Scalability concerns: lacks consistent end-to-end semantics.\n• Head-of-line blocking and poor latency propagation in long paths.\n• Fragile under path diversity and route reconfiguration.\n7.2.3\nRate-Based Flow Control\nRate-based flow control, standardized as part of the ATM ABR (Avail-\nable Bit Rate) service class, aimed to regulate traffic from the edge.\nSources declare a desired transmission rate, and switches generate Re-\nsource Management (RM) cells containing congestion feedback. These\nRM cells traverse the path forward and backward, carrying fields such\nas Explicit Rate (ER) that guide sender behavior.\nAdvantages\n• End-to-end perspective scales better with network size.\n• Enables policy-driven traffic contracts and rate shaping.\n• Compatible with QoS-aware routing and admission control.\nDrawbacks\n• More complex per-switch logic and state maintenance.\n• Relies on timely and reliable RM cell feedback.\n• Convergence time can be slow in bursty or highly dynamic condi-\ntions.\n7.2.4\nThe Verdict: Standardization\nAfter extensive debate, the ATM Forum chose Rate-Based Flow Con-\ntrol as the official standard. This decision reflected a belief in the end-\nto-end model of networking, better alignment with telco administration,\nand superior support for SLAs (Service Level Agreements). Switch\nvendors also favored rate-based schemes for their reduced buffer re-\nquirements and predictability.\n7.2.5\nLegacy and Modern Echoes\nAlthough ATM faded from prominence, the ideas from its flow control\ndebate echo through modern networking:\n• InfiniBand and credit-based Ethernet revived hop-by-hop flow con-\ntrol for low-latency datacenter fabrics.\nopen atomic ethernet\n46\n• TCP Vegas and XCP extended the rate-based idea into congestion-\naware transport.\n• PFC and QCN in Data Center Bridging (DCB) illustrate hybrid ap-\nproaches that combine both paradigms.\nIn hindsight, both models have value—hop-by-hop for tight fabrics\nwith predictable topology; rate-based for scalable, heterogeneous sys-\ntems. The ATM Forum chose well for its assumptions—but the future\nfragmented.\n7.2.6\nConclusion\nThe ATM Forum’s choice to standardize rate-based flow control was\nless a dismissal of hop-by-hop than a reflection of the broader ambi-\ntions of the ATM architecture. It aimed to build a global, carrier-grade\nnetwork substrate. In contrast, datacenters—where predictability and\ntight control dominate—would later rediscover the strengths of local-\nized flow control.\nRate-based flow control won the standard. But hop-by-hop flow control won the\ndatacenter.\n7.3\nEthernet\nOriginal 10 Mb/s Ethernet (and most ‘best-effort” variants since) offers\na CRC to detect corruption but no link-level retransmission. Frames\ncan be dropped by congestion, policing, or topology loops. Hence raw\nEthernet is both unreliable and fallible; higher layers—typically TCP—\nsupply ABP-like recovery.\n7.3.1\nHow InfiniBand Raises the Game\nInfiniBand embeds ABP into silicon:\n• Per-hop credit flow control makes buffer overflow almost impossible.\n• Link-level CRC plus optional link retransmission retries any corrupted\nframe.\n• Reliable Connection and Reliable Datagram queue pairs carry ACK-\n/NACK sequence numbers end-to-end, guaranteeing exactly-once,\nin-order delivery across multi-switch fabrics.\nTo software, the fabric appears nearly infallible; drops are rare and\nlocalized.\n7.3.2\nReliable vs. Infallible, Unreliable vs, Fallible\nTable 8.1 highlights the nuance. Priority Flow Control (PFC) can ren-\nder an Ethernet link loss-less in steady state, but deadlock, mis-configuration,\nor burst congestion can still drop frames. Such a link is ‘reliable yet\nfallible.\" Infiniband’s credit + retransmit pipeline, by contrast shifts\nreal-world operation toward ‘reliable and almost infallible.”\nopen atomic ethernet\n47\n7.3.3\nWhy Ethernet Still Struggles\n1. Retrofitting: inserting link retransmission into the IEEE 802 stack\nbreaks long-standing timing and compatibility assumptions.\n2. Congestion domain: shallow switch queues and ECMP paths leave\nmore surfaces for loss than InfiniBand’s strict hop-by-hop credits.\n3. Layering philosophy: because TCP ‘already” ensures delivery, many\noperators accept occasional loss rather than pay silicon cost for\nhardware recovery.\n8\nTheory\n8.1\nIntroduction\nIt would be a mistake to assume conventional network concepts and\nterminology that you already know and love will remain unscathed in\nthis project. We have no intention of reinventing the wheel, yet some\nnew concepts and terminology will be necessary in order to escape the\nincrementalist momentum of the last five decades.\nWe carefully described in four presenta-\ntions why the concept of time is widely\nmisunderstood in the OCP TAP (Time\nAppliance Community). We respectfully\nrequest that you watch those presen-\ntations before insisting on timestamps\nor synchronized time in the context of\nOpen Atomic Ethernet.\nOpen Atomic\nEthernet\n1. The word and the concept of TIME does not appear in this specifi-\ncation. This concept is the largest single source of misunderstand-\ning in computer science today, so we eliminate that first. We replace\nthis with intervals that are defined within sets (not on the real line).\nDefinite Total Order (DTO), Definite Partial Order (DPO), Indefi-\nnite Partial Order (IPO). .\nFormal analysis and connections to the\nliterature will appear in the index.\n2. Claude Shannon described information as surprisal. We will call it\nShanformation in this document to tear everyone away from old\nideas that have been conflated for too long about “bits in memory\nor storage”, hiding its deeper meaning of \"the resolution of uncer-\ntainty\".\n3. We replace conventional notions of Error Detection and Correction\n(ECC, EDC, FEC, Parity, etc.) with a new concept, while not new,\nis widely misunderstood: Common Knowledge.\n4. We replace conventional notions of liveness with a continuously\ncirculating token, within which we define “logical simultaneity\"\n5. We are not shy of delving into Quantum Information Theory or\nQuantum Thermodynamics to find solutions to the problems in\nhardware and software infrastructure.\nTHERE IS NO GLOBAL DRUM BEAT In Episodes 1 through 4 we ex-\npressed doubts about the common belief system of a Newtonian\nview of the world in this community.\nWe showed how to think\nabout race conditions, and why Timeouts and Retries (TAR) are\nopen atomic ethernet\n50\nthe root of all evil. Our conclusion is that Timestamps are an Illu-\nsion. They can’t be fixed by software. The quest for a single, con-\nsistent timeline across distributed systems collides with the reality\nthat physics itself does not provide a universal notion of time—and\nin quantum mechanics (the machine code of our universe), there is\nno consistent causal order at all. We cannot, therefore, rely on this\nillusion of an irreversible drumbeat on an inaccessible “real line” to\nprovide linear time order for events in our networked systems. Al-\nthough timestamps will remain indispensable in engineering prac-\ntice, we must recognize them as approximations rather than abso-\nlutes, and design our systems accordingly.\nEPISODE 1 – What There is no now. You cannot synchronize clocks\nthe way you think. Talk Originally given at the 2023 Asilomar Mi-\ncrocomputer Workshop presented live with Jonathan Gorard. Mo-\ntivation: (1) To get people thinking about the nature of time and\ncausality, as far removed from the Earth (and TAI/GPS) as possible.\n(2) To stimulate “First Principles Thinking” for Distributed Systems.\n• Clocks can be disseminated, but require interaction to be syn-\nchronized:\n• Simultaneity planes don’t exist (except in an empty frozen uni-\nverse) Einstein proved this over 100 years ago Why do we still\nthink we can synchronize clocks?\n• Network Time Protocol (NTP) and Precision Time Protocol (PTP)\nare causal TREES – choose your root, and how you do failover\n• Entanglement and indefinite causal order are the new relativity\n(Not restricted to low relative velocities or atomic scales)\n• We cannot assume spacetime is irreversible and monotonic\n• Irreversibility and monotonicity is in the Eye of the Observer\nEPISODE 2 - Hidden assumptions about causality lead to lost & corrupted data\nWhen we think about clocks as an incrementing number, we are\ncommitting the FITO fallacy – “Forward In-Time-Only” Thinking -\nCounterfactuals, i.e., “events that could have occurred but eventu-\nally did not, play a unique role in quantum mechanics in that they\nexert causal effects despite their non-occurrence”\n• Clock Synchronization Error is indistinguishable from Latency\n• Irreversibility (Monotonicity) is an illusion not guaranteed by\nphysics, unless we build Ancilla to explicitly manipulate causal-\nity\n• Irreversibility and “causal order” are IN THE EYE OF THE OB-\nSERVER—not guaranteed to be consistent across different ob-\nservers\nEPISODE 3 – How a static PTP hierarchy can be made dynamic to support causal failover for distributed systems\nopen atomic ethernet\n51\nIn Episode 1(What) & Episode 2 (Why) we showed how misun-\nderstandings accumulate within a Newtonian framework of time,\nand how this leads to lost transactions and corrupted data. In this\nEpisode we help the audience make the leap from Newtonian Time\n(what we know for certain that just ain’t so) to Post-Newtonian Time\n(relativistic SR/GR, and QM — Indefinite Causal Order (ICO).\n• PTP is widely available in Datacenters, we propose experiments\nto falsify beliefs about Newtonian Time.\n• All is not lost. The excellent engineering behind PTP and PTM,\ncan still be used with a different perspective, by using the clock\nhierarchy to build Causal Trees and reliable failover, to help ad-\ndress race conditions and achieve Exactly Once Semantics\nEPISODE 4 – Why we can’t have nice things in Distributed Systems\n• Instants are meaningless, only intervals (on the same computer/-\ntimeline) are relevant\n• Photons don’t carry timestamps, but timestamps are carried by\nphotons\n• The speed of light is the “pivot” around which time and space\nevolve\n• Timeout and retry (TAR) on different timelines will silently cor-\nrupt data structures\n• Shannon entropy is a logarithm. The logarithm of zero (no infor-\nmation) is minus infinity.\n• Bayesian approaches require a prior belief, which can be un-\nbounded (zero to infinity).\nActually, it’s much worse: can be\n{−∞−1 −0, +0, +1, +∞}. We can’t do Bayesian statistics under\nthose conditions, mathematically, their results are undefined.\n• Shannon Entropy is uncertainty, and the same problem applies\nwhen you apply the set {−∞−1−0, +0, +1, +∞} to Information\nand Entropy p ∗log(p)\n• Measurements “appear” instantaneous because there is no back-\nground of time on which to measure anything. Timestamps don’t\nIt does appear instantaneous to an ob-\nserver,\nbecause when they receive a\npacket (or a photon in a detector), you\ncapture information and turn it into\nknowledge (state in a register you can\ndo something with)\nhelp with causal order.\n8.2\nIP Foundations\nWe begin with Bartlett, Scantlebury and Wilkinson’s (?) Alternating\nBit Protocol (ABP).\nAlternating messages are implemented as a single snake (a longitu-\ndinal set of bits traveling through the wire and FPGA’s). Wrapping its\nway through the SerDes Registers of Alice and Bob on both ends.\nFirst imagine a zero length wire connecting the chiplets for Alice an\nBob (they are as adjacent as they can be on a module or motherboard).\nopen atomic ethernet\n52\nTwo SerDes channels are directly connected.\nWhere in BSW1, the edges of the automata are labeled with the\n1 A note on reliable full-duplex transmis-\nsion over half-duplex links\nalternation’ bit, Lynch expands the single bit to multiple bits.\nA single bit alternates, but it does not have a direction.\nAlternating 2-Bit Protocol (from Lynch):\nTwo bits at least have a direction in their evolution through their set.\n{00 01 11 11}\nOR\n{11 10 01 00}\nWhere the next item establishes the direction of evolution of the set.\nWe use Ternary logic -1,0, +1 in our model of the protocol.\n0 simply means equilibrium’, which gives us the +1 and −1 com-\nplementary states that are expected of Ternary Logic. But there is a\nmathematical subtlety: we need both two versions of Zero, one ap-\nproaching from the negative side, and one approaching from the pos-\nitive side.\nThis provides a mechanism for forward-propagation and , of the state.\n8.2.1\nProof of Fallibility\n‘the alternating validation bit becoming the additionally the alternation\nbit for message transmission in one direction, while the alternation bit\nfor the reverse directions serves additionally as a validation bit” SBW ?\nLynch’s scheme is constructed from in-\ndependent simplex procedures\n8.2.2\nFraming the Vocabulary\nIn 1967 Bartlett, Scantlebury & Wilkinson (BSW) sketched the alternating-\nbit protocol (ABP): add one history bit to every frame, wait for an ACK\nthat echoes it, and retransmit until the right ACK appears. ABP wraps\nan unreliable medium and presents a service that looks reliable—even\ninfallible in steady state.\nTerm\nMeaning\nUnreliable Frames may be lost.\nFallible\nChannel may violate any promise\n(drop, duplicate, reorder, corrupt).\nReliable\nNo drops in steady state;\nrecovery still required.\nInfallible\nNo violations ever; no recovery\nlogic needed above the link.\nFigure 8.1: Taxonomy of link qualities.\nNancy Lynch later formalised these ideas with the I/O-automaton: a\nfallible channel is one whose execution may deviate from the specifi-\ncation, subject only to fairness.\n8.2.3\nLessons from BSW and Lynch\n• Make reliability local. ABP attaches one bit; InfiniBand embeds a few\nmore. End-to-end recovery alone expands the failure scope.\nopen atomic ethernet\n53\n• Fail fast. InfiniBand retransmits on explicit NACK within microsec-\nonds; Ethernet traditionally converts a microsecond drop into a mil-\nlisecond TCP timeout.\n• Separate reliability from recovery. Even a reliable link needs a failsafe\nplan; design that plan explicitly.\nBSW showed that a single alternating bit can tame a capricious wire; Lynch\nsupplied the proof rules. InfiniBand adopted both insights in hardware\nand delivers a fabric whose normal behavior feels infallible. Classic Ether-\nnet remains best-effort—unreliable and fallible—and relies on upper layers\nfor recovery. Bridging that gap means absorbing more of the ABP playbook\nat the link: credits, link-level retransmission, and tight ACK/NACK loops\nthat shrink recovery from milliseconds to microseconds.\n8.2.4\nIP and Patent Implications\nThe core concept of credit-based flow control is now public domain,\nbut a handful of post-2005 implementation patents remain enforceable\nthrough at least 2036. Modern designs should audit those families but\ncan build freely on the expired foundational work.\nPractical Take-Aways\n1. Freedom to Operate. A straightforward “one credit = one buffer”\ndesign can rely on the expired Intel/Compaq and Brocade patents\nfor prior-art cover. Avoid features identical to the still-active patents\nor license them.\n2. Design Around. Active claims tend to be narrow. You can sidestep\nthe Mellanox “macro credit” idea by limiting link span or by using\nrate-based pacing instead of credit aggregation.\n8.3\nTwo-State Vector Formalism\nThe Two-State Vector Formalism (TSVF), developed by Aharonov and\ncollaborators, describes a quantum system using both a forward-evolving\nstate vector from the past and a backward-evolving vector from the fu-\nture, forming a complete description of the system between two time\nboundaries.\nThis formalism maps intriguingly well onto the two-phase behavior\nof supervised learning:\n• Forward propagation: evolving the input forward through the net-\nwork to predict an output.\n• Backpropagation: retroactively applying a loss function at the out-\nput and propagating error information backward through the net-\nwork to adjust weights.\nopen atomic ethernet\n54\nForward propagation plays the role of the forward-evolving quantum state\n|ψ(t)⟩, and backpropagation corresponds to the backward-evolving dual\nstate ⟨ϕ(t)|. Together, they constrain the learning dynamics at each layer\nvia a two-state viewpoint.\n8.3.1\nForward Propagation as Forward Evolution\nIn TSVF:\n|ψ(t)⟩= U(t, t0)|ψ(t0)⟩,\nwhere U is the unitary time evolution operator from an initial prepa-\nration at t0.\nIn machine learning:\na(l+1) = f (l)(W(l)a(l) + b(l)),\nwhere the activations a(l) propagate the input forward.\n8.3.2\nBackpropagation as Backward Evolution\nIn TSVF, a post-selected state ⟨ϕ(t1)| evolves backward:\n⟨ϕ(t)| = ⟨ϕ(t1)|U(t1, t),\ncomplementing the forward-evolving |ψ(t)⟩.\nIn neural nets:\nδ(l) = (W(l+1))⊤δ(l+1) ◦f ′(l)(z(l)),\nwhere δ(l) encodes error at layer l and propagates backward to adjust\nweights.\n8.3.3\nTwo-State Update Rule\nIn TSVF, expectation values take the form:\n⟨A⟩w = ⟨ϕ|A|ψ⟩\n⟨ϕ|ψ⟩,\nand represent weak values or amplitudes constrained by both past and\nfuture states.\nIn machine learning, the update rule:\n∆W(l) ∝δ(l)(a(l−1))⊤\ndepends on the forward activations a(l−1) and backward error signal\nδ(l). Together, they act like a sandwich operator:\nUpdate(l) ∼⟨ϕ(l)|operator|ψ(l)⟩.\nopen atomic ethernet\n55\n8.3.4\nTime-Symmetric Learning View\nRather than treating backpropagation as a mere computational trick,\nTSVF offers a time-symmetric interpretation:\n• Both the input and the desired output state determine the interme-\ndiate learning dynamics.\n• Each layer mediates between past input and future supervision,\nforming a time-bridging node.\nConcept\nNeural Network\nTSVF QM\nInitial input\nx\n|ψ(t0)⟩\nPrediction process\nForward prop\nU(t, t0) evolution\nTarget supervision\nLoss function\nPost-selection ⟨ϕ(t1)|\nError signal\nδ(l)\n⟨ϕ(t)|\nIntermediate activity\na(l)\n|ψ(t)⟩\nWeight update\nδ(l)(a(l−1))⊤\n⟨ϕ|A|ψ⟩\nTable 8.1: Analogies between supervised\nlearning and the Two-State Vector For-\nmalism (TSVF) in quantum mechanics.\n8.3.5\nFITO Thinking vs. Time Symmetry\nMost machine learning frameworks assume Forward-In-Time-Only (FITO)\ncausality: input causes output, and learning proceeds only by adjust-\ning from past to future. TSVF suggests a richer model:\n• Supervision from the future constrains the learning of the past.\n• This bidirectional model aligns with concepts from goal-driven be-\nhavior and active inference.\n8.3.6\nConclusion\nThe TSVF reframing of forward and backpropagation illuminates the\ndeeper time-symmetric structure underlying learning. Far from being\njust a computational trick, backpropagation can be seen as a physical\ndual to forward propagation—both necessary to fully specify a learn-\ning system between two boundary conditions.\nThis is highly relevant to our model of the protocol, where we use\nreversible state machines to specify forward propagation, with what-\never reversible glitches might be needed to handle failures are im-\nplemented as reversible steps, and the backpropagation as the credit-\nbased flow control mechanism.\nBecause they are completely symmetric, packets being sent and\npackets being unsent are fully managed by the flow control system.\n8.4\nCommon Knowledge\nIn what follows, assume that node Alice is sending a packet to node\nBob over the single, fallible link between them.\nThe Stop and Wait and alternating bit protocols provide credit based\nflow control using a single round trip.\nBob is free to forward the\nopen atomic ethernet\n56\npacket as soon as it arrives, but Alice must wait for a signal from Bob\nbefore sending another packet. If the link breaks before Alice gets a\nsignal from Bob, then Alice may forward the packet again, perhaps\non another path. This behavior makes exactly-once, in-order delivery\ndifficult to implement.\nTIKTYKTYK is one round trip beyond stop and wait, which pro-\nvides partial common knowledge that aids in recovery from failures.\nBob cannot forward the packet until he receives the signal from Al-\nice that completes the second round trip. A key point is that there are\nmany times when both sides know that both sides know which of them\nis responsible for forwarding the packet. In the other cases, the partial\ncommon knowledge simplifies recovery. Alice and Bob use their par-\ntial common knowledge to ensure that any packet is only forwarded\nonce, which is a key condition for exactly-once, in-order delivery.\nThere is minimal loss in latency, because Bob doesn’t have to wait\nfor the entire packet to arrive before signaling to Alce that the packet\nis arriving. He can do any integrity checks (CRC) while waiting for Al-\nice’s signal. Any loss in latency is compensated for by needing smaller\nbuffers. There is minimal loss in bandwidth because the signal can be\na data packet going in the other direction.\nSometimes links fail silently, which means a signal might not arrive.\nIn those cases, he nodes will need some heuristic to decide when to\nstop waiting and declare the link dead. Fortunately, this heuristic can\nbe purely local because Bob will never get a signal from Alice once\nshe’s decided the link is dead.\nA clock is commonly used for the\nheuristic, but care is needed. For example, if Bob is heavily loaded but\nAlice is not, she might set her timeout to be too short. If the situation\nis reversed, the timeout may be too long. An alternative is for Alice to\ncount the events she receives on her other ports. She can declare the\nlink dead if too many of these events are received before she gets one\nfrom Bob. This heuristic is effectively averaging over the workload of\nall the nodes connected to her, providing a more consistent metric.\n8.5\nTIKTYKTIK\nTIKTYKTIK is like the alternating-bit and stop-and-wait protocols in\nthat receipt of a packet over a link is acknowledged over that link with\na “signal” packet. In that sense, these three protocols implement credit\nbased flow control, which simplifies buffer management and makes it\npossible to not have to drop packets when there is a lot of traffic.\nTIKTYKTIK adds a second round trip, which provides partial com-\nmon knowledge helpful for recovery from link failures. This document\nopen atomic ethernet\n57\nwalks through TIKTYKTIK showing how that common knowledge is\nused. First look at the various stages of common knowledge as the\nprotocol runs without failure when Alice sends a packet to Bob.\n1. Alice sends the packet to Bob\n• Alice doesn’t know if Bob received the packet\n• Bob does not know the packet exists\n2. Bob receives the packet\n• Bob knows that Alice doesn’t know that Bob received the packet\n3. Bob sends a signal to Alice\n• Bob doesn’t know if Alice knows that Bob received the packet\n4. Alice receives the signal\n• Alice knows that Bob received the packet\n• Alice knows that Bob doesn’t know that Alice knows that Bob\nreceived the packet\n5. Alice sends the signal\n• Alice doesn’t know if Bob knows that Alice knows that Bob re-\nceived the packet.\n6. Bob receives the signal\n• Bob knows that Alice knows that Bob received the packet.\n• Bob doesn’t know if Alice knows that Bob knows that Alice\nknows that Bob received the packet.\n• Bob can forward the packet\n7. Alice receives the signal\n• Alice knows that Bob knows that Alice knows that Bob received\nthe packet.\n• Alice can delete her copy of the packet.\nThis common knowledge is not needed if links never fail. Alice\ncould delete the packet as soon as she sent it, and Bob could forward\nit as soon as he received it. That’s what current systems do and why\nit’s so hard to recover from a link failure.\nA data packet can serve as a signal.2 Links can fail in a number of\n2 A data packet can serve as a signal.\nways. If they physically break or are unplugged, the PHY detects the\nlost of electrical signal and informs the higher layers. Links can also\nfail silently, such as when the NIC misbehaves. They can also fail in\none direction but not the other. Silent failures can be detected in these\nprotocols because a signal will never be received in either direction. In\nthat sense, there is a level of common knowledge on a link failure. In\nwhat follows, I’ll describe what happens when Alice wants to send a\npacket to Bob, but the link fails at various steps of the protocol. The\nlink is no longer used once one of these failures occurs. (The link can\nbe used later after re-initializing the connection.)\n• 1 Alice has a packet to send when link fails\n– Alice\nopen atomic ethernet\n58\n* Knows Bob doesn’t have the packet\n* Knows Alice is responsible for it\n– Bob\n* Doesn’t know the packet exists\n• 2 Alice sends the packet to Bob then link fails\n– Alice\n* Doesn’t know if Bob got the packet\n* Knows that Bob knows Alice is responsible\n– Bob\n* Doesn’t know that the packet exists\n• 3 Bob receives the packet then link fails\n– Bob\n* Knows that Alice knows that Alice is responsible\n– Alice\n* Alice doesn’t know if Alice or Bob is responsible\n• 4 Bob sends signal then link fails\n– Bob\n* Doesn’t know if Alice got the signal\n* Doesn’t know if Bob or Alice is responsible\n– Alice\n* Alice doesn’t know if Alice or Bob is responsible\n• 5 Alice receives the signal then link fails\n– Alice\n* Knows that Bob is responsible\n* Knows that Bob doesn’t know he is responsible\n– Bob\n* Doesn’t know if Alice got the signal\n* Doesn’t know if Alice knows that Bob is responsible\n• 6 Alice sends signal then link fails\n– Alice\n* Knows that Bob is responsible\n* Doesn’t know if Bob knows he is responsible\n– Bob\n* Doesn’t know if he’s responsible for the packet\n• 7 Bob receives the signal then link fails\n– Bob\n* Knows that Alice knows that Bob is responsible\n– Alice\n* Doesn’t know if Bob knows that Bob is responsible\n• 8 Bob sends signal then link fails\n– Bob\n* Knows that he is responsible\n* Doesn’t know if Alice knows he is responsible\n– Alice\nopen atomic ethernet\n59\n* Knows that Bob is responsible\n* Doesn’t know if Bob knows that Bob is responsible\n• 9 Alice receives signal\n– Alice\n* Knows that Bob knows that he is responsible\nAt this point, Alice knows that Bob knows that Bob is responsible,\nand Bob knows that Alice knows that Bob is responsible.\nThe items in red indicate where incomplete common knowledge\nneeds to be resolved over the new path between Alice and Bob.\n8.5.1\nTIKTYKTIK: Feedback from ChatGPT\nThe analysis you provided explores how \"common knowledge\" op-\nerates within the TIKTYKTIK protocol, especially in the context of\nlink failure recovery. The progression of common knowledge is ex-\nplained through several stages, starting with Alice sending a packet\nto Bob and progressing through various acknowledgment signals and\nlink failures.\nKey observations:\n1. Common Knowledge Phases: The stages you outlined show how\nknowledge evolves between Alice and Bob as they interact, espe-\ncially when there’s uncertainty about packet receipt and acknowl-\nedgment. These stages are useful for understanding how commu-\nnication protocols can handle and resolve ambiguities.\n2. Link Failures: You go into detail about different link failure scenar-\nios, from Alice sending the packet before failure to Bob acknowl-\nedging receipt of the packet after a failure. Each failure step in-\ndicates the differing levels of knowledge held by Alice and Bob.\nThese steps, especially when the link fails, highlight the challenges\nof network fault tolerance, and the importance of \"common knowl-\nedge\" for recovering from these failures.\n3. Protocol Behavior with Failure: The distinction between knowl-\nedge of responsibility and knowledge of receipt is well captured.\nThe incomplete common knowledge as the link fails suggests that\nTIKTYKTIK, by adding a second round-trip acknowledgment, re-\nsolves uncertainties that could otherwise hinder recovery.\nSuggested Refinements:\nClarity: Consider rephrasing the stages of knowledge with more em-\nphasis on the protocol mechanics and timing of messages. It could\nbe helpful to lay out the flow of the protocol in a diagram or a\nclearer timeline to illustrate the evolution of knowledge.\nopen atomic ethernet\n60\nLink Failures and Recovery: While the failure scenarios are well outlined,\nyou could further enhance the analysis by providing examples of\nreal-world failure cases and how TIKTYKTIK compares to other\nprotocols in handling these failures. For example, you could con-\ntrast how TCP handles packet loss versus how TIKTYKTIK’s multi-\nstep acknowledgment approach helps resolve knowledge gaps.\nMathematical Notation: If possible, you could introduce formal mathe-\nmatical notations to express the knowledge states. This would help\nreaders better grasp the protocol’s behavior in a more structured\nform.\n"
  },
  {
    "filename": "SPEC/OAE-Spec-Full.pdf",
    "content": "S A H A S M U N A M A L A , PAU L B O R R I L L\nO P E N AT O M I C\nE T H E R N E T\nO P E N C O M P U T E P R O J E C T – O A E W O R K S T R E A M\nContents\n1\nPrinciples of Operation\nRcv\nSnd\nSnd\nRcv\nBob\nAlice\nGreen: Forward Evolution\nBlue: Reverse Evolution\nForward Progress (+1)\nReverse Progress (-1)\nTernary Logic Link\nEquilibrium = 0\nFigure 1.1: Two CELLs and a LINK with\nConserved Quantities (CQ) in dynamic\nequilibrium (Alternating Bit Protocol),\nepistricted with Ternary Logic\n1.1\nSymmetric Reversibility\nThis protocol is symmetric and reversible. Asymmetry occurs when\none party becomes the INITIATOR, and the other party becomes the\nRESPONDER. When the responder is complete and closes the transaction\nwith the sender, the LINK returns to the equilibrium state. There is\nno need for counting protocols. Accounting of Shannon information\nis how far we deviate from equilibrium, and what precisely is needed to\nbring it back.\n1.2\nAtomicity and Causal Determinism\nTo begin and remain open, this protocol\nis based on the earliest known prior art\n[Bartlett, Lynch & Metcalfe]\nCausal operators follow a mathematical framework of invertibility\nand an equilibrium state (§). Equilibrium is maintained in the LINK\nthrough continually circulating tokens in the PHI layer, to maintain\nliveness, keeping LINKs in a state of preparedness for transactions.\nThis mathematical symmetry is reflected\nthroughout the architecture RISC-like\nradical minimalist design.\n1.3\nShift from promiscuous Bandwidth \"rate\" to\ncausal Interaction \"rate\"\nInitiators Flow Frames (without stopping), to responders. Responders\nflow responses (without stopping) back to initiators.\n1.4\nRace Conditions and Conserved Quantities\nFor short-range ≤1m links, intrinsic\n(internal ASIC or FPGA) rates of the\nSerDes dominate, making cable propa-\ngation ‘time’ and RTT irrelevant because\nthe occupation length of the packet\nexceeds the length of the wire.\nWith appropriate buffering and pipeline\nmanagement,\nmaximum\nEthernet\nthroughput\nbecomes\nachievable,\nstrongly favoring short-range intercon-\nnects for high-performance and ultra-\nlow-latency Ethernet.\nwhile providing\nreliable (ACK/NAK) transfers ?\nAlice may initiate new transactions when she (a) owns the token, and\n(b) has that token in her possession in the alternating message proto-\ncol. The other party (Bob) becomes the responder, as if the token were\nborrowed. All protocol interactions must be paired (c.f. queue pairs,\nprocess pairs, or rpc pairs in other protocols).\nopen atomic ethernet\n2\nAtomic Ethernet is fully reversible; on any error the receiver can\nreverse the transfer of a token returning ownership, and return re-\nsponsibility for correct operation to the initiator (e.g. Hardware Error,\nProtocol violation, Software Error or resource exhaustion error).\n1.5\nFixed size Slots, Perfect Information Feedback\nBy returning the first (context) slice (with minor rewriting rules), we\ncan Achieve Perfect Information Transfer\n“In Information Theory Terms, those\nchannels are modeled as channels with\nperfect information feedback”. [Abram-\nson, 1973]\nWe distinguish between Shannon Slots (in the FPGA registers), and\nbits on the wire slots. The rate (FPGA clock) is limited by the ability\nto \"close timing\" within the chosen FPGA Clock.\n2\nBits and Bytes\n2.1\n64-Byte Record\nSlice 1 (8 Bytes)\nSlice 2 (16 Bytes)\nSlice 3 (24 Bytes)\nSlice 4 (32 Bytes)\nSlice 5 (40 Bytes)\nSlice 6 (48 Bytes)\nSlice 7 (56 Bytes)\nSlice 8 (64 Bytes)\nFigure 2.1: 64-Byte Record. 8 × 8 byte\nslices, pre-emptible by responders\nFrame size of 64 Bytes. Follows a log2 increase in slot size. The first\nslot (Context) corresponds to the arrival of the first slice off the bits on\nthe wire. Remaining slots follows a Hadamard multiple (1, 2, 4, or any\nmultiple of 4 slices).\n2.1.1\nCONTEXT Processing : From the Inside Out\nSlice 1 [8 Bytes LINK Context] Protocol <RTL>\nSlice 2 [8 Bytes CELL Context] Context] <FSA> <Linear Algebra>\nSlices 3-4 [16 Bytes TILE Context] <State Machines><Petri-Nets>\nSlices 5-8 [32-Bytes ] ULL App PAYLOAD> <Address Bridging>\n2.1.2\nProtocol hierarchy: Four levels of Reversibility:\n• Context Slice Reversibility\n• Shannon Information (Operand Zone A in Serdes)\n• Spekkens Knowledge (Operand Zone B FPGAs, 2-3 clock cycles in)\n• Metcalfe Semantics (Operand Zone C in FPGA, 5-8 clock cycles in)\n2.1.3\nExtended Addressing Modes for Legacy Compatibility\nTo guarantee that no information is lost1the slots must be fixed size.\n1 All distributed systems need transac-\ntions.\nEven applications that run on a\nsingle (multicore) machine need them. If\nit runs in the cloud, it needs a transac-\ntional infrastructure underneath.\nPCIe and CXL attempt to transfer 64 bytes minimum. This makes the\nlatency (occupation time on the wire) too long for ULL applications.\nInstead, we propose a minimum of the first slice (Protocol – Context).\nOptional second slice (Reliability/Recoverability). The rest is payload\nfor local Ultra-Low-Latency (ULL) Transactions.\nContext (Slice 1 [0..7] 8 Octets)\nOperand Zone A  (Slice 2 [8..15] Octets)\n Operand Zone B (Slices 3-4 [16..31 Octets)\nOperand Zone C (Slices 5-8 [32-64 Octets])\n64 Bits\nArrival order of slices in SerDes\nFigure 2.2: Slice Arrival order (Temporal\nIntimacy Depth)\nMode 1 - N2N Neighbor Self-Addressing\nMode 2 - Ethernet MAC Addressing\nopen atomic ethernet\n4\nMode 3 - 32-Bit IP Addressing\nMode 4 - 128-Bit IP Addressing (Container virtual addresses?)\nMode 5 - 10-Bit Cluster Addressing 12-bit VLAN Addressing.\nModes 6..8 - Reserved\nMode 7 - Reserved\nMode 8 - Reserved\n2.1.4\nFlow Transactions\nOperator (4B)\nPayload  (4B)\n64-bits (8B)\n1 Slice\nFigure 2.3: 1 Slice Flow Subtransaction\nULL protocol designers play around with 32 bits as the minimum unit\nof transactional transfer, but experiments demonstrate the difficulty\nof making this consistently reliable i; the general consensus is that\nmodern SerDes’ work best with ≥64 bit (8 Byte) slices/flits. Ethernet\nhas a minimum frame size of 64 bytes (although only 42 bytes were\navailable for the payload).\n2 Slices\nPayload  (12B)\nOperator (4B)\nOperand\nFigure 2.4: 2 slice Flow SubTransaction\nWe therefore choose a fixed 64 Byte frame for the Shannon Slots, but\nmake them pre-emptable so that even the minimum size frame does not\nneed to occupy space on the wire, increase latency, or FPGA processing\nsteps, when the receiver has something more important it wishes to\nsend (e.g. local status messages sent in the background can be pre-\nempted, giving way to a two phase commit (2PC) transaction).\n4 Slices\nPayload  (28B)\nOperator (4B)\nOperand\nFigure 2.5: 4 4 slice Flow SubTransaction\nwith 28B payload (operand)\nSome transactional systems are sensitive to making transactions re-\nliable, but don’t mind missing events, such as highly perishable market\ndata. We might call these one-phase commit (1PC) transactions. These\ncan be made to flow at maximum line rate, even though each individ-\nual slice is being acknowledged. This is particularly important in HFT\nfor example.\nWe therefore provide the following “flow\" transactions in the en-\ncoding scheme:\nPayload  (60B)\nOperator (4B)\n8 Slices\nOperand\nFigure 2.6: 1 × 8 slice Flow Transaction\nwith 60B payload\n2.1.5\nBack Propagation Encodings\nThis encoding scheme (with slice acknowledgements), guarantees com-\nmon knowledge in a flow of transactions, and their backpropagation\npacked into a single frame. Examples shown here include:\n1. One Flow Transaction in with 4B payload in a single slice (addi-\ntional encoding in TX beats:\n01 I intend to send only one slice.\n10 I intend to send 2 slices, count down from there in replies\n11 I intend to send 4 slices, count down from there in replies\nOperator (4B)\nPayload  (4B)\nOperator (4B)\nPayload  (4B)\nOperator (4B)\nPayload  (4B)\nOperator (4B)\nPayload  (4B)\nOperator (4B)\nPayload  (4B)\nOperator (4B)\nPayload  (4B)\nOperator (4B)\nPayload  (4B)\nOperator (4B)\nPayload  (4B)\n8 Slices\n64-bits (8B)\nFigure 2.7: 8 independent Flow Transac-\ntions in a one frame\n2. One Two Slice Flow Transaction context with 12B of Payload\n3. One Four Slice Flow Transaction context with 28B of Payload\nopen atomic ethernet\n5\n4. Eight one-slice Flow Transactions context with 60B of Payload\n2.1.6\nMixing and Matching Flow Transactions\n2.1.7\nTwo 4 slice Flow Transactions\nOperator (4B)\nPayload \nPayload  (28B)\nOperator (4B)\nPayload  (28B)\nOperator (4B)\nOperand\nOperand\n8 Slices\n64-bits (8 Octets)\nFigure 2.8: 2 × 4 slice Flow Transactions\nYou can also mix them in the same frame, but remember, they can\nonly be used for One-Phase-Commit (1PC) in a single stream of trans-\nactions. This is because 1PC requires only one \"round trip\", whereas\n2PC requires two round trips (although this scheme can be made to\nwork for 2PC, and perhaps 4PC, but they have not yet been tested).\n2.1.8\nFour 2 slice Flow Transactions\nPayload  (12B)\nOperator (4B)\nOperand\nPayload  (12B)\nOperator (4B)\nPayload  (12B)\nOperator (4B)\nPayload  (12B)\nOperator (4B)\nOperand\nOperand\nOperand\n8 Slices\n64-bits (8 Octets)\nFigure 2.9: 4 × 2 slice Flow Transactions\n2.1.9\nEight one-slice Flow Transactions\n2.1.10\nMixture of different Flow Transactions\nPayload  (28B)\nOperator (4B)\nOperand\nPayload  (12B)\nOperator (4B)\nOperator (4B)\nPayload  (4B)\nOperator (4B)\nPayload  (4B)\nOperand\n8 Slices\n64-bits (8 Octets)\nFigure 2.10: One 8 slice Flow Sub Trans-\naction with 60B payload\n2.1.11\nLink Efficiency\nTable 2.1: Transaction efficiency by oper-\nator and operand size.\nFlows Operator Operand Efficiency\n1\n4\n4\n50%\n1\n4\n12\n75%\n1\n4\n28\n87.5%\n1\n4\n60\n93.75%\n2\n4\n4\n100%\n2\n4\n12\n150%\n2\n4\n28\n175%\n2\n4\n60\n187.5%\n4\n4\n4\n200%\n4\n4\n12\n300%\n4\n4\n28\n350%\n4\n4\n60\n375%\n8\n4\n4\n400%\n8\n4\n12\n600%\n8\n4\n28\n700%\n8\n4\n60\n750%\nopen atomic ethernet\n6\n2.2\nRISC Protocol Design: OPCODE (Information)\nOPCODE\nJAM\nPROTOCOL\nBEATS\nSLICE\nFigure 2.11: One Byte Provides the entry\npoint for an Entire family of Protocols\n2.2.1\nCONTEXT Frame format: First Slice, First Byte: OPCODE\n8SLICE\n11 -- TX Sender Init\n11 -- RX SACK 1 (8B)\n10 -- RX SACK 2 (16B)\n01 -- RX SACK 3 (32B)\n00 -- RX SACK 4 (64B)\n(SLICE, BEATS, PROTOCOL, JAM) provides state encodings for an\nultra-low-latency, hardware-friendly, and atomic transaction-friendly\nÆthernet protocol.\nSupports transactional operations, structured acknowledgments, and\nreversible flow control (causal backpropagation). Instead of positive-\nonly credits, the first hop receiver provides the equivalent of negative\ncredits, to indicate it is returning previously sent frames.\n4SLICE\n10 -- TX Sender Init\n10 -- RX SACK 3 (32B)\n01 -- RX SACK 1 (8B)\n00 -- RX SACK 2 (16B)\n2SLICE\n01 -- TX Sender Init\n01 -- RX SACK 1 (8B)\n00 -- RX SACK 2 (16B)\n1SLICE\n00 -- TX Sender Init\n00 -- RX SACK 1 (8B)\n2.2.2\nnSLICE\nOn cables shorter than the occupation\ntime on the wire, slice acknowledges are\nsent before the receiver sees the whole\nframe – exploiting full concurrency on\nthe transmit/receive channels.\nSet by the Sender to[00] – indicating a new context.\nModified by the receiver Closing the loop: [11]→[10]→[01]→[00]\nEncodes how many slices of the sender’s 64-byte Frame has been\nreceived so far. A 2-bit field with reversed temporal direction to encode\nthe acknowledgment depth in a power of 2 number of slices. This might\nrepresent the trailing edge of a window in a reversible or partially\ncommitted state machine. The naming “SACK” suggests slot or slice\nacknowledgments, as fine-grained positions in the interaction.\n2.2.3\nBEATS\nBEATS\n00 -- TX 1 FRAME (64B)\n01 -- TX 4 FRAMES (256B)\n10 -- TX 16 FRAMES (1024B)\n11 -- TX 64 FRAMES (4096B)\n00 -- RACK 1 FRAME (64B)\n01 -- RACK 4 FRAMES (256B)\n10 -- RACK 16 FRAMES (1024B)\n11 -- RACK 64 FRAMES (4096B)\nEncodes burst sizes TX (forwardproaga-\ntion) and RX (backpropagation) code to\nframe groupings, enabling optimization\nof bandwidth and latency trade-offs.\nDefines a beat-structured flow control mechanism. Sender declares the\nnumber of frames it plans to send advance. The receiver responds with\na corresponding \"slot acknowledgment\". Aimed at reliable, ordered\ndelivery without the need for heavyweight TCP.\n2.2.4\nPROTOCOL\nPROTOCOL\n000 -- Initialization\n001 -- Liveness\n010 -- State Machines\n011 -- RESERVED\n100 -- RESERVED\n101 -- RESERVED\n110 -- RESERVED\n111 -- ESCAPE\nThis field defines the high-level intent of the frame or transaction, by\nthe sender (causal initiator). The 3-bit code is always in the first (con-\ntext) slice of the Frame. Three of the eight possibilities are defined\nin this specification. The remaining ones are reserved for higher level\nprotocols in this standard. Escape will always be available to escape to\nlegacy protocols. This compact opcode space (3 bits) is similar to what\nRISC architectures do. This simplifies logic at the NIC or SmartNIC\nlevel and allows for deterministic dispatch.\nJAM\nABORT/CANCEL\n2.2.5\nPRE-EMPT/JAM\nThe use of “JAM” evokes classic Ether-\nnet collision handling, but here it’s mod-\nernized for transactional cancellation or\nSet by TX to [0]. Set by RX to [0] to accept, and [1] to pre-empt, for\nerror, or to (cancel/rollback the transaction).\nopen atomic ethernet\n7\n2.3\nRISC Protocol Design: LIVENESS (Knowledge)\nProtocol\nLiveness\nState Machine\nTransition\nFirst Slice: CONTEXT (Packet Mission). All\nbits are green (owned and written by Alice)\n2.3.1\nBipartite Link\nThere are exactly two parties on the DAE Link. We could call them\nalice and bob. We prefer to call them self and not self. From Al-\nice’s perspective, she knows her own identify, but she does not know\nthe identity of the party she is communicating with (yet). We aim to\nachieve mathematical precision in our specifications. This will be im-\nportant when we wish to formally verify the scouting, routing, and\ncluster membership protocols. It will be critical also in formally veri-\nfying confinement properties of the trees above.\nThe encoding supports Intanglement (hidden circulating events in-\nternal to the link) and Extanglement (Atomic Token Passing through\nthe link (Newtons cradle). These protocols obey the mathematics of\nmutual information, and provides some of the properties of quantum\nentanglement, such as superposition, conservation of information, and\nno-cloning. We use these properties to provide our protocols with a\nclear notion of simultaneity (through the synchronization of mutual in-\nformation), and guarantee atomicity for transaction protocols through\nconserved quantities which in-turn guarantees exactly once semantics\n(EOS).\nConventional L2 & L3 networks rely on redundancy, repetition and\nrerouting, in multipartite (1:N) relationships.\nWhich was necessary\nwhen information is disseminated (transmitted blindly hoping the re-\nceiver catches it). When information can also be synchronized, by a\nTx/Rx—T/Rx loop on a bipartite Ethernet link, we can employ Pseudo\nEntanglement: A form of temporal intimacy, where bits shared in a\ncirculating frame can exploit the same mathematics, (but not the full\nquantum properties) of Entanglement. This insight allows us to en-\ngineer a clear notion of simultaneity, and exploit a classical version of\nthe no-cloning theorem to achieve the holy grail in distributed systems\nand database isolation: exactly once semantics.\n2.3.2\nLink Engine\nAlternating Causality (AC) is the name we give to the initialization,\nmaintenance and tear down of Common Knowledge (CK) in the Link.\nExperience with modern SerDes designs leads us to an 8 byte slice\narchitecture for a “minimum irreducible” CK protocol. Symmetry de-\nmands that we use half (4-bytes) for alice (what I know about me)\nopen atomic ethernet\n8\nand the other 4-bytes for bob (what I know about you). Three packet\nexchanges get us from initialization (both sides know nothing about\neach other) to the “I know that you know that I know” (IKT YKT IKT)\nequilibrium state for basic liveness.\nIt takes a while to gain an intuition\nfor this issue of causality, based on the\nphysics. For now, please accept that this\nis way of doing things is essential and\nenables a rich set of transaction types to\nbe built on top, all with immunity to link\nhazards.\nWe don’t use classical (increment only) clocks, counters, or timers in\nthe link. Instead, we use balanced ternary arithmetic [1] The digits of\na balanced ternary numeral are coefficients of powers of 3, but instead\nof coming from the set 0, 1, 2, the digits are -1, 0 and +1. They are\nbalanced because they are arranged symmetrically about zero.\nWe\nuse this symmetry to manage the direction of causality (is alice the\ninitiator of causal flow sending tokens to bob, or the receiver in causal\nflow receiving tokens from bob?). This becomes important as we go\nup the protocol stack and construct reversible subtransactions.\nWe extend the simple ternary arithmetic with plus and minus zero.\n-1,-0,+0,+1. This enables the protocol to differentiate between the posi-\nbits and negabits [2], with an ancilla control over the intended direc-\ntion of the next operation (positive or negative). This is used to control\nthe direction of the state machine when recovering from errors.\nIntanglement is enabled by reserving 4 bits in the frame for CK (2\nbits for Alice, 2 Bits for Bob). One message will let Bob know about\nAlice. A second message lets Alice know that Bob knows, the third\nmessage lets Bob know that Alice knows that Bob Knows, consistent\nwith both Moses and Halpern version of CK, and the Spekkens Knowl-\nedge Balance Principle (KBP). Time, inside the link moves forward\nwhen packets arrive. Time moves backwards when packets depart. It\ndoesn’t matter how many times a packet bounces around, time goes\nforward only when it is received by one end of the link and it stays (is\nabsorbed). Information is then turned into Knowledge.\nIn a similar way to two phase locking, Link CK can be extended\nfrom 2 Ternary bits (Trits) to any number. Since we are using 2 binary\nbits to encode one Trit, we posit that the set of 2-message exchanges\nto synchronize them is 1, 2, 4 and any multiple of 4. This observation\ndrives the encoding for the State Machine Engine, Described below.\nOur Protocol is based on Reversible Computing.\nProtocol\nLiveness\nState Machine\nTransition\nFigure 2.12: First Slice: CONTEXT. Least\nsignificant 32 bits of transmitted packet.\n2.3.3\nSlice Engine\nThe core of the Æ protocol is the Slice Engine. The first slice (or pre-\nframe slice) determines the packet mission, and carries the alternating\ncausality for the Link State Machine (LSM).\nEach 64-bit slice represents an atomic delivery of bits on the wire\nfrom the SerDes. Typically 2 slices will be sent back to back and the\nopen atomic ethernet\n9\nSlice Engine must be prepared to receive both, although the receiver\nmay decide to pre-empt the frame in its immediate response to the\nfirst slice if it wishes to immediately begin a real data or transaction\noperation. The second slice will be on its way, and its Error Detection\nByte must be evaluated before forwarding on other ports (with the\nexception of the port it was received on, which is the entanglement\nmechanism).\nLIVENESS (Knowledge)\nALICE\nBOB\nFigure 2.13: One Byte Provides\nKnowledge\nAlice Token\n8-bits\nBob Token\n4-bits\n4-bits\nAlice \nToken\nBob \nToken\n2-bits\n2-bits\nFigure 2.14: First Rewriting Rule. Alice\nOwns and possesses Context Slice\nThe first slice completely defines the rest of the frame. There are\n4 fields: PROTOCOL, LIVENESS, STATE, and TRANSITION. This is\n“reflected” from the upper half to the lower half by the receiver, so\nthat only the lower 32 bits are modified, and the upper 32 bits remain\nunmodified.\nThe PROTOCOL Byte defines the “mission” of the packet. What each\nside of the link needs the other side to know about the current frame.\nLIVENESS defines the Temporal Intimacy of the link — whether events\non both sides of the link are directly connected or not.\nSTATE Defines which state machine is currently in use. Can be used\nas a sanity check in conjunction with Protocol.\nTransition Defines\nwhich state in the state machine we are in, and which direction we\nare going (forward or reverse).\n2.3.4\nGeneral Principles\nLinks are constantly interacting, at the slice level, instead broadcast-\ning entire frames (or sets of frames) imposing on the other side and\nhoping they catch the bits. This provides opportunities for error detec-\ntion and correction that would otherwise require ECC and FEC. The\ntheory behind this is described in detail in the document “Shannon-\nInteraction-Machine”.\nThe first 4 slices are dedicated to Theseus (scouting protocols). The\npayload (slices 4-7) contain the Theseus Opcode and parameters —\ninstructions to the scout, including what to do if it encounters an ex-\nception (a software or hardware hazard).\nWhen the protocol type is Ariadne (groundplane/trees) the last 4\nslices (payload) contains tree-building instructions, such as the CellID\nof the originator, and the CellID of the Deputy (one hop away from\nroot). This becomes a complete specification for dissemination of the\ntree without unnecessarily revealing secrets which need to be kept\nlocal (confined).\nAnother protocol type is Icarus (legacy connections to the outside\nworld). This represents a more heavyweight protocol which provides\nopen atomic ethernet\n10\na formally verified TPI (Transaction Processing Interface), which pro-\nvides significant guarantees, but with costs.\n2.3.5\nGeneral Frame Format\nB1\nB2\nB3\nB4\nB5\nB6\nB7\nB8\nS1\nProtocol\nLiveness\nState Machine\nTransition\nProtocol\nLiveness\nState Machine\nTransition\nS2\nOperand 1 (2nd Slice)\nS3\nOperand 2 (3rd/4th Slice)\nS4\nS5\nOperand 3  (5th through 8th Slice)\nS6\nS7\nS8\nThis protocol is symmetric. We describe all operations from the per-\nspective of ALICE, with responses from BOB.\n2.3.6\nError Detection and Correction\nThe transmitted first (context) slice is reflected by the receiver back\nto the transmitter – this Perfect Information Feedback [Ref] means that\nthe context byte does not need additional error detection codes such as\nChecksums, CRC or FEC. This is especially true with flow transactions.\nHowever, the rest of the payload is under the complete control of\nthe application, and the Application can append (within the available\nblocks) any coding scheme it wishes to ensure that the data arrives in-\ntact and untampered with. This will often mean that the senders and\nreceivers will have pre-arranged cryptographic keys which allow them\nto manage the entropy and cryptographic strength of the authentica-\ntion.\n2.3.7\nNo EDC or FEC\nEach side of the link maintains two EPI (epistricted) registers : the last\nSee Quantum Ethernet\nslice sent out, and the last slice received. The sender “owns” the lower\n32 bits, and preserves the upper 32 bits. When slice 1 is received, the\nupper 32 bits are swapped with the lower 32 bits. This preserves the\nsymmetry of the protocol, and clearly delineates the causal initiator\nregister field ownership in addition to causal ownership.\nopen atomic ethernet\n11\nThis provides the first level of error detection: the Initiator has Per-\nfect Information Feedback (PIF) and sees. exactly what the receiver\nsees, and compare it to what was sent, And if they don’t agree, declare\nan error and proceed with mitigations to get the link back in sync\nagain.\n2.3.8\nEpistricted registers\nImagine two vectors [abcd] one for Alice and one for Bob. A 4 x 4\nmatrix has 16 slots, which has 216 = 65, 535 possible states. However,\naccording t o the Spekkens Toy model applied to FPGA Registers, there\nare only 12 ’disjoint’ (6 for Alice and a complimentary 6 for Bob).\nInstead of trying to build a EDD/EDC code, we check only the disjoint\nstates by combining them into one register and sending them back and\nforth in the context frame.\n2.3.9\nOVERVIEW\n2.3.10\nProtocol Overview\nTRANSACTION FABRIC: A separate compute realm, sandwiched\nbetween the CXL bus and Ethernet, to support database semantics.\nWe eliminate CAP Theorem tradeoffs, by providing the illusion of\nan unbreakable network: detecting, isolating and healing failures\nfar faster than protocol or application stacks using traditional time-\nouts and retries.\nTHESEUS: Ethernet-based scouting protocols explore local environ-\nments to discover and bring back knowledge of resources, con-\nstraints, and topologies in local (Chiplet) environments. THESEUS\nsilently monitors local connectivity, raising alerts when links be-\ncome flakey or server software hiccups.\nARIADNE: Ethernet based routing protocols dynamically construct\nand tear down communication graphs for consensus, load balancing\nand failover in global (rack-scale) environments. Enables: observ-\nability on demand, fault isolation and distributed debugging.\nICARUS: Connects the secure internal world of the Transaction Fab-\nrix with the hostile external world of legacy systems and networks;\nusing compositional (zero knowledge) techniques: formally verified\nAPIs, comprehensively tested implementations.\nLABYRINTH: A simulator driven toolset for Chiplet based micro-\ndatadatacenters.\nBased on algorithms whose assumptions about\ncausality go beyond simplistic notions of time. We empower dis-\ntributed system developers with formally verified rules and FPGAs\nto execute Reversible Subtransactions ‘invisibly’ and ‘indivisibly’ in\nopen atomic ethernet\n12\nthe Transaction Fabrix.\n3\nCells and Links\nCELLs and LINKs are fundamental elements. LINKs are bipartite causal\nrelationships connected over physical cables (backplanes, coax, fiber).\n3.1\nInitial Discovery\nFigure 3.1: A Link yet to be discovered,\nor a flakey link that need to be repaired\nCELLs discover connections ∃xist on each of their ports. For connections\nthat once existed (which may have been remembered from previously\nbeing powered up), we will find it impossible to tell whether we are\nbeing woken up for the 1st time, or the Nth time*.\n*Sleeping Beauty paradox: Veritasium:\nThe Most Controversial Problem in Phi-\nlosophy\nSingle Links are subject to partial or total failure.\nAlthough net-\nworks use the word ‘partition’, for example in the CAP Theorem?, this\nconcept is inappropriate except in the single LINK case, when there’s\nno communication with the other side; the causal universes** are now\n**Quantum Compatible Interpretation\nisolated from each other.\n3.2\nIt takes Two to Tango, and Three to Party\nBecause a single link between Alice and Bob can be causally dis-\nconnected by real-world, permanent or intermittent failures, an alter-\nnative: statistically–independent–failure–path is necessary, to recover\nfrom LINK Failures. This is the heart of the Æ ATOMICITY claim: A local\n(one hop LINK) TRIANGLE is the minimum necessary. See TRIANGLE\nClocks later in this specification.\nFigure 3.2: It takes three to party. Links\nneed an alternate path. This won’t work\nover a Switched (Clos) Network.\n3.3\nAlice Bob, and The role of Charlie\n3.4\nGraph Aware Determinism\nWhen treating the “Network” as an opaque cloud, it’s easy to underes-\ntimate how varied network partitions when link failures are asymmet-\nrical: A can see B, but B can’t see A. In a 4 node setup, there are over\n1295 potential partitions, and a flaky network can reproduce them all.\nopen atomic ethernet\n14\nFrom a distributed systems (event ordering in a cluster) as an avail-\nability equation, we can easily overestimate how reliable they are, by 3\norders of magnitude.\nLink failures are invisible (hidden) in a Clos. They are 100% Visible\nto us in a local graph of triangular relationships.\nAnd that’s only the clean (binary) binary failures. Real system flakey\nconnections are much worse.\n3.4.1\nTransactions need a coordinator?\nThe Æthernet protocol is designed to be exquisitely sensitive to packet\nloss and corruption We monitor, detect, diagnose link failures, and\nrecover reversibly and automatically.\n3.5\nFault Detection Model\nBenefits include (i) Shorter packets and\nmore effective use of bandwidth, (ii)\nmore complete coverage of possible fail-\nure modes. (iii) Guarantees at least the\nfirst slice is perfect (matches what the\ntransmitter knows they sent).\nAE-Links present two major differences to the conventional FEC think-\ning in today’s Ethernet, which exploits the physics from 25Gb/s to\n1.6Tb and beyond:\nPerfect Information Transfer (PIF) Æ-Links use Back-to-Back (B2B) Shan-\nnon Links, where the receiver returns the first 8-byte slice of each\n64-Byte packet to the transmitter. This “here is what I heard you\nsay\" ( Perfect Information Transfer (PIF)?\nEpistricted Registers (EPI) Borrowing from the Spekkens’ toy model for\nquantum entanglement, we narrow down the possible entangled\nstates to a vastly smaller set of possibilities, using the model de-\nscribed in Quantum Ethernet?.\n3.6\nFailure Model\nConsider a network of n nodes connected by undirected Ethernet links.\nEach link can be in one of four independent reliability states, where\nΣ = {00, 01, 10, 11},\n11 means the link works in both directions, 10 or 01 means it works in\nonly one direction, and 00 means it is broken in both directions.\n3.7\nLink count\nBecause every node may attach to at most eight neighbours (an octava-\nlent mesh), the number of physical links is\nL(n) = min\n\b(n\n2), 4n\n\t =\n\n\n\n(n\n2),\nn ≤9,\n4n,\nn ≥9.\n3.8\nReliability configurations\nEach link chooses a state from Σ independently, so the total number of\nconfigurations is 4 L(n). Exactly one of these is fully healthy (all links\nopen atomic ethernet\n15\nin state 11), hence\nFailureModes(n) = 4 L(n) −1.\n3.9\nEnumerated results for 2 ≤n ≤20\nn\nL(n)\nFailure modes 4 L −1\n2\n1\n3\n3\n3\n63\n4\n6\n4 095\n5\n10\n1 048 575\n6\n15\n1.074 × 109\n7\n21\n4.398 × 1012\n8\n28\n7.206 × 1016\nTable 3.1: Failure-mode counts for an oc-\ntavalent mesh with n nodes.\n3.10\nReliable, Deterministic Atomicity (RDA)\nReliable, Deterministic, Atomicity (RDA) is achievable on an AE-LINK,\nAll or nothing multicast token transfer\nacross all observers.\nas long as the Shannon Slots are continuously reconciled on both sides\nof the link by atomic token exchanges.\nHowever, a single link can\nbreak. This is why a 3rd party in the triangle (Carol (causal arbiter) or\nCharlie (causal coordinator) is necessary.\n3.11\nProblem recap\nA fully connected network of n = 4 nodes has\nL =\n\u00124\n2\n\u0013\n= 6\nundirected Ethernet links.\nEach link independently assumes one of four reliability states\nΣ = { 00, 01, 10, 11 }.\n3.12\nCorrect failure-mode count\nThe total number of distinct network configurations is\n4 L = 46 = 4096.\nExactly one configuration represents the perfectly healthy network\n(all links working in both directions) therefore the number of failure\nmodes is\n46 −1 = 4095.\n3.13\nWhere the earlier 1295 came from\nThe earlier calculation reversed base and exponent, using 64 instead of\n46:\n64 −1 = 1295,\nwhich under-counts the possibilities because it treats the links as the\nalphabet size and the state space as the exponent.\nopen atomic ethernet\n16\nMethod\nExpression\nCount\nCorrect (stateslinks)\n46 −1\n4095\nEarlier mis-step (linksstates)\n64 −1\n1295\nTable 3.2:\nFailure-mode counts for a\n4-node (6-link) fully connected network.\n3.14\nThe Blast Radius of Link Failures in a 4-cell\n(4-node) system\n3.14.1\nLINK initialization\nAlice and Bob have no knowledge of each other prior to being powered\nup for the first time. They discover each other by sending and respond-\ning to BEACONs on each of their 8 ports {n, ne, de, se, ds, sw, dw, nw}.\nBEACONs are questions: “is anyone there?” They assume neighbor CELLs\nhave SerDes’ that can send & receive @ 25Gb/s (defined by local clocks,\nin their frame of reference). Photon cavities (copper and fiber) are ex-\npected to be in a fixed frame of reference relative to the SELF CELL.\nMobile entities may need to adjust this expectation based on the range\nof doppler shifts expected by CELLs in motion, for example, in moving\nvehicles, cars, planes, and spacecraft.\nAlice sends BEACONs with an exponential backoff: every 1µs, 2µs,\n4µs, 8 µs, etc. The policy for a maximum interval is determined by the\nenvironment, e.g. within a datacenter, one might wish to send BEACONs\nevery second, whether you need to or not. This represents a balance\nbetween infrastructure liveness and needless energy dissipation.\n3.15\nShort-Range ANT (Local) Scouting\nOnce a link has been established, they are recorded in the local knowledge\nof the cell, and used as a baseline for future algorithmic and policy de-\ncisions.\nImmediately after establishing a reliable connection, CELLs may emit\nANT-SCOUTS to explore their local environment. These are ANT’s, which\nobey an initial source routing algorithm, but when encountering a\nfailed or disconnected port in another cell, respond with either clock-\nwise, anticlockwse packet forwarding, which keeps the scout local, or\nrandom, with a hopcount limit, which allows exploration further afield.\nSee ANT Specification for details\n3.16\nLong-Range BEE (Global) Scouting\nCELLs may also emit BEE-SCOUTS to explore the extremities of their\nenvironment. These are BEE’s which obey only one rule: proceed in\nthe same direction as the radial port. BEE’s emitted on the n port may\nonly go n. BEEs emitted on the se port may only go se. Until they\nencounter a disconnected port, whereupon they execute a return path\nopen atomic ethernet\n17\nalgorithm, accumulating information at each CELL and returning it to\nthe root.\nSee BEE specification for details\n3.17\nANT Specification: Triangle Packet Clocks in\n3 × 3 Tiles\nFigure 3.4: Race-Free Triangle Token\nPacket clocks are initiated by the coordinator, on any of it’s active links.\nThe ANT (source routing) algorithm goes out on any port, and are\nprogrammed to turn left or right at the first available active port. The\nconvention is turning right makes it go clockwise, and turning left\nmakes it go antilockwise, but this is an artificial distinction. As with\nreal ants, they can get lost, and never find their way back to the nest,\nand they die (or return to the nest by inverting their source routing\npaths). This “limited range”, is part of the Security mechanism.\n3.18\nANT Specification: Race-Free Packet Clocks\nin 3 × 3 Tiles\nFigure 3.5:\nSquare Race-Free 1-hop\nClock\nFigure 3.6: Race-Free Anticlockwise\nOnce the cell has discovered it’s local environment, it may establish\npacket clocks. These are ANTs, which go out with a pre-defined pat-\ntern, to return events the cell on a periodic basis. Because there is no\nbackground of time, this system will create events, which are guaran-\nteed to occur without race conditions, but will catastrophically fail if\nthere are an broken links around the circuit.\nFigure 3.7: 2 Circulating Race-free to-\nkens\nPackets clocks may be initiated around the closest (one-hop) cell\ntiles, next closest (two-hop) tiles, furthest (three-hop) tiles. Atomicity\n3.18.1\nANT Specification Building a Compass Clock\n8 physical ports per cell. Inactive ports may be:\n• Failed (out of service)\n• Standby, ready to go\n• Off, saving energy\n3.18.2\nANT Specification: Counter Circulating Race-Free ANTS\nC (Carol, Charlie, Coordinator, Chief) may initiate clockwise, counter-\nclockwise, and/or both at once. Each is exploring the health of the\nconnectivity local to the center cell.\nThis is what ANT Algorithms\n(source routed, or random) tokens.\nPorts at edge of mesh connected back to same cell on a different\nport to traverse routing table 2nd time to create virtual cut-through\ntorus.\nIf the ANT gets blocked, and either runs out of hopcout resource, it\ndoes ‘reverse path forwarding’ back to the C CELL. and reports what\nopen atomic ethernet\n18\nit finds. It can either carry all its state in the packet, or (ror BEEs),\nclean up on its way and erase its footprints in the CELLs it visited.\n3.18.3\n7 x 7 Nodes Packet Clock\nFigure 3.8: Green Packet Rateless Clock\n3.19\nBeyond Packet Clocks\nPacket clocks don’t scale (they are not intended to). Instead, they pro-\nvide circulating logical loops ?. The local system policy will establish\nthe radius limit for local exploration. Everything beyond that is in the\ndomain of the BEE scouts .\nPacket clocks can circulate at any physical hop distance. The one-\nhop agents are described above. The two figures on the right show an\nexample of an ANT which goes two hops, or three hops, before the\nANT turns left or right. This give a CELL the opportunity to explore\nlarger hop distances from the coordinator\n3.20\nPacket Clocks in Larger Tiles\nFigure\n3.9:\n3rd-hop\ncircular\npacket\nclocks. Blue Links Complete\n3.20.1\nBEE scouts\nBEE Scouts explore the boundaries of their environment. The are emit-\nted by the Coordinator, and travel as far as they can in ONE direc-\ntion, {dn,ne,de, se, ds, sw, dw, nw}, and then return on the recipro-\ncal path (Compass-Point vector direction) to inform the hive (root) what\nthey discovered, so the root can build it’s model of the topology, and\nEdge resources to perform their function.\n3.20.2\nN x N Nodes Packet Search Rays (BEEs)\nBEEs are radial distance scouting agents. Single packets that go in\nonly one direction, and when they reach the end (extremities of the\nCellular interconnect) they execute a reverse path forwarding algo-\nrithm, collecting knowledge on their way, delivering this knowledge\nback to the root, whose agent uses the returned information to build\nit’s model of it’s topology and available resources to offer ‘services’ to\nthe applications.\nThese don’t have to be square, or rectangular. BEE algorithms work\non any arbitrary Topology.\nFigure 3.10: BEE Algorithms explore be-\nyond ANT algorithms\nRadial (Ray) source-routed scouts have two parameters (a) which\nport they go out on, and continue indefinitely until they reach a bound-\nary (or exhaust their hop count resource). And then they return along\nexactly the same path, accumulating knowledge of the CELLS on their\nway (e.g. properties of the cell, do they have a CPU, a GPU, an IPU, or\nopen atomic ethernet\n19\nQPU?). Most Bees make it back home to the nest (C) but it is also pos-\nsible for a failure to occur between the outbound BEE and the home-\nbound BEE. In which case the packet try’s to make it’s way to ‘Lost and\nFound’, the control structures identified by the Coordinator to provide\nGEV notification of failures. Lost and Found is most likely to be dis-\ncovered by the one or more of the BEEs. Edge nodes (on the corners\nof the interconnect), will always be able to ‘find’ Lost and Found (and\nother external control paths controlled by monitoring or configuration\nLOGICAL Administrator Agentss ) with a ‘due north or south’ dn,ds,\n‘due-east or west’ de,dw BEE Scout.\n3.21\nDistributed Systems\n3.22\nSet Reconciliation of Shannon Slots\nThe first claim is that a finite and enumerable number of ‘slots’ exist\non both sides of the LINK. In conventional Ethernet, once these slots\nare exhausted (with for example, a timeout and retry, the XPU CELLS\n(SmartNICs) on both sides of the LINK must evict (erase) the infor-\nmation on one side and then the other. This ‘loss of Koherence’ is the\ncentral problem of Distributed Systems. From an information theoretic\n(Back to Back Shannon channel) perspective, this precipitates a ‘smash\nand restart (SAR) of the Shannon Information – the loss of ‘pairing’\nof information. This is described in more detail in the specification of\nback-to-back Shannon Pairs.\nTimeouts and Retries are the root of all evil. Once a Timeout Storm\noccurs, in a switched network, the distributed systems in the Host pro-\ncessor are all broken. Unless RELIABILITY (maintenance of Shannon\nLink Pairing), the ‘global’ illusion of event ordering in distributed sys-\ntems will be lost, and corruption will occur. This is why queue-pairs\nwork in Infiniband/RDMA. This is why information pairing is essen-\ntial, in Tandem’s Process Pairs, and RDMA’s Queue pairs.\nThe whole point of this specification is to engineer a solution, where\nShannon-pairing is never lost, but if it is, a TRIANGLE healing occurs\nlocally, without the need to depend on a switched or router to discover\nand ‘reconverge’ their routing tables, to re-establish the point to point\nconnections over a different paths in the network.\nThe main mechanism to do this is to make the Æthernet Link main-\ntain Koherence, and when loss occurs, a 3rd party (The Triangle rela-\ntionship) can recover with local information only. This makes XPU/S-\nmartNICs, where the recovery algorithms (healing the tree) occur lo-\ncally, instead of waiting for the switched or routed packets (in a sepa-\nrate switched network.\nopen atomic ethernet\n20\nThe original Ethernet was unreliable. This was a mistake. Infini-\nband already proved this, and succeeded both in the trust system\narchicitcts have in the far greater. The unique contributions of this\nspecification is to go (far) beyond Infiniband’s discovery, and recog-\nnize the fundamental simplifications and benefits that Infiniband (and\nToken Ring, Fibrechannel, and Sonet), in creating ‘Race-Free’ proto-\ncols, where distributed systems can guarantee, not just the ‘ordering\nof events’, but the guarantee of recovery of transactional loss in when\nfailures occur in the middle of, say, a 2 Phase Commit.\nÆthernet (Atomic Ethernet) guarantees that Shannon Pairing is never\nlost, and if a link breaks, that the Coordinator (Charlie, Carol, Chief)\ncan recover with TRIANGLE Relationships, far faster than any proto-\ncol stack in the host processor, or in the RMDA message relationships,\nbut then add, on top of this a true ‘atomic’ relationship between CELLS\n(nodes) in a distributed system.\nThe original Ethernet [ref] was designed around a notion of slots.\nThese were ‘time slots’ on an imaginary timeline that each node on\nthe Ethernet Cable, could manage in a half-Duplex way.\nThe new\nnotion is to replace this with circulating tokens, where each slice is\nindependently acknowledged, providing a guarantee of delivery to\nthe NEXT hop in the network.\nThis is achieved with 1PC (one phase commit), where each Ethernet\nPacket (eight slices) are fully acknowledged in each link. The general-\nization of this is to explicitly manage Shannon slots (data structures on\neach side of the link) to maintain Koherence, even when the link fails\n(in one direction, the other direction, or in both directions at once).\nThis can be done (as in Fibrechannel) by arranging the ‘interaction\nprotocol’ to guarantee the pairing of events, and not resort to Timeout\nand Retry (TAR), which causes cascade failures in networks, both large\nand small.\nThis is achieved with the Link Protocol employing the Alternating\nBit protocol, and adding the Bill Lynch ABP reconciliation, with two or\nmore bits instead of the individual 1 bit of alternation, which required\na round trip to guarantee Shannon Slot Pairing.\n3.23\nBiologically Inspired “Scouting” before “Rout-\ning”\n3.23.1\nLocal decisions and emergent global organization\n• Scouting/Discovery Phase: Biologically inspired methods (e.g., ant-\ncolony-inspired or pheromone-based algorithms) often employ “scout”\nopen atomic ethernet\n21\npackets or “explorer” agents that roam the network. These scouts\ncollect local congestion or path-quality information and deposit some\nform of “trail” (akin to pheromones).\n• Emergent Routing Table Updates: Each router or switch updates\nlocal routing information (sometimes called a local “pheromone ta-\nble”).\nOver time, paths that prove consistently “good” get rein-\nforced; less efficient paths fade. This local, probabilistic approach\ncan converge on globally efficient routes with no central coordina-\ntion.\n3.23.2\nRelevance to On-Chip or 2D Mesh Topologies\n• Local Compass Directions: In a regular mesh (e.g., 2D grid) or torus,\neach router has up to 4 (N, E, S, W) or 8 ports (adding NW, NE, SW,\nSE). A biologically inspired algorithm can treat each output port as\na possible “direction of travel.”\n• Natural Fit for Scouting: The local directional structure matches\nhow “ants” or “foraging agents” might look around in each direc-\ntion, choosing a route based on local pheromone levels (akin to local\ncongestion or link utilization).\nThus, the scouting/discovery mechanism is all about gathering lo-\ncal “pathworthiness” data and then directing future traffic toward bet-\nter routes—exactly how a local compass-based system can easily be\nintegrated.\n3.23.3\n2. Bufferless (Hot-Potato) Routing\n3.23.4\nBasics of Bufferless Routing\n• No Packet Buffers (or Very Limited Buffers): In a bufferless architec-\nture, every router typically either immediately forwards or deflects\neach incoming packet. Packets cannot wait in large queues when an\noutput port is congested.\n• Hot-Potato / Deflection Character: When the preferred output port\nis unavailable, the packet is sent out of a different (less ideal) port—“hot-\npotato” style—rather than being buffered.\n3.23.5\nConnection with Biologically Inspired Approaches\n• Continuous Movement: Biologically inspired scouts are already de-\nsigned to wander and discover; in a bufferless system, “wandering”\n(via deflections) is also central. This synergy means a router can ap-\nply a heuristic (like a pheromone table) to pick the “best available\nport” quickly, but if that port is busy, the packet must choose an\nalternate direction.\n• Adaptive Reinforcement Over Time: In a bufferless design, a packet\ncannot linger while waiting for the optimal output. However, lo-\nopen atomic ethernet\n22\ncal “pheromone” or “congestion” metrics can still help route the\nmajority of packets down better ports more often. Over time, high-\ntraffic edges might become less appealing, guiding packets to less-\ncongested directions.\n3.23.6\n3. Deflection Routing\n3.23.7\nHow Deflection Routing Works\n• Forced Misrouting / Deflection: If the desired or minimal-distance\noutput port cannot be taken (due to contention), the router picks\nanother output. The packet may travel away from its ultimate des-\ntination (a “deflection”), but eventually, it should be re-routed back\non track.\n• Common in Low- or No-Buffer Architectures: Deflection routing is\none way to handle resource contention when buffer space is un-\navailable.\n3.23.8\nTying It Back to the Compass Ports (N, E, S, W, NW, NE, SW,\nSE)\n• Local Prioritization: In an 8-port (or 4-port) router, one can define\na strict or heuristic priority among the directions. For example, a\npacket traveling generally “north-east” might prefer the N or E port\nif free; if both are busy, it might deflect NE, or in the worst case,\ndeflect NW or SE.\n• Biologically Inspired Ranking: The “pheromone” concept can be\nused to rank the output directions. The highest “pheromone” port\nis tried first, then so on down the rank.\nThis effectively merges\na local heuristic (pheromone) with forced deflection for whichever\nports remain free.\nIn practice, such a scheme allows packets to “scout” and reinforce\ncertain directions while still ensuring that they never have to wait for\na blocked port.\n3.23.9\n4. Example Flow in an 8-Port Router\n1. Receive a Packet coming in from, say, the south port.\n2. Look Up Destination (or partial coordinate heading). For instance,\nthe packet is trying to reach a node in the north-east region, so N\nor E might be favored.\n3. Check Local “Pheromone” or Routing Table: Suppose the local\npheromone table says port NE is the best guess based on past traf-\nfic patterns.\n4. If NE Port Is Free: Forward the packet NE.\n5. If NE Port Is Busy: Check next best local direction (N, E, or NW/SE\nfallback).\nopen atomic ethernet\n23\n6. If All Preferred Ports Are Busy: Packet is deflected to any open\nport (could be even SW in the worst case).\n7. Local Table Update: The router sees how that choice ended up\naffecting the packet (if it eventually left the region quickly or ended\nup in a congested area). Over time, these experiences feed back\ninto local pheromone levels.\nDespite the forced misrouting (deflections), the biologically inspired\nfeedback approach often keeps net throughput healthy and tries to\navoid systematic congestion “hot spots.”\n3.23.10\n5. Connection with the Literature\n1. 1. Hot-Potato Routing (Deflection Routing):\n• Baran, P. (1962).\nOn Distributed Communications Networks.\nIEEE Transactions on Communications.\n(Early ideas of “hot-\npotato” and distributed routing).\n• Dally, W., & Towles, B. (2004). Principles and Practices of Inter-\nconnection Networks. (Excellent overview of deflection routing\nin modern network design).\n2. 2. Biologically Inspired / Ant-Based Routing:\n• Di Caro, G. A., & Dorigo, M. (1997). AntNet: Distributed stig-\nmergetic control for communications networks. Journal of Arti-\nficial Intelligence Research.\n• Schoonderwoerd, R., Holland, O., Bruten, J., & Rothkrantz, L.\n(1996).\nAnt-based load balancing in telecommunications net-\nworks. Adaptive Behavior.\n3. 3. Network-on-Chip with Deflection/Bufferless Approaches:\n• Moraes, F. et al. (2004). A Low Area Overhead Packet-switched\nNetwork on Chip: Architecture and Prototyping. SBCCI.\n• Fallin, C., et al. (2012). CHIPPER: A Low-Complexity Bufferless\nDeflection Router. HPCA.\nThese resources flesh out how bufferless or deflection routing is\nimplemented (especially in on-chip contexts) and how biologically in-\nspired heuristics can be adapted to local, minimal-knowledge scouting\ndecisions.\n3.23.11\n6. Concluding Remarks\n• Shared Tenets: Both biologically inspired scouting and deflection-\nbased, bufferless routing rest on local decision making. In biolog-\nically inspired schemes, scouting packets “discover” or “reinforce”\ncertain paths. In deflection routing, each router makes a quick (lo-\ncal) decision when a preferred port is blocked, forcing packets to\nkeep moving.\n• Complementary Mechanics: Because biologically inspired “pheromone”\nupdates naturally reflect congestion and path usage, they integrate\nopen atomic ethernet\n24\nwell with a bufferless or deflection style—turning forced misroutes\ninto valuable “exploration” signals that feed back into local heuris-\ntics.\n• Directional Routing: The presence of N, S, E, W (plus diagonals)\nsimply defines how many possible local moves each node (router)\ncan attempt. In 2D meshes or tori, these directions make for a con-\nvenient coordinate system that parallels how ants (or other scouts)\nmight sense local gradients or pheromone intensities in each of eight\ncompass directions.\nOverall, if we combine a scouting mechanism (to adaptively find\nneighbors and good routes) with deflection routing (to handle buffer\nconstraints or high contention), we get a dynamic, emergent routing\nsystem in which packets flow continuously and local updates shape\nglobal traffic patterns in a self-organizing fashion.\nAll this happens without the need for Source/Destination Addresses,\nwhich present severe security problems by exposing the “identity\" of\nnodes making them vulnerable to attack.\n3.24\nFAQ\nQ1 (Alan) What problem are you addressing in the scouting writeup?\nIf it’s discovering routes, it’s not clear to me that ant or bees or even\nboth together do full discovery of the network. In what way are they\nbetter than the flooding algorithm I used?\nA1 This is how to achieve ‘Scale-Independence’ We eliminate the\nneed for every node to do a ‘full discovery’ of the network, which is\nwhat a flooding algorithm would do. ANTs and BEEs explicitly do not\ndo “Global\" routing. This is an extra way to limit the size of the secure\nenclave, and not have it able to connect to the outside world.\n4\nTheory\n4.1\nIntroduction\nIt would be a mistake to assume conventional network concepts and\nterminology that you already know and love will remain unscathed\nin this project. While we have no intention of reinventing the wheel,\nyet some new concepts and terminology will be necessary in order to\nescape the quagmire of incrementalism of the last five decades.\nWe carefully described in four presenta-\ntions why the concept of time is widely\nmisunderstood in the OCP TAP (Time\nAppliance Community). We respectfully\nrequest that you watch those presen-\ntations before insisting on timestamps\nor synchronized time in the context of\nOpen Atomic Ethernet.\nOpen Atomic\nEthernet\n1. The word and the concept of TIME does not appear in this specifi-\ncation. This concept is the largest single source of misunderstand-\ning in computer science today, so we eliminate that first. We replace\nthis with intervals that are defined within sets (not on the real line).\nDefinite Total Order (DTO), Definite Partial Order (DPO), Indefi-\nnite Partial Order (IPO). .\nFormal analysis and connections to the\nliterature will appear in the index.\n2. Claude Shannon described information as surprisal. We will call it\nShanformation in this document to tear everyone away from old\nideas that have been conflated for too long about “bits in memory\nor storage”, hiding its deeper meaning of \"the resolution of uncer-\ntainty\".\n3. We replace conventional notions of Error Detection and Correction\n(ECC, EDC, FEC, Parity, etc.) with a new concept, while not new,\nis widely misunderstood: Common Knowledge.\n4. We replace conventional notions of liveness with a continuously\ncirculating token, within which we define “logical simultaneity\"\n5. We are not shy of delving into Quantum Information Theory or\nQuantum Thermodynamics to find solutions to the problems in\nhardware and software infrastructure.\nTHERE IS NO GLOBAL DRUM BEAT In Episodes 1 through 4 we ex-\npressed doubts about the common belief system of a Newtonian\nview of the world in this community.\nWe showed how to think\nabout race conditions, and why Timeouts and Retries (TAR) are\nopen atomic ethernet\n26\nthe root of all evil. Our conclusion is that Timestamps are an Illu-\nsion. They can’t be fixed by software. The quest for a single, con-\nsistent timeline across distributed systems collides with the reality\nthat physics itself does not provide a universal notion of time—and\nin quantum mechanics (the machine code of our universe), there is\nno consistent causal order at all. We cannot, therefore, rely on this\nillusion of an irreversible drumbeat on an inaccessible “real line” to\nprovide linear time order for events in our networked systems. Al-\nthough timestamps will remain indispensable in engineering prac-\ntice, we must recognize them as approximations rather than abso-\nlutes, and design our systems accordingly.\nEPISODE 1 – What There is no now. You cannot synchronize clocks\nthe way you think. Talk Originally given at the 2023 Asilomar Mi-\ncrocomputer Workshop presented live with Jonathan Gorard. Mo-\ntivation: (1) To get people thinking about the nature of time and\ncausality, as far removed from the Earth (and TAI/GPS) as possible.\n(2) To stimulate “First Principles Thinking” for Distributed Systems.\n• Clocks can be disseminated, but require interaction to be syn-\nchronized:\n• Simultaneity planes don’t exist (except in an empty frozen uni-\nverse) Einstein proved this over 100 years ago Why do we still\nthink we can synchronize clocks?\n• Network Time Protocol (NTP) and Precision Time Protocol (PTP)\nare causal TREES – choose your root, and how you do failover\n• Entanglement and indefinite causal order are the new relativity\n(Not restricted to low relative velocities or atomic scales)\n• We cannot assume spacetime is irreversible and monotonic\n• Irreversibility and monotonicity is in the Eye of the Observer\nEPISODE 2 - Hidden assumptions about causality lead to lost & corrupted data\nWhen we think about clocks as an incrementing number, we are\ncommitting the FITO fallacy – “Forward In-Time-Only” Thinking -\nCounterfactuals, i.e., “events that could have occurred but eventu-\nally did not, play a unique role in quantum mechanics in that they\nexert causal effects despite their non-occurrence”\n• Clock Synchronization Error is indistinguishable from Latency\n• Irreversibility (Monotonicity) is an illusion not guaranteed by\nphysics, unless we build Ancilla to explicitly manipulate causal-\nity\n• Irreversibility and “causal order” are IN THE EYE OF THE OB-\nSERVER—not guaranteed to be consistent across different ob-\nservers\nEPISODE 3 – How a static PTP hierarchy can be made dynamic to support causal failover for distributed systems\nopen atomic ethernet\n27\nIn Episode 1(What) & Episode 2 (Why) we showed how misun-\nderstandings accumulate within a Newtonian framework of time,\nand how this leads to lost transactions and corrupted data. In this\nEpisode we help the audience make the leap from Newtonian Time\n(what we know for certain that just ain’t so) to Post-Newtonian Time\n(relativistic SR/GR, and QM — Indefinite Causal Order (ICO).\n• PTP is widely available in Datacenters, we propose experiments\nto falsify beliefs about Newtonian Time.\n• All is not lost. The excellent engineering behind PTP and PTM,\ncan still be used with a different perspective, by using the clock\nhierarchy to build Causal Trees and reliable failover, to help ad-\ndress race conditions and achieve Exactly Once Semantics\nEPISODE 4 – Why we can’t have nice things in Distributed Systems\n• Instants are meaningless, only intervals (on the same computer/-\ntimeline) are relevant\n• Photons don’t carry timestamps, but timestamps are carried by\nphotons\n• The speed of light is the “pivot” around which time and space\nevolve\n• Timeout and retry (TAR) on different timelines will silently cor-\nrupt data structures\n• Shannon entropy is a logarithm. The logarithm of zero (no infor-\nmation) is minus infinity.\n• Bayesian approaches require a prior belief, which can be un-\nbounded (zero to infinity).\nActually, it’s much worse: can be\n{−∞−1 −0, +0, +1, +∞}. We can’t do Bayesian statistics under\nthose conditions, mathematically, their results are undefined.\n• Shannon Entropy is uncertainty, and the same problem applies\nwhen you apply the set {−∞−1−0, +0, +1, +∞} to Information\nand Entropy p ∗log(p)\n• Measurements “appear” instantaneous because there is no back-\nground of time on which to measure anything. Timestamps don’t\nIt does appear instantaneous to an ob-\nserver,\nbecause when they receive a\npacket (or a photon in a detector), you\ncapture information and turn it into\nknowledge (state in a register you can\ndo something with)\nhelp with causal order.\n4.2\nCommon Knowledge\nIn what follows, assume that node Alice is sending a packet to node\nBob over the single, fallible link between them.\nThe Stop and Wait and alternating bit protocols provide credit based\nflow control using a single round trip.\nBob is free to forward the\npacket as soon as it arrives, but Alice must wait for a signal from Bob\nbefore sending another packet. If the link breaks before Alice gets a\nsignal from Bob, then Alice may forward the packet again, perhaps\nopen atomic ethernet\n28\non another path. This behavior makes exactly-once, in-order delivery\ndifficult to implement.\nTIKTYKTYK is one round trip beyond stop and wait, which pro-\nvides partial common knowledge that aids in recovery from failures.\nBob cannot forward the packet until he receives the signal from Al-\nice that completes the second round trip. A key point is that there are\nmany times when both sides know that both sides know which of them\nis responsible for forwarding the packet. In the other cases, the partial\ncommon knowledge simplifies recovery. Alice and Bob use their par-\ntial common knowledge to ensure that any packet is only forwarded\nonce, which is a key condition for exactly-once, in-order delivery.\nThere is minimal loss in latency, because Bob doesn’t have to wait\nfor the entire packet to arrive before signaling to Alce that the packet\nis arriving. He can do any integrity checks (CRC) while waiting for Al-\nice’s signal. Any loss in latency is compensated for by needing smaller\nbuffers. There is minimal loss in bandwidth because the signal can be\na data packet going in the other direction.\nSometimes links fail silently, which means a signal might not arrive.\nIn those cases, he nodes will need some heuristic to decide when to\nstop waiting and declare the link dead. Fortunately, this heuristic can\nbe purely local because Bob will never get a signal from Alice once\nshe’s decided the link is dead.\nA clock is commonly used for the\nheuristic, but care is needed. For example, if Bob is heavily loaded but\nAlice is not, she might set her timeout to be too short. If the situation\nis reversed, the timeout may be too long. An alternative is for Alice to\ncount the events she receives on her other ports. She can declare the\nlink dead if too many of these events are received before she gets one\nfrom Bob. This heuristic is effectively averaging over the workload of\nall the nodes connected to her, providing a more consistent metric.\n4.3\nTIKTYKTIK\nTIKTYKTIK is like the alternating-bit and stop-and-wait protocols in\nthat receipt of a packet over a link is acknowledged over that link with\na “signal” packet. In that sense, these three protocols implement credit\nbased flow control, which simplifies buffer management and makes it\npossible to not have to drop packets when there is a lot of traffic.\nTIKTYKTIK adds a second round trip, which provides partial com-\nmon knowledge helpful for recovery from link failures. This document\nwalks through TIKTYKTIK showing how that common knowledge is\nused. First look at the various stages of common knowledge as the\nprotocol runs without failure when Alice sends a packet to Bob.\nopen atomic ethernet\n29\n1. Alice sends the packet to Bob\n• Alice doesn’t know if Bob received the packet\n• Bob does not know the packet exists\n2. Bob receives the packet\n• Bob knows that Alice doesn’t know that Bob received the packet\n3. Bob sends a signal to Alice\n• Bob doesn’t know if Alice knows that Bob received the packet\n4. Alice receives the signal\n• Alice knows that Bob received the packet\n• Alice knows that Bob doesn’t know that Alice knows that Bob\nreceived the packet\n5. Alice sends the signal\n• Alice doesn’t know if Bob knows that Alice knows that Bob re-\nceived the packet.\n6. Bob receives the signal\n• Bob knows that Alice knows that Bob received the packet.\n• Bob doesn’t know if Alice knows that Bob knows that Alice\nknows that Bob received the packet.\n• Bob can forward the packet\n7. Alice receives the signal\n• Alice knows that Bob knows that Alice knows that Bob received\nthe packet.\n• Alice can delete her copy of the packet.\nThis common knowledge is not needed if links never fail. Alice\ncould delete the packet as soon as she sent it, and Bob could forward\nit as soon as he received it. That’s what current systems do and why\nit’s so hard to recover from a link failure.\nA data packet can serve as a signal.1 Links can fail in a number of\n1 A data packet can serve as a signal.\nways. If they physically break or are unplugged, the PHY detects the\nlost of electrical signal and informs the higher layers. Links can also\nfail silently, such as when the NIC misbehaves. They can also fail in\none direction but not the other. Silent failures can be detected in these\nprotocols because a signal will never be received in either direction. In\nthat sense, there is a level of common knowledge on a link failure. In\nwhat follows, I’ll describe what happens when Alice wants to send a\npacket to Bob, but the link fails at various steps of the protocol. The\nlink is no longer used once one of these failures occurs. (The link can\nbe used later after re-initializing the connection.)\n• 1 Alice has a packet to send when link fails\n– Alice\n* Knows Bob doesn’t have the packet\n* Knows Alice is responsible for it\n– Bob\nopen atomic ethernet\n30\n* Doesn’t know the packet exists\n• 2 Alice sends the packet to Bob then link fails\n– Alice\n* Doesn’t know if Bob got the packet\n* Knows that Bob knows Alice is responsible\n– Bob\n* Doesn’t know that the packet exists\n• 3 Bob receives the packet then link fails\n– Bob\n* Knows that Alice knows that Alice is responsible\n– Alice\n* Alice doesn’t know if Alice or Bob is responsible\n• 4 Bob sends signal then link fails\n– Bob\n* Doesn’t know if Alice got the signal\n* Doesn’t know if Bob or Alice is responsible\n– Alice\n* Alice doesn’t know if Alice or Bob is responsible\n• 5 Alice receives the signal then link fails\n– Alice\n* Knows that Bob is responsible\n* Knows that Bob doesn’t know he is responsible\n– Bob\n* Doesn’t know if Alice got the signal\n* Doesn’t know if Alice knows that Bob is responsible\n• 6 Alice sends signal then link fails\n– Alice\n* Knows that Bob is responsible\n* Doesn’t know if Bob knows he is responsible\n– Bob\n* Doesn’t know if he’s responsible for the packet\n• 7 Bob receives the signal then link fails\n– Bob\n* Knows that Alice knows that Bob is responsible\n– Alice\n* Doesn’t know if Bob knows that Bob is responsible\n• 8 Bob sends signal then link fails\n– Bob\n* Knows that he is responsible\n* Doesn’t know if Alice knows he is responsible\n– Alice\n* Knows that Bob is responsible\n* Doesn’t know if Bob knows that Bob is responsible\n• 9 Alice receives signal\nopen atomic ethernet\n31\n– Alice\n* Knows that Bob knows that he is responsible\nAt this point, Alice knows that Bob knows that Bob is responsible,\nand Bob knows that Alice knows that Bob is responsible.\nThe items in red indicate where incomplete common knowledge\nneeds to be resolved over the new path between Alice and Bob.\n4.4\nTIKTYKTIK: Feedback from ChatGPT\nThe analysis you provided explores how \"common knowledge\" op-\nerates within the TIKTYKTIK protocol, especially in the context of\nlink failure recovery. The progression of common knowledge is ex-\nplained through several stages, starting with Alice sending a packet\nto Bob and progressing through various acknowledgment signals and\nlink failures.\n4.4.1\nKey observations:\n1. Common Knowledge Phases: The stages you outlined show how\nknowledge evolves between Alice and Bob as they interact, espe-\ncially when there’s uncertainty about packet receipt and acknowl-\nedgment. These stages are useful for understanding how commu-\nnication protocols can handle and resolve ambiguities.\n2. Link Failures: You go into detail about different link failure scenar-\nios, from Alice sending the packet before failure to Bob acknowl-\nedging receipt of the packet after a failure. Each failure step in-\ndicates the differing levels of knowledge held by Alice and Bob.\nThese steps, especially when the link fails, highlight the challenges\nof network fault tolerance, and the importance of \"common knowl-\nedge\" for recovering from these failures.\n3. Protocol Behavior with Failure: The distinction between knowl-\nedge of responsibility and knowledge of receipt is well captured.\nThe incomplete common knowledge as the link fails suggests that\nTIKTYKTIK, by adding a second round-trip acknowledgment, re-\nsolves uncertainties that could otherwise hinder recovery.\n4.4.2\nSuggested Refinements:\nClarity: Consider rephrasing the stages of knowledge with more em-\nphasis on the protocol mechanics and timing of messages. It could\nbe helpful to lay out the flow of the protocol in a diagram or a\nclearer timeline to illustrate the evolution of knowledge.\nLink Failures and Recovery: While the failure scenarios are well outlined,\nyou could further enhance the analysis by providing examples of\nreal-world failure cases and how TIKTYKTIK compares to other\nopen atomic ethernet\n32\nprotocols in handling these failures. For example, you could con-\ntrast how TCP handles packet loss versus how TIKTYKTIK’s multi-\nstep acknowledgment approach helps resolve knowledge gaps.\nMathematical Notation: If possible, you could introduce formal mathe-\nmatical notations to express the knowledge states. This would help\nreaders better grasp the protocol’s behavior in a more structured\nform.\n4.5\nFrom Shannon to Metcalfe and Beyond\n4.5.1\nShannon One-Way Channels\nFigure 4.1: Shannon One-Way Channels.\nShannon Channels are normally shown in one direction of flow –\nfrom Information source to Information Destination. Here we exploit\ntwo-way communication (signaling) Back to Back Channels with im-\nmediate (slice by slice) feedback. Then the equations tell us something\ninteresting about the symmetry of set reconciliation on both sides of the\nlink.\nWith back-to-back Shannon Channels, with (immediate) slice by\nslice feedback, we get Perfect Information Transfer (PIT) ?. We can\ntherefore dispense with Checksums, CRC’s, FEC or even Parity, be-\ncause the failure modes these EDC and ECC codes address are already\ncovered by PIT. This has two advantages:\n• The elimination of spatial redundancy on the wire makes the pack-\nets shorter\n• The need to calculate increasingly complex codes reduces computa-\ntion and energy dissipation on the link\nRedundancy is a poor crutch when as-\nsumptions about uniform probability\ndistributions are violated (which they al-\nmost always are in practice).\n4.5.2\nMetcalfe Half-Duplex\n4.5.3\nMetcalfe Half-Duplex Channel\n4.5.4\nFull-Duplex Bi-pipelined Shannon-Metcalfe Channel\nThe figure above is a simple, formally verifiable, mathematical descrip-\ntion, from API to bits on the wire (Shannon channel).\nopen atomic ethernet\n33\nFigure 4.2:\nThe original Metcalfe +\nBoggs Ethernet was a bus. A long ca-\nble where ‘stations’ were TAPs on the\nbus.\nThis meant that each station had\nto both listen, and transmit from teach\ntap. In this figure we show two indepen-\ndent streams of packets going in oppo-\nsite direction (forwardpropagation and\nbackpropagation) through a single half-\nduplex link\nFigure 4.3: Modern Ethernet Links are\nbidirectional; two sub-channels:\none for transmit, one for receive\nPCIe\nETHERNET TX\nETHERNET RX\nSACK 11\nSACK 10\nSACK 01\nSACK 00\nSACK 11\nSACK 10\nSACK 01\nSACK 00\nInformation\nKnowledge  \nSemantics \nSyntax\nRX SERDES\nTX SERDES\nRX SLICE 2\nRX SLICE 3-4\nRX SLICE 5–8\nTX SLICE 1\nTX SLICE 2\nTX SLICE 3-4\nTX SLICE 5–8\nRX SLICE 1\nTX SERDES\nRX SERDES\nTX SLICE 1\nRX SLICE 2\nRX SLICE 3-4\nRX SLICE 5–8\nRX SLICE 1\nRX SLICE 2\nRX SLICE 3-4\nRX SLICE 5–8\nAlice\nBob\nPCIe\nPCIe\nPCIe\nSACK 11\nSACK 10\nSACK 01\nSACK 00\nFigure\n4.4:\nComplete\nmodel:\nBi-\npipelined full duplex exchange of Æth-\nernet frames.\nComplete with internal\n\"Slice ACKnowledges\" (SACKs) – se-\nquenced with increasing common knowl-\nedge depth inside SerDes/FPGA\nopen atomic ethernet\n34\n4.6\nSlice Engine Design\n4.6.1\nTwo independent Metcalfe Channels (Max flow, no Interaction)\nPipelined, No interaction\nETHERNET TX\nETHERNET RX\nRX SERDES\nTX SERDES\nTX SERDES\nRX SERDES\nRX SLICE 1\nRX SLICE 2\nRX SLICE 3-4\nRX SLICE 5–8\nCOMPLETE\nTX SLICE 1\nRX SLICE 2\nRX SLICE 3-4\nRX SLICE 5–8\nBEGIN\nRECEIVE PIPELINE\nTRANSMIT PIPELINE\nTRANSMIT PIPELINE\nRECEIVE PIPELINE\nTX  SLICE 1\nTX SLICE 1\nTX  SLICE 2\nTX  SLICE 3-4\nTX SLICE 5–8\nBEGIN\nRX SLICE 2\nRX SLICE 3-4\nRX SLICE 5–8\nCOMPLETE\nTwo Independent One-Way Metcalfe Channels\nFigure 4.5: Two Independent Metcalfe\nChannels\n4.6.2\nInternal (SACK) Feedback on last slice\nFeedback signal on 8th slice of frame\nETHERNET TX\nETHERNET RX\nRX SERDES\nTX SERDES\nTX SERDES\nRX SERDES\nRX SLICE 1\nRX SLICE 2\nRX SLICE 3-4\nRX SLICE 5–8\nCOMPLETE\nTX SLICE 1\nRX SLICE 2\nRX SLICE 3-4\nRX SLICE 5–8\nBEGIN\nRX SLICE 1\nTX SLICE 1\nRX SLICE 2\nRX SLICE 3-4\nRX SLICE 5–8\nBEGIN\nRX SLICE 2\nRX SLICE 3-4\nRX SLICE 5–8\nCOMPLETE\nSACK8\nFigure 4.6: Feedback signal on slice 8\n4.6.3\nInternal (SACK) Feedback on first slice\nSee SACK description by Sahas ?\nFeedback signal on 1st slice of frame\nETHERNET TX\nETHERNET RX\nRX SERDES\nTX SERDES\nTX SERDES\nRX SERDES\nRX SLICE 1\nRX SLICE 2\nRX SLICE 3-4\nRX SLICE 5–8\nCOMPLETE\nTX SLICE 1\nRX SLICE 2\nRX SLICE 3-4\nRX SLICE 5–8\nBEGIN\nRX SLICE 1\nTX SLICE 1\nRX SLICE 2\nRX SLICE 3-4\nRX SLICE 5–8\nBEGIN\nRX SLICE 2\nRX SLICE 3-4\nRX SLICE 5–8\nCOMPLETE\nSACK1\nFigure 4.7: Feedback signal on slice 1\n4.7\nArchitectural Framework: Four Shannon-like\nLevels\nIn the proposal for subdividing a 64-byte packet into 8-byte slices, we\nintroduce partial acknowledgments (SACKs) at four (decrementing)\nboundaries (11, 10, 01, 00). Each of these points reveals an incremen-\ntally deeper level of the receiver’s certainty about the data, the hard-\nware, and the appropriate next step in the protocol. We can interpret\nopen atomic ethernet\n35\nthis progressive certainty in terms of four conceptual layers reminiscent\nof Shannon’s information theory, but extended to address knowledge,\nsemantics, and understanding. This layering describes how a receiver\n(e.g., the SmartNIC) transitions from raw incoming bits to meaningful\nmessages that can be handed off to the host processor.\nBack-to-Back (B2B) Shannon Channels\nare “Perfect Information Feedback” (PIF)\nas senders see their own transmitted\npacket returning back from the receiver\nand thus can detect channel errors. Thus\nmaking CRCs Checksums, Parity and\nFEC unnecessary. Similar to \"Perfect In-\nformation Feedback\" in: Norm Abram-\nson, “Packet switching with satellites,”\nNCC, 1973\n4.7.1\nLayer 1: Information (Surprisal)\nAt the first level, information refers to the direct \"yes/no\" answer to a\nquestion of interest: the arrival or non-arrival of bits, which Shannon\nfamously treated as the surprisal of a received symbol. At the SACK 00\nboundary, when the receiver detects the first 8-byte slice without error,\nit learns that the link is alive and that the data matches expectations\n(i.e., no immediate mismatch).\nThis is pure information because it\ndistinguishes the event \"we did receive slice #1 correctly\" from \"we did\nnot.\" The mutual information gained here confirms a working cable\nand a functional SerDes.\nAt this early stage, the question posed is binary: \"Did the hard-\nware see valid bits?\" The surprisal is that valid bits were received, as\nopposed to no signal or corrupted data.\n4.7.2\nLayer 2: Knowledge (Captured Information)\nThe second layer, knowledge, arises when the raw bits are stored or\ncaptured in a meaningful structure. This could be as simple as a recog-\nnized slice stored in buffer memory or a pipeline register. By the time\nthe second slice arrives, the receiver has captured more bits—16 bytes\nin total—and placed them into NIC-internal registers. It can then per-\nform further checks, such as alignment, partial CRC, or checking for\nexpected header fields. The SACK 01 confirms that the hardware not\nonly saw valid bits but also placed them in the correct buffer location.\nAt this point, the system has a partial understanding of the data.\nIt knows that the 16 bytes are recognized and safely stored, awaiting\ndeeper logic to interpret them.\n4.7.3\nLayer 3: Semantics (Meaning)\nThe third layer, semantics, involves the system deciding what the bits\nmean in terms of subsequent action. This layer determines which state\nmachine or processing path is relevant for the given data. At the SACK\n10 boundary, after 32 bytes have been received, the NIC has gathered\nenough information to partially decode the data. For example, it might\nbe able to determine which protocol or message type is indicated. The\nNIC can confirm that buffer slots or ring descriptors are available and\nthat the correct state machine is loaded (e.g., state machine A for small\ncontrol frames, or state machine B for streaming payloads).\nopen atomic ethernet\n36\nOnce the NIC signals SACK 10, the sender learns that the hardware\nhas found the data coherent enough to continue. The semantics are\nrecognized sufficiently to proceed without hazard. The receiver has\nnow moved from simply knowing the bits are correct (Layers 1 and\n2) to understanding how to proceed and which internal resources or\nstate machines to activate.\n4.7.4\nLayer 4: Understanding (Syntax)\nThe final layer, understanding, refers to the recognition that the mes-\nsage fits into a finite set of concepts or message types that the NIC\naccepts. This implies that the message has a correct syntax recognized\nby the hardware. At the SACK 11 boundary, which occurs when slices\n5–8 arrive, the full 64 bytes have been received and match a legitimate\nframe or message layout. The NIC is now ready to push the message\nonto the PCIe bus or an internal ring buffer for the host processor.\nAt this stage, the NIC has a full understanding of the message,\nknowing exactly how to finalize the packet, classify it, and pass it\nupstream for higher-level processing. No further layer-2 repairs are\nneeded, and the message is ready for the next step in the protocol.\n"
  },
  {
    "filename": "SPEC/Bandwidth works in Practice not in Theory.pdf",
    "content": "© 2025 Atomic Ethernet Industry Association (AEIA) — All Rights Reserved\nBandwidth Works in Practice, not in Theory\nSahas Munamala, Andy Helland, Varun Datta, Dean Gladish, Paul Borrill, DÆDÆLUS Research\nJune 8, 2025\nEthernet, for the last 5 decades, has operated under the assumption that reliability begins with TCP.\nThis has allowed network hardware to design failure modes of packet transmission into normal oper-\nation and sell it as bandwidth. There are more dimensions of throughput than raw link capacity, and\nmore to reliability than patching over losses with idempotent APIs, nonce tokens, and retry logic.\nThere is a simple fact: once the epistemic knowledge of an event is lost in the network, it is unrecov-\nerable by either sender or receiver. No amount of timeout-and-retry or fail-fast design principles can\nrecover the exactly-once event after it is lost. Distributed systems rely on exactly-once for correct-\nness, but commodity hardware built for modern Ethernet consistently violate token integrity. Only\na global, open, free standard can truly bridge the gap between Ethernet and proprietary reliable\nnetworks like Infiniband and Fibre Channel.\nIntroduction\nThe computer networking industry has been marking its progress\nby the theoretical maximum bandwidth of links. The exponential\nincrease of bits that fit on a 3 m copper cable make a latency argu-\nment by claiming the frame will arrive earlier because it transmits\nfaster. On point-to-point connections, this is true, based on the cur-\nrent definitions of bandwidth and latency. However, there is more\nto bandwidth than # of bits/second that makes it useful, and there’s\nmore nuance to latency that will stall distributed applications no\nmatter how fast the hardware gets.\nRound-trip interactions are a fundamental unit of computation,\nparticularly in distributed systems, networked computing, and inter-\nactive AI workflows. However, conventional networking thinking has\nplaced this as a feature of Layer 4, as an optional transport layer, and\nnot a fundamental method of networked communication. The result\nof this is TCP, where a Layer 4 protocol between endpoints negoti-\nates the bidirectional transmission of variable length messages on an\nunreliable network.\nThis architecture has led to a widespread fallacy: that faster links\nmean faster systems. In practice, modern distributed applications are\nnot limited by raw link capacity but by round trip latency, queuing\nbehavior, and contention across multiple hops. A 400 Gbps link does\nnot eliminate the propagation delay, backpressure effects, or failures\nthat cascade through switches, NIC buffers, and software stacks. As\na result, the marginal gains in link speed are often masked by tail-\nlatency outliers, especially in systems requiring synchronized state or\nbandwidth works in practice, not in theory\n2\nsequential coordination. The assumption that we can “outrun” these\ndelays with bandwidth ignores their non-linearity and compounding\neffect in real systems.\nHidden cost of Bandwidth-First\nRaw, one-way Bandwidth metrics alone fail to account for the cru-\ncial aspect of round-trip reliability – the guaranteed and verifiable\ntransfer of packets between nodes. Such guarantees require explicit\nhandshakes by the hardware to properly transfer ownership and\nresponsibility of each packet with the lowest possible latency. With-\nout these mechanisms, software interfaces cannot trust intermediate\nnodes to handle their tokens responsibly.\nIn contrast, bandwidth-maximizing designs focus primarily on\npushing bit streams at peak throughput. Their impressive bandwidth\nbenchmarks are typically achieved by sending large, uninterrupted\nbyte sequences that minimize overhead. These systems are engi-\nneered to drop packets during congestion, prioritizing throughput\nnumbers over the integrity or reliability of tokens.\nFigure 1: A infinite bandwidth pipe\nwith packet loss can still limit through-\nput of TCP flows.\nBW = MSS\nRTT · C\n√p\nMSS: max segment size\nRTT: round-trip time\nC: constant (1.22)\np: packet loss probability\nConsider a lossy link with infinite bandwidth, as illustrated in Fig-\nure 1. In this hypothetical, the bottleneck is not raw capacity but the\ntwin constraints of latency and packet loss. Since TCP relies on ac-\nknowledgments to regulate its sending rate, the time it takes to com-\nplete a round trip –RTT – becomes a limiting factor on throughput.\nAs shown by the Mathis equation1, throughput degrades proportion-\n1 Mathis, M., Semke, J., Mahdavi, J.,\nand Ott, T. The macroscopic behav-\nior of the tcp congestion avoidance\nalgorithm. ACM SIGCOMM Computer\nCommunication Review 27, 3 (July 1997),\n67–82\nally to the inverse of RTT and the square root of the loss probability.\nIn such regimes, increasing bandwidth alone does not improve per-\nformance; if anything, the absence of reliable round-trip feedback\nrenders the network incapable of sustaining high-throughput flows.\nEven in a system of perfect raw transmission capacity, epistemic un-\ncertainty introduced by loss and latency can strangle performance.\nRound trips are essential to any communication that requires cer-\ntainty, ordering, or acknowledgment.\nIn practical networks where congestion is a real and dynamic\nforce, TCP flows must adapt their behavior to avoid collapse. This\nadaptation is governed by Additive Increase/Multiplicative Decrease\n(AIMD) – a deceptively simple algorithm that allows each sender to\nprobe the available capacity of the network while reacting swiftly to\ncongestion signals. Each flow increases its sending window linearly\nover time, but upon detecting loss (interpreted as a sign of conges-\ntion), it slashes the rate multiplicatively. This feedback loop produces\na sawtooth pattern in throughput, enabling multiple flows to con-\nverge to a fair, stable sharing of the underlying path. Crucially, AIMD\nis fully decentralized and stateless beyond the endpoints. Yet, this\nbandwidth works in practice, not in theory\n3\nelegant self-regulation only functions when loss reflects congestion,\nand when RTT remains a trustworthy signal of delay. In networks\nwhere loss is stochastic or induced by buffer mismanagement, AIMD\nunderperforms or misbehaves 2 – but in its ideal regime, it is a mar-\n2 Gettys, J., and Nichols, K.\nBufferbloat: dark buffers in the in-\nternet. Commun. ACM 55, 1 (Jan. 2012),\n57–65\nvel of distributed equilibrium: each sender, optimizing selfishly,\ncontributes to global stability.\nPacket loss and network congestion represent more than ineffi-\nciency, they threaten the epistemic state of distributed systems. When\na packet is dropped due to congestion, the information it carried\nvanishes completely, erasing knowledge of the event it represented.\nThis loss isn’t just temporary. It’s fundamental and irreversible. With-\nout this information, no node or application can know if the packet\nis coming late, or not at all. Exactly-once semantics rely entirely\nupon preserving and transferring this epistemic state across nodes.\nFailures in handling epistemic state leads to inconsistency and grey\nfailures3. Thus, the hidden peril of the bandwidth-first approach\n3 Grey failures represent a class of\nfailure where events are partially\nknown or suspected, but never fully\nprovable\nemerges clearly: by optimizing purely for throughput at the expense\nof reliable delivery, one risks catastrophic losses in epistemic cer-\ntainty, fundamentally undermining the correctness and reliability of\ndistributed computation.\nClaude Shannon\nShannon showed us that redundancy is necessary to overcome noise,\nbut it doesn’t have to come in the form of retransmissions. It can\nemerge from structure, timing, flow control, and error-detecting\ncodes. In his landmark 1948 paper4, Shannon formalized the limits\n4 Shannon, C. E. A mathematical\ntheory of communication, 1948\nof communication under uncertainty, showing that any noisy channel\ncould achieve reliable transmission — not by eliminating noise, but\nby understanding and quantifying it, then embedding just enough\nredundancy to overcome it. This gave rise to the idea of channel\ncapacity: the maximum rate at which information can be sent over a\nnoisy medium with arbitrarily low error.\nHowever, Shannon’s theory is asymptotic. It assumes infinite mes-\nsage lengths and probabilistic decoding, which don’t cleanly map\nonto real-time systems with finite payloads, strict latency bounds,\nand diverse failure modes. In practice, the design of reliable commu-\nnication must balance redundancy with delay, error handling with\ntiming, and correctness with structure.\nCrucially, redundancy does not imply retransmission. A reliable\nsystem can suppress entropy not just by encoding messages, but by\nconstraining the channel. Deterministic protocols — like InfiniBand\nand Fibre Channel — ensure losslessness not through statistical error\ncorrection, but through strict flow control, bounded buffering, and\nbandwidth works in practice, not in theory\n4\nphysical acknowledgment paths. By guaranteeing that every bit is\neither delivered or backpressured, they narrow the range of possible\noutcomes. This reduces uncertainty without increasing retries — a\nform of reliability that aligns with Shannon’s vision but adapts it to\ninteractive, bounded-latency environments.\nTrue reliability, then, need not come at the cost of throughput.\nAccording to information theory, maximum capacity is achieved\nwhen redundancy is sufficient but minimal — just enough to defeat\nuncertainty. Lossless fabrics accomplish this through design, not\nbrute force. They do not fight entropy after the fact; they prevent\nit from entering the system at all. The result is not just efficiency\n— it’s epistemic fidelity: a network where knowledge, once sent, is\npreserved without compromise.\nFibre Channel\nFibre Channel was designed as a highly reliable, lossless transmission\nprotocol, with robust flow control and acknowledgment mechanisms\nfundamentally built in. It uses a credit-based system where each re-\nceiver controls the transmission rate through buffer credits, so the\nsender can only transmit frames when the receiver is ready, elimi-\nnating overruns and ensuring lossless delivery. Acknowledgments,\nboth implicit and explicit, confirm receipt of frames, while any lost or\ncorrupted frames can be detected via CRC checks and retransmitted\nusing control frames. These mechanisms work end-to-end and at ev-\nery switch, guaranteeing in-order, reliable delivery across the entire\nfabric. As a result, Fibre Channel became the backbone of enterprise\nstorage area networks (SAN), bringing mainframe-class reliability\nand flow control to open systems and enabling storage area networks\nto scale without the risk of dropped or unordered data.\nFibre Channel hardware was much more expensive than Ether-\nnet equivalents, sometimes by an order of magnitude. Even mid-tier\nSAN switches could cost tens of thousands of dollars. Fiber Channel\nalso required dedicated expertise. Configuration, zoning, and trou-\nbleshooting were very different from the familiar world of Ethernet\nnetworking, making skilled staff scarce and expensive.\nAs Ethernet bandwidth increased from 1/10/25/40/100Gbps and\nbeyond, its price dropped and its reliability improved. Features like\niSCSI, FCoE (Fibre Channel over Ethernet), and later, NVMe-over-\nFabrics let storage ride over ordinary Ethernet with performance and\nreliability approaching Fibre Channel for most workloads. Ether-\nnet was already everywhere: data, management, and now storage\ncould be unified onto one network—saving hardware, cabling, and\noperational overhead.\nbandwidth works in practice, not in theory\n5\nInfiniBand\nInfiniBand5, by fixing the message structure and introducing deter-\n5 InfiniBand guarantees lossless trans-\nmission even under congestion by\nusing credit-based flow control and\nhardware backpressure. Instead of\ndropping packets, it prevents senders\nfrom overrunning buffers, ensuring\nreliable delivery without retries.\nministic flow control, turns a noisy, uncertain channel into a nearly\nnoiseless, deterministic pipeline, analogous to a physical circuit.\nFixed-size packets enable efficient buffer management, determinis-\ntic flow control, and cut-through switching— critical for maintaining\nlossless transmission. From a Shannon theory perspective, fixed\npacket sizes simplify the encoding and decoding process by reducing\nentropy per symbol and minimizing variance in transmission time,\nwhich stabilizes throughput near channel capacity.\nInfiniBand offered clear technical advantages, including guaran-\nteed lossless delivery, extremely low latency through cut-through\nswitching, and efficient memory transfers via RDMA. However, it\nfailed to achieve mainstream adoption beyond high-performance\ncomputing and certain enterprise deployments. This outcome re-\nsulted from a combination of economic, architectural, and ecosystem\nrealities. InfiniBand required specialized hardware, tight coupling,\nand strict credit-based flow control, making it difficult to scale and\nintegrate in diverse environments. While these features served sci-\nentific and tightly synchronized workloads well, they were overengi-\nneered and prohibitively expensive for the broader datacenter and\ncloud markets.\nThe acquisition of Mellanox6 by NVIDIA in 2020 was a significant\n6 Mellanox was the steward and pri-\nmary driver of InfiniBand technology. It\nplayed a central role in both the devel-\nopment and commercialization of the\nInfiniBand standard, acting as the lead\nimplementer and key evangelist within\nthe HPC and low-latency networking\ncommunity.\nmove that sent ripples through Silicon Valley, though it did not cause\na dramatic upheaval in the traditional sense. It was less of a shock-\nwave and more of a strategic signal—one that made clear NVIDIA’s\nambitions to move beyond GPUs and into the heart of data center\ninfrastructure.\nAI training benefits enormously from lossless networking, but\nit’s not because the algorithms require it for correctness. Rather, it’s\nabout efficiency, scale, and determinism in distributed computation.\nReliable networking seamlessly, and near-losslessly, extends GPU\nmemory space across multiple GPUs, allowing compute pods to\nshare memory like a single fast memory pool.\nEthernet Workarounds\nUltimately, Fibre Channel and InfiniBand are specialized solutions\nin a world that prioritizes openness, cost efficiency, and broad adop-\ntion. Rather than merge with a proprietary technology, the Ethernet\necosystem chose to adapt and absorb its most useful features. The\nresult was not technical defeat but strategic obsolescence.\nEthernet embraces simplicity, flexibility, and continuous evolution.\nbandwidth works in practice, not in theory\n6\nIts early limitations were addressed through layered improvements\nsuch as Data Center Bridging, Priority Flow Control, and RDMA\nover Converged Ethernet. These additions made Ethernet “good\nenough” for many high-throughput, low-latency applications without\nabandoning compatibility with legacy systems. Each of these en-\nhancements represents a patch on top of a fundamentally best-effort,\nlossy protocol stack. While they reduce packet drops in controlled\nenvironments, their guarantees are neither universal nor absolute.\nAt their core, these Ethernet extensions still operate atop the IP\nprotocol, whose very design assumes and accepts the possibility of\nloss, reordering, and duplication. Reliability is punted up the stack to\ntransport protocols like TCP, or to the application layer, where error\ndetection, retransmission, and exactly-once semantics are laboriously\nreconstructed. As a result, the burden of handling ambiguity, uncer-\ntainty, and failure is pushed to the endpoints and the software, rather\nthan being enforced in the network fabric itself.\nThis architecture cannot escape its origins. Any guarantee of reli-\nability or determinism is inherently probabilistic and contingent on\nnetwork conditions, traffic patterns, and careful configuration. In the\npresence of congestion, misconfiguration, or adversarial workloads,\nthese workarounds can break down, leading to unpredictable loss,\njitter, and transient failures – exactly the failure modes that storage\nand distributed systems sought to avoid by adopting Fibre Channel\nor InfiniBand in the first place.\nThus, the quest to retrofit lossless, reliable behavior onto a protocol\nstack designed for “good enough” connectivity results in a system\nthat is complex, fragile, and never truly deterministic. Until the foun-\ndational assumption of best-effort delivery is replaced with provable,\nin-fabric reliability, Ethernet’s workarounds will always be at risk of\nfailure, and the promise of robust, exactly-once distributed computa-\ntion will remain out of reach.\nAre Reliable Networks still Niche Today?\nApplications require predictable and deterministic behavior from\nthe networks they rely upon. Every layer – from API down to the\nphysical transmission of bits on the wire and back – must preserve\nthe semantics of exactly-once requests.\nToday, applications are forced to tolerate all forms of network un-\nreliability in their communication because lossless, deterministic net-\nworks are expensive, proprietary, and specialized. However, modern\napplications from distributed microservices, replicated databases,\nrobotics, and automation, are fundamentally dependent on pre-\ndictable, exactly-once semantics. These applications crave reliability\nbandwidth works in practice, not in theory\n7\nbecause it vastly simplifies their internal logic, improves consistency\nguarantees, and significantly reduces the burden of handling retries,\nduplicates, and partial failures.\nWith easy and open access to a fully verified, open-source stan-\ndard for reliable communication, applications can trust their in-\nfrastructure implicitly, dramatically simplifying their design and\nenhancing operational robustness. The availability of such open, re-\nliable standards democratizes technology previously reserved for\nniche, high-budget environments, enabling widespread adoption and\nfundamentally reshaping expectations around distributed system\nreliability.\nLocal Only Control\n• Software Defined Networking provides applications with network-\nawareness by dynamically through centralized controllers, how-\never a centralized control system suffers from the same exactly-\nonce semantic issues as any other application\n• It is impossible to create a gods-eye-view entirely reactive system\nthat avoids network congestion entirely. Instead, state of the art\nSoftware Defined Networking will always be one-step behind\ncongestion\n• Instead, fully verifiable algorithms like spanning trees, failure\nrouting, and healing must be done with local-only information\nNew Metrics for Networks\n• New Local-First metrics must be created to measure network per-\nformance. Reliance on one-way bandwidth performance does not\ncharacterize network reliability, resilience, or performance.\n• Interaction Latency – time (ns) for a round trip acknowledgement\n(hop-by-hop)\n• Round Trip Bandwidth – # payload bits per second of acknowl-\nedged data bits (ignores headers)\n• Resilience Metric for Constrained-Valency Networks via Graph\nLaplacian. Classically Edge Connectivity (minimum number of\nedges whose removal disconnects G), and Vertex Connectivity\n(minimum number of vertices whose removal disconnects G) cap-\nture global connectivity\nbandwidth works in practice, not in theory\n8\nReferences\n[1] Gettys, J., and Nichols, K. Bufferbloat: dark buffers in the\ninternet. Commun. ACM 55, 1 (Jan. 2012), 57–65.\n[2] Mathis, M., Semke, J., Mahdavi, J., and Ott, T. The macroscopic\nbehavior of the tcp congestion avoidance algorithm. ACM SIG-\nCOMM Computer Communication Review 27, 3 (July 1997), 67–82.\n[3] Shannon, C. E. A mathematical theory of communication, 1948.\n"
  }
]